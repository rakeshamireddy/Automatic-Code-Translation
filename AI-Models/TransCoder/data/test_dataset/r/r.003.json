{ "repo_name": "SurajGupta/r-source", "ref": "refs/heads/master", "path": "src/library/methods/R/ClassUnion.R", "content": "#  File src/library/methods/R/ClassUnion.R\n#  Part of the R package, https://www.R-project.org\n#\n#  Copyright (C) 1995-2012 The R Core Team\n#\n#  This program is free software; you can redistribute it and/or modify\n#  it under the terms of the GNU General Public License as published by\n#  the Free Software Foundation; either version 2 of the License, or\n#  (at your option) any later version.\n#\n#  This program is distributed in the hope that it will be useful,\n#  but WITHOUT ANY WARRANTY; without even the implied warranty of\n#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#  GNU General Public License for more details.\n#\n#  A copy of the GNU General Public License is available at\n#  https://www.R-project.org/Licenses/\n\n.InitClassUnion <- function(where) {\n    setClass(\"ClassUnionRepresentation\",  \"classRepresentation\",\n             validity =function(object) {\n                 if(identical(object@virtual, TRUE) && length(object@slots)==0 &&\n                    is.null(object@prototype))\n                     TRUE\n                 else\n                     \"Class must be an empty virtual class with NULL prototype\"\n             }, where = where)\n    ## some classes in methods package are unions--now they can be officially\n    setClassUnion(\"OptionalFunction\", c(\"function\", \"NULL\"), where)\n    setClassUnion(\"PossibleMethod\", c(\"function\", \"MethodDefinition\"), where)\n    clList <- c(\"ClassUnionRepresentation\", \"OptionalFunction\",\n                \"PossibleMethod\")\n    assign(\".SealedClasses\", c(get(\".SealedClasses\", where), clList), where)\n}\n\nsetClassUnion <- function(name, members = character(), where = topenv(parent.frame())) {\n    if(length(members)>0) {\n        membersDefined <- sapply(members, isClass, where = as.environment(where))\n        if(!all(membersDefined))\n            stop(gettextf(\"the member classes must be defined: not true of %s\",\n                          paste(.dQ(as(members[!membersDefined], \"character\")), collapse=\", \")), domain = NA)\n    }\n    def <- new(\"ClassUnionRepresentation\",\n               makeClassRepresentation(name, package = getPackageName(where), where = where))\n    prev <- getClassDef(name, where = where)\n    value <- setClass(name, def, where = where)\n    failed <- character()\n    ## the prototype of the union will be from the first non-virtual\n    ## subclass, except that we prefer NULL if \"NULL\" is a subclass\n    hasNull <- match(\"NULL\", members, 0)\n    if(hasNull)\n        members <- c(\"NULL\", members[-hasNull])\n    for(what in members) {\n        if(is(try(setIs(what, name, where = where)), \"try-error\")) {\n            if(!is.character(what))\n                what <- getClass(what, TRUE, where)@className\n            failed <- c(failed, what)\n        }\n    }\n    if(length(failed)>0) {\n        if(is.null(prev))\n            try(removeClass(name, where = where))\n        else\n            try(setClass(name, prev, where = where))\n        stop(gettextf(\"unable to create union class:  could not set members %s\",\n                      paste(.dQ(failed), collapse=\", \")), domain = NA)\n    }\n    invisible(value)\n}\n\nisClassUnion <- function(Class) {\n    ## test the class DEFINITION for representing a union\n    if(is.character(Class))\n        Class <- getClass(Class, TRUE) # the real def. or a dummy\n    extends(class(Class), \"ClassUnionRepresentation\")\n}\n" }
{ "repo_name": "SurajGupta/r-source", "ref": "refs/heads/master", "path": "src/library/utils/tests/completion.R", "content": "\n## test some typical completion attempts\n\ntestLine <- function(line, cursor = nchar(line))\n{\n    str(utils:::.win32consoleCompletion(line, cursor))\n}\n\ntestLine(\"\")\n\ntestLine(\"lib\")\ntestLine(\"data(\")\ntestLine(\"data(US\")\ntestLine(\"data(US\", 3)\n\ntestLine(\"?INS\")\n\ntestLine(\"utils::data\")\ntestLine(\"utils:::.show_help_on_topic_\")\ntestLine(\"utils::.show_help_on_topic_\")\n\ntestLine(\"update(\")\n\ntestLine(\"version$m\")\ntestLine(\"nchar(version[\")\n\n\n\ntestLine(\"method?coe\")\ntestLine(\"?coe\")\ntestLine(\"?\\\"coerce,AN\")\ntestLine(\"method?\\\"coerce,AN\")\n\n\n## testLine(\"\")\n## testLine(\"\")\n## testLine(\"\")\n" }
{ "repo_name": "SurajGupta/r-source", "ref": "refs/heads/master", "path": "src/library/graphics/R/curve.R", "content": "#  File src/library/graphics/R/curve.R\n#  Part of the R package, https://www.R-project.org\n#\n#  Copyright (C) 1995-2012 The R Core Team\n#\n#  This program is free software; you can redistribute it and/or modify\n#  it under the terms of the GNU General Public License as published by\n#  the Free Software Foundation; either version 2 of the License, or\n#  (at your option) any later version.\n#\n#  This program is distributed in the hope that it will be useful,\n#  but WITHOUT ANY WARRANTY; without even the implied warranty of\n#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#  GNU General Public License for more details.\n#\n#  A copy of the GNU General Public License is available at\n#  https://www.R-project.org/Licenses/\n\ncurve <- function(expr, from = NULL, to = NULL, n = 101, add = FALSE,\n                  type = \"l\", xname = \"x\", xlab = xname,\n                  ylab = NULL, log = NULL, xlim = NULL, ...)\n{\n    sexpr <- substitute(expr)\n    if (is.name(sexpr)) {\n        ## beter than parse() !\n        expr <- call(as.character(sexpr), as.name(xname))\n    } else {\n\tif ( !( (is.call(sexpr) || is.expression(sexpr)) &&\n              xname %in% all.vars(sexpr) ))\n\t    stop(gettextf(\"'expr' must be a function, or a call or an expression containing '%s'\", xname), domain = NA)\n\texpr <- sexpr\n    }\n    if (dev.cur() == 1L && !identical(add, FALSE)) {\n        warning(\"'add' will be ignored as there is no existing plot\")\n        add <- FALSE\n    }\n    addF <- identical(add, FALSE)\n    if (is.null(ylab)) ylab <- deparse(expr)\n    if (is.null(from) || is.null(to)) {\n        xl <- if (!is.null(xlim)) xlim\n        else if (!addF) {\n            ## determine xlim of current plot.\n            pu <- par(\"usr\")[1L:2L]\n            if (par(\"xaxs\") == \"r\") pu <- extendrange(pu, f = -1/27)\n            if (par(\"xlog\")) 10^pu else pu\n       } else c(0, 1) # was c(1/27, 26/27) in R < 2.14.0\n        if (is.null(from)) from <- xl[1L]\n        if (is.null(to)) to <- xl[2L]\n    }\n    lg <- if (length(log)) log else if (!addF && par(\"xlog\")) \"x\" else \"\"\n    if (length(lg) == 0) lg <- \"\"\n    if (grepl(\"x\", lg, fixed = TRUE)) {\n        if (from <= 0 || to <= 0)\n            stop(\"'from' and 'to' must be > 0 with log=\\\"x\\\"\")\n        x <- exp(seq.int(log(from), log(to), length.out = n))\n    } else x <- seq.int(from, to, length.out = n)\n    ll <- list(x = x); names(ll) <- xname\n    y <- eval(expr, envir = ll, enclos = parent.frame())\n    if (length(y) != length(x))\n        stop(\"'expr' did not evaluate to an object of length 'n'\")\n    if (isTRUE(add))\n\tlines(x = x, y = y, type = type, ...)\n    else\n        plot(x = x, y = y, type = type, xlab = xlab, ylab = ylab,\n             xlim = xlim, log = lg, ...)\n    invisible(list(x = x, y = y))\n}\n" }
{ "repo_name": "SurajGupta/r-source", "ref": "refs/heads/master", "path": "tests/reg-plot-latin1.R", "content": "pdf(file = \"reg-plot-latin1.pdf\", encoding = \"ISOLatin1\",\n    width = 7, height = 7, paper = \"a4r\", compress = FALSE)\nlibrary(graphics) # to be sure\nexample(text)     # has examples that need to he plotted in latin-1\nq(\"no\")\n" }
{ "repo_name": "SurajGupta/r-source", "ref": "refs/heads/master", "path": "src/library/base/R/lapply.R", "content": "#  File src/library/base/R/lapply.R\n#  Part of the R package, https://www.R-project.org\n#\n#  Copyright (C) 1995-2012 The R Core Team\n#\n#  This program is free software; you can redistribute it and/or modify\n#  it under the terms of the GNU General Public License as published by\n#  the Free Software Foundation; either version 2 of the License, or\n#  (at your option) any later version.\n#\n#  This program is distributed in the hope that it will be useful,\n#  but WITHOUT ANY WARRANTY; without even the implied warranty of\n#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#  GNU General Public License for more details.\n#\n#  A copy of the GNU General Public License is available at\n#  https://www.R-project.org/Licenses/\n\nlapply <- function (X, FUN, ...)\n{\n    FUN <- match.fun(FUN)\n    ## internal code handles all vector types, including expressions\n    ## However, it would be OK to have attributes which is.vector\n    ## disallows.\n    if(!is.vector(X) || is.object(X)) X <- as.list(X)\n    ## Note ... is not passed down.  Rather the internal code\n    ## evaluates FUN(X[i], ...) in the frame of this function\n    .Internal(lapply(X, FUN))\n}\n\nrapply <-\n    function(object, f, classes = \"ANY\", deflt = NULL,\n             how = c(\"unlist\", \"replace\", \"list\"), ...)\n{\n    if(typeof(object) != \"list\")\n        stop(\"'object' must be a list\")\n    how <- match.arg(how)\n    res <- .Internal(rapply(object, f, classes, deflt, how))\n    if(how == \"unlist\") unlist(res, recursive = TRUE) else res\n}\n" }
{ "repo_name": "SurajGupta/r-source", "ref": "refs/heads/master", "path": "src/library/stats/R/mcnemar.test.R", "content": "#  File src/library/stats/R/mcnemar.test.R\n#  Part of the R package, https://www.R-project.org\n#\n#  Copyright (C) 1995-2013 The R Core Team\n#\n#  This program is free software; you can redistribute it and/or modify\n#  it under the terms of the GNU General Public License as published by\n#  the Free Software Foundation; either version 2 of the License, or\n#  (at your option) any later version.\n#\n#  This program is distributed in the hope that it will be useful,\n#  but WITHOUT ANY WARRANTY; without even the implied warranty of\n#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#  GNU General Public License for more details.\n#\n#  A copy of the GNU General Public License is available at\n#  https://www.R-project.org/Licenses/\n\nmcnemar.test <- function(x, y = NULL, correct = TRUE)\n{\n    if (is.matrix(x)) {\n        r <- nrow(x)\n        if ((r < 2) || (ncol (x) != r))\n            stop(\"'x' must be square with at least two rows and columns\")\n        if (any(x < 0) || anyNA(x))\n            stop(\"all entries of 'x' must be nonnegative and finite\")\n        DNAME <- deparse(substitute(x))\n    }\n    else {\n        if (is.null(y))\n            stop(\"if 'x' is not a matrix, 'y' must be given\")\n        if (length(x) != length(y))\n            stop(\"'x' and 'y' must have the same length\")\n        DNAME <- paste(deparse(substitute(x)), \"and\",\n                       deparse(substitute(y)))\n        OK <- complete.cases(x, y)\n        x <- as.factor(x[OK])\n        y <- as.factor(y[OK])\n        r <- nlevels(x)\n        if ((r < 2) || (nlevels(y) != r))\n            stop(\"'x' and 'y' must have the same number of levels (minimum 2)\")\n        x <- table(x, y)\n    }\n\n    PARAMETER <- r * (r-1) / 2\n    METHOD <- \"McNemar's Chi-squared test\"\n\n    if (correct && (r == 2) && any(x - t(x) != 0)) {\n        y <- (abs(x - t(x)) - 1)\n        METHOD <- paste(METHOD, \"with continuity correction\")\n    }\n    else\n        y <- x - t(x)\n    x <- x + t(x)\n\n    STATISTIC <- sum(y[upper.tri(x)]^2 / x[upper.tri(x)])\n    PVAL <- pchisq(STATISTIC, PARAMETER, lower.tail = FALSE)\n    names(STATISTIC) <- \"McNemar's chi-squared\"\n    names(PARAMETER) <- \"df\"\n\n    RVAL <- list(statistic = STATISTIC,\n                 parameter = PARAMETER,\n                 p.value = PVAL,\n                 method = METHOD,\n                 data.name = DNAME)\n    class(RVAL) <- \"htest\"\n    return(RVAL)\n}\n" }
{ "repo_name": "SurajGupta/r-source", "ref": "refs/heads/master", "path": "src/library/base/R/outer.R", "content": "#  File src/library/base/R/outer.R\n#  Part of the R package, https://www.R-project.org\n#\n#  Copyright (C) 1995-2013 The R Core Team\n#\n#  This program is free software; you can redistribute it and/or modify\n#  it under the terms of the GNU General Public License as published by\n#  the Free Software Foundation; either version 2 of the License, or\n#  (at your option) any later version.\n#\n#  This program is distributed in the hope that it will be useful,\n#  but WITHOUT ANY WARRANTY; without even the implied warranty of\n#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#  GNU General Public License for more details.\n#\n#  A copy of the GNU General Public License is available at\n#  https://www.R-project.org/Licenses/\n\nouter <- function (X, Y, FUN = \"*\", ...)\n{\n    if(is.array(X)) {\n        dX <- dim(X)\n        nx <- dimnames(X)\n        no.nx <- is.null(nx)\n    } else { # a vector\n        dX <- length(X)  # cannot be long, as form a matrix below\n        no.nx <- is.null(names(X))\n        if(!no.nx) nx <- list(names(X))\n    }\n    if(is.array(Y)) {\n        dY <- dim(Y)\n        ny <- dimnames(Y)\n        no.ny <- is.null(ny)\n    } else { # a vector\n        dY <- length(Y)\n        no.ny <- is.null(names(Y))\n        if(!no.ny) ny <- list(names(Y))\n    }\n    if (is.character(FUN) && FUN==\"*\") {\n        if(!missing(...)) stop('using ... with FUN = \"*\" is an error')\n        # this is for numeric vectors, so dropping attributes is OK\n        robj <- as.vector(X) %*% t(as.vector(Y))\n        dim(robj) <- c(dX, dY)\n    } else {\n        FUN <- match.fun(FUN)\n        ## Y may have a class, so don't use rep.int\n        Y <- rep(Y, rep.int(length(X), length(Y)))\n        ##  length.out is not an argument of the generic rep()\n        ##  X <- rep(X, length.out = length(Y))\n        if(length(X))\n            X <- rep(X, times = ceiling(length(Y)/length(X)))\n        robj <- FUN(X, Y, ...)\n        dim(robj) <- c(dX, dY) # careful not to lose class here\n    }\n    ## no dimnames if both don't have ..\n    if(!(no.nx && no.ny)) {\n\tif(no.nx) nx <- vector(\"list\", length(dX)) else\n\tif(no.ny) ny <- vector(\"list\", length(dY))\n\tdimnames(robj) <- c(nx, ny)\n    }\n    robj\n}\n\n## Binary operator, hence don't simply do \"%o%\" <- outer.\n`%o%` <- function(X, Y) outer(X, Y)\n" }
{ "repo_name": "SurajGupta/r-source", "ref": "refs/heads/master", "path": "src/library/stats/R/p.adjust.R", "content": "#  File src/library/stats/R/p.adjust.R\n#  Part of the R package, https://www.R-project.org\n#\n#  Copyright (C) 1995-2012 The R Core Team\n#\n#  This program is free software; you can redistribute it and/or modify\n#  it under the terms of the GNU General Public License as published by\n#  the Free Software Foundation; either version 2 of the License, or\n#  (at your option) any later version.\n#\n#  This program is distributed in the hope that it will be useful,\n#  but WITHOUT ANY WARRANTY; without even the implied warranty of\n#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#  GNU General Public License for more details.\n#\n#  A copy of the GNU General Public License is available at\n#  https://www.R-project.org/Licenses/\n\np.adjust.methods <-\n    c(\"holm\", \"hochberg\", \"hommel\", \"bonferroni\", \"BH\", \"BY\", \"fdr\", \"none\")\n\np.adjust <- function(p, method = p.adjust.methods, n = length(p))\n{\n    ## Methods 'Hommel', 'BH', 'BY' and speed improvements\n    ## contributed by Gordon Smyth\n    method <- match.arg(method)\n    if(method == \"fdr\") method <- \"BH\"\t# back compatibility\n    nm <- names(p)\n    p <- as.numeric(p)\n    p0 <- setNames(p, nm)\n    if(all(nna <- !is.na(p))) nna <- TRUE\n    p <- p[nna]\n    lp <- length(p)\n    stopifnot(n >= lp)\n    if (n <= 1) return(p0)\n    if (n == 2 && method == \"hommel\") method <- \"hochberg\"\n\n    p0[nna] <-\n\tswitch(method,\n\t       bonferroni = pmin(1, n * p),\n\t       holm = {\n\t\t   i <- seq_len(lp)\n\t\t   o <- order(p)\n\t\t   ro <- order(o)\n\t\t   pmin(1, cummax( (n - i + 1L) * p[o] ))[ro]\n\t       },\n\t       hommel = { ## needs n-1 >= 2 in for() below\n\t\t   if(n > lp) p <- c(p, rep.int(1, n-lp))\n\t\t   i <- seq_len(n)\n\t\t   o <- order(p)\n\t\t   p <- p[o]\n\t\t   ro <- order(o)\n\t\t   q <- pa <- rep.int( min(n*p/i), n)\n\t\t   for (j in (n-1):2) {\n\t\t       ij <- seq_len(n-j+1)\n\t\t       i2 <- (n-j+2):n\n\t\t       q1 <- min(j*p[i2]/(2:j))\n\t\t       q[ij] <- pmin(j*p[ij], q1)\n\t\t       q[i2] <- q[n-j+1]\n\t\t       pa <- pmax(pa,q)\n\t\t   }\n\t\t   pmax(pa,p)[if(lp < n) ro[1:lp] else ro]\n\t       },\n\t       hochberg = {\n\t\t   i <- lp:1L\n\t\t   o <- order(p, decreasing = TRUE)\n\t\t   ro <- order(o)\n\t\t   pmin(1, cummin( (n - i + 1L) * p[o] ))[ro]\n\t       },\n\t       BH = {\n\t\t   i <- lp:1L\n\t\t   o <- order(p, decreasing = TRUE)\n\t\t   ro <- order(o)\n\t\t   pmin(1, cummin( n / i * p[o] ))[ro]\n\t       },\n\t       BY = {\n\t\t   i <- lp:1L\n\t\t   o <- order(p, decreasing = TRUE)\n\t\t   ro <- order(o)\n\t\t   q <- sum(1L/(1L:n))\n\t\t   pmin(1, cummin(q * n / i * p[o]))[ro]\n\t       },\n\t       none = p)\n    p0\n}\n" }
{ "repo_name": "SurajGupta/r-source", "ref": "refs/heads/master", "path": "src/library/base/R/paste.R", "content": "#  File src/library/base/R/paste.R\n#  Part of the R package, https://www.R-project.org\n#\n#  Copyright (C) 1995-2012 The R Core Team\n#\n#  This program is free software; you can redistribute it and/or modify\n#  it under the terms of the GNU General Public License as published by\n#  the Free Software Foundation; either version 2 of the License, or\n#  (at your option) any later version.\n#\n#  This program is distributed in the hope that it will be useful,\n#  but WITHOUT ANY WARRANTY; without even the implied warranty of\n#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#  GNU General Public License for more details.\n#\n#  A copy of the GNU General Public License is available at\n#  https://www.R-project.org/Licenses/\n\npaste <- function (..., sep = \" \", collapse = NULL)\n    .Internal(paste(list(...), sep, collapse))\npaste0 <- function(..., collapse = NULL)\n    .Internal(paste0(list(...), collapse))\n\n##=== Could we extend  paste(.) to (optionally) accept a\n##    2-vector for collapse ?\t With the following functionality\n\n##- paste.extra <- function(r, collapse=c(\", \",\" and \")) {\n##-\t    n <- length(r)\n##-\t    if(n <= 1) paste(r)\n##-\t    else\n##-\t      paste(paste(r[-n],collapse=collapse[1L]),\n##-\t\t    r[n], sep=collapse[min(2,length(collapse))])\n##- }\n" }
{ "repo_name": "jimthompson5802/kaggle-BNP-Paribas", "ref": "refs/heads/master", "path": "src/L0_xgb21/train_model.R", "content": "###\n# training skeleton\n###\n\nlibrary(data.table)\nlibrary(caret)\n# add any model specific package library commands\nlibrary(xgboost)\n\n# set working directory\nWORK.DIR <- \"./src/L0_xgb21\"  # modify to specify directory to contain model artififacts\n\n# Common Functions and Global variables\nsource(\"./src/CommonFunctions.R\")\n\n# import model configuration parameters\nsource(paste0(WORK.DIR,\"/model_parameters.R\"))\n\nMODEL.COMMENT <- \"Build Model\"\n\n\n# model specific training parameter\nCARET.TRAIN.CTRL <- trainControl(method=\"none\",\n                                 number=5,\n                                 repeats=1,\n                                 verboseIter=FALSE,\n                                 classProbs=TRUE,\n                                 summaryFunction=caretLogLossSummary)\n\nCARET.TRAIN.OTHER.PARMS <- list(trControl=CARET.TRAIN.CTRL,\n                            maximize=FALSE,\n                           tuneGrid=CARET.TUNE.GRID,\n                           tuneLength=5,\n                           metric=\"LogLoss\")\n\n\n\n# amount of data to train\nFRACTION.TRAIN.DATA <- 1.0\n\n# force recording model flag\nFORCE_RECORDING_MODEL <- TRUE\n\n# get training data\ntrain.df <- fread(paste0(DATA.DIR,\"/train.csv\"))\nsetkey(train.raw,ID)\n\nif (FRACTION.TRAIN.DATA != 1.0) {\n    # extract subset for inital training\n    set.seed(29)\n    idx <- createDataPartition(train.df$target,p=FRACTION.TRAIN.DATA,list=FALSE)\n    train.df <- train.df[idx,]\n}\n\n# prepare data for training\ntrain.data <- PREPARE.MODEL.DATA(train.df)\n\nlibrary(doMC)\nregisterDoMC(cores = 6)\n\n# library(doSNOW)\n# cl <- makeCluster(5,type=\"SOCK\")\n# registerDoSNOW(cl)\n# clusterExport(cl,list(\"logLossEval\"))\n\n# train the model\nSys.time()\nset.seed(825)\n\ntime.data <- system.time(mdl.fit <- do.call(train,c(list(x=train.data$predictors,\n                                                         y=train.data$response),\n                                                    CARET.TRAIN.PARMS,\n                                                    MODEL.SPECIFIC.PARMS,\n                                                    CARET.TRAIN.OTHER.PARMS)))\n\ntime.data\nmdl.fit\n# stopCluster(cl)\n\ncat(\"saving...\\n\")\ndate.time <- as.character(Sys.time())\nfile.name <- paste0(\"model_\",CARET.TRAIN.PARMS$method,\"_\",date.time[last.idx],\".RData\")\nfile.name <- gsub(\" \",\"_\",file.name)\nfile.name <- gsub(\":\",\"_\",file.name)\n\nsave(mdl.fit,PREPARE.MODEL.DATA,file=paste0(WORK.DIR,\"/\",file.name))\n\n# estalish pointer to current model\nwriteLines(file.name,paste0(WORK.DIR,\"/this_model\"))\n\n\n\n\n" } 
{ "repo_name": "jimthompson5802/kaggle-BNP-Paribas", "ref": "refs/heads/master", "path": "src/L0_xtc31/train_model.R", "content": "###\n# training skeleton\n###\n\nlibrary(data.table)\nlibrary(caret)\n# add any model specific package library commands\n\n\n# set working directory\nWORK.DIR <- \"./src/L0_xtc31\"  # modify to specify directory to contain model artififacts\n\n# Common Functions and Global variables\nsource(\"./src/CommonFunctions.R\")\n\n# import model configuration parameters\nsource(paste0(WORK.DIR,\"/model_parameters.R\"))\n\n# import model configuration parameters\nsource(paste0(WORK.DIR,\"/model_parameters.R\"))\n\nMODEL.COMMENT <- \"K-Fold, Build Model\"\n\n\n# amount of data to train\nFRACTION.TRAIN.DATA <- 1.0\n\n# force recording model flag\nFORCE_RECORDING_MODEL <- FALSE\n\n# get training data\ntrain.df <- fread(paste0(DATA.DIR,\"/train.csv\"))\nsetkey(train.df,ID)\n\nif (FRACTION.TRAIN.DATA != 1.0) {\n    # extract subset for inital training\n    set.seed(29)\n    idx <- createDataPartition(train.df$target,p=FRACTION.TRAIN.DATA,list=FALSE)\n    train.df <- train.df[idx,]\n}\n\n# prepare data for training\ntrain.data <- PREPARE.MODEL.DATA(train.df)\n\n# save prepared training data for Python function\n# put response as first column in data set\nwrite.table(cbind(response=train.data$response,train.data$predictors),\n            file=paste0(WORK.DIR,\"/py_train.tsv\"),row.names = FALSE,\n            sep=\"\\t\")\n\n\n# invoke Python training model\npython.train.command <- paste(PYTHON_COMMAND,paste0(WORK.DIR,\"/train_model.py\"),WORK.DIR)\n\nSys.time()\n\n\ntime.data <- system.time(system(python.train.command))\n\ntime.data\n\n\ncat(\"saving...\\n\")\ndate.time <- as.character(Sys.time())\nfile.name <- paste0(\"model_\",MODEL.NAME,\"_\",date.time,\".RData\")\nfile.name <- gsub(\" \",\"_\",file.name)\nfile.name <- gsub(\":\",\"_\",file.name)\nsave(PREPARE.MODEL.DATA,file=paste0(WORK.DIR,\"/\",file.name))\n\n# save Python model data\npy.file.name <- paste0(\"model_\",MODEL.NAME,\"_\",date.time,\".PyData\")\npy.file.name <- gsub(\" \",\"_\",py.file.name)\npy.file.name <- gsub(\":\",\"_\",py.file.name)\nfile.rename(paste0(WORK.DIR,\"/possible_model\"),paste0(WORK.DIR,\"/\",py.file.name))\n\n# estalish pointer to current model\nwriteLines(c(file.name,py.file.name),paste0(WORK.DIR,\"/this_model\"))\n\n# clean up files no longer needed\nfile.remove(paste0(WORK.DIR,\"/py_train.tsv\"))\n              #paste0(WORK.DIR,\"/py_test.tsv\"),\n              #paste0(WORK.DIR,\"/py_test_predictions.tsv\")\n              #))\n\n\n" } 
{ "repo_name": "jimthompson5802/kaggle-BNP-Paribas", "ref": "refs/heads/master", "path": "src/L2_nnet1/create_submission.R", "content": "###\n#  create ensemble model combining selected models\n###\n\nlibrary(data.table)\nlibrary(caret)\n\n\n# import global variabels and common functions\nsource(\"./src/CommonFunctions.R\")\nWORK.DIR <- \"./src/L2_nnet1\"\n\n# retrive generated blending weights data structure\nmodel.file.name <- readLines(paste0(WORK.DIR,\"/this_model\"))\nload(paste0(WORK.DIR,\"/\",model.file.name))\n\n# retrieve Level 1 submissions\n# L1_gbm2\ngbm2.pred.probs <- read.csv(\"./src/L1_gbm2/submission.csv\")\n\n#L1_nnet1\nnnet1.pred.probs <- read.csv(\"./src/L1_nnet1/submission.csv\")\n\n#create data for predictions\nsubmission <- list()\nsubmission$predictors <- cbind(gbm2=gbm2.pred.probs[,\"PredictedProb\"],\n                               nnet1=nnet1.pred.probs[,\"PredictedProb\"])\n\n# make prediction\npred.probs <- predict(mdl.fit,newdata = submission$predictors,type = \"prob\")\n\n#create kaggle submission file\nwrite.csv(data.frame(ID=gbm2.pred.probs[,\"ID\"],PredictedProb=pred.probs[,\"Class_1\"]),file=paste0(WORK.DIR,\"/submission.csv\"),\n          row.names=FALSE)\n\n" }
{ "repo_name": "jimthompson5802/kaggle-BNP-Paribas", "ref": "refs/heads/master", "path": "src/L0_xtc31/create_level1_features.R", "content": "###\n# Model training\n###\n\nlibrary(data.table)\nlibrary(plyr)\nlibrary(caret)\n# add any model specific package library commands\n\n\n# set working directory\nWORK.DIR <- \"./src/L0_xtc31\"  # modify to specify directory to contain model artififacts\n\n# Common Functions and Global variables\nsource(\"./src/CommonFunctions.R\")\n\n# import model configuration parameters\nsource(paste0(WORK.DIR,\"/model_parameters.R\"))\n\n\n\nMODEL.COMMENT <- \"prepL0FeatureSet3, 5-fold training\"\n\n# amount of data to train\nFRACTION.TRAIN.DATA <- 1.0\n\n# force recording model flag\nFORCE_RECORDING_MODEL <- FALSE\n\n# get training data\ntrain.raw <- fread(paste0(DATA.DIR,\"/train.csv\"))\nsetkey(train.raw,ID)\n\n# get data fold specification\nload(paste0(DATA.DIR,\"/fold_specification.RData\"))\n\n\ntrainFolds <- function(this.fold) {\n    # prepare data for training\n    test.data <- PREPARE.MODEL.DATA(train.raw[this.fold,])\n    test.data$ID <- train.raw[this.fold,ID]\n    \n    train.data <- PREPARE.MODEL.DATA(train.raw[-this.fold,])\n    \n    \n    if (FRACTION.TRAIN.DATA != 1 ) {\n        # extract subset for inital training\n        set.seed(29)\n        idx <- createDataPartition(train.data$response,p=FRACTION.TRAIN.DATA,list=FALSE)\n        train.data$predictors <- train.data$predictors[idx,]\n        train.data$response <- train.data$response[idx]\n    }\n    \n    # save prepared training data for Python function\n    # put response as first column in data set\n    write.table(cbind(response=train.data$response,train.data$predictors),\n                file=paste0(WORK.DIR,\"/py_train.tsv\"),row.names = FALSE,\n                sep=\"\\t\")\n    \n    \n    # invoke Python training model\n    python.train.command <- paste(PYTHON_COMMAND,paste0(WORK.DIR,\"/train_model.py\"),WORK.DIR)\n    \n    Sys.time()\n    \n    \n    time.data <- system.time(system(python.train.command))\n    \n    time.data\n    # stopCluster(cl)\n    \n    # prepare data for training\n    write.table(test.data$predictors,file=paste0(WORK.DIR,\"/py_test.tsv\"),row.names = FALSE,\n                sep=\"\\t\")\n    \n    # execute Python prediction code\n    python.test.command <- paste(PYTHON_COMMAND,paste0(WORK.DIR,\"/make_prediction.py\"),\n                                 WORK.DIR,\n                                 \"possible_model\",\n                                 \"py_test.tsv\",\n                                 \"py_test_predictions.tsv\")\n    system(python.test.command)\n    \n    # get predictions from Python model\n    pred.probs <- fread(paste0(WORK.DIR,\"/py_test_predictions.tsv\"), sep=\"\\t\")\n    \n    score <- logLossEval(pred.probs[,Class_1],test.data$response)\n    score\n    \n    # clean up files no longer needed\n    file.remove(c(paste0(WORK.DIR,\"/py_train.tsv\"),paste0(WORK.DIR,\"/py_test.tsv\"),\n                  paste0(WORK.DIR,\"/possible_model\"),\n                  paste0(WORK.DIR,\"/py_test_predictions.tsv\")))\n    \n    ans <- list(score=score,\n                level1.features=data.frame(ID=test.data$ID,pred.probs,response=test.data$response))\n    \n    return(ans)\n    \n}\n# train the model\nSys.time()\n\ntime.data <- system.time(ll <- llply(data.folds,trainFolds,.parallel = FALSE))\n\ntime.data\n\nfold.scores <- unlist(lapply(ll,function(x){x$score}))\nlevel1.features <- do.call(rbind,lapply(ll,function(x){x$level1.features}))\n\nmean(fold.scores)\n\n# record Model performance\nmodelPerf.df <- read.delim(paste0(WORK.DIR,\"/model_performance.tsv\"),\n                         stringsAsFactors=FALSE)\n# determine if score improved\nimproved <- ifelse(mean(fold.scores) < min(modelPerf.df$score),\"Yes\",\"No\")\n\nrecordModelPerf(paste0(WORK.DIR,\"/model_performance.tsv\"),\n                                MODEL.NAME,\n                              time.data,\n                              data.frame(),\n                              mean(fold.scores),\n                              improved=improved,\n                              bestTune=NA,\n                              tune.grid=NA,\n                              model.parms=NA,\n                              comment=MODEL.COMMENT)\n\nmodelPerf.df <- read.delim(paste0(WORK.DIR,\"/model_performance.tsv\"),\n                         stringsAsFactors=FALSE)\n\n\n#display model performance record for this run\ntail(modelPerf.df[,1:10],1)\n\n# if last score recorded is better than previous ones save model object\nlast.idx <- length(modelPerf.df$score)\nif (last.idx == 1 || improved == \"Yes\"  || FORCE_RECORDING_MODEL) {\n    cat(\"found improved model, saving...\\n\")\n    flush.console()\n    #yes we have improvement or first score, save generated model\n    file.name <- paste0(\"level1_features_\",MODEL.NAME,\"_\",modelPerf.df$date.time[last.idx],\".RData\")\n    file.name <- gsub(\" \",\"_\",file.name)\n    file.name <- gsub(\":\",\"_\",file.name)\n    \n    save(level1.features,PREPARE.MODEL.DATA,file=paste0(WORK.DIR,\"/\",file.name))\n    \n    # estalish pointer to current model\n    writeLines(file.name,paste0(WORK.DIR,\"/this_level1_features\"))\n} else {\n    cat(\"no improvement!!!\\n\")\n    flush.console()\n}\n\n\n\n" }
{ "repo_name": "jimthompson5802/kaggle-BNP-Paribas", "ref": "refs/heads/master", "path": "src/L1_nnet11/train_model.R", "content": "###\n# neural network model\n###\n\nlibrary(data.table)\nlibrary(caret)\n# add any model specific package library commands\nlibrary(nnet)\n\n# set working directory\nWORK.DIR <- \"./src/L1_nnet11\"  # modify to specify directory to contain model artififacts\n\n# Common Functions and Global variables\nsource(\"./src/CommonFunctions.R\")\n\n# set caret training parameters\nCARET.TRAIN.PARMS <- list(method=\"nnet\")   # Replace MODEL.METHOD with appropriate caret model\n\nCARET.TUNE.GRID <-  NULL  # NULL provides model specific default tuning parameters\n\n# user specified tuning parameters\n#CARET.TUNE.GRID <- expand.grid(nIter=c(100))\n\n# model specific training parameter\nCARET.TRAIN.CTRL <- trainControl(method=\"repeatedcv\",\n                                 number=5,\n                                 repeats=1,\n                                 verboseIter=FALSE,\n                                 classProbs=TRUE,\n                                 summaryFunction=caretLogLossSummary)\n\nCARET.TRAIN.OTHER.PARMS <- list(trControl=CARET.TRAIN.CTRL,\n                            maximize=FALSE,\n                           tuneGrid=CARET.TUNE.GRID,\n                           tuneLength=7,\n                           metric=\"LogLoss\")\n\nMODEL.SPECIFIC.PARMS <- list(verbose=FALSE) #NULL # Other model specific parameters\n\nPREPARE.MODEL.DATA <- prepL1FeatureSet1\n\nMODEL.COMMENT <- \"Only Class_1 probabilites as features\"\n\n\nLEVEL0.MODELS <- c(\"L0_gbm21\",\n                   \"L0_gbm41\",\n                   \"L0_xtc11\",\n                   \"L0_xtc21\",\n                   \"L0_xtc31\",\n                   #\"L0_xtc4\",  did not improve score\n                   \"L0_xtc51\",\n                   #\"L0_nnet1\",\n                   \"L0_xgb21\",\n                   \"L0_xgb31\")\n\n\n# amount of data to train\nFRACTION.TRAIN.DATA <- 1.0\n\n# force recording model flag\nFORCE_RECORDING_MODEL <- FALSE\n\n\n# get training data\ntrain.data <- prepL1FeatureSet3(LEVEL0.MODELS)\n\n\n# # create the partitions\n# set.seed(13)\n# data.folds <- createFolds(raw$target, k=5)\n\nlibrary(doMC)\nregisterDoMC(cores = 7)\n\n\n# train the model\nSys.time()\nset.seed(825)\n\ntime.data <- system.time(mdl.fit <- do.call(train,c(list(x=train.data$predictors,\n                                                         y=train.data$response),\n                                                    CARET.TRAIN.PARMS,\n                                                    MODEL.SPECIFIC.PARMS,\n                                                    CARET.TRAIN.OTHER.PARMS)))\n\ntime.data\nmdl.fit\n# stopCluster(cl)\n\nscore <- mean(mdl.fit$resample$LogLoss)\nscore\n\n# record Model performance\nmodelPerf.df <- read.delim(paste0(WORK.DIR,\"/model_performance.tsv\"),\n                         stringsAsFactors=FALSE)\n# determine if score improved\nimproved <- ifelse(score < min(modelPerf.df$score),\"Yes\",\"No\")\n\nrecordModelPerf(paste0(WORK.DIR,\"/model_performance.tsv\"),\n                              mdl.fit$method,\n                              time.data,\n                              train.data$predictors,\n                              score,\n                              improved=improved,\n                              bestTune=flattenDF(mdl.fit$bestTune),\n                              tune.grid=flattenDF(CARET.TUNE.GRID),\n                              model.parms=paste(names(MODEL.SPECIFIC.PARMS),\n                                                as.character(MODEL.SPECIFIC.PARMS),\n                                                sep=\"=\",collapse=\",\"),\n                              comment=paste0(MODEL.COMMENT,\":\",paste0(LEVEL0.MODELS,collapse=\", \")))\n\nmodelPerf.df <- read.delim(paste0(WORK.DIR,\"/model_performance.tsv\"),\n                         stringsAsFactors=FALSE)\n\n\n#display model performance record for this run\ntail(modelPerf.df[,1:10],1)\n\n# if last score recorded is better than previous ones save model object\nlast.idx <- length(modelPerf.df$score)\nif (last.idx == 1 || improved == \"Yes\" || FORCE_RECORDING_MODEL) {\n    cat(\"found improved model, saving...\\n\")\n    flush.console()\n    #yes we have improvement or first score, save generated model\n    # file.name <- paste0(\"model_\",mdl.fit$method,\"_\",modelPerf.df$date.time[last.idx],\".RData\")\n    file.name <- paste0(\"model_\",mdl.fit$method,\"_\",as.character(Sys.time()),\".RData\")\n    file.name <- gsub(\" \",\"_\",file.name)\n    file.name <- gsub(\":\",\"_\",file.name)\n\n    save(LEVEL0.MODELS,PREPARE.MODEL.DATA,mdl.fit,file=paste0(WORK.DIR,\"/\",file.name))\n\n    # estalish pointer to current model\n    writeLines(file.name,paste0(WORK.DIR,\"/this_model\"))\n} else {\n    cat(\"no improvement!!!\\n\")\n    flush.console()\n}\n\n\n\n" }
{ "repo_name": "jeffheaton/aifh", "ref": "refs/heads/master", "path": "vol1/r-examples/ch5/kmeans.R", "content": "## Artificial Intelligence for Humans\n## Volume 1: Fundamental Algorithms\n## R Version\n## http://www.aifh.org\n## http://www.jeffheaton.com\n##\n## Code repository:\n## https://github.com/jeffheaton/aifh\n##\n## Copyright 2013 by Jeff Heaton\n##\n## Licensed under the Apache License, Version 2.0 (the \"License\");\n## you may not use this file except in compliance with the License.\n## You may obtain a copy of the License at\n##\n##     http://www.apache.org/licenses/LICENSE-2.0\n##\n## Unless required by applicable law or agreed to in writing, software\n## distributed under the License is distributed on an \"AS IS\" BASIS,\n## WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n## See the License for the specific language governing permissions and\n## limitations under the License.\n##\n## For more information on Heaton Research copyrights, licenses\n## and trademarks visit:\n## http://www.heatonresearch.com/copyright\n\n## Chapter 5 Example: Random numbers\n\n## first load the iris data set\nirisdata <- read.csv(file=\"iris.csv\",head=TRUE,sep=\",\")\n\n## perform the kmeans into 3 clusters, max iterations of 1000\niris.kmeans <- kmeans(irisdata[, -5], 3, iter.max = 1000)\n\n## display the kmeans cluster as a table\ntable(irisdata[, 5], iris.kmeans$cluster)\n\n# The iris data is 4-dimension.  To display that in a chart we must scale the\n# dimensions down to just 2.\niris.dist <- dist(iris[, -5])\niris.mds <- cmdscale(iris.dist)\n\n# Ideal species assignments will be characters (from the iris data)\nideal.chars <- c(\"*\", \"o\", \"+\")[as.integer(iris$Species)]\n\n# Actual cluster assignments will be colors (from the kmeans cluster)\nactual.colors <- rainbow(3)[iris.kmeans$cluster]\n\n# You now plot\nplot(iris.mds, col = actual.colors, pch = ideal.chars, xlab = \"X\", ylab = \"Y\")\n\n# You will notice items on the graph.  Their char type shows their real (ideal) species.\n# The colors shows what cluster kMeans put them into.  You will notice that most errors\n# occur right at the border between the two clusters on the right of the graph.  That is\n# because there is no clearly defined border between them for kmeans to figure out on its \n# own.\n" }
{ "repo_name": "jeffheaton/aifh", "ref": "refs/heads/master", "path": "vol1/r-examples/ch7/learnPoly.R", "content": "## Artificial Intelligence for Humans\n## Volume 1: Fundamental Algorithms\n## R Version\n## http://www.aifh.org\n## http://www.jeffheaton.com\n##\n## Code repository:\n## https://github.com/jeffheaton/aifh\n##\n## Copyright 2013 by Jeff Heaton\n##\n## Licensed under the Apache License, Version 2.0 (the \"License\");\n## you may not use this file except in compliance with the License.\n## You may obtain a copy of the License at\n##\n##     http://www.apache.org/licenses/LICENSE-2.0\n##\n## Unless required by applicable law or agreed to in writing, software\n## distributed under the License is distributed on an \"AS IS\" BASIS,\n## WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n## See the License for the specific language governing permissions and\n## limitations under the License.\n##\n## For more information on Heaton Research copyrights, licenses\n## and trademarks visit:\n## http://www.heatonresearch.com/copyright\n\n## Chapter 7 Example: Towards Machine Learning, Learn Polynomial w/ Greedy Random\n## http://en.wikipedia.org/wiki/Polynomial\n\n# Calculate the error with Mean Square Error\n# http://www.heatonresearch.com/wiki/Mean_Square_Error\nmse <- function(a,b) {\n  sum(( a - b )^2) /length(a)  \n}\n\n##################################################################################\n## Generate the input data for training.  We use the x integer values of \n## -50 to 50 to train the polynomial over.\n##################################################################################\n\n# Generate input data range\ninputData = -50:50\n\n# Create a 2d matrix from the 1d vector\ninput <- matrix(inputData,ncol=1,byrow=TRUE)\n\n# Convert into a data table\ninput <- as.table(input)\n\n# Name the columns\ncolnames(input) <- c(\"x\")\n\n# Name the rows, simply provide a index number for each.  Not really used.\nrownames(input) = 1:nrow(input)\n\n##################################################################################\n## Generate the ideal data for training.  We calculate the y value of the polynomial\n## for each of the input values from the previous step.\n##################################################################################\n\n# Generate input data range (2x^2 + 4x + 6)\nidealData = (2*inputData)^2 + (4*inputData) + 6\n\n# Create a 2d matrix from the 1d vector\nideal <- matrix(idealData,ncol=1,byrow=TRUE)\n\n# Convert into a data table\nideal <- as.table(ideal)\n\n# Name the columns\ncolnames(ideal) <- c(\"y\")\n\n# Name the rows, simply provide a index number for each.  Not really used.\nrownames(ideal) = 1:nrow(ideal)\n\n# Calculate the polynomial from the coefficient\ncalcPolynomial <- function(coef)\n{\n  actual <- (input[,1]*coef[1])^2 + (input[,1]*coef[2]) + coef[3]\n  actual <- as.table(matrix(actual,ncol=1,byrow=TRUE))\n  rownames(actual) = 1:nrow(actual)\n  colnames(actual) <- c(\"y\")\n  actual\n}\n\n# Score the polynomial\nscore <- function(coef) {\n  actual <-calcPolynomial(coef)\n  mse(actual,ideal)\n}\n\n# Begin the iterations\niteration <- 0\nbestScore <- .Machine$double.xmax\nupdate <- -1\n\nrepeat {\n  newCoef <- runif(3,-10,10)\n  s <- score(newCoef)\n  \n  # Greedy, only improve\n  if( s<bestScore )\n  {\n    bestScore <- s\n    coef <- newCoef\n  }\n  \n  update <- update + 1\n  \n  if( update>=1000 ) \n  {\n    update<-0\n    cat(\"Iteration: \", iteration, \", Score: \" , bestScore, \"\\n\")\n    if( iteration>100000 ) {\n      break\n    }\n  }\n  \n  iteration <- iteration + 1\n}\n\ncoef\ncat( coef[1],\"x^2 + \", coef[2], \"x + \", coef[3] ) \n\n" }
{ "repo_name": "jeffheaton/aifh", "ref": "refs/heads/master", "path": "vol1/r-examples/ch9/tsp.R", "content": "## Artificial Intelligence for Humans\n## Volume 1: Fundamental Algorithms\n## R Version\n## http://www.aifh.org\n## http://www.jeffheaton.com\n##\n## Code repository:\n## https://github.com/jeffheaton/aifh\n##\n## Copyright 2013 by Jeff Heaton\n##\n## Licensed under the Apache License, Version 2.0 (the \"License\");\n## you may not use this file except in compliance with the License.\n## You may obtain a copy of the License at\n##\n##     http://www.apache.org/licenses/LICENSE-2.0\n##\n## Unless required by applicable law or agreed to in writing, software\n## distributed under the License is distributed on an \"AS IS\" BASIS,\n## WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n## See the License for the specific language governing permissions and\n## limitations under the License.\n##\n## For more information on Heaton Research copyrights, licenses\n## and trademarks visit:\n## http://www.heatonresearch.com/copyright\n\n## Chapter 9 Example: Discrete Optimization, Traveling Salesman\n## \n## http://xkcd.com/399/\n## http://en.wikipedia.org/wiki/Travelling_salesman_problem\n\n# how many cities\ncityCount <- 30\n\n# define cities to be in a circle\nratio <- (2 * pi) / cityCount\ncity.x <- (cos(1:cityCount*ratio) * 10) + 10\ncity.y <- (sin(1:cityCount*ratio) * 10) + 10\n\n# define an initial, random, path\npath <- sample(1:cityCount, cityCount, replace=F)\n\n# display a plot of the initial path\nplot(city.x, city.y, xlim=c(0,20), ylim=c(0,20),asp = 1,xlab = \"\", ylab = \"\", axes = TRUE, main = \"Traveling Salesman (before)\")\narrows(city.x[path[1:(cityCount-1)]],\n  city.y[path[1:(cityCount-1)]],\n  city.x[path[2:cityCount]],\n  city.y[path[2:cityCount]],\n  angle = 10, col = \"blue\")\n\n# Define a score function, this sumes the euclidean distance over the entire path\ndistance <- function(path) {  \n  path2 <- embed(path,2)\n  sqrt(sum(  (city.x[path2[,1]]-city.x[path2[,2]])^2 +  (city.y[path2[,1]]-city.y[path2[,2]])^2  ))\n}\n\n# move to neighbor solution, swap two cities on the path\nmoveNeighbor <- function(path) {  \n  idx <- seq(2, length(path)-1)\n  changepoints <- sample(idx, size = 2, replace = FALSE)\n  tmp <- path[changepoints[1]]\n  path[changepoints[1]] <- path[changepoints[2]]\n  path[changepoints[2]] <- tmp\n  path\n}\n\n# perform the simulated annealing\nresult <- optim(path, distance, moveNeighbor, method = \"SANN\",\n             control = list(maxit = 200000, temp = 10, tmax=20, trace = TRUE,\n                            REPORT = 500) )\n\n# get the result path\nresultPath <- result$par\n\n# plot the result path\nplot(city.x, city.y, xlim=c(0,20), ylim=c(0,20),asp = 1,xlab = \"\", ylab = \"\", axes = TRUE, main = \"Traveling Salesman (After)\")\narrows(city.x[resultPath[1:(cityCount-1)]],\n       city.y[resultPath[1:(cityCount-1)]],\n       city.x[resultPath[2:cityCount]],\n       city.y[resultPath[2:cityCount]],\n       angle = 10, length=0.15, col = \"blue\")\n\n\n" }
{ "repo_name": "tonyfischetti/sake", "ref": "refs/heads/master", "path": "functests/test1/dui-correlates.R", "content": "#!/usr/bin/rscript --vanilla\n\nrm(list=ls())\n\n\n\ndui.frame <- read.table(\"duistatsâ˜Ž.tsv\", stringsAsFactors=FALSE, \n                        sep='\\t', header=TRUE)\n\nteen.frame <- read.csv(\"teenstats.csv\", stringsAsFactors=FALSE)\n\n\n# dui frame to upper\ndui.frame$State <- toupper(dui.frame$State)\ndui.frame[9,1] <- \"D.C.\"\n\n# control for population size (the higher, the worse)\ndui.frame$dui.score <- dui.frame$DUI.Arrests..2012. / dui.frame$Population.Size\n\n# rank states by fewest dui arrests by population\ndui.frame <- dui.frame[ order(dui.frame$dui.score), ]\ndui.frame$rank <- 1:nrow(dui.frame)\n\nnames(teen.frame)[1] <- \"State\"\nnames(teen.frame)[2] <- \"Percent.HS.Grad\"\ntest <- merge(dui.frame, teen.frame[,c(1,2)])\n\nplot(test$dui.score ~ test$Percent.HS.Grad)\ndev.copy(png,'correlation.png')\ndev.off()\n\nres <- lm(test$dui.score ~ test$Percent.HS.Grad)\n\nwrite(res$coefficients, \"lmcoeffs.txt\")\n\n" }
{ "repo_name": "marchtaylor/sinkr", "ref": "refs/heads/master", "path": "R/pca_loocv.R", "content": "#' Principal component analysis \"leave-one-out\" cross-validation\n#'\n#' @param X Matrix to be subjected to svd\n#' @param npc.max The maximum number of principal components to test. Default=ncol(X)\n#'\n#' @return Matrix of square error values for each element in X  \n#' \n#' @references \\url{http://stats.stackexchange.com/a/115477/10675}\n#' @export\n#'\n#' @examples\n#' \n#' X <- as.matrix(iris[,1:4])\n#' res <- pca_loocv(X)\n#' res2 <- lapply(res, colSums)\n#' res2\n#' \n#' COL <- 2:4\n#' LTY <- 1:3\n#' op <- par(mar=c(4,4,2,1), tcl=-0.25, mgp=c(2.5,0.5,0))\n#' for(i in seq(res)){\n#'   if(i==1) {\n#'     plot(res2[[i]], t=\"n\", ylim=range(unlist(res2)), \n#'      main=\"iris\", xlab=\"n PCs\", ylab=\"PRESS\")\n#'     grid()\n#'   } \n#'   lines(res2[[i]], t=\"b\", bg=c(NaN,COL[i])[(res2[[i]]==min(res2[[i]])) + 1],\n#'    col=COL[i], lty=LTY[i], pch=21)\n#' }\n#' legend(\"topright\", legend=c(\"naive\", \"approximate\", \"pseudoinverse\"),\n#'  col=COL, lty=LTY, pch=21, bty=\"n\")\n#' par(op)\n#' \n#' \npca_loocv <- function(X, npc.max=ncol(X)){\n  error1 <- matrix(NaN, nrow=dim(X)[1], ncol=min(dim(X)[2],npc.max))\n  error2 <- matrix(NaN, nrow=dim(X)[1], ncol=min(dim(X)[2],npc.max))\n  error3 <- matrix(NaN, nrow=dim(X)[1], ncol=min(dim(X)[2],npc.max))\n  for(n in 1:dim(X)[1]){\n    Xtrain = X[-n,]\n    Xtrain = scale(Xtrain, center=TRUE, scale=FALSE)\n    V = svd(Xtrain)$v\n    Xtest = X[n,,drop = FALSE]\n    Xtest = scale(Xtest, center=attr(Xtrain, \"scaled:center\"), scale=FALSE)\n    for(j in 1:min(dim(V)[2],npc.max)){\n        P = V[,1:j] %*% t(V[,1:j])\n        err1 <- Xtest %*% (diag(length(diag(P))) - P)\n        err2 <- Xtest %*% (diag(length(diag(P))) - P + diag(diag(P)))\n        err3 <- array(NaN, dim=dim(Xtest))\n        for(k in 1:dim(Xtest)[2]){\n          proj = Xtest[,-k] %*% t(expmat(V[-k,1:j])) %*% t(V[,1:j])\n          err3[k] = Xtest[k] - proj[k]\n        }\n        error1[n,j] <- sum(sqrt(err1^2))\n        error2[n,j] <- sum(sqrt(err2^2))\n        error3[n,j] <- sum(sqrt(err3^2))\n    }\n  }\n  res <- list(\n    error1=error1,\n    error2=error2,\n    error3=error3\n  )\n  return(res)\n}\n" }
{ "repo_name": "pablo14/funModeling", "ref": "refs/heads/master", "path": "R/numbers.R", "content": "#' @title Outliers Data Preparation\n#' @description\n#' Deal with outliers by setting an 'NA value' or by 'stopping' them at a certain. The parameters: 'top_percent'/'bottom_percent' are used to consider a value as outlier.\n#' Setting NA is recommended when doing statistical analysis, parameter: type='set_na'.\n#' Stopping is recommended when creating a predictive model without biasing the result due to outliers, parameter: type='stop'.\n#' @param data data frame\n#' @param str_input string input variable (if empty, it runs for all numeric variable).\n#' @param top_percent value from 0 to 1, represents the highest X percentage of values to treat\n#' @param bottom_percent value from 0 to 1, represents the lowest X percentage of values to treat\n#' @param type can be 'stop' or 'set_na', in the first case the original variable is stopped at the desiered percentile, 'set_na'  sets NA to the same values.\n#' @examples\n#' # Creating data frame with outliers\n#' set.seed(10)\n#' df=data.frame(var1=rchisq(1000,df = 1), var2=rnorm(1000))\n#' df=rbind(df, 1135, 2432) # forcing outliers\n#' df$id=as.character(seq(1:1002))\n#'\n#' # for var1: mean is ~ 4.56, and max 2432\n#' summary(df)\n#'\n#' ########################################################\n#' ### PREPARING OUTLIERS FOR DESCRIPTIVE STATISTICS\n#' ########################################################\n#'\n#' #### EXAMPLE 1: Removing top 1% for a single variable\n#' # checking the value for the top 1% of highest values (percentile 0.99), which is ~ 7.05\n#' quantile(df$var1, 0.99)\n#'\n#' # Setting type='set_na' sets NA to the highest value)\n#' var1_treated=prep_outliers(data = df,  str_input = 'var1', type='set_na', top_percent  = 0.01)\n#'\n#' # now the mean (~ 0.94) is more accurate, and note that: 1st, median and 3rd quartiles remaining very similar to the original variable.\n#' summary(var1_treated)\n#'\n#' #### EXAMPLE 2: if 'str_input' is missing, then it runs for all numeric variables (which have 3 or more distinct values).\n#' df_treated2=prep_outliers(data = df, type='set_na', top_percent  = 0.01)\n#' summary(df_treated2)\n#'\n#' #### EXAMPLE 3: Removing top 1% (and bottom 1%) for 'N' specific variables.\n#' vars_to_process=c('var1', 'var2')\n#' df_treated3=prep_outliers(data = df, str_input = vars_to_process, type='set_na', bottom_percent = 0.01, top_percent  = 0.01)\n#' summary(df_treated3)\n#'\n#' ########################################################\n#' ### PREPARING OUTLIERS FOR PREDICTIVE MODELING\n#' ########################################################\n#'\n#' #### EXAMPLE 4: Stopping outliers at the top 1% value for all variables. For example if the top 1% has a value of 7, then all values above will be set to 7. Useful when modeling because outlier cases can be used.\n#' df_treated4=prep_outliers(data = df, top_percent  = 0.01, type='stop')\n\n#' @return A vector or data frame with the desired outlier transformation\n#' @export\nprep_outliers <- function(data, str_input, type=c('stop', 'set_na'), top_percent, bottom_percent)\n{\n\tif(!(type %in% c('stop', 'set_na', 'sigmoid')))\n\t\tstop(\"Parameter 'type' must be one 'stop' or 'set_na'\")\n\n\n\tif(missing(str_input))\n\t\tstr_input=give_me_num_vars(data)\n\n\n\t# #########################################################\n\t# ### Sigmoid procesing\n\t# #########################################################\n\t# if(type == 'sigmoid')\n\t# {\n\t# \tfor(i in 1:length(str_input))\n\t#   {\n\t#    \tdata[, str_input[i]]=sigmoid(as.numeric(scale(data[, str_input[i]])))\n\t# \t}\n\t# \treturn(data)\n\t# }\n\n\t#########################################################\n\t### Stopping and Setting NA processing\n\t#########################################################\n\t## If not sigmoid, then it's stop or set_na, thus it has to have top or bottom param.\n\tif(missing(top_percent) & missing(bottom_percent))\n\t\tstop(\"Parameters 'top_percent' and 'bottom_percent' cannot be missing at the same time\")\n\n\t## Logic for top value\n\tif(!missing(top_percent))\n\t{\n\t  for(i in 1:length(str_input))\n\t  {\n\t   \ttop_value=round(quantile(data[,str_input[i]], probs=(1-top_percent), names=F, na.rm=T))\n\t   \tdata[, str_input[i]][data[, str_input[i]]>top_value]=ifelse(type=='stop', top_value, NA)\n\t  }\n\t}\n\n\t## Logic for bottom value\n\tif(!missing(bottom_percent))\n\t{\n\t  for(i in 1:length(str_input))\n\t  {\n\t   \tbottom_value=round(quantile(data[,str_input[i]], probs=bottom_percent, names=F, na.rm=T))\n\t   \tdata[, str_input[i]][data[, str_input[i]]<bottom_value]=ifelse(type=='stop', bottom_value, NA)\n\t  }\n\t}\n\n\t## Return the input vector if only 1 var was desired, otherwise it returns all the data frame transformed\n\tif(length(str_input)==1) {\n\t\treturn(data[, str_input[i]])\n\t} else {\n \t\treturn(data)\n\t}\n\n}\n\n#' @title Compare two vectors of keys\n#' @description Obtain correlation table of all variables that belongs to data against target variable\n#' @param data data frame\n#' @param str_target string variable to predict\n#' @examples\n#' v1=c(1,2,4)\n#' v2=c(1,2,5,6)\n#' res=compare_df(key_x=v1, key_y=v2)\n#' # Print the keys that didn't match\n#' res\n#' # Accessing the keys not present in\n#' @return Correlation index for all data input variable\n#' @export\ncompare_df <- function(key_x, key_y)\n{\n\t# key_x=v1;key_y=v2\n  df_x=data.frame(key_x=key_x, flag_x=1)\n  df_y=data.frame(key_y=key_y, flag_y=1)\n\n  df_x$key_x=as.character(df_x$key_x)\n\tdf_y$key_y=as.character(df_y$key_y)\n\n  merge_all=merge(df_x, df_y, by.x='key_x', by.y='key_y', all=T)\n\n  names(merge_all)[1]=\"key\"\n\n  merge_all_nona=merge_all[!is.na(merge_all$flag_x) & !is.na(merge_all$flag_y),]\n\n  not_in_x=merge_all[is.na(merge_all$flag_x),]\n  not_in_y=merge_all[is.na(merge_all$flag_y),]\n\n  print(sprintf(\"Coincident in both: %s\", nrow(merge_all_nona)))\n  print(sprintf(\"Rows not present in X: %s\", nrow(not_in_x)))\n  print(sprintf(\"Rows not present in Y: %s\", nrow(not_in_y)))\n\n\n  list_diff=list()\n\n  res=list(\n    present_in_both=merge_all_nona$key,\n    rows_not_in_X=not_in_x$key,\n    rows_not_in_Y=not_in_y$key\n  \t)\n\n  return(res)\n}\n\n#' @title Correlation analyisis against target variable\n#' @description Obtain correlation table of all variables that belongs to data against target variable. Only numeric variables are analyzed.\n#' @param data data frame\n#' @param str_target string variable to predict\n#' @examples\n#' correlation_table(data=heart_disease, str_target=\"has_heart_disease\")\n#' @return Correlation index for all data input variable\n#' @export\ncorrelation_table <- function(data, str_target)\n{\n\tdata[, str_target]=as.numeric(data[, str_target])\n\n\tdata=data[, c(give_me_num_vars(data, str_target), str_target)]\n\n  df_cor=as.data.frame(round(cor(data, use=\"complete.obs\"\t),2))\n  df_cor$Variable = rownames(df_cor)\n  df_cor=df_cor[, names(df_cor) %in% c(str_target, \"Variable\")]\n\n  df_cor=df_cor[interp(~order(df_cor, -v) , v=as.name(str_target)),  ]\n\n  row.names(df_cor) = NULL\n  df_cor=df_cor[, c(2,1)]\n\n  df_cor[order(-df_cor[,2]) , ]\n\n  return(df_cor)\n}\n\n#' @title Sigmoid function\n#' @description Sigmoid function, also known as logistic or s-shaped\n#' @param x numeric input vector\n#' @param a constant to multiply 'x', default=1\n#' @examples\n#' sigmoid()\n#' @return vector transformed with sigmoid\n#' @export\nsigmoid<-function(x, a=1)\n{\n\tif(missing(a))\n\t\ta=1\n\n\ty = 1/(1 + exp(-a*x))\n\n\treturn(y)\n}\n\n#' @title Transform a variable into the 0 to 1 range\n#' @description Range a variable into [0-1], assigning 0 to the min and 1 to the max of the input variable.\n#' @param x numeric input vector\n#' @examples\n#' range01(mtcars$cyl)\n#' @return vector ranged into 0-1\n#' @export\nrange01 <- function(x)\n{\n\treturn((x-min(x, na.rm=T))/(max(x, na.rm=T)-min(x, na.rm=T)))\n}\n" }
{ "repo_name": "zozlak/ZPD", "ref": "refs/heads/master", "path": "R/pobierz_schematy_odp.R", "content": "#' @title Pobiera dystraktory kryteriÃ³w oceny\r\n#' @description\r\n#' W wypadku pobierania z bazy wynikÃ³w w postaci niewypunktowanej wybrana przez \r\n#' ucznia odpowiedÅº zakodowana jest liczbowo. Dane pobierane funkcjÄ… \r\n#' pobierz_schematy_odp() pozwalajÄ… przekodowaÄ‡ je na faktyczne oznaczenia uÅ¼yte\r\n#' w teÅ›cie.\r\n#' \r\n#' Innym zastosowaniem moÅ¼e byÄ‡ sprawdzanie, czy zbiÃ³r danych z wynikami testu \r\n#' nie zawiera wartoÅ›ci spoza moÅ¼liwych do wyboru dla danego zadania odpowiedzi.\r\n#' @param src uchwyt ÅºrÃ³dÅ‚a danych dplyr-a \r\n#' @import dplyr\r\n#' @export\r\npobierz_schematy_odp = function(\r\n  src\r\n){\r\n  stopifnot(is.src(src))\r\n  \r\n  query = \"\r\n    SELECT 'k_' || id_kryterium AS kryterium, dystraktor, kolejnosc AS kolejnosc_dystr\r\n    FROM \r\n      pytania \r\n      JOIN kryteria_oceny USING (id_pytania) \r\n      JOIN sl_schematy_odp_dystr USING (schemat_odp)\r\n    ORDER BY 1, 3\r\n  \"\r\n  data = tbl(src, sql(e(query)))\r\n  return(data)\r\n}\r\nattr(pobierz_schematy_odp, 'grupa') = 'kryteriaOceny'\r\n" }
{ "repo_name": "zozlak/ZPD", "ref": "refs/heads/master", "path": "tests/testthat/test-normalizuj.R", "content": "context('normalizuj')\n\nsrc = polacz()\n\ntest_that('normalizuj dziaÅ‚a', {\n  dane = data.frame(wynik = rep(1:40, 50))\n  \n  norm = normalizuj(dane)\n  \n  expect_equal(norm$wynik, dane$wynik)\n  expect_less_than(abs(mean(norm$wynik_norm) - 100), 1)\n  expect_less_than(abs(median(norm$wynik_norm) - 100), 1)\n  expect_less_than(abs(sd(norm$wynik_norm) - 15), 1)\n  \n  skale = pobierz_skale(src) %>% \n    filter(posiada_normy == T, rodzaj_egzaminu == 'sprawdzian', rok == 2010, rodzaj_skali == 'zrÃ³wnywanie') %>% \n    select(id_skali, skalowanie, grupa) %>%\n    distinct() %>%\n    collect()\n  norm = normalizuj(dane, src, idSkali = skale$id_skali[1], skalowanie = skale$skalowanie[1], grupa = skale$grupa[1])\n  \n  expect_equal(norm$wynik, dane$wynik)\n  expect_more_than(min(norm$wynik_norm), 0)\n  expect_less_than(max(norm$wynik_norm), 40.001)\n  expect_less_than(sd(norm$wynik_norm), 15)\n})" }
{ "repo_name": "zozlak/ZPD", "ref": "refs/heads/master", "path": "R/pobierz_wyniki_zrownywania.R", "content": "#' @title Pobiera ramke danych z wynikami egzaminacyjnymi testow zrownujacych\r\n#' @param src uchwyt ÅºrÃ³dÅ‚a danych dplyr-a\r\n#' @param rodzajEgzaminu rodzaj egzaminu, ktorego wyniki maja zostac pobrane\r\n#' @param punktuj wybor, czy dane maja byc pobrane w postaci dystraktorow, czy punktow\r\n#' @param rok rok, z ktorego dane maja zostac pobrane\r\n#' @param idSkali identyfikator skali, ktora ma zostac zastosowana do danych\r\n#' @param skroc czy do danych zastosowac skrocenia skal opisane w skali\r\n#' @import dplyr\r\n#' @export\r\npobierz_wyniki_zrownywania = function(\r\n  src,\r\n\trodzajEgzaminu, \r\n\trok, \r\n\tpunktuj = TRUE, \r\n\tidSkali = NULL,\r\n\tskroc   = TRUE\r\n){\r\n  stopifnot(\r\n    is.src(src),\r\n    is.vector(rodzajEgzaminu), is.character(rodzajEgzaminu), length(rodzajEgzaminu) == 1,\r\n    is.vector(rok), is.numeric(rok), length(rok) == 1, \r\n    is.vector(punktuj), is.logical(punktuj), length(punktuj) == 1, punktuj %in% c(T, F),\r\n    is.null(idSkali) | is.vector(idSkali) & is.numeric(idSkali) & length(idSkali) == 1,\r\n    is.vector(skroc), is.logical(skroc), length(skroc) == 1, skroc %in% c(T, F)\r\n  )\r\n  \r\n  regExp = e(paste0('^zrÃ³wnywanie;', rodzajEgzaminu, ';', rok, ';.*$'))\r\n\ttests = pobierz_testy(src) %>% \r\n    collect() %>%\r\n    filter_(~grepl(regExp, opis_testu))\r\n\tif(nrow(tests) == 0){\r\n\t\tstop(e('w bazie nie ma takiego zrownywania'))\r\n\t}\r\n\r\n\ttmpName = sub('[.]', '_', paste0('t', as.numeric(Sys.time(), runif(1))))\r\n\tDBI::dbGetQuery(src$con, e(paste0(\"CREATE TEMPORARY VIEW \", tmpName, \" AS SELECT 1\")))\r\n\tquery = sprintf(\r\n    \"SELECT zbuduj_widok_zrownywania(%s, %s, %d, %s, %s, %s, true)\",\r\n    escape(tmpName),\r\n    escape(rodzajEgzaminu),\r\n    rok,\r\n    ifelse(punktuj, 'true', 'false'),\r\n    ifelse(is.null(idSkali), 'null', as.numeric(idSkali)),\r\n    ifelse(skroc, 'true', 'false')\r\n  )\r\n\tDBI::dbGetQuery(src$con, e(query))\r\n\tdata = tbl(src, sql(e(paste0(\"SELECT * FROM \", tmpName))))\r\n\r\n\tattr(data, 'idSkali') = idSkali\r\n  \r\n\treturn(data)\r\n}\r\nattr(pobierz_wyniki_zrownywania, 'grupa') = 'wyniki'\r\nattr(pobierz_wyniki_zrownywania, 'testArgs') = list(\r\n  'rodzajEgzaminu' = 'sprawdzian', 'rok' = 2013, 'idSkali' = 41\r\n)\r\n" }
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/R/Decimal-to-binary.R","content":"# Program to convert decimal number into binary number using recursive function\nconvert_to_binary <- function(n) {\n  if(n > 1) {\n    convert_to_binary(as.integer(n/2))\n  }\n  cat(n %% 2)\n}\n\nconvert_to_binary(52)"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/R/Factorial.R","content":"# take input from the user\nfactorial <- function(n) {\nfactorial = 1\n# check is the number is negative, positive or zero\nif(num < 0) {\n  print('Sorry factorial does not exist for negative numbers')\n} else if(num == 0) {\n  print('The factorial of 0 is 1')\n} else {\n  for(i in 1:num) {\n    factorial = factorial * i\n  }\n  print(paste('The factorial of', num ,'is',factorial))\n}\n}\n\nfactorial(4)"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/R/First-10-Fibonacci.R","content":"fibonacci <- function(n) {\nFibonacci <- numeric(n)\nFibonacci[1] <- Fibonacci[2] <- 1\nfor (i in 3:10) Fibonacci[i] <- Fibonacci[i - 2] + Fibonacci[i - 1]\nprint('First 10 Fibonacci numbers:'')\nprint(Fibonacci)\n}\n\nfibonacci(10)"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/R/Max-Min-of-Vector.R","content":"max_min_vector <- function() {\nnums = c(10, 20, 30, 40, 50, 60)\nprint('Original vector:')\nprint(nums)   \nprint(paste('Maximum value of the said vector:',max(nums)))\nprint(paste('Minimum value of the said vector:',min(nums)))\n}\n\nmax_min_vector()"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/R/Odd-or-Even.R","content":"# Program to check if the input number is odd or even.\n# A number is even if division by 2 give a remainder of 0.\n# If remainder is 1, it is odd.\nodd_or_even <- function(n){\nnum = n\nif((num %% 2) == 0) {\n  print(paste(num,'is Even'))\n} else {\n  print(paste(num,'is Odd'))\n}\n}\n\nodd_or_even(4)"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/R/Prime-Numbers.R","content":"prime_numbers <- function(n) {\n  if (n >= 2) {\n    x = seq(2, n)\n    prime_nums = c()\n    for (i in seq(2, n)) {\n      if (any(x == i)) {\n        prime_nums = c(prime_nums, i)\n        x = c(x[(x %% i) != 0], i)\n      }\n    }\n    return(prime_nums)\n  }\n  else \n  {\n    stop('Input number should be at least 2.'')\n  }\n} \nprime_numbers(12)"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/R/Read-csv-file.R","content":"read_csv_file <- function() {\nmovie_data = read.csv(file=movies.csv, header=TRUE, sep=',')\nprint('Content of the .csv file:'')\nprint(movie_data)\n}\n\nread_csv_file()"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/R/add1.r","content":"add1 <- function(n) {\n   print( n+1)\n}\n\nadd1(90)\n"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/R/add2numbers.r","content":"add2nums <- function(num1, num2) {\n   print( num1+num2)\n}\n\nadd2nums(34, 6)\n"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/R/areaofsquare.r","content":"areaSquare <- function(num) {\n   msg1 <- 'Invalid measurement'\n   msg2 <- 'Area of the Square is: '\n   if  (num <= 0){\n        print(msg1)\n   }else {\n       print (msg2)\n       print(num*num)\n   }\n  \n}\n\nareaSquare(6)"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/R/divisibleby10.r","content":"divisibleby10 <- function(num) {\nif(num %% 10 == 0){\n    print('True')\n}else{\n    print('False')\n}\n\n}\n\ndivisibleby10(60)\n"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/R/integertype.r","content":"integerType <- function(num){\nif(num > 0) {\nprint('Positive number')\n} else {\nif(num == 0) {\nprint('Zero')\n} else {\nprint('Negative number')\n}\n}\n}\n\nintegerType(-90)\n"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/R/lengthoflist.r","content":"\nlengthofVector <- function(vector){\ncount <- 0\nfor (i in vector){\n    count <- count + 1\n}\nprint(count)\n}\n\narray <- c(3,4,5,1,6)\nlengthofVector(array)\n"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/R/palindrome.r","content":"\npalindrome <- function(n){\nrev = 0\n    num = n\n\n    while (n > 0) {\n      r = n %% 10\n      rev = rev * 10 + r\n      n = n %/% 10\n    }\n\n    if (rev == num)\n    {\n      print(paste('Number is palindrome :', rev))\n    }\n    else{\n      print(paste('Number is not palindrome :', rev))\n    }\n}\npalindrome(121)\n"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/R/sort.r","content":"integerType <- function(num){\nif(num > 0) {\nsortvector <- function(vector){\nprint(sort(vector))\n}\n\narray <- c(23,12,11,34,21)\nsortvector(array)\n"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/R/spmv.r","content":"\nsum <- function(vector){\nresult <- 0\nfor(i in vector){\n    result = result + i\n}\nprint(result)\n}\n\nproduct <- function(vector){\n    result <- 1\n    for(i in vector){\n        result = result*i\n    }\n    print(result)\n}\n\narray <- c(1,2,3,4)\nsum(array)\nproduct(array)\nmean(array, na.rm=TRUE)\n"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/R/upperlower.r","content":"\nupperCase <- function(word){\nresult <- toupper(word)\nprint(result)\n}\n\nlowerCase <- function(word){\nresult <- tolower(word)\nprint(result)\n}\n\nupperCase('Function')\nlowerCase('FUNCTION')\n"}
{ "repo_name": "mathii/europe_selection", "ref": "refs/heads/master", "path": "analysis/genome_wide_scan_imputed.R", "content": "#This is the genome-wide scan but using the read level information to try and\n#get some idea about diploid calls. For reasons of speed, we break this one\n#by chromosome. Genomic correction has to be done in another step for this reason.\n\n#Test whether the modern population frequencies can be modelled as a mixture of the\n#Three ancestral populations.\n#Using genotype probabilities imputed with Beagle.\n\nsource(\"~/selection/code/lib/3pop_lib.R\")\n\n#Modern GBR, CEU, IBS, TSI\n#Ancient WHG, ENeo, Yamnaya\n\n########################################################################\n## Details\nchr <- 1                                #set manually, or from --args\nversion <- \"vx\" #v6, v7 etc...\nresults.tag <- \"\"\nwhich.impute <- \"within\"\n\ncA <- commandArgs(TRUE)\nif(length(cA)){\n  chr <- cA[1]\n  version <- cA[2]\n  if(length(cA)>2){\n    results.tag <- cA[3]\n  }\n  if(length(cA)>3){\n    which.impute <- cA[4]\n  }\n}\n\nverbose=TRUE\n## Supposed to check if running on cluster, but YMMV\nif( Sys.info()[\"login\"]!=Sys.info()[\"user\"]){\n    verbose=FALSE\n}\n\n########################################################################\n## Details\nroot <- paste0(\"~/selection/counts/\", version, \"/all\")\nout <- paste0(\"~/selection/analysis/\", version, \"/gscan/\")\nindfile <- paste0(\"~/data/\", version, \"/use/\", version,\"1kg_europe2names.ind\")\nimpute.file <- paste0(\"~/selection/imputation/\", version, \"/imputed.\", which.impute ,\".chr\", chr, \".vcf.gz\")\nerror.prob <- 0.001\n\npops <- c(\"WHG\", \"EN\", \"Yamnaya\", \"CEU\", \"GBR\", \"IBS\", \"TSI\")\n#Check if the SNP is monomorphic in these populations. \nmonocheck <- c(\"CEU\", \"GBR\", \"IBS\", \"TSI\", \"HungaryGamba_HG\", \"Loschbour\", \"Stuttgart\",\n               \"LBK_EN\", \"HungaryGamba_EN\", \"Spain_EN\", \"Starcevo_EN\", \"LBKT_EN\", \"Yamnaya\")\nA <- matrix(c(0.164, 0.366, 0.470, 0.213, 0.337, 0.450, 0, 0.773, 0.227, 0, 0.712, 0.288),3, 4) \n\n########################################################################\n\nif(version==\"v6\" | version==\"v7\"){\n\n  pops <- c(\"WHG\", \"EN\", \"Yamnaya\", \"CEU\", \"GBR\", \"IBS\", \"TSI\")\n#Check if the SNP is monomorphic in these populations. \n  monocheck <- c(\"CEU\", \"GBR\", \"IBS\", \"TSI\", \"HungaryGamba_HG\", \"Loschbour\", \"Stuttgart\",\n               \"LBK_EN\", \"HungaryGamba_EN\", \"Spain_EN\", \"Starcevo_EN\", \"LBKT_EN\", \"Yamnaya\")\n  A <- matrix(c(0.164, 0.366, 0.470, 0.213, 0.337, 0.450, 0, 0.773, 0.227, 0, 0.712, 0.288),3, 4) \n\n  include.counts <- list(                 #Include these populations as hard calls. \n    \"WHG\"=\"Loschbour\",\n    \"EN\"=\"Stuttgart\",\n    \"CEU\"=\"CEU\", \"GBR\"=\"GBR\", \"IBS\"=\"IBS\", \"TSI\"=\"TSI\" )\n  \ninclude.probs <- list(                  #Include these populations as reads\n    ## \"WHG\"=c(\"LaBrana1\", \"HungaryGamba_HG\"), #Replace LaBrana1 with SpanishMesolithic for the high coverage LaBrana I0585\n    \"WHG\"=c(\"SpanishMesolithic\", \"HungaryGamba_HG\"), #Replace LaBrana1 with SpanishMesolithic for the high coverage LaBrana I0585\n    \"EN\"=c(\"LBK_EN\", \"HungaryGamba_EN\", \"Spain_EN\", \"Starcevo_EN\", \"LBKT_EN\"), \n    \"Yamnaya\"=\"Yamnaya\")\n}\nif(version==\"v7\"){\n  include.probs[[\"WHG\"]] <- gsub(\"SpanishMesolithic\", \"Iberian_Mesolithic\", include.probs[[\"WHG\"]], fixed=TRUE)\n}\nif(version==\"v8\"){\n  mix.dir <- \"~/selection/code/files/v8/mixtures/\"\n  \n  if(results.tag==\"\"){stop(\"Must specify results tag - group from 1-6 - for v8 analysis\")}\n  include.counts <- list( \"CEU\"=\"CEU\", \"GBR\"=\"GBR\", \"IBS\"=\"IBS\", \"TSI\"=\"TSI\" )\n  always.counts <- c(\"Loschbour\", \"Stuttgart\")\n  group <- results.tag\n  choice <- read.table(paste0(mix.dir, \"Choice\", results.tag), as.is=TRUE, header=FALSE)\n  include.probs <- list(c(), c(), c())\n  names(include.probs) <- unique(choice[,2])\n  for(i in 1:NROW(choice)){\n    if(choice[i,1] %in% c(\"Loschbour\", \"Stuttgart\")){\n      include.counts[[choice[i,2]]] <- choice[i,1]\n    } else{\n      include.probs[[choice[i,2]]] <- c(include.probs[[choice[i,2]]], choice[i,1])\n    }\n  }\n  mix.mat <- read.table(paste0(mix.dir, \"Proportion\", results.tag), as.is=TRUE, header=TRUE)\n  rownames(mix.mat) <- mix.mat[,1]\n  mix.mat <- mix.mat[,2:NCOL(mix.mat)]\n  \n  anc.pops <- names(include.probs)\n  mod.pops <- c(\"CEU\", \"GBR\", \"IBS\", \"TSI\")\n  pops <- c(anc.pops, mod.pops)\n  A <- t(mix.mat)[anc.pops,mod.pops]\n\n  monocheck <- c(unlist(include.probs), unlist(include.counts))\n  names(monocheck) <- NULL\n}\n\n##################################################################################################\n\n## Setup the count data. \ncounts <- read.table(paste0(root, \".count\"), header=TRUE, as.is=TRUE)\ntotals <- read.table(paste0(root, \".total\"), header=TRUE, as.is=TRUE)\ndata <- counts[,1:5]\ninclude <- data$CHR==chr\ndata <- data[include,]\n\ncounts <- data.matrix(counts[,6:NCOL(counts)])\ntotals <- data.matrix(totals[,6:NCOL(totals)])\ncounts <- counts[include,]\ntotals <- totals[include,]\n\n#Load imputed likelihoods\nimpute <- read.table(impute.file, comment.char=\"\", as.is=TRUE, header=FALSE, sep=\"\\t\", fill=TRUE)\ncomment.lines <- sum(grepl(\"^##\", impute[,1]))\nimpute <- read.table(impute.file, comment.char=\"\", as.is=TRUE, header=TRUE, skip=comment.lines, sep=\"\\t\", fill=TRUE)\nrownames(impute) <- impute$ID\nimpute <- impute[impute$ID %in% data[,1],]\nimpute.info <- impute[,8]\nimpute <- impute[,10:NCOL(impute)]\n\n## get list of samples in each population of reads\ninclude.prob.samples <- read.samples(indfile, include.probs)\n\n## set up results\nresults <- matrix(0, nrow=NROW(data), ncol=3)\nrownames(results) <- data$ID\n\n## Data structure\nempty.data <- make.empty.data(pops)\n\nfor(i in 1:NROW(data)){\n    this.snp <- data[i,1]\n    if(verbose){cat(paste0(\"\\r\", i, \" \", this.snp))}\n    this.prob <- impute[i,]\n\n    freq.data <- make.prob.freq.data(pops, include.probs, include.prob.samples, include.counts,\n                                this.prob, counts[i,], totals[i,], empty.data)\n    monomorphic <- all(counts[i,monocheck]==0)|all(counts[i,monocheck]==totals[i,monocheck])\n    if(monomorphic){\n        results[i,] <- NA\n    }else{\n        AR2 <- as.numeric(strsplit(strsplit(impute.info[i], \";\", fixed=TRUE)[[1]][1], \"=\", fixed=TRUE)[[1]][2])\n        results[i,] <- c(test.3pop.reads(freq.data, A, error.prob=error.prob), AR2)\n    }\n}\n\nresults <- results[!is.na(results[,2]),]\n\nresults <- cbind(rownames(results), results)\ncolnames(results) <- c(\"ID\", \"ChiSq\", \"uncorrected.p\", \"AR2\")\nresults <- data.frame(results)\nout.file <-  paste0(\"~/selection/analysis/\",version,\"/gscan/scan_results_imputed\", results.tag, \".\", which.impute, \".chr\", chr, \".txt\")\nprint(out.file)\nwrite.table(results,out.file, row.names=FALSE, col.names=TRUE, quote=FALSE, sep=\"\\t\")\n\n" }
{ "repo_name": "jonhoo/volley", "ref": "refs/heads/master", "path": "benchmark/plot.R", "content": "#!/usr/bin/env Rint\nlibrary(grDevices)\nlibrary(utils)\nX11(width=12, height=10)\n\nlibrary(ggplot2)\nargs <- commandArgs(trailingOnly = TRUE)\nargs <- if (length(args) == 0) Sys.getenv(\"ARGS\") else args\nargs <- if (args[1] == \"\") \"plot.dat\" else args\n\nd <- data.frame(read.table(\n\t\t\t   text=gsub('us ', ' ', readLines(file(args[1]))),\n\t\t\t   col.names=c(\"server\", \"clients\", \"cores\", \"time\", \"stddev\", \"n\")\n\t\t\t   ))\n\nd$ci = 2.58 * d$stddev / sqrt(d$n)\nd$ops = d$clients/(d$time/1000.0/1000.0)\nd$min = d$clients/((d$time-d$ci)/1000.0/1000.0)\nd$max = d$clients/((d$time+d$ci)/1000.0/1000.0)\n\n#d = d[d[, \"clients\"] == 80,]\n#d = d[grep(\"^go\", d[, \"server\"]),]\nprint(d)\np <- ggplot(data=d, aes(x = cores, y = ops, ymin = min, ymax = max, color = server))\np <- p + geom_line()\np <- p + ylim(0, 2000000)\np <- p + geom_errorbar()\np <- p + facet_wrap(~ clients)\np <- p + xlab(\"CPU cores\")\np <- p + ylab(\"Mean ops/s\")\n\np\nggsave(\"plot.png\", plot = p, width = 8, height = 6)\n" }
{ "repo_name": "jaredhuling/rfunctions", "ref": "refs/heads/master", "path": "R/lanczos.R", "content": "\n\n#' Compute Largest Singular Value of Matrix x\n#'\n#' @param x matrix input\n#' @param v numeric vector. Initialize GKL bidiagonalization with random vector on unit sphere\n#' @param maxit integer. Maximum number of Lanczos iterations\n#' @param reorthog Takes values in 0:2. 0 for no reorthogonalization, 1 for reorthogonalization of \n#' V vectors (slower, more accurate), 2 for reorthogonalization of V and U vectors (slowest and most \n#' memory, most accurate. Not implemented yet)\n#' @param upper.bound.prob upper bound probability for the largest singular value\n#' @return list \n#' @references Hochstenbach (2013) Probabilistic upper bounds for the matrix two-norm, http://link.springer.com/article/10.1007/s10915-013-9716-x \n#' Journal of Scientific Computing, Vol. 57(3), Dec. 2013\n#' @export\n#' @examples\n#'n.obs <- 1e5\n#'n.vars <- 150\n#'\n#'x <- matrix(rnorm(n.obs * n.vars), n.obs, n.vars)\n#'\n#'## compute largest singular value of x\n#'lanczos <- gklBidiag(x, runif(ncol(x)), 10L, reorth = 0, upper.bound.prob = 0.99)\n#'str(lanczos)\nsetGeneric(\"gklBidiag\", function(x, v, maxit, reorthog = 0, upper.bound.prob = NULL) {\n  stopifnot(is.numeric(x) | inherits(x, \"CsparseMatrix\"))\n  stopifnot(is.numeric(v))\n  reorthog <- as.integer(reorthog)\n  if (inherits(x, \"CsparseMatrix\")) {\n    .Call(\"GKLBidiagSparse\", A = x, v = v, k = maxit, reorthog = reorthog, PACKAGE = \"rfunctions\")\n  } else {\n    .Call(\"GKLBidiag\", A = x, v = v, k = maxit, reorthog = reorthog, PACKAGE = \"rfunctions\")\n  }\n})\n\nsetMethod(\"gklBidiag\", signature(x = \"matrix\", v = \"numeric\", maxit = \"numeric\", \n                                 reorthog = \"numeric\", upper.bound.prob = \"numeric\"),\n            function(x, v, maxit = 50L, reorthog = 0, upper.bound.prob = NULL) {\n              maxit <- as.integer(maxit)\n              reorthog <- as.integer(reorthog)\n              delt <- computeDelta(eps = 1 - upper.bound.prob, p = ncol(x))\n              res <- .Call(\"GKLBidiag\", A = x, v = v, k = maxit, reorthog = reorthog, PACKAGE = \"rfunctions\")\n              upper <- computeUpperBound(res, delt)\n              res$upper.bound <- upper\n              res$upper.bound.prob <- upper.bound.prob\n              res\n            })\n\nsetMethod(\"gklBidiag\", signature(x = \"dgeMatrix\", v = \"numeric\", maxit = \"numeric\", \n                                 reorthog = \"numeric\", upper.bound.prob = \"numeric\"),\n          function(x, v, maxit = 50L, reorthog = 0, upper.bound.prob = NULL) {\n            maxit <- as.integer(maxit)\n            reorthog <- as.integer(reorthog)\n            delt <- computeDelta(eps = 1 - upper.bound.prob, p = ncol(x))\n            res <- .Call(\"GKLBidiag\", A = x, v = v, k = maxit, reorthog = reorthog, PACKAGE = \"rfunctions\")\n            upper <- computeUpperBound(res, delt)\n            res$upper.bound <- upper\n            res$upper.bound.prob <- upper.bound.prob\n            res\n          })\n\n\nsetMethod(\"gklBidiag\", signature(x = \"CsparseMatrix\", v = \"numeric\", maxit = \"numeric\", \n                                 reorthog = \"numeric\", upper.bound.prob = \"numeric\"),\n          function(x, v, maxit = 50L, reorthog = 0, upper.bound.prob = NULL) {\n            maxit <- as.integer(maxit)\n            reorthog = as.integer(reorthog)\n            delt <- computeDelta(eps = 1 - upper.bound.prob, p = ncol(x))\n            res <- .Call(\"GKLBidiagSparse\", A = x, v = v, k = maxit, reorthog = reorthog, PACKAGE = \"rfunctions\")\n            upper <- computeUpperBound(res, delt)\n            res$upper.bound <- upper\n            res$upper.bound.prob <- upper.bound.prob\n            res\n          })\n\n\nsetMethod(\"gklBidiag\", signature(x = \"matrix\", v = \"numeric\", maxit = \"numeric\", \n                                 reorthog = \"numeric\", upper.bound.prob = \"missing\"),\n          function(x, v, maxit = 50L, reorthog = 0, upper.bound.prob = NULL) {\n            maxit <- as.integer(maxit)\n            reorthog <- as.integer(reorthog)\n            res <- .Call(\"GKLBidiag\", A = x, v = v, k = maxit, reorthog = reorthog, PACKAGE = \"rfunctions\")\n            res$upper.bound <- NULL\n            res$upper.bound.prob <- NULL\n            res\n          })\n\nsetMethod(\"gklBidiag\", signature(x = \"dgeMatrix\", v = \"numeric\", maxit = \"numeric\", \n                                 reorthog = \"numeric\", upper.bound.prob = \"missing\"),\n          function(x, v, maxit = 50L, reorthog = 0, upper.bound.prob = NULL) {\n            maxit <- as.integer(maxit)\n            reorthog <- as.integer(reorthog)\n            res <- .Call(\"GKLBidiag\", A = x, v = v, k = maxit, reorthog = reorthog, PACKAGE = \"rfunctions\")\n            res$upper.bound <- NULL\n            res$upper.bound.prob <- NULL\n            res\n          })\n\n\nsetMethod(\"gklBidiag\", signature(x = \"CsparseMatrix\", v = \"numeric\", maxit = \"numeric\", \n                                 reorthog = \"numeric\", upper.bound.prob = \"missing\"),\n          function(x, v, maxit = 50L, reorthog = 0, upper.bound.prob = NULL) {\n            maxit <- as.integer(maxit)\n            reorthog <- as.integer(reorthog)\n            res <- .Call(\"GKLBidiagSparse\", A = x, v = v, k = maxit, reorthog = reorthog, PACKAGE = \"rfunctions\")\n            res$upper.bound <- NULL\n            res$upper.bound.prob <- NULL\n            res\n          })\n\n" }
{ "repo_name": "edzer/gstat", "ref": "refs/heads/master", "path": "tests/sim.R", "content": "options(digits=6)\nlibrary(sp)\ndata(meuse)\nset.seed(158229572)\nnew.locs <- data.frame(x = c(181170, 180310, 180205, 178673, 178770, 178270),\n\ty = c(333250, 332189, 331707, 330066, 330675, 331075))\nlibrary(gstat)\nkrige(zinc ~ 1, ~ x + y, meuse, newdata = new.locs, \n\t\tmodel = vgm(1.34e5, \"Sph\", 800, nug = 2.42e4), \n\t\tblock = c(40,40), nmax = 40, nsim = 10)\n" }
{ "repo_name": "edzer/gstat", "ref": "refs/heads/master", "path": "tests/na.action.R", "content": "library(sp)\n\ndata(meuse)\ndata(meuse.grid)\n\nset.seed(13131) # reproduce results\n\n# select 10 random rows;\n# create two missing values in the coordinates:\nm = meuse.grid[sample(nrow(meuse.grid), 10), ]\nm[c(2,8), \"x\"] = NA\n\nlibrary(gstat)\n## this is not allowed anymore:\ntry(krige(log(zinc)~1,~x+y,meuse,m, na.action = na.pass))\ntry(krige(log(zinc)~1,~x+y,meuse,m, na.action = na.omit))\ntry(krige(log(zinc)~1,~x+y,meuse,m, na.action = na.exclude))\ntry(krige(log(zinc)~1,~x+y,meuse,m, na.action = na.fail))\n\n# select 10 random rows;\n# create two missing values in the regressor variable:\nm = meuse.grid[sample(nrow(meuse.grid), 10), ]\nm[c(3,7), \"dist\"] = NA\nkrige(log(zinc)~dist,~x+y,meuse,m, na.action = na.pass)\nkrige(log(zinc)~dist,~x+y,meuse,m, na.action = na.omit)\nkrige(log(zinc)~dist,~x+y,meuse,m, na.action = na.exclude)\ntry(krige(log(zinc)~dist,~x+y,meuse,m, na.action = na.fail))\n" }
{ "repo_name": "edzer/gstat", "ref": "refs/heads/master", "path": "demo/grass.R", "content": "# $Id: grass.R,v 1.4 2006-02-10 19:05:02 edzer Exp $\n# this demo assumes quite a lot:\n#  a. it assumes GRASS gis is running\n#  b. it assumes that the meuse data zinc variable is available as a site list\n#  c. it assumes that mask_map is present, and contains the mask map values\n#     (i.e., the study area)\n\nlibrary(sp)\nlibrary(GRASS)           # load R GRASS interface\n\nG = gmeta()              # retrieves active data base locations and topology\nd = sites.get(G, \"zinc\") # retrieve zinc observations \nplot(d$east, d$north, asp=1)\nnames(d)[4] = \"zinc\"     # rename attribute\nmask = rast.get\n\nhist(d$zinc)\nhist(log(d$zinc))\n\nmask = rast.get(G, \"mask_map\")\nplot(G, mask$mask.map)\npoints(d$east,d$north, pch=\"+\")\n\nlibrary(gstat)           # load gstat library\n\nbubble(d, zcol = \"zinc\", col=c(4,5), maxsize=2)\n\n# explain S formulae: ~\nv = variogram(log(zinc)~1, ~east+north, d)\nplot(v)\n\nv.mod = vgm(.6, \"Sph\", 900, .1)\nplot(v, model = v.mod)\n\nv.fit = fit.variogram(v, v.mod)\nplot(v, model = v.fit)\n\nzinc.g = gstat(NULL, \"lzinc\", log(zinc)~1, ~east+north, d, model = v.fit)\nnew.data = data.frame(east = east(G), north = north(G))\nnew.data[is.na(mask$mask.map), ] = c(NA,NA)\n\nzinc.kr = predict(zinc.g, new.data)\nimage(zinc.kr)\n\nlibrary(lattice)\n\nlevelplot(lzinc.pred~east+north, zinc.kr, asp=1.34, col.regions=bpy.colors(100))\n\n# push prediction and variances grids back into GRASS data base:\nrast.put(G, \"lzinc.pred\", zinc.kr$lzinc.pred)\nrast.put(G, \"lzinc.var\",  zinc.kr$lzinc.var)\n\n# push cross validation residuals back to GRASS data base:\nxv = krige.cv(log(zinc)~1, ~east+north, d, v.fit, nmax = 40, verb=F)\nsites.put2(G, data = xv, dims = c(\"east\", \"north\", \"residual\", \"zscore\"), \n\tlname = \"lzinc.xv\")\n" }
{ "repo_name": "edzer/gstat", "ref": "refs/heads/master", "path": "R/xyz2img.R", "content": "# $Id: xyz2img.q,v 1.4 2006-02-10 19:01:07 edzer Exp $\n\n\"xyz2img\" <-\nfunction (xyz, zcol = 3, xcol = 1, ycol = 2, tolerance = 10 * .Machine$double.eps) \n{\n    if (ncol(xyz) < 3) \n        stop(\"xyz object should have at least three columns\")\n    z = xyz[, zcol]\n    x = xyz[, xcol]\n    y = xyz[, ycol]\n    xx = sort(unique(x))\n    yy = sort(unique(y))\n    nx = length(xx)\n    ny = length(yy)\n    nmax = max(nx, ny)\n    difx = diff(xx)\n    if (diff(range(unique(difx))) > tolerance) \n        stop(\"x intervals are not constant\")\n    dify = diff(yy)\n    if (diff(range(unique(dify))) > tolerance) \n        stop(\"y intervals are not constant\")\n    dx = mean(difx)\n    dy = mean(dify)\n    xmin = min(xx)\n    xmax = max(xx)\n    xrange = xmax - xmin\n    ymin = min(yy)\n    ymax = max(yy)\n    yrange = ymax - ymin\n    row = round((x - xmin)/dx) + 1\n    col = round((y - ymin)/dy) + 1\n\tzz = rep(as.numeric(NA), nx * ny)\n\tzz[row + nx * (col - 1)] = z\n\tzz = matrix(zz, nrow = nx, ncol = ny)\n    list(x = seq(xmin, xmax, dx), y = seq(ymin, ymax, dy), z = zz)\n}\n" }
{ "repo_name": "edzer/gstat", "ref": "refs/heads/master", "path": "tests/vdist.R", "content": "library(sp)\nlibrary(gstat)\n\ndata(meuse)\ncoordinates(meuse) = ~x+y\ndata(meuse.grid)\ngridded(meuse.grid) = ~x+y\n\nmg = meuse.grid\ngridded(mg) = FALSE\nmg= mg[1500,]\nkrige(log(zinc)~1,meuse,mg,vgm(1, \"Exp\", 300, anis=c(0,0.01)),\n\tvdist=FALSE, maxdist=1000,nmax=10)\nkrige(log(zinc)~1,meuse,mg,vgm(1, \"Exp\", 300, anis=c(0,0.01)),\n\tvdist=TRUE, maxdist=1000,nmax=10)\n" }
{ "repo_name": "edzer/gstat", "ref": "refs/heads/master", "path": "demo/ikr.R", "content": "library(sp)\nlibrary(gstat)\ndata(meuse)\ndata(meuse.grid)\ncoordinates(meuse)=~x+y\ngridded(meuse.grid)=~x+y\nv = variogram(I(zinc < 500)~1,meuse)\nplot(v)\nvm = fit.variogram(v, vgm(1, \"Sph\", 300, 1))\nplot(v,vm)\nvm\n# possibly adjust sum of sill to be max. 0.25?\nik = krige(I(zinc>500)~1, meuse, meuse.grid, vm)\nspplot(ik[1],col.regions=bpy.colors())\nsummary(ik[[1]])\n# adjust values outside [0,1] to nearest limit:\nik[[1]][ik[[1]]<0] = 0\nik[[1]][ik[[1]]>1] = 1\nsummary(ik[[1]])\nspplot(ik[1],col.regions=bpy.colors())\n" }
{ "repo_name": "google/rappor", "ref": "refs/heads/master", "path": "analysis/R/alternative.R", "content": "# Copyright 2014 Google Inc. All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nlibrary(limSolve)\nlibrary(Matrix)\n\n# The next two functions create a matrix (G) and a vector (H) encoding\n# linear inequality constraints that a solution vector (x) must satisfy:\n#                       G * x >= H\n\n# Currently represent three sets of constraints on the solution vector:\n#  - all solution coefficients are nonnegative\n#  - the sum total of all solution coefficients is no more than 1\n#  - in each of the coordinates of the target vector (estimated Bloom filter)\n#    we don't overshoot by more than three standard deviations.\nMakeG <- function(n, X) {\n  d <- Diagonal(n)\n  last <- rep(-1, n)\n  rbind2(rbind2(d, last), -X)\n}\n\nMakeH <- function(n, Y, stds) {\n  # set the floor at 0.01 to avoid degenerate cases\n  YY <- apply(Y + 3 * stds,  # in each bin don't overshoot by more than 3 stds\n              1:2,\n              function(x) min(1, max(0.01, x)))  # clamp the bound to [0.01,1]\n\n  c(rep(0, n),  # non-negativity condition\n    -1,         # coefficients sum up to no more than 1\n    -as.vector(t(YY))   # t is important!\n    )\n}\n\nMakeLseiModel <- function(X, Y, stds) {\n  m <- dim(X)[1]\n  n <- dim(X)[2]\n\n# no slack variables for now\n#   slack <- Matrix(FALSE, nrow = m, ncol = m, sparse = TRUE)\n#   colnames(slack) <- 1:m\n#   diag(slack) <- TRUE\n#\n#   G <- MakeG(n + m)\n#   H <- MakeH(n + m)\n#\n#   G[n+m+1,n:(n+m)] <- -0.1\n#  A = cbind2(X, slack)\n\n  w <- as.vector(t(1 / stds))\n  w_median <- median(w[!is.infinite(w)])\n  if(is.na(w_median))  # all w are infinite\n    w_median <- 1\n  w[w > w_median * 2] <- w_median * 2\n  w <- w / mean(w)\n\n  list(# coerce sparse Boolean matrix X to sparse numeric matrix\n       A = Diagonal(x = w) %*% (X + 0),\n       B = as.vector(t(Y)) * w,  # transform to vector in the row-first order\n       G = MakeG(n, X),\n       H = MakeH(n, Y, stds),\n       type = 2)  # Since there are no equality constraints, lsei defaults to\n                  # solve.QP anyway, but outputs a warning unless type == 2.\n}\n\n# CustomLM(X, Y)\nConstrainedLinModel <- function(X,Y) {\n  model <- MakeLseiModel(X, Y$estimates, Y$stds)\n  coefs <- do.call(lsei, model)$X\n  names(coefs) <- colnames(X)\n\n  coefs\n}" }
{ "repo_name": "google/rappor", "ref": "refs/heads/master", "path": "analysis/R/fast_em.R", "content": "# fast_em.R: Wrapper around analysis/cpp/fast_em.cc.\n#\n# This serializes the input, shells out, and deserializes the output.\n\n.Flatten <- function(list_of_matrices) {\n  listOfVectors <- lapply(list_of_matrices, as.vector)\n  #print(listOfVectors)\n\n  # unlist takes list to vector.\n  unlist(listOfVectors)\n}\n\n.WriteListOfMatrices <- function(list_of_matrices, f) {\n  flattened <- .Flatten(list_of_matrices)\n\n  # NOTE: UpdateJointConditional does outer product of dimensions!\n\n  # 3 letter strings are null terminated\n  writeBin('ne ', con = f)\n  num_entries <- length(list_of_matrices)\n  writeBin(num_entries, con = f)\n\n  Log('Wrote num_entries = %d', num_entries)\n\n  # For 2x3, this is 6\n  writeBin('es ', con = f)\n\n  entry_size <- as.integer(prod(dim(list_of_matrices[[1]])))\n  writeBin(entry_size, con = f)\n\n  Log('Wrote entry_size = %d', entry_size)\n\n  # now write the data\n  writeBin('dat', con = f)\n  writeBin(flattened, con = f)\n}\n\n.ExpectTag <- function(f, tag) {\n  # Read a single NUL-terminated character string.\n  actual <- readBin(con = f, what = \"char\", n = 1)\n\n  # Assert that we got what was expected.\n  if (length(actual) != 1) {\n    stop(sprintf(\"Failed to read a tag '%s'\", tag))\n  }\n  if (actual != tag) {\n    stop(sprintf(\"Expected '%s', got '%s'\", tag, actual))\n  }\n}\n\n.ReadResult <- function (f, entry_size, matrix_dims) {\n  .ExpectTag(f, \"emi\")\n  # NOTE: assuming R integers are 4 bytes (uint32_t)\n  num_em_iters <- readBin(con = f, what = \"int\", n = 1)\n\n  .ExpectTag(f, \"pij\")\n  pij <- readBin(con = f, what = \"double\", n = entry_size)\n\n  # Adjust dimensions\n  dim(pij) <- matrix_dims\n\n  Log(\"Number of EM iterations: %d\", num_em_iters)\n  Log(\"PIJ read from external implementation:\")\n  print(pij)\n   \n  # est, sd, var_cov, hist\n  list(est = pij, num_em_iters = num_em_iters)\n}\n\n.SanityChecks <- function(joint_conditional) {\n  # Display some stats before sending it over to C++.\n\n  inf_counts <- lapply(joint_conditional, function(m) {\n    sum(m == Inf)\n  })\n  total_inf <- sum(as.numeric(inf_counts))\n\n  nan_counts <- lapply(joint_conditional, function(m) {\n    sum(is.nan(m))\n  })\n  total_nan <- sum(as.numeric(nan_counts))\n\n  zero_counts <- lapply(joint_conditional, function(m) {\n    sum(m == 0.0)\n  })\n  total_zero <- sum(as.numeric(zero_counts))\n\n  #sum(joint_conditional[joint_conditional == Inf, ])\n  Log('total inf: %s', total_inf)\n  Log('total nan: %s', total_nan)\n  Log('total zero: %s', total_zero)\n}\n\nConstructFastEM <- function(em_executable, tmp_dir) {\n\n  return(function(joint_conditional, max_em_iters = 1000,\n                  epsilon = 10 ^ -6, verbose = FALSE,\n                  estimate_var = FALSE) {\n    matrix_dims <- dim(joint_conditional[[1]])\n    # Check that number of dimensions is 2.\n    if (length(matrix_dims) != 2) {\n      Log('FATAL: Expected 2 dimensions, got %d', length(matrix_dims))\n      stop()\n    }\n\n    entry_size <- prod(matrix_dims)\n    Log('entry size: %d', entry_size)\n\n    .SanityChecks(joint_conditional)\n\n    input_path <- file.path(tmp_dir, 'list_of_matrices.bin')\n    Log(\"Writing flattened list of matrices to %s\", input_path)\n    f <- file(input_path, 'wb')  # binary file\n    .WriteListOfMatrices(joint_conditional, f)\n    close(f)\n    Log(\"Done writing %s\", input_path)\n     \n    output_path <- file.path(tmp_dir, 'pij.bin')\n\n    cmd <- sprintf(\"%s %s %s %s\", em_executable, input_path, output_path,\n                   max_em_iters)\n\n    Log(\"Shell command: %s\", cmd)\n    exit_code <- system(cmd)\n\n    Log(\"Done running shell command\")\n    if (exit_code != 0) {\n      stop(sprintf(\"Command failed with code %d\", exit_code))\n    }\n\n    f <- file(output_path, 'rb')\n    result <- .ReadResult(f, entry_size, matrix_dims)\n    close(f)\n\n    result\n  })\n}\n" }
{ "repo_name": "kwanjeeraw/grinn", "ref": "refs/heads/master", "path": "R/getGrinnDb.R", "content": "#'Get Grinn database location\n#'@description get Grinn database location of the current working envornment. \n#'By default Grinn database lacation is http://grinn.genomecenter.ucdavis.edu:7474/db/data/cypher \n#'which contains only human database.\n#'@usage getGrinnDb()\n#'@return url of Grinn database location.\n#'@author Kwanjeera W \\email{kwanich@@ucdavis.edu}\n#'@export\ngetGrinnDb <- function(){\n  print(nld)\n}" }
{ "repo_name": "kwanjeeraw/grinn", "ref": "refs/heads/master", "path": "R/fetchtRelation.R", "content": "#' \\code{fetchRelation} get path information\n#'@description get path information as the output for further uses by \\code{formatNetworkOutput}.\n#'@seealso \\code{formatNetworkOutput}\n#'#result <- fetchRelation(\"http://localhost:7474/db/data/relationship/53\")\n#'#return start-relation-end\n\nfetchRelation <- function(url){\n  out <- tryCatch(\n  {\n    path = curlRequestUrlToList(url)\n    start = curlRequestUrlToList(path$start)\n    end = curlRequestUrlToList(path$end)\n    type = path$type\n    dataSource = path$data$source\n    startGID = start$data$GID\n    startName = start$data$name\n    startXref = paste0(start$data$xref,collapse = \"||\")\n    startLabel = start$metadata$labels[[1]]\n    endGID = end$data$GID\n    endName = end$data$name\n    endXref = paste0(end$data$xref,collapse = \"||\")\n    endLabel = end$metadata$labels[[1]]\n    ## Set the name for the class\n    relation = list(startGID=startGID, startName=startName, startXref=startXref, startLabel=startLabel, \n                    endGID=endGID, endName=endName, endXref=endXref, endLabel=endLabel, type=type, dataSource=dataSource)\n  },\n  error=function(e) {\n    message(e)\n    cat(\"\\n..RETURN empty list of relations\")\n    out = list() # Choose a return value in case of error\n  })    \n  return(out)\n}\n\nfetchRelation.TRANSACTION <- function(graph){\n  out <- tryCatch(\n    {\n      ## Set the name for the class\n      data.frame(t(sapply(graph$graph$relationships, \n                                 function(x) list(source=x$startNode, target=x$endNode, relname=x$type, relsource=x$properties[\"source\"]))))\n      \n      #relationInfo = list(source=graph$graph$relationships[[1]]$startNode, target=graph$graph$relationships[[1]]$endNode, relname=graph$graph$relationships[[1]]$type, relsource=graph$graph$relationships[[1]]$properties[\"source\"])\n    },\n    error=function(e) {\n      message(e)\n      cat(\"\\n..RETURN empty list of relations\")\n      out = data.frame() # Choose a return value in case of error\n    })    \n  return(out)\n}\n\nfetchNode.TRANSACTION <- function(node){\n  out <- tryCatch(\n    {\n      data.frame(t(sapply(node, \n                          function(x) list(id=x$id, gid=x$properties$GID, nodename=x$properties$name, xref=paste0(x$properties$xref,collapse = \"||\"), nodetype=x$labels))))\n      #nodeInfo = list(id=node$id, gid=node$properties$GID, nodename=node$properties$name, xref=paste0(node$properties$xref,collapse = \"||\"), nodetype=node$labels)\n    },\n    error=function(e) {\n      message(e)\n      cat(\"\\n..RETURN empty list of relations\")\n      out = data.frame() # Choose a return value in case of error\n    })    \n  return(out)\n}" }
{ "repo_name": "kwanjeeraw/grinn", "ref": "refs/heads/master", "path": "inst/shiny/layout/setdb.R", "content": "mainPanel(width=12,\n          fluidRow(column(12,\n                          mainPanel(width=12,\n                                    h3(\"setGrinnDb\"),\n                                    p(\"Set the graph database location for the currently working environment, see \",\n                                      a(href='http://kwanjeeraw.github.io/grinn/setdb.html',target='_blank','here'),' for argument details.'\n                                    )\n                          )#end mainPanel\n          )),\n          wellPanel(\n            h4(\"Current database location:\"),\n            fluidRow(\n              column(12, verbatimTextOutput(\"currentdb\"))\n            ),\n            h4(\"Input arguments:\"), helpText(\"* required field\"),\n            fluidRow(\n              column(6, textInput(inputId='dburl', label='url *', value=\"\"))\n            ),\n            hr(),\n            actionButton(\"submit\",\"Submit\")\n          )\n)" }
{ "repo_name": "kwanjeeraw/grinn", "ref": "refs/heads/master", "path": "R/fetchNodeRelation.R", "content": "#' \\code{fetchNodeRelation} format get node relationships\n#'@description get node relationships as the output for further uses by \\code{formatNodeOutput}.\n#'@seealso \\code{formatNodeOutput}\n#'#result <- fetchNodeRelation(\"http://localhost:7474/db/data/node/53/relationships/in\")\n#'#return start-relation-end\n\nfetchNodeRelation <- function(url){\n  path = curlRequestUrlToList(url)\n  relations = list()\n  if(length(path)>0){\n    for(i in 1:length(path)){\n      start = curlRequestUrlToList(path[[i]]$start)\n      end = curlRequestUrlToList(path[[i]]$end)\n      type = path[[i]]$type\n      dataSource = path[[i]]$data$source\n      startGID = start$data$GID\n      startName = start$data$name\n      startXref = paste0(start$data$xref,collapse = \"||\")\n      startLabel = start$metadata$labels[[1]]\n      endGID = end$data$GID\n      endName = end$data$name\n      endXref = paste0(end$data$xref,collapse = \"||\")\n      endLabel = end$metadata$labels[[1]]\n      ## Set the name for the class\n      relation = data.frame(startGID=startGID, startName=startName, startXref=startXref, startLabel=startLabel, \n                      endGID=endGID, endName=endName, endXref=endXref, endLabel=endLabel, type=type, dataSource=dataSource)\n      relations = rbind(relations,relation)\n    }\n    relations <- unique(relations)\n  }else{\n    #cat(\"\\n..RETURN empty list\")\n    relations = list() # Choose a return value in case of error\n  } \n  return(relations)\n}" }
{ "repo_name": "sestelo/shiny_npregfast", "ref": "refs/heads/master", "path": "ui.R", "content": "#detach(\"package:npregfast\")\nlibrary(shiny)\n#library(shinyjs)\nlibrary(miniUI)\nlibrary(wesanderson)\nlibrary(npregfast)\n\n\nshinyUI(fluidPage(\n  title = \"Demo of npregfast\",\n  tags$head(includeCSS(file.path('www', 'style.css'))),   \n  shinyjs::useShinyjs(),\n  \n  fluidRow(id = \"title-row\",\n           column(12,\n                  h1(\"Demo of\",em(a(\"npregfast\", href = \"https://github.com/sestelo/npregfast\"))),\n                  h4(\"Example with\", a(\"barnacle\", href = \"https://github.com/sestelo/npregfast/blob/master/man/barnacle.Rd\"),\" data set\"),\n                  div(\"Created by\", a(\"Marta Sestelo\", href = \"http://sestelo.github.io\"),\n                      \"and\", a(\"Nora M. Villanueva\",href = \"http://noramvillanueva.github.io\"), HTML(\"&bull;\"),\n                      \"Code on\", a(\"GitHub\", href = \"https://github.com/sestelo/shiny_npregfast/\")\n                  )\n           )\n  ),\n  \n  \n  \n  div(id = \"loading-content\", h2(\"Loading...\")),\n  \n  fluidRow(id = \"app-content\",\n           column(2, wellPanel(\n             class = \"settings\",\n             h4(class = \"settings-title\", \"Estimation\"),\n             \n             selectInput(inputId = \"type\", \n                         label = \"Factor-by-curve interaction?\",\n                         choices = c(\"Without\" = \"without\", \"With\" = \"with\")),\n             \n             selectInput(inputId = \"kernel\",\n                         label = \"Choose a kernel:\",\n                         choices = c(\"Epanechnikov\" = \"epanech\", \n                                     \"Gaussian\" = \"gaussian\",\n                                     \"Triangular\" = \"triang\")),\n             \n             selectInput(inputId = \"poly\",\n                         label = \"Polynomial degree:\",\n                         choices = c(1, \n                                     2,\n                                     3),\n                         selected = 3),\n             \n             radioButtons(inputId = \"selband\",\n                          label = \"Bandwidth selection:\",\n                          choices = c(\"Cross-validation\" = \"cv\", \n                                      \"Manual\" = \"man\"),\n                          selected = \"cv\"),\n             \n             conditionalPanel(\n               condition = \"input.selband == 'man'\",\n               sliderInput(inputId = \"band\",\n                           label = \"Bandwidth selection:\",\n                           min = 0,\n                           max = 1,\n                           value = 0.5,\n                           step = 0.1, \n                           ticks = TRUE,\n                           animate = TRUE))\n             \n           )),\n           \n           \n           \n           \n           \n           column(2, wellPanel(\n             class = \"settings\",\n             h4(class = \"settings-title\", \"Graphical\"),\n             \n             conditionalPanel(\n               condition = \"input.poly == 1\",\n               checkboxGroupInput(inputId = \"der1\",\n                                  label = \"Output:\",\n                                  choices = c(\"Conditional mean\" = '0'),\n                                  selected = '0')),\n             \n             conditionalPanel(\n               condition = \"input.poly == 2\",\n               checkboxGroupInput(inputId = \"der2\",\n                                  label = \"Output:\",\n                                  choices = c(\"Conditional mean\" = '0', \n                                              \"First derivative\" = '1'),\n                                  selected = '0')),\n             \n             conditionalPanel(\n               condition = \"input.poly == 3\",\n               checkboxGroupInput(inputId = \"der3\",\n                                  label = \"Output:\",\n                                  choices = c(\"Conditional mean\" = '0', \n                                              \"First derivative\" = '1',\n                                              \"Second derivative\" = '2'),\n                                  selected = '0')),\n             \n             \n             \n             \n             div(id = \"marginal-settings\",\n                 shinyjs::colourInput(\"colmu\", \"Line color\", \"#D67236\", \n                                      showColour = \"background\",\n                                      palette = \"limited\",\n                                      allowedCols = unlist(wes_palettes),\n                                      allowTransparent = FALSE),\n                 \n                 \n                 shinyjs::colourInput(\"colci\", \"CI color\", \"#5B1A18\", \n                                      showColour = \"background\",\n                                      palette = \"limited\",\n                                      allowedCols = unlist(wes_palettes),\n                                      allowTransparent = FALSE)\n             ),\n             \n             conditionalPanel(\n               condition =\"input.poly == 1 & input.der1[0] == '0'||input.poly == 2 & input.der2[0] == '0'||input.poly == 3 & input.der3[0] == '0'\",\n               checkboxInput(\"show_points\", \"Show data points\", TRUE),\n               conditionalPanel(\n                 condition =\"input.show_points == true\",\n                 shinyjs::colourInput(\"pcol\", \"Points color\", \"#899DA4\", \n                                      showColour = \"background\",\n                                      palette = \"limited\",\n                                      allowedCols = unlist(wes_palettes),\n                                      allowTransparent = FALSE)\n               )\n             )\n           )),\n           \n           \n           \n           column(8,\n                  plotOutput(\"distPlot\", \n                             height = \"500px\", \n                             width = \"100%\",\n                             click = \"plot1_click\",\n                             brush = brushOpts(id = \"plot1_brush\"),\n                  ),\n                  \n                  miniButtonBlock(\n                   \n                    actionButton(\"exclude_toggle\", \"Toggle points\",\n                                 icon = icon(\"fa fa-codiepie\", class = \"fa-1x\")),\n                    \n                    actionButton(\"exclude_reset\", \"Reset\", \n                                 icon = icon(\"fa fa-refresh\", class = \"fa-1x\")),\n                    actionButton(inputId =\"info_btn\", \n                                 label = \"Info\", \n                                 icon = icon(\"fa fa-info-circle\", class = \"fa-1x\"))\n                    \n                  )\n                  \n                  \n                 # includeMarkdown(\"plot_shiny.md\")\n                  \n                  \n                  \n           )\n           \n  )\n))\n\n\n\n\n\n\n\n\n" }
{ "repo_name": "FrissAnalytics/shinyJsTutorials", "ref": "refs/heads/master", "path": "tutorials/materials2/C3/R/C3Pie.R", "content": "#' <Add Title>\n#'\n#' <Add Description>\n#'\n#' @import htmlwidgets\n#'\n#' @export\nC3Pie <- function(values, legendPosition = \"bottom\", width = NULL, height = NULL) {\n\n  # forward options using x\n  x = list(\n    values = values,\n    legendPosition = legendPosition\n  )\n\n  # create widget\n  htmlwidgets::createWidget(\n    name = 'C3Pie',\n    x,\n    width = width,\n    height = height,\n    package = 'C3'\n  )\n}\n\n#' Shiny bindings for C3Pie\n#'\n#' Output and render functions for using C3Pie within Shiny\n#' applications and interactive Rmd documents.\n#'\n#' @param outputId output variable to read from\n#' @param width,height Must be a valid CSS unit (like \\code{'100\\%'},\n#'   \\code{'400px'}, \\code{'auto'}) or a number, which will be coerced to a\n#'   string and have \\code{'px'} appended.\n#' @param expr An expression that generates a C3Pie\n#' @param env The environment in which to evaluate \\code{expr}.\n#' @param quoted Is \\code{expr} a quoted expression (with \\code{quote()})? This\n#'   is useful if you want to save an expression in a variable.\n#'\n#' @name C3Pie-shiny\n#'\n#' @export\nC3PieOutput <- function(outputId, width = '100%', height = '400px'){\n  htmlwidgets::shinyWidgetOutput(outputId, 'C3Pie', width, height, package = 'C3')\n}\n\n#' @rdname C3Pie-shiny\n#' @export\nrenderC3Pie <- function(expr, env = parent.frame(), quoted = FALSE) {\n  if (!quoted) { expr <- substitute(expr) } # force quoted\n  htmlwidgets::shinyRenderWidget(expr, C3PieOutput, env, quoted = TRUE)\n}\n" }
{ "repo_name": "FrissAnalytics/shinyJsTutorials", "ref": "refs/heads/master", "path": "tutorials/materials2/C3/R/C3LineBarChart.R", "content": "#' <Add Title>\n#'\n#' <Add Description>\n#'\n#' @import htmlwidgets\n#'\n#' @export\nC3LineBarChart <- function(dataset, colors, width = NULL, height = NULL) {\n\n  # forward options using x\n  x = list(\n    dataset  = dataset,\n    colors   = colors\n  )\n\n  # create widget\n  htmlwidgets::createWidget(\n    name = 'C3LineBarChart',\n    x,\n    width = width,\n    height = height,\n    package = 'C3'\n  )\n}\n\n#' Shiny bindings for C3LineBarChart\n#'\n#' Output and render functions for using C3LineBarChart within Shiny\n#' applications and interactive Rmd documents.\n#'\n#' @param outputId output variable to read from\n#' @param width,height Must be a valid CSS unit (like \\code{'100\\%'},\n#'   \\code{'400px'}, \\code{'auto'}) or a number, which will be coerced to a\n#'   string and have \\code{'px'} appended.\n#' @param expr An expression that generates a C3LineBarChart\n#' @param env The environment in which to evaluate \\code{expr}.\n#' @param quoted Is \\code{expr} a quoted expression (with \\code{quote()})? This\n#'   is useful if you want to save an expression in a variable.\n#'\n#' @name C3LineBarChart-shiny\n#'\n#' @export\nC3LineBarChartOutput <- function(outputId, width = '100%', height = '400px'){\n  htmlwidgets::shinyWidgetOutput(outputId, 'C3LineBarChart', width, height, package = 'C3')\n}\n\n#' @rdname C3LineBarChart-shiny\n#' @export\nrenderC3LineBarChart <- function(expr, env = parent.frame(), quoted = FALSE) {\n  if (!quoted) { expr <- substitute(expr) } # force quoted\n  htmlwidgets::shinyRenderWidget(expr, C3LineBarChartOutput, env, quoted = TRUE)\n}\n" }
{ "repo_name": "swarm-lab/Shiny", "ref": "refs/heads/master", "path": "aggregation_segregation/global.R", "content": "rw <- function(df) {\n  n <- nrow(df)\n  \n  within(df, {\n    h <- h + rnorm(n, sd = pi / 6)\n    x <- x + s * cos(h)\n    y <- y + s * sin(h)\n    \n    h[x < -1] <- 0\n    h[x > 1] <- pi\n    h[y < -1] <- pi / 2\n    h[y > 1] <- -pi / 2\n  })\n}\n\nsigmoid <- function(x, a = 0, k = 1, b = 0.1, m = 100, v = 1, q = 1) {\n  a + (k - a) / ((1 + q * exp(-b * (x - m))) ^ (1 / v))\n}\n\npdist <- function(A, B) {\n  an = apply(A, 1, function(rvec) crossprod(rvec,rvec))\n  bn = apply(B, 1, function(rvec) crossprod(rvec,rvec))\n  \n  m = nrow(A)\n  n = nrow(B)\n  \n  tmp = matrix(rep(an, n), nrow = m) \n  tmp = tmp +  matrix(rep(bn, m), nrow = m, byrow = TRUE)\n  sqrt( tmp - 2 * tcrossprod(A,B) )\n}\n\nsp <- function(df, affinSame = 0, affinOther = 0) {\n  dist <- pdist(as.matrix(df[, 1:2]), as.matrix(df[, 1:2]))\n  neighbor <- dist < 0.125\n  b_neighbor <- apply(df$col == \"#107AB6\" & neighbor, 2, sum) - (df$col == \"#107AB6\")\n  r_neighbor <- apply(df$col == \"#D86810\" & neighbor, 2, sum) - (df$col == \"#D86810\")\n  \n  nb <- (df$col == \"#107AB6\") * affinSame * b_neighbor + \n    (df$col == \"#D86810\") * affinSame * r_neighbor + \n    (df$col == \"#107AB6\") * affinOther * r_neighbor + \n    (df$col == \"#D86810\") * affinOther * b_neighbor\n  \n  df$s <- sigmoid(nb, k = 0.1, m = 4, b = -1)\n  df\n}\n\npop <- NULL\nrun <- FALSE\n" }
{ "repo_name": "swarm-lab/Shiny", "ref": "refs/heads/master", "path": "wisdom_of_crowds/model/old/server_old.R", "content": "library(shiny)\nlibrary(dplyr)\nlibrary(ggplot2)\nsource(\"ibm.R\")\n\nshinyServer(function(input, output, session) {  \n  \n  dat <- reactiveValues(tab = NULL)\n  counter <- reactiveValues(count = -1)\n  \n  observe({\n    if (counter$count != input$goButton) {\n      counter$count <- input$goButton\n      \n      withProgress(message = \"Simulating 1000 experiments\", value = 0, {\n        n <- 1000\n        \n        m1 <- replicate(n, woc(n = input$n, \n                               val = input$val,\n                               error = input$error,\n                               soc = 0))\n        \n        m2 <- replicate(n, woc(n = input$n, \n                               val = input$val,\n                               error = input$error,\n                               soc = input$soc))\n        \n        dat$tab <- data.frame(SOC = as.factor(rep(c(\"Control   \", \"Experimental   \"), each = n * 2)),\n                              TYPE = rep(c(\"mean\", \"sd\", \"mean\", \"sd\"), each = n),\n                              VAL = c(apply(m1, 2, mean),\n                                      apply(m1, 2, sd),\n                                      apply(m2, 2, mean),\n                                      apply(m2, 2, sd)))\n      }) \n    }\n  })\n  \n  output$IBM.plot1 <- renderPlot({\n    g <- ggplot(filter(dat$tab, TYPE == \"mean\"),\n                aes(x = VAL, color = SOC)) + \n      geom_density(size = 1) +\n      theme_minimal(base_size = 18) + \n      theme(legend.position = \"top\", legend.title = element_blank()) +\n      xlab(\"Group average\") + ylab(\"Density\") +\n      scale_color_manual(values = c(\"tomato3\", \"dodgerblue3\"))\n    \n    print(g)\n  })\n  \n  output$IBM.plot2 <- renderPlot({\n    g <- ggplot(filter(dat$tab, TYPE == \"sd\"),\n                aes(x = VAL, color = SOC)) + \n      geom_density(size = 1) +\n      theme_minimal(base_size = 18) + \n      theme(legend.position = \"top\", legend.title = element_blank()) +\n      xlab(\"Group standard deviation\") + ylab(\"Density\") +\n      scale_color_manual(values = c(\"tomato3\", \"dodgerblue3\"))\n    \n    print(g)\n  })\n})\n" }
{ "repo_name": "swarm-lab/Shiny", "ref": "refs/heads/master", "path": "wisdom_of_crowds/model/server.R", "content": "shinyServer(function(input, output, session) {\n  \n  react <- reactiveValues(tab = {}, count = -1)\n  \n  observe({\n    if (react$count != input$goButton) {\n      react$count <- input$goButton\n      \n      withProgress(message = \"Simulating 1000 experiments\", {\n        m1 <- replicate(N, woc(n = input$n, \n                               val = 200,\n                               error = input$error / 100,\n                               soc = 0))\n        tmp1 <- abs(m1 - 200) \n        tmp2 <- abs(matrix(apply(m1, 2, mean), nrow = input$n, ncol = 1000, byrow = TRUE) - 200)\n        r1 <- apply(tmp2 < tmp1, 2, sum)\n        \n        m2 <- replicate(N, woc(n = input$n, \n                               val = 200,\n                               error = input$error / 100,\n                               soc = input$soc))\n        tmp1 <- abs(m2 - 200) \n        tmp2 <- abs(matrix(apply(m2, 2, mean), nrow = input$n, ncol = 1000, byrow = TRUE) - 200)\n        r2 <- apply(tmp2 < tmp1, 2, sum)\n        \n        react$tab <- data.frame(\n          SOC = as.factor(rep(c(\"Control   \", \"Experimental   \"), each = N * 2)),\n          TYPE = rep(c(\"mean\", \"sd\", \"mean\", \"sd\"), each = N),\n          VAL = c(100 * (r1 / input$n),\n                  apply(m1, 2, sd),\n                  100 * (r2 / input$n),\n                  apply(m2, 2, sd)))\n      }) \n    }\n  })\n  \n  output$IBM.plot1 <- renderPlot({\n    g <- ggplot(filter(react$tab, TYPE == \"mean\"),\n                aes(x = VAL, color = SOC, fill = SOC)) + \n      geom_histogram(position = \"identity\", bins = 40) +\n      geom_vline(xintercept = 50, linetype = 2) +\n      xlim(0, 100) +\n      theme_minimal(base_size = 16) + \n      theme(legend.position = \"top\", legend.title = element_blank()) +\n      xlab(\"Average > x% of group members\") + ylab(\"Density\") +\n      scale_color_manual(values = c(\"tomato3\", \"dodgerblue3\")) + \n      scale_fill_manual(values = alpha(c(\"tomato3\", \"dodgerblue3\"), 0.25))\n    \n    print(g)\n  })\n  \n  output$IBM.plot2 <- renderPlot({\n    g <- ggplot(filter(react$tab, TYPE == \"sd\"),\n                aes(x = VAL, color = SOC, fill = SOC)) + \n      geom_histogram(position = \"identity\", bins = 40) +\n      theme_minimal(base_size = 16) + \n      theme(legend.position = \"top\", legend.title = element_blank()) +\n      xlab(\"Group standard deviation\") + ylab(\"Density\") +\n      scale_color_manual(values = c(\"tomato3\", \"dodgerblue3\")) + \n      scale_fill_manual(values = alpha(c(\"tomato3\", \"dodgerblue3\"), 0.25))\n    \n    print(g)\n  })\n})\n" }
{ "repo_name": "swarm-lab/Shiny", "ref": "refs/heads/master", "path": "opinion_dynamic/global.R", "content": "grid_sys <- function(time, init, parms) {\n  o1 <- init\n  o1[o1 < 0] <- 0\n  \n  o2 <- init\n  o2[o2 > 0] <- 0\n  \n  p1 <- eightneighbors(o1) / 8\n  p2 <- p1 - eightneighbors(o2) / 8\n  \n  r <- runif(nrow(init) * ncol(init))\n  \n  idx1 <- r <= p1\n  idx2 <- r <= p2 & r > p1\n  \n  init[idx1] <- 1 * parms$w1\n  init[idx2] <- -1 * parms$w2\n  \n  init\n}\n\n\n\n\n\n\n" }
{ "repo_name": "swarm-lab/Shiny", "ref": "refs/heads/master", "path": "wisdom_of_crowds/experiment/panels/panel3.R", "content": "panel3 <- bsCollapsePanelNoHead(\n  title = \"NULL\", id = \"col3\", value = \"col3\",\n\n  div(class = \"button\",\n      uiOutput(\"plot_title\"),\n      \n      plotOutput(\"dots\", width = \"400px\", inline = TRUE),\n      \n      h4(textOutput(\"time_left\"))\n  )\n)\n" }
{ "repo_name": "bryantrobbins/baseball", "ref": "refs/heads/master", "path": "worker/build/staging/generic.R", "content": "library(jsonlite)\nlibrary(plyr)\nquery <- fromJSON('config.json')\n\ntableName <- query$table\nload(paste(tableName,'Rdata', sep = '.'))\nmy.table <- eval(parse(text = tableName))\n\nfilterv <- rep(TRUE, nrow(my.table))\nif ('filter' %in% names(query$metadata)) {\n\tfilters <- query$metadata$filter\n\tfor (i in 1:length(filters)){\n\t\tif(!is.na(filters[i,1])) {\n\t\t\tfilterv <- filterv & grepl(filters[i,1], my.table[[query$metadata$colName[i]]]) \n\t\t}\n\t\tif (!is.na(filters[i,2])) {\n\t\t\tfilterv <- filterv & my.table[[query$metadata$colName[i]]] > filters[i,2]\n\t\t}\n\t\tif (!is.na(filters[i,3])) {\n\t\t\tfilterv <- filterv & my.table[[query$metadata$colName[i]]] < filters[i,3]\t\n\t\t}\n\t}\n}\n\nout.tab <- my.table[query$metadata$colName][which(filterv),]\n\nif ('fields' %in% names(query$export)) {\n\tdecr <- query$export$fields[[1]]$value[2] == 'desc' \n\tout.tab <- out.tab[order(out.tab[[query$export$fields[[1]]$value[1]]], decreasing = decr),]\n}\n\n\n#fix POS variable\nif('POS' %in% colnames(out.tab)) {\n\tref.v <- c('P' = 1, 'C' = 2, '1B' = 3, '2B' = 4, '3B' = 5, 'SS' = 6, 'LF' = 7, 'CF' = 8, 'RF' = 9, 'OF' = 10, 'DH' = 11)\n\tout.tab$POS <- names(ref.v)[out.tab$POS]\n}\nwrite.csv(out.tab, file = 'output.csv')\n" }
{ "repo_name": "broadinstitute/gatk", "ref": "refs/heads/master", "path": "src/main/resources/org/broadinstitute/hellbender/tools/picard/analysis/qualityScoreDistribution.R", "content": "# Script to generate a chart of quality score distribution in a file\n# @author Tim Fennell\n\n# Parse the arguments\nargs <- commandArgs(trailing=T)\nmetricsFile  <- args[1]\noutputFile   <- args[2]\nbamFile  <- args[3]\nsubtitle <- ifelse(length(args) < 4, \"\", args[4])\n\n# Figure out where the metrics and the histogram are in the file and parse them out\nstartFinder <- scan(metricsFile, what=\"character\", sep=\"\\n\", quiet=TRUE, blank.lines.skip=FALSE)\n\nfirstBlankLine=0\n\nfor (i in 1:length(startFinder))\n{\n        if (startFinder[i] == \"\") {\n                if (firstBlankLine==0) {\n                        firstBlankLine=i+1\n                } else {\n                        secondBlankLine=i+1\n                        break\n                }\n        }\n}\n\nmetrics <- read.table(metricsFile, header=T, nrows=1, sep=\"\\t\", skip=firstBlankLine)\nhistogram <- read.table(metricsFile, header=T, sep=\"\\t\", skip=secondBlankLine)\n\n# Then plot the histogram as a PDF\npdf(outputFile)\n\nplot(histogram$QUALITY,\n     histogram$COUNT_OF_Q,\n     type=\"n\",\n     main=paste(\"Quality Score Distribution\\nin file \",bamFile,\" \",ifelse(subtitle == \"\",\"\",paste(\"(\",subtitle,\")\",sep=\"\")),sep=\"\"),\n     xlab=\"Quality Score\",\n     ylab=\"Observations\")\n\nqColor  <- \"blue\"\noqColor <- \"lightcyan2\"\nwidth <- 5\n\n# Plot OQ first so that it's \"behind\" the regular qualities\nif (!is.null(histogram$COUNT_OF_OQ)) {\n    lines(histogram$QUALITY+0.25, histogram$COUNT_OF_OQ, type=\"h\", col=oqColor, lty=1, lwd=width, lend=\"square\");\n}\n\n# Then plot the regular qualities\nlines(histogram$QUALITY, histogram$COUNT_OF_Q, type=\"h\", col=qColor, lty=1, lwd=width, lend=\"square\");\n\n# And add a legend\nlegend(\"topleft\", pch=c(15,15), legend=c(\"Quality Scores\", \"Original Quality Scores\"), col=c(qColor, oqColor))\n\ndev.off()\n\n" }
{ "repo_name": "RevolutionAnalytics/miniCRAN", "ref": "refs/heads/master", "path": "inst/doc/miniCRAN-non-CRAN-repos.R", "content": "## ----setup---------------------------------------------------------------\n# Wrapper around available.packages ---------------------------------------\n \nindex <- function(url, type=\"source\", filters=NULL, head=5, cols=c(\"Package\", \"Version\")){\n  contribUrl <- contrib.url(url, type=type)\n  p <- available.packages(contribUrl, type=type, filters=filters)\n  p[1:head, cols]\n}\n \n\n## ----CRAN, eval=FALSE----------------------------------------------------\n#  CRAN <- \"http://cran.r-project.org\"\n#  index(CRAN)\n\n## ----revo, eval=FALSE----------------------------------------------------\n#  revoStable <- \"http://packages.revolutionanalytics.com/cran/3.1/stable\"\n#  index(revoStable)\n#  \n#  revoMirror <- \"http://cran.revolutionanalytics.com\"\n#  index(revoMirror)\n\n## ----rforge, eval=FALSE--------------------------------------------------\n#  rforge <- \"http://r-forge.r-project.org\"\n#  index(rforge)\n\n## ----bioc, eval=FALSE----------------------------------------------------\n#  bioc <- local({\n#    env <- new.env()\n#    on.exit(rm(env))\n#    evalq(source(\"http://bioconductor.org/biocLite.R\", local=TRUE), env)\n#    biocinstallRepos()\n#  })\n#  \n#  bioc\n#  bioc[grep(\"BioC\", names(bioc))]\n#  \n#  \n#  index(bioc[\"BioCsoft\"])\n\n" }
{ "repo_name": "RevolutionAnalytics/miniCRAN", "ref": "refs/heads/master", "path": "inst/examples/example_pkgDep.R", "content": "\n\\dontrun{\npkgDep(pkg = c(\"ggplot2\", \"plyr\", \"reshape2\"), \n       repos = c(CRAN = \"http://mran.microsoft.com\")\n)\n}\n\npdb <- cranJuly2014\n\\dontrun{\npdb <- pkgAvail(repos = c(CRAN = \"http://mran.microsoft.com\"))\n}\n\npkgDep(pkg=c(\"ggplot2\", \"plyr\", \"reshape2\"), pdb)\n\n" }
{ "repo_name": "RevolutionAnalytics/miniCRAN", "ref": "refs/heads/master", "path": "inst/examples/example_plot.pkgDepGraph.R", "content": "tags <- \"chron\"\n\n# Plot using defaults\npdb <- cranJuly2014\n\n\\dontrun{\n  pdb <- pkgAvail(\n    repos = c(CRAN = \"http://mran.microsoft.com\"),\n    type=\"source\"\n  )\n}\n\ndg <- makeDepGraph(tags, availPkgs = pdb  , includeBasePkgs=FALSE, suggests=TRUE, enhances=TRUE)\n\nset.seed(42); \nplot(dg)\n\n# Move edge legend to top left\nset.seed(42); \nplot(dg, legendPosition=c(-1, 1))\n\n# Change font size and shape size\nset.seed(42); \nplot(dg, legendPosition=c(-1, 1), vertex.size=20,  cex=0.5)\n\n\n# Move vertex legend to top right\nset.seed(42); \nplot(dg, legendPosition=c(1, 1), vertex.size=20,  cex=0.5)\n\n" }
{ "repo_name": "RevolutionAnalytics/miniCRAN", "ref": "refs/heads/master", "path": "R/pkgDepTools.R", "content": "# Code copied from the pkgDepTools project\n# Copyright (C) Seth Falcon\n# http://www.bioconductor.org/packages/release/bioc/html/pkgDepTools.html\n# \n# This program is free software; you can redistribute it and/or\n# modify it under the terms of the GNU General Public License version 2\n# as published by the Free Software Foundation\n\n\n\n# Code copied from the pkgDepTools project\n# Copyright (C) Seth Falcon\n# http://www.bioconductor.org/packages/release/bioc/html/pkgDepTools.html\n\n\n# Copy of tools:::split_op_version.\n\n# @rdname pkgDepTools\n# @keywords internal\nsplit_op_version <- function (x) {\n  pat <- \"^([^\\\\([:space:]]+)[[:space:]]*\\\\(([^\\\\)]+)\\\\).*\"\n  x1 <- sub(pat, \"\\\\1\", x)\n  x2 <- sub(pat, \"\\\\2\", x)\n  if (x2 != x1) {\n    pat <- \"[[:space:]]*([[<>=!]+)[[:space:]]+(.*)\"\n    version <- sub(pat, \"\\\\2\", x2)\n    if (!grepl(\"^r\", version)) \n      version <- package_version(version)\n    list(name = x1, op = sub(pat, \"\\\\1\", x2), version = version)\n  }\n  else list(name = x1)\n}\n\n\n# Copy of tools:::.split_dependencies.\n\n# @rdname pkgDepTools\n# @keywords internal\nsplit_dependencies <- function (x) {\n  if (!length(x)) \n    return(list())\n  x <- unlist(strsplit(x, \",\"))\n  x <- sub(\"[[:space:]]+$\", \"\", x)\n  x <- unique(sub(\"^[[:space:]]*(.*)\", \"\\\\1\", x))\n  names(x) <- sub(\"^([[:alnum:].]+).*$\", \"\\\\1\", x)\n  lapply(x, split_op_version)\n}\n\n\n# Clean package fields.\n# \n# Given the value from a field like 'Depends' in a package's DESCRIPTION file, return a character vector of package names with the version restrictions stripped and \\R~removed.\n# @param val Value from a field like 'Depends' in a package's DESCRIPTION file\n# @rdname pkgDepTools\n# @keywords internal\ncleanPkgField <- function(val) {\n  if (is.na(val))\n    return(character(0))\n  val <- names(split_dependencies(val))\n  if (is.null(val))\n    return(character(0))\n  val <- val[! val %in% \"R\"]\n  if (length(val))\n    return(val)\n  return(character(0))\n}\n" }
{ "repo_name": "RevolutionAnalytics/miniCRAN", "ref": "refs/heads/master", "path": "tests/testthat/test-3-makeRepo.R", "content": "if (interactive()) {library(testthat); Sys.setenv(NOT_CRAN = \"true\")}\n\ncontext(\"makeRepo\")\n\nrevolution <- MRAN(\"2014-10-15\")\nif(!miniCRAN:::is.online(revolution, tryHttp = FALSE)) {\n  # Use http:// for older versions of R\n  revolution <- sub(\"^https://\", \"http://\", revolution)\n}\nrvers = \"3.2\"\npkgs <- c(\"Bmix\")\nrepo_root <- file.path(tempdir(), \"miniCRAN\", Sys.Date())\nif (file.exists(repo_root)) unlink(repo_root, recursive = TRUE)\n\n# list.files(repo_root, recursive = TRUE)\n\n\ntypes <- c(\"source\", \"win.binary\", \"mac.binary\", \"mac.binary.mavericks\")\nnames(types) <- c(\"source\", \"win.binary\", \"mac.binary\", \"mac.binary\")\n\nfor (pkg_type in names(types)) {\n  test_that(sprintf(\"makeRepo downloads %s files and builds PACKAGES file\", pkg_type), {\n    skip_on_cran()\n    skip_if_offline()\n\n    pdb <- pkgAvail(repos = revolution, type = pkg_type, Rversion = rvers)\n    pkgList <- pkgDep(pkgs, availPkgs = pdb, repos = revolution, type = pkg_type,\n                      suggests = FALSE, Rversion = rvers)\n    prefix <- miniCRAN:::repoPrefix(pkg_type, Rversion = rvers)\n    dir.create(repo_root, recursive = TRUE, showWarnings = FALSE)\n\n    ret <- makeRepo(pkgList, path = repo_root, repos = revolution, \n             type = pkg_type, quiet = TRUE, Rversion = rvers)\n    \n    expect_is(ret, \"character\")\n    expect_equal(length(ret), length(pkgList))\n\n    expect_true(\n      miniCRAN:::.checkForRepoFiles(repo_root, pkgList, prefix)\n    )\n    expect_true(\n      file.exists(file.path(repo_root, prefix, \"PACKAGES.gz\"))\n    )\n    expect_true(\n      all(\n        pkgList %in% pkgAvail(repos = repo_root, type = pkg_type, Rversion = rvers)[, \"Package\"]\n      )\n    )\n  })\n}\n\nunlink(repo_root, recursive = TRUE)\n" }
{ "repo_name": "RevolutionAnalytics/miniCRAN", "ref": "refs/heads/master", "path": "tests/testthat/test-2-makeDepGraph.R", "content": "checkPkgDepFunctions <- function(pkg, availPkgs = cranJuly2014, \n                                 repos = MRAN(), \n                                 type=\"source\", \n                                 suggests=TRUE, \n                                 enhances=FALSE, \n                                 includeBasePkgs=FALSE){\n  \n  if(!require(igraph, quietly = TRUE)){\n    skip(\"package igraph not installed\")\n  }\n  p1 <- pkgDep(pkg, availPkgs=availPkgs, \n               repos=repos, type=type, \n               suggests=suggests, enhances=enhances, \n               includeBasePkgs=includeBasePkgs)\n  p2 <- makeDepGraph(pkg, availPkgs=availPkgs, \n                     repos=repos, type=type, \n                     suggests=suggests, enhances=enhances, \n                     includeBasePkgs=includeBasePkgs)\n\n  vnames <- V(p2)$name\n  diff1 <- setdiff(vnames, p1)\n  diff2 <- setdiff(p1, vnames)\n  result <- length(diff1) == 0 & length(diff2) == 0\n  if(!result) {\n    msg <- paste0(\"\\nmakeDepGraph() results not in pkgDep(): \\n - \", paste(diff1, collapse=\", \"),\n                  \"\\npkgDep() results not in makeDepGraph(): \\n - \", paste(diff2, collapse=\", \"))\n    \n    warning(msg)\n  }\n  result\n}\n\n\ncontext(\"makeDepGraph \")\n\nmock_require <- function(pkg, ...){\n  packages.to.exclude <- c(\"igraph\")\n  inSearchPath <- any(\n    grepl(sprintf(\"package:%s$\", paste(packages.to.exclude, collapse = \"|\")), search())\n  )\n  if(inSearchPath) stop(\"Required package already in search path\")\n  \n  package <- as.character(substitute(pkg))\n  if(package %in% packages.to.exclude)\n    FALSE \n  else \n    base::requireNamespace(package, character.only = TRUE, ...)\n}\n\n\ntest_that(\"throws error if igraph not available\", {\n  skip_if_offline()\n  with_mock(\n    `base::requireNamespace` = function(pkg, ...){\n      packages.to.exclude <- c(\"igraph\")\n      inSearchPath <- any(\n        grepl(sprintf(\"package:%s$\", paste(packages.to.exclude, collapse = \"|\")), search())\n      )\n      if(inSearchPath) stop(\"Required package already in search path\")\n      \n      package <- as.character(substitute(pkg))\n      if(package %in% packages.to.exclude)\n        FALSE \n      else \n        base::requireNamespace(package, character.only = TRUE, ...)\n    }, \n{\n  expect_false(requireNamespace(\"igraph\"))\n  \n  tag <- \"MASS\"\n  \n  expect_error(\n    makeDepGraph(tag, availPkgs=cranJuly2014)\n  )\n  \n})\n\n})\n\ntest_that(\"makeDepGraph and pgkDep gives similar results for MASS\", {\n  skip_if_offline()\n\n  tag <- \"MASS\"\n  \n  expect_true(\n    checkPkgDepFunctions(tag)\n  )\n  \n  skip_on_cran()\n  \n  expect_true(\n    checkPkgDepFunctions(tag, includeBasePkgs = TRUE)\n  )\n  \n  expect_true(\n    checkPkgDepFunctions(tag, includeBasePkgs = TRUE, suggests=FALSE)\n  )\n  expect_true(\n    checkPkgDepFunctions(tag, includeBasePkgs = TRUE, enhances=TRUE)\n  )\n  \n})\n\n\ntest_that(\"makeDepGraph and pgkDep gives similar results for chron\", {\n  \n  skip_on_cran()\n  \n  tag <- \"chron\"\n  \n  expect_true(\n    checkPkgDepFunctions(tag)\n  )\n  expect_true(\n    checkPkgDepFunctions(tag, includeBasePkgs = TRUE)\n  )\n  expect_true(\n    checkPkgDepFunctions(tag, includeBasePkgs = TRUE, suggests=FALSE)\n  )\n  expect_true(\n    checkPkgDepFunctions(tag, includeBasePkgs = TRUE, enhances=TRUE)\n  )\n  \n})\n\n\ntest_that(\"makeDepGraph and pgkDep gives similar results for data.table\", {\n  \n  skip_on_cran()\n  \n  tag <- \"data.table\"\n  \n  expect_true(\n    checkPkgDepFunctions(tag)\n  )\n  expect_true(\n    checkPkgDepFunctions(tag, includeBasePkgs = TRUE)\n  )\n  expect_true(\n    checkPkgDepFunctions(tag, includeBasePkgs = TRUE, suggests=FALSE)\n  )\n  expect_true(\n    checkPkgDepFunctions(tag, includeBasePkgs = TRUE, enhances=TRUE)\n  )\n  \n})\n\ntest_that(\"makeDepGraph and pgkDep gives similar results for ggplot2\", {\n  \n  skip_on_cran()\n  \n  tag <- \"ggplot2\"\n  \n  expect_true(\n    checkPkgDepFunctions(tag)\n  )\n  expect_true(\n    checkPkgDepFunctions(tag, includeBasePkgs = TRUE)\n  )\n  expect_true(\n    checkPkgDepFunctions(tag, includeBasePkgs = TRUE, suggests=FALSE)\n  )\n  expect_true(\n    checkPkgDepFunctions(tag, includeBasePkgs = TRUE, enhances=TRUE)\n  )\n  \n})\n\n\ntest_that(\"makeDepGraph and pgkDep gives similar results for complex query\", {\n  \n  skip_on_cran()\n  \n  tag <- c(\"ggplot2\", \"data.table\", \"plyr\", \"knitr\", \"shiny\", \"xts\", \"lattice\")\n  \n  expect_true(\n    checkPkgDepFunctions(tag)\n  )\n  expect_true(\n    checkPkgDepFunctions(tag, includeBasePkgs = TRUE)\n  )\n  expect_true(\n    checkPkgDepFunctions(tag, includeBasePkgs = TRUE, suggests=FALSE)\n  )\n  expect_true(\n    checkPkgDepFunctions(tag, includeBasePkgs = TRUE, enhances=TRUE)\n  )\n  \n})\n\n" }
{ "repo_name": "WinVector/CampaignPlanner", "ref": "refs/heads/master", "path": "server.R", "content": "\n# This is the server logic for a Shiny web application.\n# You can find out more about building applications with Shiny here:\n#\n# http://shiny.rstudio.com\n#\n\nlibrary('shiny')\nlibrary('ggplot2')\nsource(\"functions.R\")\n\n\nmakeTypicalTable = function(planTable, sizes, dummy) {\n  dummy  # cause dummy promise to be evaluated (and trigger recalc)\n  ptab = typicalTable(planTable, sizes)\n  if(sum(sizes) > 0) {\n    ptab$expectedSuccessRate = with(ptab, (Successes+0.5)/(Actions+1)) # posteriors from Jeffrey prior\n    ptab$expectedValuePerAction = ptab$expectedSuccessRate*planTable$ValueSuccess\n  }\n  ptab\n}\n\nlabeledPlan = function(sizes,rates,values,countGoal) {\n  data.frame(Label=paste(\"Campaign_\", seq_len(length(sizes)), sep=''),\n             ActionsToMeetErrorGoals=sizes,\n             ActionsToMeetCountGoals=ceiling(countGoal/rates),\n             MatchingRates=c(rates[2]*values[2]/values[1],rates[1]*values[1]/values[2]))\n}\n\ndisplayGraph = function(pgraph, doplot) {\n  if(doplot) {\n    plotSample(pgraph)\n  } else NULL\n}\n\n# ---------------------------------\n\nassembleResultTable = function(actions, successes, values, wishPrice) {\n  ptab = data.frame(Label=paste(\"Campaign_\", seq_len(length(successes)), sep=''),\n             Actions=actions,\n             Successes=successes,\n             ValueSuccess=values)\n  ptab$observedSuccessRate = (successes+0.5)/(actions+1) #  posterior Jeffreys prior 0.5,0.5 smoothing\n  ptab$observedValuePerAction = ptab$observedSuccessRate*values\n  ptab$pAboveWishPrice = pbeta(wishPrice/values,\n                               shape1=0.5+successes,\n                               shape2=0.5+actions-successes,\n                               lower.tail=FALSE)\n  ptab\n}\n\nshinyServer(function(input, output) {\n   #\n   # for planning campaign\n   #\n   cprobabilities = reactive(c(input$conv1a, input$conv2a))\n   values = reactive(c(input$value1a, input$value2a))\n   sizes = reactive(c(input$sizes1a, input$sizes2a))\n   proposedsizes = reactive(heuristicPowerPlan(data.frame(Probability=cprobabilities(), \n                                                          ValueSuccess=values()), \n                                       errorProbability=input$errorProb,relativeError=input$relErr)) \n   countGoalV <- reactive(input$countGoal)\n   \n  docalc = reactive(sum(sizes()) != 0)\n\n  planTable = reactive(data.frame(Label=c('Campaign1','Campaign2'),\n                                  Probability=cprobabilities(), \n                                  ValueSuccess=values()))\n  typicalTable = reactive(makeTypicalTable(planTable(), sizes(), input$reseed))\n  pgraph2T = reactive(posteriorGraph(typicalTable()))\n  output$planGraph2T = renderPlot(plotPosterior(pgraph2T()))\n  output$probTable2T = renderPrint(computeProbsGEP(typicalTable(),pgraph2T()$graph))\n  \n  pgraph = reactive(sampleGraph(planTable(),sizes()))\n  bgraph = reactive(computeProbsGES(planTable(),pgraph()))\n\n  output$plan = renderTable(labeledPlan(proposedsizes(),cprobabilities(),values(),countGoalV()),digits=4)\n  output$typicalTable = renderPrint(typicalTable()) # I'll render it verbatim, rather than as a table.\n                                               # Saves me from having to worry about sig figs\n  output$planGraph = renderPlot(displayGraph(pgraph(), docalc()))\n  output$probTable = renderPrint(bgraph())\n\n\n  #\n  # for evaluating campaign\n  #\n  actions = reactive(c(input$actions1b, input$actions2b))\n  successes = reactive(c(input$success1b, input$success2b))\n  svalues = reactive(c(input$value1b, input$value2b))\n\n  resTable = reactive(assembleResultTable(round(input$rescale*actions()), \n                                          round(input$rescale*successes()), \n                                          svalues(),\n                                          input$wishPrice))\n  pgraph2 = reactive(posteriorGraph(resTable()))\n\n  output$resTable = renderPrint(resTable())\n  output$planGraph2 = renderPlot(plotPosterior(pgraph2(),input$wishPrice))\n  output$probTable2 = renderPrint(computeProbsGEP(resTable(),pgraph2()$graph))\n\n})\n" }
{ "repo_name": "Reproducible-Science-Curriculum/rr-organization1", "ref": "refs/heads/master", "path": "files/file-org/forensic-science/rev1_final_analysis.R", "content": "data <- read.csv(file = \"data1_full.csv\", header = T)\n\nsub_data <- data[data$country == \"Canada\", ]\n\nwrite.csv(Canada, file = \"/Users/csoderbe/rr-organization1/files/Canada.csv\", row.names = FALSE)\n\nlibrary(ggplot2)\nggplot(data = sub_data, aes(x = year, y = lifeExp)) +\n  geom_point() +\n  geom_line() \nggsave(\"graph.png\")\n\n\n\n" }
{ "repo_name": "Shians/Glimma", "ref": "refs/heads/master", "path": "R/gllink.R", "content": "#' Plot linkages\n#' \n#' Helper function for writing the link properties in interactive Glimma plots\n#' \n#' @param from the index of the plot from which the event is dispatched.\n#' @param to the index of the plot which receives the event and performs an action.\n#' @param src the action that is performed in the \"from\" plot.\n#' @param dest the action that is performed in the \"to\" plot.\n#' @param flag indicates special links for particular chart types.\n#' @param both creates symmetric links whereby the \"dest\" action in \"to\" also triggers the \"src\" action in \"from\".\n#' @param info additional info for creating the link.\n#' \n#' @return a link object containing the plot linking information.\n#' \n#' @examples\n#' data(iris)\n#' data <- data.frame(Name=paste(\"Flower\", 1:nrow(iris), sep=\"-\"), iris)\n#' \\donttest{\n#' plot1 <- glScatter(data, xval=\"Sepal.Length\", yval=\"Sepal.Width\", colval=\"Species\")\n#' plot2 <- glScatter(data, xval=\"Species\", yval=\"Petal.Length\", colval=\"Species\")\n#' link1 <- gllink(1, 2, src=\"hover\", dest=\"hover\", both=TRUE)\n#' glimma(plot1, plot2, link1, layout=c(1,2))\n#' }\n\ngllink <- function(from, to, src=\"none\", dest=\"none\", flag=\"none\", both=FALSE, info=\"none\") {\n    out <- list()\n\n    if (src != \"none\" && dest == \"none\") {\n        stop(\"src cannot be defined while dest is 'none'\")\n    }\n\n    if (src == \"none\" && dest != \"none\") {\n        stop(\"dest cannot be defined while src is 'none'\")\n    }   \n\n    if (src == \"none\" && dest == \"none\" && flag == \"none\") {\n        stop(\"'src', 'dest' and 'flag' cannot simultaneously be 'none'\")\n    }\n\n    out$link <- data.frame(from=from, to=to, src=src, dest=dest, flag=flag, info=info)\n    if (both) {\n        out$link <- rbind(out$link, data.frame(from=to, to=from, src=dest, dest=src, flag=flag, info=info))\n    }\n\n    out$type <- \"link\"\n\n    class(out) <- \"jslink\"\n    return(out)\n}\n" }
{ "repo_name": "Shians/Glimma", "ref": "refs/heads/master", "path": "R/glMDSPlot.R", "content": "#' Glimma MDS Plot\n#'\n#' Draw an interactive MDS plot gene expression matrix with distances calculated from most variable genes.\n#'\n#' @author Shian Su, Gordon Smyth\n#'\n#' @param x the data.frame containing data to plot.\n#' @param ... additional arguments affecting the plots produced. See specific methods for detailed arguments.\n#'\n#' @return Draws a two-panel interactive MDS plot in an html page. The left panel contains the plot between two MDS dimensions, with annotations displayed on hover. The right panel contains a bar plot of the eigenvalues of each dimension, clicking on any of the bars will plot the corresponding dimension against the next dimension.\n#'\n#' @seealso \\code{\\link{glMDSPlot.default}}, \\code{\\link{glMDSPlot.DGEList}}\n#'\n#' @examples\n#' data(lymphomaRNAseq)\n#' genotype <- relevel(lymphomaRNAseq$samples$group, \"Smchd1-null\")\n#' \\donttest{\n#' glMDSPlot(lymphomaRNAseq, labels=1:7, groups=genotype)\n#' }\n#'\n#' @export\n\nglMDSPlot <- function(x, ...) {\n    UseMethod(\"glMDSPlot\")\n}\n\n#' Glimma MDS Plot\n#'\n#' Draw an interactive MDS plot from a gene expression matrix with distances calculated from most variable genes.\n#'\n#' @author Shian Su, Gordon Smyth\n#'\n#' @param x the matrix containing the gene expressions.\n#' @param top the number of top most variable genes to use.\n#' @param labels the labels for each sample.\n#' @param groups the experimental group to which samples belong.\n#' @param gene.selection \"pairwise\" if most variable genes are to be chosen for each pair of samples or \"common\" to select the same genes for all comparisons.\n#' @param main the title of the plot.\n#' @param path the path in which the folder will be created.\n#' @param folder the name of the fold to save html file to.\n#' @param html the name of the html file to save plots to.\n#' @param launch TRUE to launch plot after call.\n#' @param ... additional arguments.\n#'\n#' @return Draws a two-panel interactive MDS plot in an html page. The left panel contains the plot between two MDS dimensions, with annotations displayed on hover. The right panel contains a bar plot of the eigenvalues of each dimension, clicking on any of the bars will plot the corresponding dimension against the next dimension.\n#'\n#' @method glMDSPlot default\n#'\n#' @importFrom stats cmdscale as.dist\n#'\n#' @export\n\n# Code taken from plotMDS of limma bioConductor package with alterations\nglMDSPlot.default <- function(x, top=500, labels=1:ncol(x),\n                            groups=rep(1, ncol(x)), gene.selection=\"pairwise\",\n                            main=\"MDS Plot\", path=getwd(),\n                            folder=\"glimma-plots\", html=\"MDS-Plot\",\n                            launch=TRUE, ...) {\n    #   Multi-dimensional scaling with top-distance\n    #   Di Wu and Gordon Smyth\n    #   19 March 2009.  Last modified 14 Jan 2015\n    #   Modified by Shian Su on 25 Jan 2016\n\n    ##\n    # Check Inputs\n\n    x <- as.matrix(x)\n    nsamples <- ncol(x)\n    ndim <- nsamples - 1\n\n    if (nsamples < 3) {\n        stop(paste(\"Only\", nsamples, \"columns of data: need at least 3\"))\n    }\n\n    cn <- colnames(x)\n    bad <- rowSums(is.finite(x)) < nsamples\n\n    if (any(bad)) {\n        x <- x[!bad, drop=FALSE]\n    }\n\n    nprobes <- nrow(x)\n    top <- min(top, nprobes)\n\n    #\n    ##\n\n    plot.title <- quotify(main)\n\n    gene.selection <- match.arg(gene.selection, c(\"pairwise\", \"common\"))\n\n    # Distance matrix from pairwise leading fold changes\n    dd <- matrix(0, nrow=nsamples, ncol=nsamples, dimnames=list(cn, cn))\n    if (gene.selection == \"pairwise\") {\n    # Distance measure is mean of top squared deviations for each pair of arrays\n        topindex <- nprobes - top + 1L\n        for (i in 2L:(nsamples)) {\n            for (j in 1L:(i - 1L)) {\n                dist <- sort.int((x[, i] - x[, j])^2, partial=topindex)\n                topdist <- dist[topindex:nprobes]\n                dd[i, j] <- sqrt(mean(topdist))\n            }\n        }\n    } else {\n    # Same genes used for all comparisons\n        if (nprobes > top) {\n            s <- rowMeans((x-rowMeans(x))^2)\n            o <- order(s, decreasing=TRUE)\n            x <- x[o[1L:top],, drop=FALSE]\n        }\n        for (i in 2L:(nsamples))\n            dist <- sqrt(colMeans( (x[, i]-x[, 1:(i-1), drop=FALSE])^2 ))\n            dd[i, 1L:(i-1L)] <- dist\n        axislabel <- \"Principal Component\"\n    }\n\n    # Multi-dimensional scaling\n    a1 <- suppressWarnings(cmdscale(as.dist(dd), k=min(ndim, 8), eig=TRUE))\n\n    # Method for MDS objects\n    points <- a1$points\n\n    if (!is.data.frame(groups)) {\n    # Rename for the column name in dataframe\n        group <- groups\n        groups <- data.frame(group)\n    }\n\n    first.col.name <- colnames(groups)[1]\n\n    points <- data.frame(points)\n    names(points) <- paste0(\"dim\", 1:ncol(points))\n    points <- data.frame(points, label=labels, groups)\n\n    eigen <- data.frame(name = 1:min(ndim, 8),\n                        eigen = round(a1$eig[1:min(ndim, 8)]/sum(a1$eig), 2))\n\n    plot1 <- glScatter(points, xval=\"dim1\", yval=\"dim2\", point.size=4,\n                        xlab=\"Dimension 1\", ylab=\"Dimension 2\",\n                        annot=c(\"label\", first.col.name, \"dim1\", \"dim2\"),\n                        colval=first.col.name, main=main,\n                        info=list(groupsNames=colnames(groups)))\n\n    plot2 <- glBar(eigen, names.arg=\"name\", yval=\"eigen\",\n                    main=\"Variance Explained\",\n                    xlab=\"Dimension\", ylab=\"Proportion\",\n                    height=300, width=300, info=list(dims=ndim))\n\n    link1 <- gllink(2, 1, flag=\"mds\")\n\n    glimma(plot1, plot2, link1, layout=c(1, 2), overwrite=TRUE,\n            path=path, folder=folder, html=html, launch=launch)\n}\n\n#' Glimma MDS Plot\n#'\n#' Draw an interactive MD plot from a DGEList object with distances calculated from most variable genes.\n#'\n#' @author Shian Su, Gordon Smyth\n#'\n#' @param x the DGEList containing the gene expressions.\n#' @param top the number of top most variable genes to use.\n#' @param labels the labels for each sample.\n#' @param groups the experimental group to which samples belong.\n#' @param gene.selection \"pairwise\" if most variable genes are to be chosen for each pair of samples or \"common\" to select the same genes for all comparisons.\n#' @param main the title of the plot.\n#' @param path the path in which the folder will be created.\n#' @param folder the name of the fold to save html file to.\n#' @param html the name of the html file to save plots to.\n#' @param launch TRUE to launch plot after call.\n#' @param ... additional arguments.\n#'\n#' @return Draws a two-panel interactive MDS plot in an html page. The left panel contains the plot between two MDS dimensions, with annotations displayed on hover. The right panel contains a bar plot of the eigenvalues of each dimension, clicking on any of the bars will plot the corresponding dimension against the next dimension.\n#'\n#' @method glMDSPlot DGEList\n#'\n#' @export\nglMDSPlot.DGEList <- function (x, top=500, labels=1:ncol(x),\n                            groups=rep(1, ncol(x)), gene.selection=\"pairwise\",\n                            main=\"MDS Plot\", path=getwd(),\n                            folder=\"glimma-plots\", html=\"MDS-Plot\",\n                            launch=TRUE, ...) {\n    x <- edgeR::cpm(x, log=TRUE)\n    glMDSPlot.default(x, top=500, labels=labels, groups=groups,\n                    gene.selection=\"pairwise\", main=main, path=path,\n                    folder=folder, html=html, launch=launch, ...)\n}\n" }
{ "repo_name": "percyfal/biomake", "ref": "refs/heads/master", "path": "scripts/plotThetas.R", "content": "#! /usr/bin/Rscript --vanilla\n# File: plotThetas.R\n# Created: Tue Oct 29 17:12:00 2013\n# $Id: $\n#\n# Copyright (C) 2013 by Per Unneberg\n#\n# Author: Per Unneberg\n#\n# Description:\n#\n\nlibrary(utils)\nlibrary(lattice)\nlibrary(RColorBrewer)\ncpal <- colorRampPalette(brewer.pal(9,\"Paired\"))(1000)\n\nargs <- commandArgs(TRUE)\nif (length(args) != 2) {\n    message(\"Usage: plotThetas.R infile outfile!\")\n    quit(\"yes\")\n}\n\ninfile <- args[1]\n\ndir <- basename(dirname(normalizePath(infile)))\nif (grep(\"w[0-9]+_[0-9]+\", dir)) {\n    message(\"We have a window match\")\n    window <- gsub(\"w([0-9]+)_.*\", \"\\\\1\", dir)\n    step <- gsub(\".*_([0-9]+)\", \"\\\\1\", dir)\n} else {\n    window <- 50000\n    step <- 50000\n}\npop = gsub(\"(^[A-Z]+)_.*\", \"\\\\1\", infile)\n\nd <- read.table(infile)\nnames(d) <- c(\"range\", \"chr\", \"pos\", \"tW\", \"tP\", \"tF\", \"tH\", \"tL\", \"tajD\", \"fulif\", \"fuliD\", \"fayH\", \"zengsE\", \"numSites\")\nd <- cbind(d, d[,c(\"tW\", \"tP\", \"tF\", \"tH\", \"tL\")] / d$numSites)\nnames(d) <- c(\"range\", \"chr\", \"pos\", \"tW\", \"tP\", \"tF\", \"tH\", \"tL\", \"tajD\", \"fulif\", \"fuliD\", \"fayH\", \"zengsE\", \"numSites\", \"tW.norm\", \"tP.norm\", \"tF.norm\", \"tH.norm\", \"tL.norm\")\nd$pop = pop\nd.stack <- cbind(stack(d[,c(\"numSites\", \"tajD\", \"fuliD\", \"fulif\", \"fayH\", \"zengsE\", \"tW\", \"tP\", \"tW.norm\", \"tP.norm\")]), pop=d$pop, pos=d$pos, chr=d$chr)\noutfile <- args[2]\n\n# Redefine factor levels\nd.stack$ind <- factor(d.stack$ind, levels = c(\"numSites\",  \"tajD\", \"tW\", \"fuliD\", \"tW.norm\", \"fulif\", \"tP\", \"fayH\", \"tP.norm\",   \"zengsE\"))\n\npdf(outfile)\nprint(xyplot(values ~ pos/1e6 | ind, data=d.stack, type=\"l\", layout=c(2,5), xlab=\"pos (Mb)\", scales=list(y=list(rot=45, relation=\"free\")), strip=FALSE, strip.left=TRUE, main=paste(basename(infile), \", w:\", window, \", s:\", step, sep=\"\"), par.settings=simpleTheme()))\n\n\nd.stack$ind <- factor(d.stack$ind, levels = c(\"numSites\", \"tW\",  \"tW.norm\",  \"tP\", \"tP.norm\", \"tajD\", \"fuliD\", \"fulif\", \"fayH\", \"zengsE\"))\nprint(xyplot(values ~ pos/1e6 | ind, data=d.stack, type=\"l\", layout=c(1,10), xlab=\"pos (Mb)\", scales=list(y=list(rot=45, relation=\"free\")), strip=FALSE, strip.left=TRUE, main=paste(basename(infile), \", w:\", window, \", s:\", step, sep=\"\"), par.settings=simpleTheme()))\n\ndev.off()\n" }
{ "repo_name": "kbseah/genome-bin-tools", "ref": "refs/heads/master", "path": "gbtools/R/setOperation.R", "content": "#' Generic operation for merging and subsetting two gbtbin objects\n#' \n#' @param x1 Object of class gbtbin\n#' @param x2 Object of class gbtbin\n#' @param shortlist Vector of contig IDs to make new bin\n#' @return Object of class gbtbin\n#' @keywords internal\n\nsetOperation <- function(x1, x2, shortlist) UseMethod(\"setOperation\")\n" }
{ "repo_name": "kbseah/genome-bin-tools", "ref": "refs/heads/master", "path": "gbtools/R/choosebinPolygon.gbt.R", "content": "#' Choose bin from gbt object by defining polygon in coverage-GC or differential coverage plot\n#'\n#' Choose genome bin by specifying coordinates of a polygon from\n#' GC-coverage or differential coverage plot of a gbt object\n#'\n#' @param x Object of class gbt\n#' @param slice Slice parameter for drawing the polygon\n#' @param polygon Polygon that would define the bin\n#'\n#' @importFrom sp point.in.polygon\n#' @return Object of class gbtbin\n#' @seealso \\code{\\link{plot.gbt}}\n#' @export\n#'\nchoosebinPolygon.gbt <- function(x,  # Object of class gbt\n                          slice,  # Which slices used for the plot from which points to be chosen?\n                          taxon=\"Class\",  # Deprecated - user don't change this\n                          binpolygon=NA, # The polygon\n                          save=FALSE,  # Save list of contigs in bin to external file?\n                          file=\"interactive_bin.list\"  # Name of file to save list of contigs in bin\n                          ) {\n    require(sp)\n## Wrapper for picking bin interactively from GC-cov or diff-cov plot\n    if (!is.numeric(slice) || length(slice) > 2) {\n        cat (\"gbtools ERROR: Please specify the library(-ies) used to make the plot in focus\\n\")\n    } else {\n        if (length(slice)==1) {  # Pick bin from GC-coverage plot\n            X <- merge(data.frame(ID=x$scaff$ID,\n                                  Ref_GC=x$scaff$Ref_GC),\n                       data.frame(ID=x$covs$ID,\n                                  Avg_fold=x$covs[slice[1]+1]),\n                       by=\"ID\")\n            names(X) <- c(\"ID\",\"Ref_GC\",\"Avg_fold\")\n            inpolygon <- sp::point.in.polygon(X$Ref_GC,\n                                              X$Avg_fold,\n                                              binpolygon$x,\n                                              binpolygon$y)\n        }\n        else if (length(slice)==2) {  # Pick bin from differential coverage plot\n            X <- merge(data.frame(ID=x$scaff$ID,\n                                  Ref_GC=x$scaff$Ref_GC),\n                       data.frame(ID=x$covs$ID,\n                                  Avg_fold_1=x$covs[slice[1]+1],\n                                  Avg_fold_2=x$covs[slice[2]+1]),\n                       by=\"ID\")\n            names(X) <- c(\"ID\",\"Ref_GC\",\"Avg_fold_1\",\"Avg_fold_2\")\n            inpolygon <- sp::point.in.polygon(X$Avg_fold_1,\n                                              X$Avg_fold_2,\n                                              binpolygon$x,\n                                              binpolygon$y)\n        }\n        X.subset <- X[which(inpolygon==1),]\n        X.shortlist <- as.character(X.subset$ID)\n        result <- gbtbin(shortlist=X.shortlist,\n                         x=x,\n                         slice=slice,\n                         taxon=taxon,\n                         points=binpolygon,\n                         save=save,\n                         file=file)\n        result$call[[length(result$call)+1]] <- match.call()  # Record choosebin() function call\n        return(result)\n    }\n}\n" }
{ "repo_name": "kbseah/genome-bin-tools", "ref": "refs/heads/master", "path": "gbtools/R/countSingleFromTable.R", "content": "#' Tabulate objects and count how many singletons\n#'\n#' @param x Object of class data.frame or vector\n#' @return Numeric vector of length 1\n#' @keywords internal\ncountSingleFromTable <- function(x) {\n    x.tab <- table(x)\n    uniq <- length(which(x.tab==1))\n    return(uniq)\n}\n" }
{ "repo_name": "kbseah/genome-bin-tools", "ref": "refs/heads/master", "path": "gbtools/R/lej.gbtbin.R", "content": "#' Take difference between two gbtbin objects\n#'\n#' Takes the reverse complement of two gbtbin objects. Equivalent to setdiff\n#' in R, or left-exclusive-join in SQL. Non commutative!\n#'\n#' Self explanatory...\n#'\n#' @inheritParams add\n#'\n#' @seealso \\code{\\link{add}}\n#'\n#' @export\nlej.gbtbin <- function(x1,x2) {\n## Take difference between two bins - non commutative! i.e. left exclusive join\n    shortlist <- x1$scaff$ID[which(!x1$scaff$ID %in% x2$scaff$ID)]\n    result <- setOperation.gbtbin(x1=x1,\n                                  x2=x2,\n                                  shortlist=shortlist)\n    result$call[[length(result$call)+1]] <- match.call()  # Record function call \n    return(result)\n}\n" }
{ "repo_name": "kbseah/genome-bin-tools", "ref": "refs/heads/master", "path": "gbtools/R/generatePlotColors2.R", "content": "#' Generates colors for marker gene phylotypes in plot by cumulative weight\n#'\n#' For each taxon, calculates the total contigLength*coverage, and assigns\n#' colors for the top taxa which in total account for more than a specified\n#' minimum weight.\n#'\n#' @param scaffold.stats Scaff table from gbt object\n#' @param marker.list markTab table from gbt object\n#' @param taxon Taxonomic level to do coloring\n#' @param consensus Logical - if taxon assignments conflict, take consensus?\n#' @param weightCutoff Cutoff quantile for contig length*coverage weight (between 0 and 1)\n#' @return data.frame with color assignments for each scaffold\n#' @keywords internal\n#'\ngeneratePlotColors2 <- function(scaffold.stats,  # scaff table from gbt object\n                               marker.list,  # markTab table from gbt object\n                               taxon,  # Taxonomic level to do the coloring\n                               consensus,  # Logical-if taxon assgs conflict, take consens?\n                               weightCutoff # Cutoff quantile for assigning colors (between 0 and 1)\n                               ) {           # This took a very long time to get it right\n## Generates colors for marker gene phylotypes in plot\n    ## Merge tables to have points to plot for the markers #########################\n    marker.stats <- mergeScaffMarker(scaffold.stats,\n                                     marker.list,\n                                     taxon,\n                                     consensus)\n    ## Calculate total weight for each taxon #######################################\n    taxon.agg <- aggregate(marker.stats$Length*marker.stats$Avg_fold,\n                           by=list(marker.stats$taxon),\n                           FUN=sum\n                           )\n    total.weight <- sum(taxon.agg$x)\n    taxon.agg.order <- taxon.agg[order(taxon.agg$x,decreasing=TRUE),] # Sort descending\n    ## Make list of top taxa #######################################################\n    if (weightCutoff > 1 || weightCutoff < 0) { # Catch errors for weightCutoff\n        cat (\"gbtools ERROR: weightCutoff parameter must be between 0 and 1\\n\")\n    } \n    else {\n        # Count taxa which have the highest weight, until weightCutoff\n        numAboveCutoff <- length(\n                                 which(\n                                       cumsum(taxon.agg.order$x) <= weightCutoff*total.weight\n                                       )\n                                 )\n        numBelowCutoff <- length(\n                                 which(\n                                       cumsum(taxon.agg.order$x) > weightCutoff*total.weight\n                                       )\n                                 )\n        # Generate colors from red to violet for taxa above cutoff\n        thecolors <- rainbow (numAboveCutoff,\n                              start=0,\n                              end=3/4)\n        # Everything else is colored grey\n        repgrey <- rep (\"grey50\", numBelowCutoff)\n        # Combine the two vectors\n        thecolors <- c(thecolors, repgrey)\n        colorframe <- data.frame(taxon=taxon.agg.order[,1],\n                                 colors=thecolors)\n        # Merge into marker.stats df\n        marker.stats <- merge(marker.stats,\n                              colorframe,\n                              by=\"taxon\")\n        # Return table\n        return(marker.stats)\n    }\n\n}" }
{ "repo_name": "kbseah/genome-bin-tools", "ref": "refs/heads/master", "path": "gbtools/R/identify.gbt.R", "content": "#' Identify points in gbtools plot\n#'\n#' Click on GC-coverage plot or differential coverage plot to identify contigs.\n#' In cluttered plots it may not be very accurate! Will write the contig ID\n#' as a label overlay on the plot.\n#'\n#' @return Object of class gbtbin containing identified contigs\n#' @export\n#' @seealso \\code{\\link{plot.gbt}}\n#' @seealso \\code{\\link{choosebin}}\n\nidentify.gbt <- function(d,\n#' @param d Object of class gbt or gbtbin, in plot\n                         slice=1,\n#' @param slice Which sample data was plotted? (Default: 1)\n                         ...\n#' @param ... Further arguments passed to identify.default()\n                         ) {\n    # Catch invalid \"slice\" parameters\n    if (is.na(slice) || !is.numeric(slice)) {\n        cat (\"gbtools ERROR: Please specify valid value for slice parameter\\n\")\n    } else {\n        # Data frame for GC-coverage plots\n        if (length (slice) == 1) {\n            X <- merge(data.frame(ID=d$scaff$ID,\n                                  Ref_GC=d$scaff$Ref_GC,\n                                  Length=d$scaff$Length,\n                                  Avg_fold=d$scaff$Avg_fold,\n                                  xVals=d$scaff$Ref_GC),\n                       data.frame(ID=d$covs$ID,\n                                  yVals=d$covs[[slice[1]+1]]\n                                  ),\n                       by=\"ID\")\n            names(X) <- c(\"ID\",\"Ref_GC\",\"Length\",\"Avg_fold\",\"xVals\",\"yVals\")\n        }\n        # Data frame for differential coverage plots\n        else if (length(slice) == 2) {\n            X <- merge (data.frame (ID=d$scaff$ID,\n                                    Ref_GC=d$scaff$Ref_GC,\n                                    Length=d$scaff$Length,\n                                    Avg_fold=d$scaff$Avg_fold),\n                        data.frame (ID=d$covs$ID,\n                                    xVals=d$covs[[slice[1]+1]],\n                                    yVals=d$covs[[slice[2]+1]]),\n                        by=\"ID\")\n            names(X) <- c(\"ID\",\"Ref_GC\",\"Length\",\"Avg_fold\",\"xVals\",\"yVals\")\n        }\n        # Implement the identify parameter...\n        shortlist <- identify(x=X$xVals,\n                              y=X$yVals,\n                              labels=X$ID,\n                              ...\n                              )\n        shortlist.contigs <- X$ID[shortlist]\n        return(gbtbin(as.character(shortlist.contigs),d,slice=slice))\n        #return(shortlist)\n    }\n}" }
{ "repo_name": "kbseah/genome-bin-tools", "ref": "refs/heads/master", "path": "gbtools/R/userAdd.gbt.R", "content": "#' Add custom user annotations to gbt object\n#'\n#' Custom user annotations for each scaffold can be added to existing gbt\n#' objects. The annotations should be in a data.frame, with at least column\n#' \"scaffold\" that matches scaffold IDs in the gbt object. Pass the name of the\n#' data.frame to the userTab parameter. Give a unique name for this annotation\n#' to the userSource parameter.\n#'\n#' @param x Object of class gbt\n#' @param userTab data.frame with user annotations, see Details\n#' @param userSource Name for this annotation table\n#' @return Object of class gbt\n#' @seealso \\code{\\link{gbt}} \\code{\\link{plot.gbt}}\n#' @export\nuserAdd.gbt <- function(x,\n                        userTab,\n                        userSource=NA\n                        ) {\n    ## Check that userTab is data.frame with col \"scaffold\" ###################\n    if (!is.data.frame(userTab) ||\n        length(which(names(userTab)==\"scaffold\"))==0 ||\n        is.na(userSource) ) {\n        cat(\"gbtools ERROR: Please check inputs. See help(userAdd) \\n\")\n    } else {\n        ## Check that userTab scaffold IDs match x scaffold IDs ###############\n        if (length(which(userTab$scaffold %in% x$scaff$ID))==0) {\n            cat (\"gbtools ERROR: Scaffold IDs in userTab don't match gbt object\\n\")\n        } else {\n            x$userTab[[length(x$userTab)+1]] <- userTab  # Append userTab\n            x$userSource[length(x$userTab)] <- userSource # Append userSource\n            # NB: Using c() will create discrepancy between userTab and userSource\n            # because c() on an empty vector will create first element \"\"\n            x$call[[length(x$call)+1]] <- match.call()  # Record function call\n            return(x)  # Return result\n        }\n    }\n}\n" }
{ "repo_name": "deroneriksson/systemml", "ref": "refs/heads/master", "path": "system-ml/src/test/scripts/functions/binary/matrix/UaggOuterChainEquals.R", "content": "#-------------------------------------------------------------\r\n#\r\n# (C) Copyright IBM Corp. 2010, 2015\r\n#\r\n# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n# you may not use this file except in compliance with the License.\r\n# You may obtain a copy of the License at\r\n#\r\n#     http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n#\r\n#-------------------------------------------------------------\r\n\r\nargs <- commandArgs(TRUE)\r\noptions(digits=22)\r\n\r\nlibrary(\"Matrix\")\r\n\r\nA <- as.matrix(readMM(paste(args[1], \"A.mtx\", sep=\"\")))\r\nB <- as.matrix(readMM(paste(args[1], \"B.mtx\", sep=\"\")))\r\n\r\nC = rowSums(outer(A,B,\"==\"));\r\n\r\nwriteMM(as(C, \"CsparseMatrix\"), paste(args[2], \"C\", sep=\"\")); \r\n\r\n\r\n" }
{ "repo_name": "deroneriksson/systemml", "ref": "refs/heads/master", "path": "system-ml/src/test/scripts/functions/aggregate/RowMaxs.R", "content": "#-------------------------------------------------------------\r\n#\r\n# (C) Copyright IBM Corp. 2010, 2015\r\n#\r\n# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n# you may not use this file except in compliance with the License.\r\n# You may obtain a copy of the License at\r\n#\r\n#     http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n#\r\n#-------------------------------------------------------------\r\n\r\nargs <- commandArgs(TRUE)\r\n\r\nif(!(\"matrixStats\" %in% rownames(installed.packages()))){\r\n   install.packages(\"matrixStats\")\r\n}\r\n\r\nlibrary(\"Matrix\")\r\nlibrary(\"matrixStats\") \r\n\r\nA <- as.matrix(readMM(paste(args[1], \"A.mtx\", sep=\"\")))\r\nB <- rowMaxs(A);\r\n\r\nwriteMM(as(B, \"CsparseMatrix\"), paste(args[2], \"B\", sep=\"\")); " }
{ "repo_name": "deroneriksson/systemml", "ref": "refs/heads/master", "path": "system-ml/src/test/scripts/functions/misc/ScalarFunctionTest2.R", "content": "#-------------------------------------------------------------\r\n#\r\n# (C) Copyright IBM Corp. 2010, 2015\r\n#\r\n# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n# you may not use this file except in compliance with the License.\r\n# You may obtain a copy of the License at\r\n#\r\n#     http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n#\r\n#-------------------------------------------------------------\r\n\r\n\r\nargs <- commandArgs(TRUE)\r\noptions(digits=22)\r\nlibrary(\"Matrix\")\r\n\r\nsquare <- function(a) {\r\n   b = a*a;   \r\n   return(b);\r\n}\r\n\r\nx = 1.9/2.9;\r\ny = square(x);\r\nR = as.matrix(y);\r\n\r\nwriteMM(as(R, \"CsparseMatrix\"), paste(args[1], \"R\", sep=\"\")); \r\n" }
{ "repo_name": "deroneriksson/systemml", "ref": "refs/heads/master", "path": "system-ml/src/test/scripts/functions/binary/matrix/UaggOuterChain.R", "content": "#-------------------------------------------------------------\r\n#\r\n# (C) Copyright IBM Corp. 2010, 2015\r\n#\r\n# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n# you may not use this file except in compliance with the License.\r\n# You may obtain a copy of the License at\r\n#\r\n#     http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n#\r\n#-------------------------------------------------------------\r\n\r\nargs <- commandArgs(TRUE)\r\noptions(digits=22)\r\n\r\nlibrary(\"Matrix\")\r\n\r\nA <- as.matrix(readMM(paste(args[1], \"A.mtx\", sep=\"\")))\r\nB <- as.matrix(readMM(paste(args[1], \"B.mtx\", sep=\"\")))\r\n\r\nC = rowSums(outer(A,B,\"<\"));\r\n\r\nwriteMM(as(C, \"CsparseMatrix\"), paste(args[2], \"C\", sep=\"\")); \r\n\r\n\r\n" }
{ "repo_name": "deroneriksson/systemml", "ref": "refs/heads/master", "path": "system-ml/src/test/scripts/functions/vect/VectorizeLixRowPos.R", "content": "#-------------------------------------------------------------\n#\n# (C) Copyright IBM Corp. 2010, 2015\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n#-------------------------------------------------------------\n\n\r\nargs <- commandArgs(TRUE)\r\noptions(digits=22)\r\n\r\nlibrary(\"Matrix\")\r\n\r\nA = as.matrix(readMM(paste(args[1], \"A.mtx\", sep=\"\")))\r\n\r\nR = A;\r\nR[3,7] = as.matrix(3);\r\nR[3,8] = as.matrix(4);\r\n\r\n\r\nwriteMM(as(R, \"CsparseMatrix\"), paste(args[2], \"R\", sep=\"\")); \r\n\r\n\r\n" }
{ "repo_name": "deroneriksson/systemml", "ref": "refs/heads/master", "path": "system-ml/src/test/scripts/functions/parfor/parfor_optimizer3.R", "content": "#-------------------------------------------------------------\n#\n# (C) Copyright IBM Corp. 2010, 2015\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n#-------------------------------------------------------------\n\n\r\nargs <- commandArgs(TRUE)\r\noptions(digits=22)\r\n\r\nlibrary(\"Matrix\")\r\n\r\nV1 <- readMM(paste(args[1], \"V.mtx\", sep=\"\"))\r\nV <- as.matrix(V1);\r\nn <- ncol(V); \r\nn2 <- n/2;\r\n\r\nR <- array(0,dim=c(1,n2))\r\n\r\nfor( i in 1:n2 )\r\n{\r\n   X <- V[,i];                 \r\n   Y <- V[,n-i+1];                \r\n   R[1,i] <- sum(X)+sum(Y);\r\n}   \r\n\r\nwriteMM(as(R, \"CsparseMatrix\"), paste(args[2], \"Rout\", sep=\"\")); \r\n" }
{ "repo_name": "deroneriksson/systemml", "ref": "refs/heads/master", "path": "system-ml/src/test/scripts/functions/unary/matrix/replace_maxmin.R", "content": "#-------------------------------------------------------------\n#\n# (C) Copyright IBM Corp. 2010, 2015\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n#-------------------------------------------------------------\n\n\r\nargs <- commandArgs(TRUE)\r\noptions(digits=22)\r\n\r\nlibrary(\"Matrix\")\r\n\r\nA <- as.matrix(readMM(paste(args[1], \"A.mtx\", sep=\"\")))\r\n\r\nC <- replace(A, A==as.numeric(min(A)), max(A));\r\n\r\nwriteMM(as(C, \"CsparseMatrix\"), paste(args[3], \"C\", sep=\"\")); \r\n\r\n\r\n" }
{ "repo_name": "deroneriksson/systemml", "ref": "refs/heads/master", "path": "system-ml/src/test/scripts/functions/binary/matrix_full_other/IntegerDivision_mod.R", "content": "#-------------------------------------------------------------\n#\n# (C) Copyright IBM Corp. 2010, 2015\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n#-------------------------------------------------------------\n\n\r\nargs <- commandArgs(TRUE)\r\noptions(digits=22)\r\n\r\nlibrary(\"Matrix\")\r\n\r\nA <- as.matrix(readMM(paste(args[1], \"A.mtx\", sep=\"\")))\r\nB <- as.matrix(readMM(paste(args[1], \"B.mtx\", sep=\"\")))\r\nif( nrow(A)==1 ){ #support for scalars        \r\n   A <- as.numeric(A);\r\n}\r\nif( nrow(B)==1 ){ #support for scalars\r\n   B <- as.numeric(B);\r\n}\r\nC <- A%%B;\r\n\r\n#note: writeMM replaces NaN and Inf\r\nwriteMM(as(C, \"CsparseMatrix\"), paste(args[2], \"C\", sep=\"\")); \r\n\r\n\r\n" }
{ "repo_name": "deroneriksson/systemml", "ref": "refs/heads/master", "path": "system-ml/src/test/scripts/functions/parfor/parfor_optimizer2.R", "content": "#-------------------------------------------------------------\n#\n# (C) Copyright IBM Corp. 2010, 2015\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n#-------------------------------------------------------------\n\n\r\nargs <- commandArgs(TRUE)\r\noptions(digits=22)\r\n\r\nlibrary(\"Matrix\")\r\n\r\n\r\nD1 <- readMM(paste(args[1], \"D.mtx\", sep=\"\"))\r\nS11 <- readMM(paste(args[1], \"S1.mtx\", sep=\"\"))\r\nS21 <- readMM(paste(args[1], \"S2.mtx\", sep=\"\"))\r\nK11 <- readMM(paste(args[1], \"K1.mtx\", sep=\"\"))\r\nK21 <- readMM(paste(args[1], \"K2.mtx\", sep=\"\"))\r\nD <- as.matrix(D1);\r\nS1 <- as.matrix(S11);\r\nS2 <- as.matrix(S21);\r\nK1 <- as.matrix(K11);\r\nK2 <- as.matrix(K21);\r\n\r\nnumPairs <- ncol(S1) * ncol(S2); # number of attribute pairs (|S1|*|S2|)\r\nmaxC <- args[2]; # max number of categories in any categorical attribute\r\n\r\ns1size <- ncol(S1);\r\ns2size <- ncol(S2);\r\n\r\n# R, chisq, cramers, spearman, eta, anovaf\r\nnumstats <- 8;\r\nbasestats <- array(0,dim=c(numstats,numPairs)); \r\ncat_counts <- array(0,dim=c(maxC,numPairs)); \r\ncat_means <- array(0,dim=c(maxC,numPairs));\r\ncat_vars <- array(0,dim=c(maxC,numPairs));\r\n\r\n\r\nfor( i in 1:s1size ) { \r\n    a1 <- S1[,i];\r\n    k1 <- K1[1,i];\r\n    A1 <- as.matrix(D[,a1]);\r\n\r\n    for( j in 1:s2size ) {\r\n        pairID <-(i-1)*s2size+j;\r\n        a2 <- S2[,j];\r\n        k2 <- K2[1,j];\r\n        A2 <- as.matrix(D[,a2]);\r\n    \r\n        if (k1 == k2) {\r\n            if (k1 == 1) {   \r\n                # scale-scale\r\n                print(\"scale-scale\");\r\n                basestats[1,pairID] <- cor(D[,a1], D[,a2]);\r\n                #basestats[1,pairID] <- cor(A1, A2);\r\n                \r\n                print(basestats[1,pairID]);\r\n            } else {\r\n                # nominal-nominal or ordinal-ordinal\r\n                print(\"categorical-categorical\");\r\n                F <- table(A1,A2);\r\n                cst <- chisq.test(F);\r\n                chi_squared <- as.numeric(cst[1]);\r\n                degFreedom <- (nrow(F)-1)*(ncol(F)-1);\r\n                pValue <- as.numeric(cst[3]);\r\n                q <- min(dim(F));\r\n                W <- sum(F);\r\n                cramers_v <- sqrt(chi_squared/(W*(q-1)));\r\n\r\n                basestats[2,pairID] <- chi_squared;\r\n                basestats[3,pairID] <- degFreedom;\r\n                basestats[4,pairID] <- pValue;\r\n                basestats[5,pairID] <- cramers_v;\r\n\r\n                if ( k1 == 3 ) {\r\n                    # ordinal-ordinal   \r\n                    print(\"ordinal-ordinal\");\r\n                    basestats[6,pairID] <- cor(A1,A2, method=\"spearman\");\r\n                }\r\n            }\r\n        } \r\n        else {       \r\n            if (k1 == 1 || k2 == 1) {    \r\n                # Scale-nominal/ordinal\r\n                print(\"scale-categorical\");\r\n                if ( k1 == 1 ) {\r\n                    Av <- as.matrix(A2); \r\n                    Yv <- as.matrix(A1); \r\n                }\r\n                else {\r\n                    Av <- as.matrix(A1); \r\n                    Yv <- as.matrix(A2); \r\n                }\r\n                \r\n                W <- nrow(Av);\r\n                my <- mean(Yv); \r\n                varY <- var(Yv);\r\n                \r\n                CFreqs <- as.matrix(table(Av)); \r\n                CMeans <- as.matrix(aggregate(Yv, by=list(Av), \"mean\")$V1);\r\n                CVars <- as.matrix(aggregate(Yv, by=list(Av), \"var\")$V1);\r\n                R <- nrow(CFreqs);\r\n              \r\n                Eta <- sqrt(1 - ( sum((CFreqs-1)*CVars) / ((W-1)*varY) ));\r\n                anova_num <- sum( (CFreqs*(CMeans-my)^2) )/(R-1);\r\n                anova_den <- sum( (CFreqs-1)*CVars )/(W-R);\r\n                ANOVAF <- anova_num/anova_den;\r\n\r\n                basestats[7,pairID] <- Eta;\r\n                basestats[8,pairID] <- ANOVAF;\r\n\r\n                cat_counts[ 1:length(CFreqs),pairID] <- CFreqs;\r\n                cat_means[ 1:length(CMeans),pairID] <- CMeans;\r\n                cat_vars[ 1:length(CVars),pairID] <- CVars;\r\n            }\r\n            else {\r\n                # nominal-ordinal or ordinal-nominal    \r\n                print(\"nomial-ordinal\"); #TODO should not be same code            \r\n                F <- table(A1,A2);\r\n                cst <- chisq.test(F);\r\n                chi_squared <- as.numeric(cst[1]);\r\n                degFreedom <- (nrow(F)-1)*(ncol(F)-1);\r\n                pValue <- as.numeric(cst[3]);\r\n                q <- min(dim(F));\r\n                W <- sum(F);\r\n                cramers_v <- sqrt(chi_squared/(W*(q-1)));\r\n                \r\n                basestats[2,pairID] <- chi_squared;\r\n                basestats[3,pairID] <- degFreedom;\r\n                basestats[4,pairID] <- pValue;\r\n                basestats[5,pairID] <- cramers_v;\r\n            }\r\n        }\r\n    }\r\n}\r\n\r\nwriteMM(as(basestats, \"CsparseMatrix\"), paste(args[3], \"bivar.stats\", sep=\"\"));\r\nwriteMM(as(cat_counts, \"CsparseMatrix\"), paste(args[3], \"category.counts\", sep=\"\"));\r\nwriteMM(as(cat_means, \"CsparseMatrix\"), paste(args[3], \"category.means\", sep=\"\"));\r\nwriteMM(as(cat_vars, \"CsparseMatrix\"), paste(args[3], \"category.variances\", sep=\"\"));\r\n\r\n" }
{ "repo_name": "deroneriksson/systemml", "ref": "refs/heads/master", "path": "system-ml/src/test/scripts/functions/unary/matrix/Floor.R", "content": "#-------------------------------------------------------------\n#\n# (C) Copyright IBM Corp. 2010, 2015\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n#-------------------------------------------------------------\n\n\r\nargs <- commandArgs(TRUE)\r\noptions(digits=22)\r\n\r\nlibrary(\"Matrix\")\r\n\r\nA <- as.matrix(readMM(paste(args[1], \"math.mtx\", sep=\"\")))\r\n\r\nR = floor(A);\r\n\r\nwriteMM(as(R, \"CsparseMatrix\"), paste(args[2], \"R\", sep=\"\")); \r\n\r\n" }
{ "repo_name": "deroneriksson/systemml", "ref": "refs/heads/master", "path": "system-ml/src/test/scripts/functions/binary/matrix/UltraSparseMatrixMultiplication.R", "content": "#-------------------------------------------------------------\n#\n# (C) Copyright IBM Corp. 2010, 2015\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n#-------------------------------------------------------------\n\n\r\nargs <- commandArgs(TRUE)\r\noptions(digits=22)\r\n\r\nlibrary(\"Matrix\")\r\n\r\nA <- as.matrix(readMM(paste(args[1], \"A.mtx\", sep=\"\")))\r\nB <- as.matrix(readMM(paste(args[1], \"B.mtx\", sep=\"\")))\r\n\r\nP <- diag( as.vector(B==2) )\r\nPx <- P[rowSums((P==0) | is.na(P)) != ncol(P),];\r\n\r\nC <- Px %*% A;\r\n\r\nwriteMM(as(C, \"CsparseMatrix\"), paste(args[2], \"C\", sep=\"\")); \r\n\r\n" }
{ "repo_name": "deroneriksson/systemml", "ref": "refs/heads/master", "path": "system-ml/src/test/scripts/applications/descriptivestats/ScaleCategoricalWithWeightsTest.R", "content": "#-------------------------------------------------------------\r\n#\r\n# (C) Copyright IBM Corp. 2010, 2015\r\n#\r\n# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n# you may not use this file except in compliance with the License.\r\n# You may obtain a copy of the License at\r\n#\r\n#     http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n#\r\n#-------------------------------------------------------------\r\n\r\n# JUnit test class: dml.test.integration.descriptivestats.BivariateScaleCategoricalTest.java\r\n# command line invocation assuming $SC_HOME is set to the home of the R script\r\n# Rscript $SC_HOME/ScaleCategorical.R $SC_HOME/in/ $SC_HOME/expected/\r\n\r\nargs <- commandArgs(TRUE)\r\noptions(digits=22)\r\n\r\nlibrary(\"Matrix\")\r\n# Usage: R --vanilla -args Xfile X < ScaleCategoricalTest.R\r\n\r\n#parseCommandArgs()\r\n######################\r\nAtemp = readMM(paste(args[1], \"A.mtx\", sep=\"\"));\r\nYtemp = readMM(paste(args[1], \"Y.mtx\", sep=\"\"));\r\nWM = readMM(paste(args[1], \"WM.mtx\", sep=\"\"));\r\n\r\nYv=rep(Ytemp[,1],WM[,1])\r\nAv=rep(Atemp[,1],WM[,1])\r\n\r\nW = sum(WM);\r\nmy = sum(Yv)/W;\r\nvarY = var(Yv);\r\n\r\nCFreqs = as.matrix(table(Av)); \r\nCMeans = as.matrix(aggregate(Yv, by=list(Av), \"mean\")$x);\r\nCVars = as.matrix(aggregate(Yv, by=list(Av), \"var\")$x);\r\n\r\n# number of categories\r\nR = nrow(CFreqs);\r\n\r\nEta = sqrt(1 - ( sum((CFreqs-1)*CVars) / ((W-1)*varY) ));\r\n\r\nanova_num = sum( (CFreqs*(CMeans-my)^2) )/(R-1);\r\nanova_den = sum( (CFreqs-1)*CVars )/(W-R);\r\nANOVAF = anova_num/anova_den;\r\n\r\nprint(W, digits=15);\r\nprint(R, digits=15);\r\nprint(anova_num, digits=15);\r\nprint(anova_den, digits=15);\r\n\r\n#######################\r\n\r\nwrite(Eta, paste(args[2], \"Eta\", sep=\"\"));\r\n\r\nwrite(ANOVAF, paste(args[2], \"AnovaF\", sep=\"\"));\r\n\r\nwrite(varY, paste(args[2], \"VarY\", sep=\"\"));\r\n\r\nwrite(my, paste(args[2], \"MeanY\", sep=\"\"));\r\n\r\nwriteMM(as(CVars,\"CsparseMatrix\"), paste(args[2], \"CVars\", sep=\"\"), format=\"text\");\r\nwriteMM(as(CFreqs,\"CsparseMatrix\"), paste(args[2], \"CFreqs\", sep=\"\"), format=\"text\");\r\nwriteMM(as(CMeans,\"CsparseMatrix\"), paste(args[2], \"CMeans\", sep=\"\"), format=\"text\");\r\n\r\n\r\n\r\n" }
{ "repo_name": "deroneriksson/systemml", "ref": "refs/heads/master", "path": "system-ml/src/test/scripts/functions/quaternary/WeightedSigmoidP4.R", "content": "#-------------------------------------------------------------\n#\n# (C) Copyright IBM Corp. 2010, 2015\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n#-------------------------------------------------------------\n\n\r\nargs <- commandArgs(TRUE)\r\noptions(digits=22)\r\n\r\nlibrary(\"Matrix\")\r\n\r\nX = as.matrix(readMM(paste(args[1], \"X.mtx\", sep=\"\")))\r\nU = as.matrix(readMM(paste(args[1], \"U.mtx\", sep=\"\")))\r\nV = as.matrix(readMM(paste(args[1], \"V.mtx\", sep=\"\")))\r\n\r\nUV = -(U%*%t(V));\r\nR = X * log(1/(1 + exp(-UV)));\r\n\r\nwriteMM(as(R, \"CsparseMatrix\"), paste(args[2], \"R\", sep=\"\")); \r\n\r\n\r\n" }
{ "repo_name": "deroneriksson/systemml", "ref": "refs/heads/master", "path": "system-ml/src/test/scripts/functions/binary/matrix/UaggOuterChainNotEqualsRowIndexMin.R", "content": "#-------------------------------------------------------------\n#\n# (C) Copyright IBM Corp. 2010, 2015\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n#-------------------------------------------------------------\n\nargs <- commandArgs(TRUE)\noptions(digits=22)\n\nlibrary(\"Matrix\")\n\nA <- as.vector(readMM(paste(args[1], \"A.mtx\", sep=\"\")))\nB <- as.vector(readMM(paste(args[1], \"B.mtx\", sep=\"\")))\n\nI <- as.matrix(outer(A,B,\"!=\"));\nC <- max.col(-I,ties.method=\"first\");\n\nwriteMM(as(C, \"CsparseMatrix\"), paste(args[2], \"C\", sep=\"\"));" }
{ "repo_name": "deroneriksson/systemml", "ref": "refs/heads/master", "path": "system-ml/src/test/scripts/functions/unary/scalar/DFTest_T.R", "content": "#-------------------------------------------------------------\n#\n# (C) Copyright IBM Corp. 2010, 2015\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n#-------------------------------------------------------------\n\n\r\n\r\nargs <- commandArgs(TRUE)\r\nlibrary(Matrix)\r\n\r\nqtle = qt(as.numeric(args[1]), df=as.numeric(args[2]));\r\np = pt(qtle, df=as.numeric(args[2]));\r\npl = pt(qtle, df=as.numeric(args[2]), lower.tail=F);\r\n\r\nout = matrix(0,nrow=3, ncol=1);\r\nout[1,1] = qtle;\r\nout[2,1] = p;\r\nout[3,1] = pl;\r\n\r\nwriteMM(as(out, \"CsparseMatrix\"), args[3]); \r\n\r\n" }
{ "repo_name": "deroneriksson/systemml", "ref": "refs/heads/master", "path": "system-ml/src/test/scripts/functions/external/DynProject.R", "content": "#-------------------------------------------------------------\n#\n# (C) Copyright IBM Corp. 2010, 2015\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n#-------------------------------------------------------------\n\n\r\nargs <- commandArgs(TRUE)\r\noptions(digits=22)\r\n\r\nlibrary(\"Matrix\")\r\n\r\nX <- as.matrix(readMM(paste(args[1], \"X.mtx\", sep=\"\")));\r\nc <- as.matrix(readMM(paste(args[1], \"c.mtx\", sep=\"\")));\r\n\r\nif( ncol(X)==1 )\r\n{\r\n   Y <- X[c];\r\n} else {\r\n   Y <- X[c,c];\r\n}\r\n\r\nwriteMM(as(Y, \"CsparseMatrix\"), paste(args[2], \"Y.mtx\", sep=\"\")); " }
{ "repo_name": "deroneriksson/systemml", "ref": "refs/heads/master", "path": "system-ml/src/test/scripts/applications/parfor/parfor_naive-bayes.R", "content": "#-------------------------------------------------------------\r\n#\r\n# (C) Copyright IBM Corp. 2010, 2015\r\n#\r\n# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n# you may not use this file except in compliance with the License.\r\n# You may obtain a copy of the License at\r\n#\r\n#     http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n#\r\n#-------------------------------------------------------------\r\n\r\nargs <- commandArgs(TRUE)\r\noptions(digits=22)\r\n\r\nlibrary(\"Matrix\")\r\n\r\nD = as.matrix(readMM(paste(args[1], \"D.mtx\", sep=\"\")))\r\nC = as.matrix(readMM(paste(args[1], \"C.mtx\", sep=\"\")))\r\n\r\n# reading input args\r\nnumClasses = as.integer(args[2]);\r\nlaplace_correction = 1\r\n\r\nnumRows = nrow(D)\r\nnumFeatures = ncol(D)\r\n\r\n# Compute conditionals\r\n\r\n# Compute the feature counts for each class\r\nclassFeatureCounts = matrix(0, numClasses, numFeatures)\r\nfor (i in 1:numFeatures) {\r\n  Col = D[,i]\r\n  classFeatureCounts[,i] = aggregate(as.vector(Col), by=list(as.vector(C)), FUN=sum)[,2];\r\n}\r\n\r\n# Compute the total feature count for each class \r\n# and add the number of features to this sum\r\n# for subsequent regularization (Laplace's rule)\r\nclassSums = rowSums(classFeatureCounts) + numFeatures*laplace_correction\r\n\r\n# Compute class conditional probabilities\r\nrepClassSums = classSums %*% matrix(1,1,numFeatures);\r\nclass_conditionals = (classFeatureCounts + laplace_correction) / repClassSums;\r\n\r\n# Compute class priors\r\nclass_counts = aggregate(as.vector(C), by=list(as.vector(C)), FUN=length)[,2]\r\nclass_prior = class_counts / numRows;\r\n\r\n# write out the model\r\nwriteMM(as(class_prior, \"CsparseMatrix\"), paste(args[3], \"class_prior\", sep=\"\"));\r\nwriteMM(as(class_conditionals, \"CsparseMatrix\"), paste(args[3], \"class_conditionals\", sep=\"\"));\r\n" }
{ "repo_name": "deroneriksson/systemml", "ref": "refs/heads/master", "path": "system-ml/src/test/scripts/functions/recompile/remove_empty_recompile.R", "content": "#-------------------------------------------------------------\n#\n# (C) Copyright IBM Corp. 2010, 2015\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n#-------------------------------------------------------------\n\n\r\nargs <- commandArgs(TRUE)\r\noptions(digits=22)\r\n\r\nlibrary(\"Matrix\")\r\n\r\nX <- readMM(paste(args[1], \"X.mtx\", sep=\"\"))\r\n\r\ntype = as.integer(args[2]);\r\n\r\nR = X;\r\n\r\nif( type==0 ){\r\n  R = as.matrix( sum(X) );\r\n}\r\nif( type==1 ){\r\n  R = round(X);\r\n}\r\nif( type==2 ){\r\n  R = t(X); \r\n}\r\nif( type==3 ){\r\n  R = X*(X-1);\r\n}\r\nif( type==4 ){\r\n  R = (X-1)*X;\r\n}\r\nif( type==5 ){\r\n  R = X+(X-1);\r\n}\r\nif( type==6 ){\r\n  R = (X-1)+X;\r\n}\r\nif( type==7 ){\r\n  R = X-(X+2);\r\n}\r\nif( type==8 ){\r\n  R = (X+2)-X;\r\n}\r\nif( type==9 ){\r\n  R = X%*%(X-1);\r\n}\r\nif( type==10 ){\r\n  R = (X-1)%*%X;\r\n}\r\nif( type==11 ){\r\n  R = X[1:(nrow(X)-1), 1:(ncol(X)-1)];\r\n}\r\nif( type==12 ){\r\n  X[1,] = X[2,];\r\n  R = X;\r\n}\r\n\r\nwriteMM(as(R, \"CsparseMatrix\"), paste(args[3], \"R\", sep=\"\")); " }