{ "repo_name": "skosukhin/spack", "ref": "refs/heads/esiwace", "path": "var/spack/repos/builtin/packages/perl-sub-install/package.py", "content": "##############################################################################\n# Copyright (c) 2013-2017, Lawrence Livermore National Security, LLC.\n# Produced at the Lawrence Livermore National Laboratory.\n#\n# This file is part of Spack.\n# Created by Todd Gamblin, tgamblin@llnl.gov, All rights reserved.\n# LLNL-CODE-647188\n#\n# For details, see https://github.com/spack/spack\n# Please also see the NOTICE and LICENSE files for our notice and the LGPL.\n#\n# This program is free software; you can redistribute it and/or modify\n# it under the terms of the GNU Lesser General Public License (as\n# published by the Free Software Foundation) version 2.1, February 1999.\n#\n# This program is distributed in the hope that it will be useful, but\n# WITHOUT ANY WARRANTY; without even the IMPLIED WARRANTY OF\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the terms and\n# conditions of the GNU Lesser General Public License for more details.\n#\n# You should have received a copy of the GNU Lesser General Public\n# License along with this program; if not, write to the Free Software\n# Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA\n##############################################################################\nfrom spack import *\n\n\nclass PerlSubInstall(PerlPackage):\n    \"\"\"Install subroutines into packages easily\"\"\"\n\n    homepage = \"http://search.cpan.org/~rjbs/Sub-Install-0.928/lib/Sub/Install.pm\"\n    url      = \"http://search.cpan.org/CPAN/authors/id/R/RJ/RJBS/Sub-Install-0.928.tar.gz\"\n\n    version('0.928', 'e1ce4f9cb6b2f6b8778b036c31afa5ab')\n" } 
{ "repo_name": "maggienj/ActiveData", "ref": "refs/heads/es5", "path": "jx_elasticsearch/es09/setop.py", "content": "# encoding: utf-8\n#\n#\n# This Source Code Form is subject to the terms of the Mozilla Public\n# License, v. 2.0. If a copy of the MPL was not distributed with this file,\n# You can obtain one at http:# mozilla.org/MPL/2.0/.\n#\n# Author: Kyle Lahnakoski (kyle@lahnakoski.com)\n#\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import unicode_literals\n\nfrom collections import Mapping\n\nfrom jx_elasticsearch import es09\nfrom jx_python import domains\nfrom mo_dots import coalesce, split_field, Data, wrap\nfrom mo_dots import listwrap, unwrap\nfrom mo_logs import Log\nfrom mo_math import AND, SUM, OR\n\nfrom jx_base.expressions import TRUE_FILTER, jx_expression, Variable\nfrom jx_base.queries import is_variable_name\nfrom jx_elasticsearch.es09.expressions import unpack_terms\nfrom jx_elasticsearch.es09.util import aggregates\nfrom jx_elasticsearch.es52.expressions import simplify_esfilter\nfrom jx_python.containers.cube import Cube\nfrom mo_collections.matrix import Matrix\nfrom mo_dots.lists import FlatList\n\n\ndef is_fieldop(query):\n    # THESE SMOOTH EDGES REQUIRE ALL DATA (SETOP)\n\n    select = listwrap(query.select)\n    if not query.edges:\n        isDeep = len(split_field(query.frum.name)) > 1  # LOOKING INTO NESTED WILL REQUIRE A SCRIPT\n        isSimple = AND(s.value != None and (s.value == \"*\" or is_variable_name(s.value)) for s in select)\n        noAgg = AND(s.aggregate == \"none\" for s in select)\n\n        if not isDeep and isSimple and noAgg:\n            return True\n    else:\n        isSmooth = AND((e.domain.type in domains.ALGEBRAIC and e.domain.interval == \"none\") for e in query.edges)\n        if isSmooth:\n            return True\n\n    return False\n\n\ndef es_fieldop(es, query):\n    FromES = es09.util.build_es_query(query)\n    select = listwrap(query.select)\n    FromES.query = {\n        \"bool\": {\n            \"query\": {\n                \"match_all\": {}\n          }\n            \"filter\": simplify_esfilter(jx_expression(query.where).to_esfilter())\n      }\n  }\n    FromES.size = coalesce(query.limit, 200000)\n    FromES.fields = FlatList()\n    for s in select.value:\n        if s == \"*\":\n            FromES.fields = None\n        elif isinstance(s, list):\n            FromES.fields.extend(s)\n        elif isinstance(s, Mapping):\n            FromES.fields.extend(s.values())\n        else:\n            FromES.fields.append(s)\n    FromES.sort = [{s.field: \"asc\" if s.sort >= 0 else \"desc\"} for s in query.sort]\n\n    data = es09.util.post(es, FromES, query.limit)\n\n    T = data.hits.hits\n    matricies = {}\n    for s in select:\n        if s.value == \"*\":\n            matricies[s.name] = Matrix.wrap([t._source for t in T])\n        elif isinstance(s.value, Mapping):\n            # for k, v in s.value.items():\n            #     matricies[join_field(split_field(s.name)+[k])] = Matrix.wrap([unwrap(t.fields)[v] for t in T])\n            matricies[s.name] = Matrix.wrap([{k: unwrap(t.fields).get(v, None) for k, v in s.value.items()}for t in T])\n        elif isinstance(s.value, list):\n            matricies[s.name] = Matrix.wrap([tuple(unwrap(t.fields).get(ss, None) for ss in s.value) for t in T])\n        elif not s.value:\n            matricies[s.name] = Matrix.wrap([unwrap(t.fields).get(s.value, None) for t in T])\n        else:\n            try:\n                matricies[s.name] = Matrix.wrap([unwrap(t.fields).get(s.value, None) for t in T])\n            except Exception as e:\n                Log.error(\"\", e)\n\n    cube = Cube(query.select, query.edges, matricies, frum=query)\n    cube.frum = query\n    return cube\n\n\ndef is_setop(query):\n    select = listwrap(query.select)\n\n    if not query.edges:\n        isDeep = len(split_field(query.frum.name)) > 1  # LOOKING INTO NESTED WILL REQUIRE A SCRIPT\n        simpleAgg = AND([s.aggregate in (\"count\", \"none\") for s in select])   # CONVERTING esfilter DEFINED PARTS WILL REQUIRE SCRIPT\n\n        # NO EDGES IMPLIES SIMPLER QUERIES: EITHER A SET OPERATION, OR RETURN SINGLE AGGREGATE\n        if simpleAgg or isDeep:\n            return True\n    else:\n        isSmooth = AND((e.domain.type in domains.ALGEBRAIC and e.domain.interval == \"none\") for e in query.edges)\n        if isSmooth:\n            return True\n\n    return False\n\n\ndef es_setop(es, mvel, query):\n    FromES = es09.util.build_es_query(query)\n    select = listwrap(query.select)\n\n    isDeep = len(split_field(query.frum.name)) > 1  # LOOKING INTO NESTED WILL REQUIRE A SCRIPT\n    isComplex = OR([s.value == None and s.aggregate not in (\"count\", \"none\") for s in select])   # CONVERTING esfilter DEFINED PARTS WILL REQUIRE SCRIPT\n\n    if not isDeep and not isComplex:\n        if len(select) == 1 and not select[0].value or select[0].value == \"*\":\n            FromES = wrap({\n                \"query\": {\"bool\": {\n                    \"query\": {\"match_all\": {}}\n                    \"filter\": simplify_esfilter(jx_expression(query.where).to_esfilter())\n              }}\n                \"sort\": query.sort,\n                \"size\": 0\n          })\n        elif all(isinstance(v, Variable) for v in select.value):\n            FromES = wrap({\n                \"query\": {\"bool\": {\n                    \"query\": {\"match_all\": {}}\n                    \"filter\": simplify_esfilter(query.where.to_esfilter())\n              }}\n                \"fields\": select.value,\n                \"sort\": query.sort,\n                \"size\": coalesce(query.limit, 200000)\n          })\n    elif not isDeep:\n        simple_query = query.copy()\n        simple_query.where = TRUE_FILTER  # THE FACET FILTER IS FASTER\n        FromES.facets.mvel = {\n            \"terms\": {\n                \"script_field\": mvel.code(simple_query),\n                \"size\": coalesce(simple_query.limit, 200000)\n          }\n            \"facet_filter\": simplify_esfilter(jx_expression(query.where).to_esfilter())\n      }\n    else:\n        FromES.facets.mvel = {\n            \"terms\": {\n                \"script_field\": mvel.code(query),\n                \"size\": coalesce(query.limit, 200000)\n          }\n            \"facet_filter\": simplify_esfilter(jx_expression(query.where).to_esfilter())\n      }\n\n    data = es09.util.post(es, FromES, query.limit)\n\n    if len(select) == 1 and  not select[0].value or select[0].value == \"*\":\n        # SPECIAL CASE FOR SINGLE COUNT\n        cube = wrap(data).hits.hits._source\n    elif isinstance(select[0].value, Variable):\n        # SPECIAL CASE FOR SINGLE TERM\n        cube = wrap(data).hits.hits.fields\n    else:\n        data_list = unpack_terms(data.facets.mvel, select)\n        if not data_list:\n            cube = Cube(select, [], {s.name: Matrix.wrap([]) for s in select})\n        else:\n            output = zip(*data_list)\n            cube = Cube(select, [], {s.name: Matrix(list=output[i]) for i, s in enumerate(select)})\n\n    return Data(\n        meta={\"esquery\": FromES}\n        data=cube\n    )\n\n\ndef is_deep(query):\n    select = listwrap(query.select)\n    if len(select) > 1:\n        return False\n\n    if aggregates[select[0].aggregate] not in (\"none\", \"count\"):\n        return False\n\n    if len(query.edges)<=1:\n        return False\n\n    isDeep = len(split_field(query[\"from\"].name)) > 1  # LOOKING INTO NESTED WILL REQUIRE A SCRIPT\n    if not isDeep:\n        return False   # BETTER TO USE TERM QUERY\n\n    return True\n\n\ndef es_deepop(es, mvel, query):\n    FromES = es09.util.build_es_query(query)\n\n    select = query.edges\n\n    temp_query = query.copy()\n    temp_query.select = select\n    temp_query.edges = FlatList()\n    FromES.facets.mvel = {\n        \"terms\": {\n            \"script_field\": mvel.code(temp_query),\n            \"size\": query.limit\n      }\n        \"facet_filter\": simplify_esfilter(jx_expression(query.where).to_esfilter())\n  }\n\n    data = es09.util.post(es, FromES, query.limit)\n\n    rows = unpack_terms(data.facets.mvel, query.edges)\n    terms = zip(*rows)\n\n    # NUMBER ALL EDGES FOR JSON EXPRESSION INDEXING\n    edges = query.edges\n    for f, e in enumerate(edges):\n        for r in terms[f]:\n            e.domain.getPartByKey(r)\n\n        e.index = f\n        for p, part in enumerate(e.domain.partitions):\n            part.dataIndex = p\n        e.domain.NULL.dataIndex = len(e.domain.partitions)\n\n    # MAKE CUBE\n    dims = [len(e.domain.partitions) for e in query.edges]\n    output = Matrix(*dims)\n\n    # FILL CUBE\n    for r in rows:\n        term_coord = [e.domain.getPartByKey(r[i]).dataIndex for i, e in enumerate(edges)]\n        output[term_coord] = SUM(output[term_coord], r[-1])\n\n    cube = Cube(query.select, query.edges, {query.select.name: output})\n    cube.frum = query\n    return cube\n" }
{ "repo_name": "SolaWing/ycmd", "ref": "refs/heads/mine", "path": "ycmd/tests/clang/signature_help_test.py", "content": "# encoding: utf-8\n#\n# Copyright (C) 2015-2018 ycmd contributors\n#\n# This file is part of ycmd.\n#\n# ycmd is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# ycmd is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with ycmd.  If not, see <http://www.gnu.org/licenses/>.\n\nfrom __future__ import absolute_import\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\n# Not installing aliases from python-future; it's unreliable and slow.\nfrom builtins import *  # noqa\n\n\nfrom hamcrest import ( assert_that, empty, has_entries, has_items )\n\nfrom ycmd.utils import ReadFile\nfrom ycmd.tests.clang import PathToTestFile, SharedYcmd\nfrom ycmd.tests.test_utils import ( EMPTY_SIGNATURE_HELP,\n                                    BuildRequest,\n                                    CompletionEntryMatcher )\n\n\n@SharedYcmd\ndef SignatureHelp_NotImplemented_test( app ):\n  app.post_json(\n    '/load_extra_conf_file',\n  { 'filepath': PathToTestFile( '.ycm_extra_conf.py' ) } )\n\n  filepath = PathToTestFile( 'unity.cc' )\n  contents = ReadFile( filepath )\n\n  app.post_json( '/event_notification',\n                 BuildRequest( filepath = filepath,\n                               contents = contents,\n                               filetype = 'cpp',\n                               event_name = 'FileReadyToParse' ) )\n\n  # Doing a completion proves that we have semantic parsing working\n  response_data = app.post_json( '/completions',\n                                 BuildRequest( filepath = filepath,\n                                               contents = contents,\n                                               filetype = 'cpp',\n                                               line_num = 27,\n                                               column_num = 11,\n                                               force_semantic = True ) ).json\n\n  assert_that( response_data[ 'completions' ],\n               has_items( CompletionEntryMatcher( 'an_int' ),\n                          CompletionEntryMatcher( 'a_char' ) ) )\n\n  # Signature help request always returns nothing\n  # FIXME: A method to say \"don't bother sending more signature help request\"\n  response_data = app.post_json( '/signature_help',\n                                BuildRequest( filepath = filepath,\n                                              contents = contents,\n                                              filetype = 'cpp',\n                                              line_num = 24,\n                                              column_num = 19 ) ).json\n\n  assert_that( response_data, has_entries( {\n    'errors': empty(),\n    'signature_help': EMPTY_SIGNATURE_HELP\n} ) )\n" }
{ "repo_name": "CyBHFal/plugin.video.freplay", "ref": "refs/heads/cyb2", "path": "resources/lib/delete_catalog_cache.py", "content": "#-*- coding: utf-8 -*-\nimport globalvar\nimport shutil\nimport xbmcgui\nimport os\n\ndef delete_catalog_cache() :\n    if os.path.exists(globalvar.CACHE_DIR) :\n        shutil.rmtree(globalvar.CACHE_DIR)\n    if not os.path.exists(globalvar.CACHE_DIR):\n        os.makedirs(globalvar.CACHE_DIR, mode=0777)\n    xbmcgui.Dialog().ok(globalvar.LANGUAGE(30000), globalvar.LANGUAGE(32000))\n    \nif ( __name__ == \"__main__\" ):\n    if  globalvar.CACHE_DIR != '' :\n        delete_catalog_cache()\n" } 
{ "repo_name": "leeper/dataverse-1", "ref": "refs/heads/4.2", "path": "tests/test_create_test_account.py", "content": "from selenium import webdriver\nimport time, unittest, config\n\ndef is_alert_present(wd):\n    try:\n        wd.switch_to_alert().text\n        return True\n    except:\n        return False\n\nclass test_create_test_account(unittest.TestCase):\n    def setUp(self):\n        if (config.local):\n            self.wd = webdriver.Firefox()\n        else:\n            desired_capabilities = webdriver.DesiredCapabilities.FIREFOX\n            desired_capabilities['version'] = '24'\n            desired_capabilities['platform'] = 'Linux'\n            desired_capabilities['name'] = 'test_access'\n            self.wd = webdriver.Remote(\n                desired_capabilities=desired_capabilities,\n                command_executor=\"http://esodvn:325caef9-81dd-47a5-8b74-433057ce888f@ondemand.saucelabs.com:80/wd/hub\"\n            )\n \n        self.wd.implicitly_wait(60)\n    \n    def test_test_create_test_account(self):\n        success = True\n        wd = self.wd\n        wd.get(config.accessURL)\n        wd.find_element_by_link_text(\"Create Account\").click()\n        wd.find_element_by_id(\"dataverseUserForm:userName\").click()\n        wd.find_element_by_id(\"dataverseUserForm:userName\").clear()\n        wd.find_element_by_id(\"dataverseUserForm:userName\").send_keys(\"tester\")\n        wd.find_element_by_id(\"dataverseUserForm:inputPassword\").click()\n        wd.find_element_by_id(\"dataverseUserForm:inputPassword\").clear()\n        wd.find_element_by_id(\"dataverseUserForm:inputPassword\").send_keys(\"tester\")\n        wd.find_element_by_id(\"dataverseUserForm:retypePassword\").click()\n        wd.find_element_by_id(\"dataverseUserForm:retypePassword\").clear()\n        wd.find_element_by_id(\"dataverseUserForm:retypePassword\").send_keys(\"tester\")\n        wd.find_element_by_id(\"dataverseUserForm:firstName\").click()\n        wd.find_element_by_id(\"dataverseUserForm:firstName\").clear()\n        wd.find_element_by_id(\"dataverseUserForm:firstName\").send_keys(\"test\")\n        wd.find_element_by_id(\"dataverseUserForm:lastName\").click()\n        wd.find_element_by_id(\"dataverseUserForm:lastName\").clear()\n        wd.find_element_by_id(\"dataverseUserForm:lastName\").send_keys(\"user\")\n        wd.find_element_by_id(\"dataverseUserForm:email\").click()\n        wd.find_element_by_id(\"dataverseUserForm:email\").clear()\n        wd.find_element_by_id(\"dataverseUserForm:email\").send_keys(\"kcondon@hmdc.harvard.edu\")\n        wd.find_element_by_id(\"dataverseUserForm:institution\").click()\n        wd.find_element_by_id(\"dataverseUserForm:institution\").clear()\n        wd.find_element_by_id(\"dataverseUserForm:institution\").send_keys(\"IQSS\")\n        wd.find_element_by_xpath(\"//div[@id='dataverseUserForm:j_idt45']/div[3]\").click()\n        wd.find_element_by_xpath(\"//div[@class='ui-selectonemenu-items-wrapper']//li[.='Staff']\").click()\n        wd.find_element_by_id(\"dataverseUserForm:phone\").click()\n        wd.find_element_by_id(\"dataverseUserForm:phone\").clear()\n        wd.find_element_by_id(\"dataverseUserForm:phone\").send_keys(\"1-222-333-4444\")\n        wd.find_element_by_id(\"dataverseUserForm:save\").click()\n        time.sleep(1)\n        if (\"This Username is already taken.\" in wd.find_element_by_tag_name(\"html\").text):\n            print(\"Username exists. Exiting.\")\n            return   \n        if not (\"Log Out\" in wd.find_element_by_tag_name(\"html\").text): \n            success = false\n            print(\"User was not logged in after create account.\")           \n        self.assertTrue(success)\n    \n    def tearDown(self):\n        if not (config.local):\n            print(\"Link to your job: https://saucelabs.com/jobs/%s\" % self.wd.session_id)        \n        self.wd.quit()\n\nif __name__ == '__main__':\n    unittest.main()\n" }
{ "repo_name": "alanjw/GreenOpenERP-Win-X86", "ref": "refs/heads/7.0", "path": "python/Lib/sqlite3/test/hooks.py", "content": "#-*- coding: ISO-8859-1 -*-\r\n# pysqlite2/test/hooks.py: tests for various SQLite-specific hooks\r\n#\r\n# Copyright (C) 2006-2007 Gerhard Häring <gh@ghaering.de>\r\n#\r\n# This file is part of pysqlite.\r\n#\r\n# This software is provided 'as-is', without any express or implied\r\n# warranty.  In no event will the authors be held liable for any damages\r\n# arising from the use of this software.\r\n#\r\n# Permission is granted to anyone to use this software for any purpose,\r\n# including commercial applications, and to alter it and redistribute it\r\n# freely, subject to the following restrictions:\r\n#\r\n# 1. The origin of this software must not be misrepresented; you must not\r\n#    claim that you wrote the original software. If you use this software\r\n#    in a product, an acknowledgment in the product documentation would be\r\n#    appreciated but is not required.\r\n# 2. Altered source versions must be plainly marked as such, and must not be\r\n#    misrepresented as being the original software.\r\n# 3. This notice may not be removed or altered from any source distribution.\r\n\r\nimport os, unittest\r\nimport sqlite3 as sqlite\r\n\r\nclass CollationTests(unittest.TestCase):\r\n    def setUp(self):\r\n        pass\r\n\r\n    def tearDown(self):\r\n        pass\r\n\r\n    def CheckCreateCollationNotCallable(self):\r\n        con = sqlite.connect(\":memory:\")\r\n        try:\r\n            con.create_collation(\"X\", 42)\r\n            self.fail(\"should have raised a TypeError\")\r\n        except TypeError, e:\r\n            self.assertEqual(e.args[0], \"parameter must be callable\")\r\n\r\n    def CheckCreateCollationNotAscii(self):\r\n        con = sqlite.connect(\":memory:\")\r\n        try:\r\n            con.create_collation(\"collä\", cmp)\r\n            self.fail(\"should have raised a ProgrammingError\")\r\n        except sqlite.ProgrammingError, e:\r\n            pass\r\n\r\n    def CheckCollationIsUsed(self):\r\n        if sqlite.version_info < (3, 2, 1):  # old SQLite versions crash on this test\r\n            return\r\n        def mycoll(x, y):\r\n            # reverse order\r\n            return -cmp(x, y)\r\n\r\n        con = sqlite.connect(\":memory:\")\r\n        con.create_collation(\"mycoll\", mycoll)\r\n        sql = \"\"\"\r\n            select x from (\r\n            select 'a' as x\r\n            union\r\n            select 'b' as x\r\n            union\r\n            select 'c' as x\r\n            ) order by x collate mycoll\r\n            \"\"\"\r\n        result = con.execute(sql).fetchall()\r\n        if result[0][0] != \"c\" or result[1][0] != \"b\" or result[2][0] != \"a\":\r\n            self.fail(\"the expected order was not returned\")\r\n\r\n        con.create_collation(\"mycoll\", None)\r\n        try:\r\n            result = con.execute(sql).fetchall()\r\n            self.fail(\"should have raised an OperationalError\")\r\n        except sqlite.OperationalError, e:\r\n            self.assertEqual(e.args[0].lower(), \"no such collation sequence: mycoll\")\r\n\r\n    def CheckCollationRegisterTwice(self):\r\n        \"\"\"\r\n        Register two different collation functions under the same name.\r\n        Verify that the last one is actually used.\r\n        \"\"\"\r\n        con = sqlite.connect(\":memory:\")\r\n        con.create_collation(\"mycoll\", cmp)\r\n        con.create_collation(\"mycoll\", lambda x, y: -cmp(x, y))\r\n        result = con.execute(\"\"\"\r\n            select x from (select 'a' as x union select 'b' as x) order by x collate mycoll\r\n            \"\"\").fetchall()\r\n        if result[0][0] != 'b' or result[1][0] != 'a':\r\n            self.fail(\"wrong collation function is used\")\r\n\r\n    def CheckDeregisterCollation(self):\r\n        \"\"\"\r\n        Register a collation, then deregister it. Make sure an error is raised if we try\r\n        to use it.\r\n        \"\"\"\r\n        con = sqlite.connect(\":memory:\")\r\n        con.create_collation(\"mycoll\", cmp)\r\n        con.create_collation(\"mycoll\", None)\r\n        try:\r\n            con.execute(\"select 'a' as x union select 'b' as x order by x collate mycoll\")\r\n            self.fail(\"should have raised an OperationalError\")\r\n        except sqlite.OperationalError, e:\r\n            if not e.args[0].startswith(\"no such collation sequence\"):\r\n                self.fail(\"wrong OperationalError raised\")\r\n\r\nclass ProgressTests(unittest.TestCase):\r\n    def CheckProgressHandlerUsed(self):\r\n        \"\"\"\r\n        Test that the progress handler is invoked once it is set.\r\n        \"\"\"\r\n        con = sqlite.connect(\":memory:\")\r\n        progress_calls = []\r\n        def progress():\r\n            progress_calls.append(None)\r\n            return 0\r\n        con.set_progress_handler(progress, 1)\r\n        con.execute(\"\"\"\r\n            create table foo(a, b)\r\n            \"\"\")\r\n        self.assertTrue(progress_calls)\r\n\r\n\r\n    def CheckOpcodeCount(self):\r\n        \"\"\"\r\n        Test that the opcode argument is respected.\r\n        \"\"\"\r\n        con = sqlite.connect(\":memory:\")\r\n        progress_calls = []\r\n        def progress():\r\n            progress_calls.append(None)\r\n            return 0\r\n        con.set_progress_handler(progress, 1)\r\n        curs = con.cursor()\r\n        curs.execute(\"\"\"\r\n            create table foo (a, b)\r\n            \"\"\")\r\n        first_count = len(progress_calls)\r\n        progress_calls = []\r\n        con.set_progress_handler(progress, 2)\r\n        curs.execute(\"\"\"\r\n            create table bar (a, b)\r\n            \"\"\")\r\n        second_count = len(progress_calls)\r\n        self.assertTrue(first_count > second_count)\r\n\r\n    def CheckCancelOperation(self):\r\n        \"\"\"\r\n        Test that returning a non-zero value stops the operation in progress.\r\n        \"\"\"\r\n        con = sqlite.connect(\":memory:\")\r\n        progress_calls = []\r\n        def progress():\r\n            progress_calls.append(None)\r\n            return 1\r\n        con.set_progress_handler(progress, 1)\r\n        curs = con.cursor()\r\n        self.assertRaises(\r\n            sqlite.OperationalError,\r\n            curs.execute,\r\n            \"create table bar (a, b)\")\r\n\r\n    def CheckClearHandler(self):\r\n        \"\"\"\r\n        Test that setting the progress handler to None clears the previously set handler.\r\n        \"\"\"\r\n        con = sqlite.connect(\":memory:\")\r\n        action = []\r\n        def progress():\r\n            action.append(1)\r\n            return 0\r\n        con.set_progress_handler(progress, 1)\r\n        con.set_progress_handler(None, 1)\r\n        con.execute(\"select 1 union select 2 union select 3\").fetchall()\r\n        self.assertEqual(len(action), 0, \"progress handler was not cleared\")\r\n\r\ndef suite():\r\n    collation_suite = unittest.makeSuite(CollationTests, \"Check\")\r\n    progress_suite = unittest.makeSuite(ProgressTests, \"Check\")\r\n    return unittest.TestSuite((collation_suite, progress_suite))\r\n\r\ndef test():\r\n    runner = unittest.TextTestRunner()\r\n    runner.run(suite())\r\n\r\nif __name__ == \"__main__\":\r\n    test()\r\n" }
{ "repo_name": "ekoi/DANS-DVN-4.6.1", "ref": "refs/heads/v4.6.1-merge", "path": "tests/test_create_test_account.py", "content": "from selenium import webdriver\nimport time, unittest, config\n\ndef is_alert_present(wd):\n    try:\n        wd.switch_to_alert().text\n        return True\n    except:\n        return False\n\nclass test_create_test_account(unittest.TestCase):\n    def setUp(self):\n        if (config.local):\n            self.wd = webdriver.Firefox()\n        else:\n            desired_capabilities = webdriver.DesiredCapabilities.FIREFOX\n            desired_capabilities['version'] = '24'\n            desired_capabilities['platform'] = 'Linux'\n            desired_capabilities['name'] = 'test_access'\n            self.wd = webdriver.Remote(\n                desired_capabilities=desired_capabilities,\n                command_executor=\"http://esodvn:325caef9-81dd-47a5-8b74-433057ce888f@ondemand.saucelabs.com:80/wd/hub\"\n            )\n \n        self.wd.implicitly_wait(60)\n    \n    def test_test_create_test_account(self):\n        success = True\n        wd = self.wd\n        wd.get(config.accessURL)\n        wd.find_element_by_link_text(\"Create Account\").click()\n        wd.find_element_by_id(\"dataverseUserForm:userName\").click()\n        wd.find_element_by_id(\"dataverseUserForm:userName\").clear()\n        wd.find_element_by_id(\"dataverseUserForm:userName\").send_keys(\"tester\")\n        wd.find_element_by_id(\"dataverseUserForm:inputPassword\").click()\n        wd.find_element_by_id(\"dataverseUserForm:inputPassword\").clear()\n        wd.find_element_by_id(\"dataverseUserForm:inputPassword\").send_keys(\"tester\")\n        wd.find_element_by_id(\"dataverseUserForm:retypePassword\").click()\n        wd.find_element_by_id(\"dataverseUserForm:retypePassword\").clear()\n        wd.find_element_by_id(\"dataverseUserForm:retypePassword\").send_keys(\"tester\")\n        wd.find_element_by_id(\"dataverseUserForm:firstName\").click()\n        wd.find_element_by_id(\"dataverseUserForm:firstName\").clear()\n        wd.find_element_by_id(\"dataverseUserForm:firstName\").send_keys(\"test\")\n        wd.find_element_by_id(\"dataverseUserForm:lastName\").click()\n        wd.find_element_by_id(\"dataverseUserForm:lastName\").clear()\n        wd.find_element_by_id(\"dataverseUserForm:lastName\").send_keys(\"user\")\n        wd.find_element_by_id(\"dataverseUserForm:email\").click()\n        wd.find_element_by_id(\"dataverseUserForm:email\").clear()\n        wd.find_element_by_id(\"dataverseUserForm:email\").send_keys(\"kcondon@hmdc.harvard.edu\")\n        wd.find_element_by_id(\"dataverseUserForm:institution\").click()\n        wd.find_element_by_id(\"dataverseUserForm:institution\").clear()\n        wd.find_element_by_id(\"dataverseUserForm:institution\").send_keys(\"IQSS\")\n        wd.find_element_by_xpath(\"//div[@id='dataverseUserForm:j_idt45']/div[3]\").click()\n        wd.find_element_by_xpath(\"//div[@class='ui-selectonemenu-items-wrapper']//li[.='Staff']\").click()\n        wd.find_element_by_id(\"dataverseUserForm:phone\").click()\n        wd.find_element_by_id(\"dataverseUserForm:phone\").clear()\n        wd.find_element_by_id(\"dataverseUserForm:phone\").send_keys(\"1-222-333-4444\")\n        wd.find_element_by_id(\"dataverseUserForm:save\").click()\n        time.sleep(1)\n        if (\"This Username is already taken.\" in wd.find_element_by_tag_name(\"html\").text):\n            print(\"Username exists. Exiting.\")\n            return   \n        if not (\"Log Out\" in wd.find_element_by_tag_name(\"html\").text): \n            success = false\n            print(\"User was not logged in after create account.\")           \n        self.assertTrue(success)\n    \n    def tearDown(self):\n        if not (config.local):\n            print(\"Link to your job: https://saucelabs.com/jobs/%s\" % self.wd.session_id)        \n        self.wd.quit()\n\nif __name__ == '__main__':\n    unittest.main()\n" }
{ "repo_name": "RonnyPfannschmidt/pytest", "ref": "refs/heads/features", "path": "testing/example_scripts/fixtures/fill_fixtures/test_extend_fixture_conftest_conftest/pkg/conftest.py", "content": "import pytest\n\n\n@pytest.fixture\ndef spam(spam):\n    return spam * 2\n" }
{ "repo_name": "pytest-dev/pytest", "ref": "refs/heads/main", "path": "testing/example_scripts/fixtures/fill_fixtures/test_extend_fixture_conftest_conftest/pkg/conftest.py", "content": "import pytest\n\n\n@pytest.fixture\ndef spam(spam):\n    return spam * 2\n" }
{ "repo_name": "rossburton/yocto-autobuilder", "ref": "refs/heads/ross", "path": "lib/python2.7/site-packages/buildbot-0.8.8-py2.7.egg/buildbot/test/unit/test_db_migrate_versions_021_fix_postgres_sequences.py", "content": "# This file is part of Buildbot.  Buildbot is free software: you can\n# redistribute it and/or modify it under the terms of the GNU General Public\n# License as published by the Free Software Foundation, version 2.\n#\n# This program is distributed in the hope that it will be useful, but WITHOUT\n# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n# FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more\n# details.\n#\n# You should have received a copy of the GNU General Public License along with\n# this program; if not, write to the Free Software Foundation, Inc., 51\n# Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.\n#\n# Copyright Buildbot Team Members\n\nimport sqlalchemy as sa\nfrom twisted.trial import unittest\nfrom buildbot.test.util import migration\n\nclass Migration(migration.MigrateTestMixin, unittest.TestCase):\n\n    def setUp(self):\n        return self.setUpMigrateTest()\n\n    def tearDown(self):\n        return self.tearDownMigrateTest()\n\n    cols = [\n        'buildrequests.id',\n        'builds.id',\n        'buildsets.id',\n        'changes.changeid',\n        'patches.id',\n        'sourcestampsets.id',\n        'sourcestamps.id',\n        'objects.id',\n        'users.uid',\n    ]\n\n    # tests\n\n    def test_update(self):\n        def setup_thd(conn):\n            metadata = sa.MetaData()\n            metadata.bind = conn\n\n            # insert a row into each table, giving an explicit id column so\n            # that the sequence is not advanced correctly, but leave no rows in\n            # one table to test that corner case\n            for i, col in enumerate(self.cols):\n                tbl_name, col_name = col.split('.')\n                tbl = sa.Table(tbl_name, metadata,\n                        sa.Column(col_name, sa.Integer, primary_key=True))\n                tbl.create()\n                if i > 1:\n                    conn.execute(tbl.insert(), { col_name : i })\n\n        def verify_thd(conn):\n            metadata = sa.MetaData()\n            metadata.bind = conn\n\n            # try inserting *without* an ID, and verify that the resulting ID\n            # is as expected\n            for i, col in enumerate(self.cols):\n                tbl_name, col_name = col.split('.')\n                tbl = sa.Table(tbl_name, metadata,\n                        sa.Column(col_name, sa.Integer, primary_key=True))\n                r = conn.execute(tbl.insert(), {})\n                if i > 1:\n                    exp = i+1\n                else:\n                    exp = 1\n                self.assertEqual(r.inserted_primary_key[0], exp)\n\n        return self.do_test_migration(20, 21, setup_thd, verify_thd)\n" }
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/Python/Decimal-to-binary.py","content":"def convert_to_binary(n): \n\n      if(n > 1):\n        convert_to_binary(n//2)\n  \n      print(n % 2, end = '')\n\nconvert_to_binary(52)\n"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/Python/Factorial.py","content":"def factorial(n):\n    factorial = 1\n    # check is the number is negative, positive or zero\n    if(n < 0):\n        print('Sorry, factorial does not exist for negative numbers')\n    elif(n == 0):\n        print('The factorial of 0 is 1')\n    else:\n        for i in range(1,n):\n            factorial = factorial * i\n        print('The factorial of {} is {}'.format(n,factorial))\n\nfactorial(4)\n"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/Python/Fibonacci.py","content":"def fibonacci(n): \n    \n    fibonacci_seq = [None for i in range(n)]\n    fibonacci_seq[0] = fibonacci_seq[1] = 1\n    for i in range(2,n):\n        \n           fibonacci_seq[i] = fibonacci_seq[i - 2] + fibonacci_seq[i - 1]\n    print('First {} Fibonacci numbers:'.format(n))\n    print(fibonacci_seq)\n\n\nfibonacci(10)\n"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/Python/Max-Min-of-Vector.py","content":"\ndef max_min_vector(n):\n\n    print('Original vector:')\n    print(n)   \n    print('Maximum value of the said vector:',max(n))\n    print('Minimum value of the said vector:',min(n))\n\n\nmax_min_vector([10, 20, 30, 40, 50, 60])\n"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/Python/Odd-or-Even.py","content":"\ndef odd_or_even(n):\n    num = n\n    \n    if((num % 2) == 0):\n        print('{} is Even'.format(num))\n    else:\n        print('{} is Odd'.format(num))\n\n\nodd_or_even(4)\n"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/Python/Prime-Numbers.py","content":"\ndef prime_numbers(n):\n    \n     prime_nums = [] \n     if (n >= 2):\n        \n        for i in range(2,n):\n             for j in range(2,i):\n                  \n                  if i%j == 0:\n                      break\n             else:\n                 prime_nums.append(i)\n                \n                \n\n        return(prime_nums)\n     else: \n           print('Input number should be at least 2.')\n"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/Python/Read-csv-file.py.","content":"\nimport pandas as pd\n\ndef read_csv_file():\n    \n    movie_data = pd.read_csv('movies.csv')\n    print('Content of the .csv file:')\n    print(movie_data)\n\n\nread_csv_file()\n"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/Python/SumMeanProduct.py","content":"\nimport numpy as np\ndef sum(nums):\n    sum = 0\n    for x in nums:\n        sum = sum + x\n    print(sum)\n\ndef avg(nums):\n   print(np.mean(nums))\n\ndef product(nums):\n    print(np.prod(nums))\n\nlist1 = [3,4,5]\n\nsum(list1)\navg(list1)\nproduct(list1)"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/Python/add1.py","content":"\ndef add1(num):\n    print(num + 1)\n    \nadd1(2)\n"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/Python/add2nums.py","content":"\ndef add2nums(a, b):\n    print (a+b)\n\nadd2nums(2, 3)\n"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/Python/areaSquare.py","content":"\ndef areaSquare(side):\n    if(side <= 0 ):\n        print 'Invalid measurement'\n    else:\n        print 'Area of the square is : ', side*side\n\nareaSquare(4)\n"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/Python/armstrong.py","content":"\nnum = int(input('Enter a number: '))\n\nsum = 0\n\ntemp = num\nwhile temp > 0:\n   digit = temp % 10\n   sum += digit ** 3\n   temp //= 10\n\nif num == sum:\n   print(num,'is an Armstrong number')\nelse:\n   print(num,'is not an Armstrong number')\n"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/Python/describe.py","content":"\nimport pandas as pd\ndf = pd.read_csv('nba_2013.csv')\ndf.describe()\n"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/Python/divisibleby10.py","content":"\ndef divisibleby10(n):\n    if(n%10 == 0):\n        print('True')\n    else:\n        print('False')\n\n\ndivisibleby10(8)\n"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/Python/factors.py","content":"\ndef print_factors(x):\n   print('The factors of',x,'are:')\n   for i in range(1, x + 1):\n       if x % i == 0:\n           print(i)\n\nnum = 320\n\nprint_factors(num)\n"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/Python/integerType.py","content":"\ndef integerType(num):\n    if (num > 0):\n        print('Number is Postive integer')\n    if(num < 0):\n        print('Number is Negative integer')\n    if(num == 0):\n        print('Number is Zero')\n"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/Python/lcm.py","content":"\ndef compute_lcm(x, y):\n\n   # choose the greater number\n   if x > y:\n       greater = x\n   else:\n       greater = y\n\n   while(True):\n       if((greater % x == 0) and (greater % y == 0)):\n           lcm = greater\n           break\n       greater += 1\n\n   return lcm\n"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/Python/lengthOfVector.py","content":"\ndef lengthOfVector(nums):\n    count = 0\n    for x in nums:\n        count = count+1\n    \n    print(count)\n"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/Python/palindrome.py","content":"\ndef palindrome(num):\n    temp = num\n    rev = 0\n    while(num > 0):\n        dig = num % 10\n        rev = rev * 10 + dig\n        num = num // 10\n    if(temp == rev):\n        print('Number is palindrome')\n    else: \n        print('Number is not palidrome')\n"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/Python/perfect.py","content":"\ndef perfect_number(n):\n    sum = 0\n    for x in range(1, n):\n        if n % x == 0:\n            sum += x\n    return sum == n\n"}
{ "repo_name":"rakeshamireddy/Automatic-Code-Translation","ref":"refs/heads/master","path":"data/test_dataset/Python/sortvector.py","content":"\ndef sortVector(nums):\n    nums.sort()\n    print(nums)\n"}
{ "repo_name": "OCA/connector-telephony", "ref": "refs/heads/12.0", "path": "setup/_metapackage/setup.py", "content": "import setuptools\n\nwith open('VERSION.txt', 'r') as f:\n    version = f.read().strip()\n\nsetuptools.setup(\n    name=\"odoo12-addons-oca-connector-telephony\",\n    description=\"Meta package for oca-connector-telephony Odoo addons\",\n    version=version,\n    install_requires=[\n        'odoo12-addon-asterisk_click2dial',\n        'odoo12-addon-base_phone',\n        'odoo12-addon-base_phone_popup',\n        'odoo12-addon-connector_voicent',\n        'odoo12-addon-crm_phone',\n        'odoo12-addon-event_phone',\n        'odoo12-addon-hr_phone',\n        'odoo12-addon-hr_recruitment_phone',\n        'odoo12-addon-sms_ovh_http',\n    ],\n    classifiers=[\n        'Programming Language :: Python',\n        'Framework :: Odoo',\n    ]\n)\n" }
{ "repo_name": "JayanthyChengan/dataverse", "ref": "refs/heads/dataverse-contactform-afflist", "path": "tests/test_create_test_account.py", "content": "from selenium import webdriver\nimport time, unittest, config\n\ndef is_alert_present(wd):\n    try:\n        wd.switch_to_alert().text\n        return True\n    except:\n        return False\n\nclass test_create_test_account(unittest.TestCase):\n    def setUp(self):\n        if (config.local):\n            self.wd = webdriver.Firefox()\n        else:\n            desired_capabilities = webdriver.DesiredCapabilities.FIREFOX\n            desired_capabilities['version'] = '24'\n            desired_capabilities['platform'] = 'Linux'\n            desired_capabilities['name'] = 'test_access'\n            self.wd = webdriver.Remote(\n                desired_capabilities=desired_capabilities,\n                command_executor=\"http://esodvn:325caef9-81dd-47a5-8b74-433057ce888f@ondemand.saucelabs.com:80/wd/hub\"\n            )\n \n        self.wd.implicitly_wait(60)\n    \n    def test_test_create_test_account(self):\n        success = True\n        wd = self.wd\n        wd.get(config.accessURL)\n        wd.find_element_by_link_text(\"Create Account\").click()\n        wd.find_element_by_id(\"dataverseUserForm:userName\").click()\n        wd.find_element_by_id(\"dataverseUserForm:userName\").clear()\n        wd.find_element_by_id(\"dataverseUserForm:userName\").send_keys(\"tester\")\n        wd.find_element_by_id(\"dataverseUserForm:inputPassword\").click()\n        wd.find_element_by_id(\"dataverseUserForm:inputPassword\").clear()\n        wd.find_element_by_id(\"dataverseUserForm:inputPassword\").send_keys(\"tester\")\n        wd.find_element_by_id(\"dataverseUserForm:retypePassword\").click()\n        wd.find_element_by_id(\"dataverseUserForm:retypePassword\").clear()\n        wd.find_element_by_id(\"dataverseUserForm:retypePassword\").send_keys(\"tester\")\n        wd.find_element_by_id(\"dataverseUserForm:firstName\").click()\n        wd.find_element_by_id(\"dataverseUserForm:firstName\").clear()\n        wd.find_element_by_id(\"dataverseUserForm:firstName\").send_keys(\"test\")\n        wd.find_element_by_id(\"dataverseUserForm:lastName\").click()\n        wd.find_element_by_id(\"dataverseUserForm:lastName\").clear()\n        wd.find_element_by_id(\"dataverseUserForm:lastName\").send_keys(\"user\")\n        wd.find_element_by_id(\"dataverseUserForm:email\").click()\n        wd.find_element_by_id(\"dataverseUserForm:email\").clear()\n        wd.find_element_by_id(\"dataverseUserForm:email\").send_keys(\"kcondon@hmdc.harvard.edu\")\n        wd.find_element_by_id(\"dataverseUserForm:institution\").click()\n        wd.find_element_by_id(\"dataverseUserForm:institution\").clear()\n        wd.find_element_by_id(\"dataverseUserForm:institution\").send_keys(\"IQSS\")\n        wd.find_element_by_xpath(\"//div[@id='dataverseUserForm:j_idt45']/div[3]\").click()\n        wd.find_element_by_xpath(\"//div[@class='ui-selectonemenu-items-wrapper']//li[.='Staff']\").click()\n        wd.find_element_by_id(\"dataverseUserForm:phone\").click()\n        wd.find_element_by_id(\"dataverseUserForm:phone\").clear()\n        wd.find_element_by_id(\"dataverseUserForm:phone\").send_keys(\"1-222-333-4444\")\n        wd.find_element_by_id(\"dataverseUserForm:save\").click()\n        time.sleep(1)\n        if (\"This Username is already taken.\" in wd.find_element_by_tag_name(\"html\").text):\n            print(\"Username exists. Exiting.\")\n            return   \n        if not (\"Log Out\" in wd.find_element_by_tag_name(\"html\").text): \n            success = false\n            print(\"User was not logged in after create account.\")           \n        self.assertTrue(success)\n    \n    def tearDown(self):\n        if not (config.local):\n            print(\"Link to your job: https://saucelabs.com/jobs/%s\" % self.wd.session_id)        \n        self.wd.quit()\n\nif __name__ == '__main__':\n    unittest.main()\n" }
{ "repo_name": "molecular/electrum", "ref": "refs/heads/cash", "path": "gui/kivy/uix/dialogs/tx_dialog.py", "content": "from kivy.app import App\nfrom kivy.factory import Factory\nfrom kivy.properties import ObjectProperty\nfrom kivy.lang import Builder\nfrom kivy.clock import Clock\nfrom kivy.uix.label import Label\n\nfrom electroncash_gui.kivy.i18n import _\nfrom datetime import datetime\nfrom electroncash.util import InvalidPassword\n\nBuilder.load_string('''\n\n<TxDialog>\n    id: popup\n    title: _('Transaction')\n    is_mine: True\n    can_sign: False\n    can_broadcast: False\n    fee_str: ''\n    date_str: ''\n    amount_str: ''\n    tx_hash: ''\n    status_str: ''\n    description: ''\n    outputs_str: ''\n    BoxLayout:\n        orientation: 'vertical'\n        ScrollView:\n            GridLayout:\n                height: self.minimum_height\n                size_hint_y: None\n                cols: 1\n                spacing: '10dp'\n                padding: '10dp'\n                GridLayout:\n                    height: self.minimum_height\n                    size_hint_y: None\n                    cols: 1\n                    spacing: '10dp'\n                    BoxLabel:\n                        text: _('Status')\n                        value: root.status_str\n                    BoxLabel:\n                        text: _('Description') if root.description else ''\n                        value: root.description\n                    BoxLabel:\n                        text: _('Date') if root.date_str else ''\n                        value: root.date_str\n                    BoxLabel:\n                        text: _('Amount sent') if root.is_mine else _('Amount received')\n                        value: root.amount_str\n                    BoxLabel:\n                        text: _('Transaction fee') if root.fee_str else ''\n                        value: root.fee_str\n                TopLabel:\n                    text: _('Outputs') + ':'\n                OutputList:\n                    height: self.minimum_height\n                    size_hint: 1, None\n                    id: output_list\n                TopLabel:\n                    text: _('Transaction ID') + ':' if root.tx_hash else ''\n                TxHashLabel:\n                    data: root.tx_hash\n                    name: _('Transaction ID')\n        Widget:\n            size_hint: 1, 0.1\n\n        BoxLayout:\n            size_hint: 1, None\n            height: '48dp'\n            Button:\n                size_hint: 0.5, None\n                height: '48dp'\n                text: _('Sign') if root.can_sign else _('Broadcast') if root.can_broadcast else ''\n                disabled: not(root.can_sign or root.can_broadcast)\n                opacity: 0 if self.disabled else 1\n                on_release:\n                    if root.can_sign: root.do_sign()\n                    if root.can_broadcast: root.do_broadcast()\n            IconButton:\n                size_hint: 0.5, None\n                height: '48dp'\n                icon: 'atlas://gui/kivy/theming/light/qrcode'\n                on_release: root.show_qr()\n            Button:\n                size_hint: 0.5, None\n                height: '48dp'\n                text: _('Close')\n                on_release: root.dismiss()\n''')\n\n\nclass TxDialog(Factory.Popup):\n\n    def __init__(self, app, tx):\n        Factory.Popup.__init__(self)\n        self.app = app\n        self.wallet = self.app.wallet\n        self.tx = tx\n\n    def on_open(self):\n        self.update()\n\n    def update(self):\n        format_amount = self.app.format_amount_and_units\n        tx_hash, self.status_str, self.description, self.can_broadcast, amount, fee, height, conf, timestamp, exp_n = self.wallet.get_tx_info(self.tx)\n        self.tx_hash = tx_hash or ''\n        if timestamp:\n            self.date_str = datetime.fromtimestamp(timestamp).isoformat(' ')[:-3]\n        elif exp_n:\n            self.date_str = _('Within %d blocks') % exp_n if exp_n > 0 else _('unknown (low fee)')\n        else:\n            self.date_str = ''\n\n        if amount is None:\n            self.amount_str = _(\"Transaction unrelated to your wallet\")\n        elif amount > 0:\n            self.is_mine = False\n            self.amount_str = format_amount(amount)\n        else:\n            self.is_mine = True\n            self.amount_str = format_amount(-amount)\n        self.fee_str = format_amount(fee) if fee is not None else _('unknown')\n        self.can_sign = self.wallet.can_sign(self.tx)\n        self.ids.output_list.update(self.tx.outputs())\n\n    def do_sign(self):\n        self.app.protected(_(\"Enter your PIN code in order to sign this transaction\"), self._do_sign, ())\n\n    def _do_sign(self, password):\n        self.status_str = _('Signing') + '...'\n        Clock.schedule_once(lambda dt: self.__do_sign(password), 0.1)\n\n    def __do_sign(self, password):\n        try:\n            self.app.wallet.sign_transaction(self.tx, password)\n        except InvalidPassword:\n            self.app.show_error(_(\"Invalid PIN\"))\n        self.update()\n\n    def do_broadcast(self):\n        self.app.broadcast(self.tx)\n\n    def show_qr(self):\n        from electroncash.bitcoin import base_encode\n        text = str(self.tx).decode('hex')\n        text = base_encode(text, base=43)\n        self.app.qr_dialog(_(\"Raw Transaction\"), text)\n" }
{ "repo_name": "S11001001/phantomjs", "ref": "refs/heads/pdf-patches", "path": "src/breakpad/src/tools/gyp/test/home_dot_gyp/gyptest-home-includes-regyp.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2009 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nVerifies inclusion of $HOME/.gyp/includes.gypi works properly with relocation\nand with regeneration.\n\"\"\"\n\nimport os\nimport TestGyp\n\n# Regenerating build files when a gyp file changes is currently only supported\n# by the make generator.\ntest = TestGyp.TestGyp(formats=['make'])\n\nos.environ['HOME'] = os.path.abspath('home')\n\ntest.run_gyp('all.gyp', chdir='src')\n\n# After relocating, we should still be able to build (build file shouldn't\n# contain relative reference to ~/.gyp/includes.gypi)\ntest.relocate('src', 'relocate/src')\n\ntest.build('all.gyp', test.ALL, chdir='relocate/src')\n\ntest.run_built_executable('printfoo',\n                          chdir='relocate/src',\n                          stdout=\"FOO is fromhome\\n\");\n\n# Building should notice any changes to ~/.gyp/includes.gypi and regyp.\ntest.sleep()\n\ntest.write('home/.gyp/include.gypi', test.read('home2/.gyp/include.gypi'))\n\ntest.build('all.gyp', test.ALL, chdir='relocate/src')\n\ntest.run_built_executable('printfoo',\n                          chdir='relocate/src',\n                          stdout=\"FOO is fromhome2\\n\");\n\ntest.pass_test()\n" }
{ "repo_name": "pigshell/nhnick", "ref": "refs/heads/vnc-websocket", "path": "src/breakpad/src/tools/gyp/test/home_dot_gyp/gyptest-home-includes-regyp.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2009 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nVerifies inclusion of $HOME/.gyp/includes.gypi works properly with relocation\nand with regeneration.\n\"\"\"\n\nimport os\nimport TestGyp\n\n# Regenerating build files when a gyp file changes is currently only supported\n# by the make generator.\ntest = TestGyp.TestGyp(formats=['make'])\n\nos.environ['HOME'] = os.path.abspath('home')\n\ntest.run_gyp('all.gyp', chdir='src')\n\n# After relocating, we should still be able to build (build file shouldn't\n# contain relative reference to ~/.gyp/includes.gypi)\ntest.relocate('src', 'relocate/src')\n\ntest.build('all.gyp', test.ALL, chdir='relocate/src')\n\ntest.run_built_executable('printfoo',\n                          chdir='relocate/src',\n                          stdout=\"FOO is fromhome\\n\");\n\n# Building should notice any changes to ~/.gyp/includes.gypi and regyp.\ntest.sleep()\n\ntest.write('home/.gyp/include.gypi', test.read('home2/.gyp/include.gypi'))\n\ntest.build('all.gyp', test.ALL, chdir='relocate/src')\n\ntest.run_built_executable('printfoo',\n                          chdir='relocate/src',\n                          stdout=\"FOO is fromhome2\\n\");\n\ntest.pass_test()\n" }
{ "repo_name": "dataxu/ansible", "ref": "refs/heads/dx-stable-2.5", "path": "lib/ansible/modules/remote_management/oneview/oneview_enclosure_facts.py", "content": "#!/usr/bin/python\n\n# Copyright: (c) 2016-2017, Hewlett Packard Enterprise Development LP\n# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)\n\nfrom __future__ import (absolute_import, division, print_function)\n__metaclass__ = type\n\nANSIBLE_METADATA = {'metadata_version': '1.1',\n                    'status': ['preview'],\n                    'supported_by': 'community'}\n\nDOCUMENTATION = '''\n---\nmodule: oneview_enclosure_facts\nshort_description: Retrieve facts about one or more Enclosures\ndescription:\n    - Retrieve facts about one or more of the Enclosures from OneView.\nversion_added: \"2.5\"\nrequirements:\n    - hpOneView >= 2.0.1\nauthor:\n    - Felipe Bulsoni (@fgbulsoni)\n    - Thiago Miotto (@tmiotto)\n    - Adriane Cardozo (@adriane-cardozo)\noptions:\n    name:\n      description:\n        - Enclosure name.\n    options:\n      description:\n        - \"List with options to gather additional facts about an Enclosure and related resources.\n          Options allowed: C(script), C(environmentalConfiguration), and C(utilization). For the option C(utilization),\n          you can provide specific parameters.\"\n\nextends_documentation_fragment:\n    - oneview\n    - oneview.factsparams\n'''\n\nEXAMPLES = '''\n- name: Gather facts about all Enclosures\n  oneview_enclosure_facts:\n    hostname: 172.16.101.48\n    username: administrator\n    password: my_password\n    api_version: 500\n  no_log: true\n  delegate_to: localhost\n- debug: var=enclosures\n\n- name: Gather paginated, filtered and sorted facts about Enclosures\n  oneview_enclosure_facts:\n    params:\n      start: 0\n      count: 3\n      sort: name:descending\n      filter: status=OK\n    hostname: 172.16.101.48\n    username: administrator\n    password: my_password\n    api_version: 500\n  no_log: true\n  delegate_to: localhost\n- debug: var=enclosures\n\n- name: Gather facts about an Enclosure by name\n  oneview_enclosure_facts:\n    name: Enclosure-Name\n    hostname: 172.16.101.48\n    username: administrator\n    password: my_password\n    api_version: 500\n  no_log: true\n  delegate_to: localhost\n- debug: var=enclosures\n\n- name: Gather facts about an Enclosure by name with options\n  oneview_enclosure_facts:\n    name: Test-Enclosure\n    options:\n      - script                       # optional\n      - environmentalConfiguration   # optional\n      - utilization                  # optional\n    hostname: 172.16.101.48\n    username: administrator\n    password: my_password\n    api_version: 500\n  no_log: true\n  delegate_to: localhost\n- debug: var=enclosures\n- debug: var=enclosure_script\n- debug: var=enclosure_environmental_configuration\n- debug: var=enclosure_utilization\n\n- name: \"Gather facts about an Enclosure with temperature data at a resolution of one sample per day, between two\n         specified dates\"\n  oneview_enclosure_facts:\n    name: Test-Enclosure\n    options:\n      - utilization:                   # optional\n          fields: AmbientTemperature\n          filter:\n            - startDate=2016-07-01T14:29:42.000Z\n            - endDate=2017-07-01T03:29:42.000Z\n          view: day\n          refresh: false\n    hostname: 172.16.101.48\n    username: administrator\n    password: my_password\n    api_version: 500\n  no_log: true\n  delegate_to: localhost\n- debug: var=enclosures\n- debug: var=enclosure_utilization\n'''\n\nRETURN = '''\nenclosures:\n    description: Has all the OneView facts about the Enclosures.\n    returned: Always, but can be null.\n    type: dict\n\nenclosure_script:\n    description: Has all the OneView facts about the script of an Enclosure.\n    returned: When requested, but can be null.\n    type: string\n\nenclosure_environmental_configuration:\n    description: Has all the OneView facts about the environmental configuration of an Enclosure.\n    returned: When requested, but can be null.\n    type: dict\n\nenclosure_utilization:\n    description: Has all the OneView facts about the utilization of an Enclosure.\n    returned: When requested, but can be null.\n    type: dict\n'''\n\nfrom ansible.module_utils.oneview import OneViewModuleBase\n\n\nclass EnclosureFactsModule(OneViewModuleBase):\n    argument_spec = dict(name=dict(type='str'), options=dict(type='list'), params=dict(type='dict'))\n\n    def __init__(self):\n        super(EnclosureFactsModule, self).__init__(additional_arg_spec=self.argument_spec)\n\n    def execute_module(self):\n\n        ansible_facts = {}\n\n        if self.module.params['name']:\n            enclosures = self._get_by_name(self.module.params['name'])\n\n            if self.options and enclosures:\n                ansible_facts = self._gather_optional_facts(self.options, enclosures[0])\n        else:\n            enclosures = self.oneview_client.enclosures.get_all(**self.facts_params)\n\n        ansible_facts['enclosures'] = enclosures\n\n        return dict(changed=False,\n                    ansible_facts=ansible_facts)\n\n    def _gather_optional_facts(self, options, enclosure):\n\n        enclosure_client = self.oneview_client.enclosures\n        ansible_facts = {}\n\n        if options.get('script'):\n            ansible_facts['enclosure_script'] = enclosure_client.get_script(enclosure['uri'])\n        if options.get('environmentalConfiguration'):\n            env_config = enclosure_client.get_environmental_configuration(enclosure['uri'])\n            ansible_facts['enclosure_environmental_configuration'] = env_config\n        if options.get('utilization'):\n            ansible_facts['enclosure_utilization'] = self._get_utilization(enclosure, options['utilization'])\n\n        return ansible_facts\n\n    def _get_utilization(self, enclosure, params):\n        fields = view = refresh = filter = ''\n\n        if isinstance(params, dict):\n            fields = params.get('fields')\n            view = params.get('view')\n            refresh = params.get('refresh')\n            filter = params.get('filter')\n\n        return self.oneview_client.enclosures.get_utilization(enclosure['uri'],\n                                                              fields=fields,\n                                                              filter=filter,\n                                                              refresh=refresh,\n                                                              view=view)\n\n    def _get_by_name(self, name):\n        return self.oneview_client.enclosures.get_by('name', name)\n\n\ndef main():\n    EnclosureFactsModule().run()\n\n\nif __name__ == '__main__':\n    main()\n" }
{ "repo_name": "etiennekruger/phantomjs-qt5", "ref": "refs/heads/qt5", "path": "src/breakpad/src/tools/gyp/test/home_dot_gyp/gyptest-home-includes-regyp.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2009 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nVerifies inclusion of $HOME/.gyp/includes.gypi works properly with relocation\nand with regeneration.\n\"\"\"\n\nimport os\nimport TestGyp\n\n# Regenerating build files when a gyp file changes is currently only supported\n# by the make generator.\ntest = TestGyp.TestGyp(formats=['make'])\n\nos.environ['HOME'] = os.path.abspath('home')\n\ntest.run_gyp('all.gyp', chdir='src')\n\n# After relocating, we should still be able to build (build file shouldn't\n# contain relative reference to ~/.gyp/includes.gypi)\ntest.relocate('src', 'relocate/src')\n\ntest.build('all.gyp', test.ALL, chdir='relocate/src')\n\ntest.run_built_executable('printfoo',\n                          chdir='relocate/src',\n                          stdout=\"FOO is fromhome\\n\");\n\n# Building should notice any changes to ~/.gyp/includes.gypi and regyp.\ntest.sleep()\n\ntest.write('home/.gyp/include.gypi', test.read('home2/.gyp/include.gypi'))\n\ntest.build('all.gyp', test.ALL, chdir='relocate/src')\n\ntest.run_built_executable('printfoo',\n                          chdir='relocate/src',\n                          stdout=\"FOO is fromhome2\\n\");\n\ntest.pass_test()\n" }
{ "repo_name": "you21979/phantomjs", "ref": "refs/heads/2.0", "path": "src/breakpad/src/tools/gyp/test/home_dot_gyp/gyptest-home-includes-regyp.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2009 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nVerifies inclusion of $HOME/.gyp/includes.gypi works properly with relocation\nand with regeneration.\n\"\"\"\n\nimport os\nimport TestGyp\n\n# Regenerating build files when a gyp file changes is currently only supported\n# by the make generator.\ntest = TestGyp.TestGyp(formats=['make'])\n\nos.environ['HOME'] = os.path.abspath('home')\n\ntest.run_gyp('all.gyp', chdir='src')\n\n# After relocating, we should still be able to build (build file shouldn't\n# contain relative reference to ~/.gyp/includes.gypi)\ntest.relocate('src', 'relocate/src')\n\ntest.build('all.gyp', test.ALL, chdir='relocate/src')\n\ntest.run_built_executable('printfoo',\n                          chdir='relocate/src',\n                          stdout=\"FOO is fromhome\\n\");\n\n# Building should notice any changes to ~/.gyp/includes.gypi and regyp.\ntest.sleep()\n\ntest.write('home/.gyp/include.gypi', test.read('home2/.gyp/include.gypi'))\n\ntest.build('all.gyp', test.ALL, chdir='relocate/src')\n\ntest.run_built_executable('printfoo',\n                          chdir='relocate/src',\n                          stdout=\"FOO is fromhome2\\n\");\n\ntest.pass_test()\n" }
{ "repo_name": "miptliot/edx-platform", "ref": "refs/heads/ginkgo_openedu_docker", "path": "cms/envs/devstack.py", "content": "\"\"\"\nSpecific overrides to the base prod settings to make development easier.\n\"\"\"\n\nfrom os.path import abspath, dirname, join\n\nfrom .aws import *  # pylint: disable=wildcard-import, unused-wildcard-import\n\n# Don't use S3 in devstack, fall back to filesystem\ndel DEFAULT_FILE_STORAGE\nCOURSE_IMPORT_EXPORT_STORAGE = 'django.core.files.storage.FileSystemStorage'\nUSER_TASKS_ARTIFACT_STORAGE = COURSE_IMPORT_EXPORT_STORAGE\n\nDEBUG = True\nUSE_I18N = True\nDEFAULT_TEMPLATE_ENGINE['OPTIONS']['debug'] = DEBUG\nHTTPS = 'off'\n\n################################ LOGGERS ######################################\n\nimport logging\n\n# Disable noisy loggers\nfor pkg_name in ['track.contexts', 'track.middleware', 'dd.dogapi']:\n    logging.getLogger(pkg_name).setLevel(logging.CRITICAL)\n\n\n################################ EMAIL ########################################\n\nEMAIL_BACKEND = 'django.core.mail.backends.console.EmailBackend'\n\n################################# LMS INTEGRATION #############################\n\nLMS_BASE = \"localhost:8000\"\nLMS_ROOT_URL = \"http://{}\".format(LMS_BASE)\nFEATURES['PREVIEW_LMS_BASE'] = \"preview.\" + LMS_BASE\n\n########################### PIPELINE #################################\n\n# Skip packaging and optimization in development\nPIPELINE_ENABLED = False\nSTATICFILES_STORAGE = 'openedx.core.storage.DevelopmentStorage'\n\n# Revert to the default set of finders as we don't want the production pipeline\nSTATICFILES_FINDERS = [\n    'openedx.core.djangoapps.theming.finders.ThemeFilesFinder',\n    'django.contrib.staticfiles.finders.FileSystemFinder',\n    'django.contrib.staticfiles.finders.AppDirectoriesFinder',\n]\n\n############################ PYFS XBLOCKS SERVICE #############################\n# Set configuration for Django pyfilesystem\n\nDJFS = {\n    'type': 'osfs',\n    'directory_root': 'cms/static/djpyfs',\n    'url_root': '/static/djpyfs',\n}\n\n################################# CELERY ######################################\n\n# By default don't use a worker, execute tasks as if they were local functions\nCELERY_ALWAYS_EAGER = True\n\n################################ DEBUG TOOLBAR ################################\nINSTALLED_APPS += ('debug_toolbar', 'debug_toolbar_mongo')\nMIDDLEWARE_CLASSES += ('debug_toolbar.middleware.DebugToolbarMiddleware',)\nINTERNAL_IPS = ('127.0.0.1',)\n\nDEBUG_TOOLBAR_PANELS = (\n    'debug_toolbar.panels.versions.VersionsPanel',\n    'debug_toolbar.panels.timer.TimerPanel',\n    'debug_toolbar.panels.settings.SettingsPanel',\n    'debug_toolbar.panels.headers.HeadersPanel',\n    'debug_toolbar.panels.request.RequestPanel',\n    'debug_toolbar.panels.sql.SQLPanel',\n    'debug_toolbar.panels.signals.SignalsPanel',\n    'debug_toolbar.panels.logging.LoggingPanel',\n    'debug_toolbar.panels.profiling.ProfilingPanel',\n)\n\nDEBUG_TOOLBAR_CONFIG = {\n    # Profile panel is incompatible with wrapped views\n    # See https://github.com/jazzband/django-debug-toolbar/issues/792\n    'DISABLE_PANELS': (\n        'debug_toolbar.panels.profiling.ProfilingPanel',\n    ),\n    'SHOW_TOOLBAR_CALLBACK': 'cms.envs.devstack.should_show_debug_toolbar',\n    'JQUERY_URL': None,\n}\n\n\ndef should_show_debug_toolbar(_):\n    return True  # We always want the toolbar on devstack regardless of IP, auth, etc.\n\n\n# To see stacktraces for MongoDB queries, set this to True.\n# Stacktraces slow down page loads drastically (for pages with lots of queries).\nDEBUG_TOOLBAR_MONGO_STACKTRACES = False\n\n\n################################ MILESTONES ################################\nFEATURES['MILESTONES_APP'] = True\n\n\n################################ ENTRANCE EXAMS ################################\nFEATURES['ENTRANCE_EXAMS'] = True\n\n################################ COURSE LICENSES ################################\nFEATURES['LICENSING'] = True\n# Needed to enable licensing on video modules\nXBLOCK_SETTINGS.update({'VideoDescriptor': {'licensing_enabled': True}})\n\n################################ SEARCH INDEX ################################\nFEATURES['ENABLE_COURSEWARE_INDEX'] = True\nFEATURES['ENABLE_LIBRARY_INDEX'] = True\nSEARCH_ENGINE = \"search.elastic.ElasticSearchEngine\"\n\n########################## Certificates Web/HTML View #######################\nFEATURES['CERTIFICATES_HTML_VIEW'] = True\n\n########################## AUTHOR PERMISSION #######################\nFEATURES['ENABLE_CREATOR_GROUP'] = False\n\n################################# DJANGO-REQUIRE ###############################\n\n# Whether to run django-require in debug mode.\nREQUIRE_DEBUG = DEBUG\n\n########################### OAUTH2 #################################\nOAUTH_OIDC_ISSUER = 'http://127.0.0.1:8000/oauth2'\n\nJWT_AUTH.update({\n    'JWT_SECRET_KEY': 'lms-secret',\n    'JWT_ISSUER': 'http://127.0.0.1:8000/oauth2',\n    'JWT_AUDIENCE': 'lms-key',\n})\n\n###############################################################################\n# See if the developer has any local overrides.\nif os.path.isfile(join(dirname(abspath(__file__)), 'private.py')):\n    from .private import *  # pylint: disable=import-error,wildcard-import\n\n#####################################################################\n# Lastly, run any migrations, if needed.\nMODULESTORE = convert_module_store_setting_if_needed(MODULESTORE)\n\n# Dummy secret key for dev\nSECRET_KEY = '85920908f28904ed733fe576320db18cabd7b6cd'\n" }
{ "repo_name": "klim-iv/phantomjs-qt5", "ref": "refs/heads/qt5", "path": "src/breakpad/src/tools/gyp/test/home_dot_gyp/gyptest-home-includes-regyp.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2009 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nVerifies inclusion of $HOME/.gyp/includes.gypi works properly with relocation\nand with regeneration.\n\"\"\"\n\nimport os\nimport TestGyp\n\n# Regenerating build files when a gyp file changes is currently only supported\n# by the make generator.\ntest = TestGyp.TestGyp(formats=['make'])\n\nos.environ['HOME'] = os.path.abspath('home')\n\ntest.run_gyp('all.gyp', chdir='src')\n\n# After relocating, we should still be able to build (build file shouldn't\n# contain relative reference to ~/.gyp/includes.gypi)\ntest.relocate('src', 'relocate/src')\n\ntest.build('all.gyp', test.ALL, chdir='relocate/src')\n\ntest.run_built_executable('printfoo',\n                          chdir='relocate/src',\n                          stdout=\"FOO is fromhome\\n\");\n\n# Building should notice any changes to ~/.gyp/includes.gypi and regyp.\ntest.sleep()\n\ntest.write('home/.gyp/include.gypi', test.read('home2/.gyp/include.gypi'))\n\ntest.build('all.gyp', test.ALL, chdir='relocate/src')\n\ntest.run_built_executable('printfoo',\n                          chdir='relocate/src',\n                          stdout=\"FOO is fromhome2\\n\");\n\ntest.pass_test()\n" }
{ "repo_name": "UrLab/DocHub", "ref": "refs/heads/main", "path": "telepathy/models.py", "content": "import json\n\nfrom django.conf import settings\nfrom django.db import models\nfrom django.urls import reverse\n\n\nclass Thread(models.Model):\n    # Possible placement options\n    PLACEMENT_OPTS = {'page-no': int}\n\n    name = models.CharField(max_length=255)\n\n    user = models.ForeignKey(settings.AUTH_USER_MODEL, on_delete=models.CASCADE)\n    created = models.DateTimeField(auto_now_add=True)\n    edited = models.DateTimeField(auto_now=True)\n    placement = models.TextField(default=\"\", blank=True)\n\n    course = models.ForeignKey('catalog.Course', on_delete=models.CASCADE)\n    document = models.ForeignKey('documents.Document', null=True, on_delete=models.CASCADE)\n\n    def __str__(self):\n        return self.name\n\n    def fullname(self):\n        return self.__str__()\n\n    @property\n    def page_no(self):\n        if self.placement:\n            placement = json.loads(self.placement)\n            if 'page-no' in placement:\n                return placement['page-no']\n        return None\n\n    def get_absolute_url(self):\n        return reverse('thread_show', args=(self.id, ))\n\n    def write_perm(self, user, moderated_courses):\n        if user.id == self.user_id:\n            return True\n\n        if self.course_id in moderated_courses:\n            return True\n\n        return False\n\n    class Meta:\n        ordering = ['-created']\n\n\nclass Message(models.Model):\n    user = models.ForeignKey(settings.AUTH_USER_MODEL, on_delete=models.CASCADE)\n    thread = models.ForeignKey(Thread, db_index=True, on_delete=models.CASCADE)\n    text = models.TextField()\n    created = models.DateTimeField(auto_now_add=True)\n    edited = models.DateTimeField(auto_now=True)\n\n    def __str__(self):\n        return self.text\n\n    def fullname(self):\n        return \"un message\"\n\n    def get_absolute_url(self):\n        return reverse('thread_show', args=(self.thread_id, )) + f\"#message-{self.id}\"\n\n    def write_perm(self, user, moderated_courses):\n        if user.id == self.user_id:\n            return True\n\n        if self.thread.course_id in moderated_courses:\n            return True\n\n        return False\n" }
{ "repo_name": "apanda/phantomjs-intercept", "ref": "refs/heads/2.0", "path": "src/breakpad/src/tools/gyp/test/home_dot_gyp/gyptest-home-includes-regyp.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2009 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nVerifies inclusion of $HOME/.gyp/includes.gypi works properly with relocation\nand with regeneration.\n\"\"\"\n\nimport os\nimport TestGyp\n\n# Regenerating build files when a gyp file changes is currently only supported\n# by the make generator.\ntest = TestGyp.TestGyp(formats=['make'])\n\nos.environ['HOME'] = os.path.abspath('home')\n\ntest.run_gyp('all.gyp', chdir='src')\n\n# After relocating, we should still be able to build (build file shouldn't\n# contain relative reference to ~/.gyp/includes.gypi)\ntest.relocate('src', 'relocate/src')\n\ntest.build('all.gyp', test.ALL, chdir='relocate/src')\n\ntest.run_built_executable('printfoo',\n                          chdir='relocate/src',\n                          stdout=\"FOO is fromhome\\n\");\n\n# Building should notice any changes to ~/.gyp/includes.gypi and regyp.\ntest.sleep()\n\ntest.write('home/.gyp/include.gypi', test.read('home2/.gyp/include.gypi'))\n\ntest.build('all.gyp', test.ALL, chdir='relocate/src')\n\ntest.run_built_executable('printfoo',\n                          chdir='relocate/src',\n                          stdout=\"FOO is fromhome2\\n\");\n\ntest.pass_test()\n" }
{ "repo_name": "danigonza/phantomjs", "ref": "refs/heads/webfonts", "path": "src/breakpad/src/tools/gyp/test/home_dot_gyp/gyptest-home-includes-regyp.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2009 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nVerifies inclusion of $HOME/.gyp/includes.gypi works properly with relocation\nand with regeneration.\n\"\"\"\n\nimport os\nimport TestGyp\n\n# Regenerating build files when a gyp file changes is currently only supported\n# by the make generator.\ntest = TestGyp.TestGyp(formats=['make'])\n\nos.environ['HOME'] = os.path.abspath('home')\n\ntest.run_gyp('all.gyp', chdir='src')\n\n# After relocating, we should still be able to build (build file shouldn't\n# contain relative reference to ~/.gyp/includes.gypi)\ntest.relocate('src', 'relocate/src')\n\ntest.build('all.gyp', test.ALL, chdir='relocate/src')\n\ntest.run_built_executable('printfoo',\n                          chdir='relocate/src',\n                          stdout=\"FOO is fromhome\\n\");\n\n# Building should notice any changes to ~/.gyp/includes.gypi and regyp.\ntest.sleep()\n\ntest.write('home/.gyp/include.gypi', test.read('home2/.gyp/include.gypi'))\n\ntest.build('all.gyp', test.ALL, chdir='relocate/src')\n\ntest.run_built_executable('printfoo',\n                          chdir='relocate/src',\n                          stdout=\"FOO is fromhome2\\n\");\n\ntest.pass_test()\n" }
{ "repo_name": "VinceZK/phantomjs", "ref": "refs/heads/decktape", "path": "src/breakpad/src/tools/gyp/test/home_dot_gyp/gyptest-home-includes-regyp.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2009 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nVerifies inclusion of $HOME/.gyp/includes.gypi works properly with relocation\nand with regeneration.\n\"\"\"\n\nimport os\nimport TestGyp\n\n# Regenerating build files when a gyp file changes is currently only supported\n# by the make generator.\ntest = TestGyp.TestGyp(formats=['make'])\n\nos.environ['HOME'] = os.path.abspath('home')\n\ntest.run_gyp('all.gyp', chdir='src')\n\n# After relocating, we should still be able to build (build file shouldn't\n# contain relative reference to ~/.gyp/includes.gypi)\ntest.relocate('src', 'relocate/src')\n\ntest.build('all.gyp', test.ALL, chdir='relocate/src')\n\ntest.run_built_executable('printfoo',\n                          chdir='relocate/src',\n                          stdout=\"FOO is fromhome\\n\");\n\n# Building should notice any changes to ~/.gyp/includes.gypi and regyp.\ntest.sleep()\n\ntest.write('home/.gyp/include.gypi', test.read('home2/.gyp/include.gypi'))\n\ntest.build('all.gyp', test.ALL, chdir='relocate/src')\n\ntest.run_built_executable('printfoo',\n                          chdir='relocate/src',\n                          stdout=\"FOO is fromhome2\\n\");\n\ntest.pass_test()\n" }
{ "repo_name": "raccoongang/edx-platform", "ref": "refs/heads/ginkgo-rg", "path": "cms/envs/devstack.py", "content": "\"\"\"\nSpecific overrides to the base prod settings to make development easier.\n\"\"\"\n\nfrom os.path import abspath, dirname, join\n\nfrom .aws import *  # pylint: disable=wildcard-import, unused-wildcard-import\n\n# Don't use S3 in devstack, fall back to filesystem\ndel DEFAULT_FILE_STORAGE\nCOURSE_IMPORT_EXPORT_STORAGE = 'django.core.files.storage.FileSystemStorage'\nUSER_TASKS_ARTIFACT_STORAGE = COURSE_IMPORT_EXPORT_STORAGE\n\nDEBUG = True\nUSE_I18N = True\nDEFAULT_TEMPLATE_ENGINE['OPTIONS']['debug'] = DEBUG\nHTTPS = 'off'\n\n################################ LOGGERS ######################################\n\nimport logging\n\n# Disable noisy loggers\nfor pkg_name in ['track.contexts', 'track.middleware', 'dd.dogapi']:\n    logging.getLogger(pkg_name).setLevel(logging.CRITICAL)\n\n\n################################ EMAIL ########################################\n\nEMAIL_BACKEND = 'django.core.mail.backends.console.EmailBackend'\n\n################################# LMS INTEGRATION #############################\n\nLMS_BASE = \"localhost:8000\"\nLMS_ROOT_URL = \"http://{}\".format(LMS_BASE)\nFEATURES['PREVIEW_LMS_BASE'] = \"preview.\" + LMS_BASE\n\n########################### PIPELINE #################################\n\n# Skip packaging and optimization in development\nPIPELINE_ENABLED = False\nSTATICFILES_STORAGE = 'openedx.core.storage.DevelopmentStorage'\n\n# Revert to the default set of finders as we don't want the production pipeline\nSTATICFILES_FINDERS = [\n    'openedx.core.djangoapps.theming.finders.ThemeFilesFinder',\n    'django.contrib.staticfiles.finders.FileSystemFinder',\n    'django.contrib.staticfiles.finders.AppDirectoriesFinder',\n]\n\n############################ PYFS XBLOCKS SERVICE #############################\n# Set configuration for Django pyfilesystem\n\nDJFS = {\n    'type': 'osfs',\n    'directory_root': 'cms/static/djpyfs',\n    'url_root': '/static/djpyfs',\n}\n\n################################# CELERY ######################################\n\n# By default don't use a worker, execute tasks as if they were local functions\nCELERY_ALWAYS_EAGER = True\n\n################################ DEBUG TOOLBAR ################################\nINSTALLED_APPS += ('debug_toolbar', 'debug_toolbar_mongo')\nMIDDLEWARE_CLASSES += ('debug_toolbar.middleware.DebugToolbarMiddleware',)\nINTERNAL_IPS = ('127.0.0.1',)\n\nDEBUG_TOOLBAR_PANELS = (\n    'debug_toolbar.panels.versions.VersionsPanel',\n    'debug_toolbar.panels.timer.TimerPanel',\n    'debug_toolbar.panels.settings.SettingsPanel',\n    'debug_toolbar.panels.headers.HeadersPanel',\n    'debug_toolbar.panels.request.RequestPanel',\n    'debug_toolbar.panels.sql.SQLPanel',\n    'debug_toolbar.panels.signals.SignalsPanel',\n    'debug_toolbar.panels.logging.LoggingPanel',\n    'debug_toolbar.panels.profiling.ProfilingPanel',\n)\n\nDEBUG_TOOLBAR_CONFIG = {\n    # Profile panel is incompatible with wrapped views\n    # See https://github.com/jazzband/django-debug-toolbar/issues/792\n    'DISABLE_PANELS': (\n        'debug_toolbar.panels.profiling.ProfilingPanel',\n    ),\n    'SHOW_TOOLBAR_CALLBACK': 'cms.envs.devstack.should_show_debug_toolbar',\n    'JQUERY_URL': None,\n}\n\n\ndef should_show_debug_toolbar(_):\n    return True  # We always want the toolbar on devstack regardless of IP, auth, etc.\n\n\n# To see stacktraces for MongoDB queries, set this to True.\n# Stacktraces slow down page loads drastically (for pages with lots of queries).\nDEBUG_TOOLBAR_MONGO_STACKTRACES = False\n\n\n################################ MILESTONES ################################\nFEATURES['MILESTONES_APP'] = True\n\n\n################################ ENTRANCE EXAMS ################################\nFEATURES['ENTRANCE_EXAMS'] = True\n\n################################ COURSE LICENSES ################################\nFEATURES['LICENSING'] = True\n# Needed to enable licensing on video modules\nXBLOCK_SETTINGS.update({'VideoDescriptor': {'licensing_enabled': True}})\n\n################################ SEARCH INDEX ################################\nFEATURES['ENABLE_COURSEWARE_INDEX'] = True\nFEATURES['ENABLE_LIBRARY_INDEX'] = True\nSEARCH_ENGINE = \"search.elastic.ElasticSearchEngine\"\n\n########################## Certificates Web/HTML View #######################\nFEATURES['CERTIFICATES_HTML_VIEW'] = True\n\n########################## AUTHOR PERMISSION #######################\nFEATURES['ENABLE_CREATOR_GROUP'] = False\n\n################################# DJANGO-REQUIRE ###############################\n\n# Whether to run django-require in debug mode.\nREQUIRE_DEBUG = DEBUG\n\n########################### OAUTH2 #################################\nOAUTH_OIDC_ISSUER = 'http://127.0.0.1:8000/oauth2'\n\nJWT_AUTH.update({\n    'JWT_SECRET_KEY': 'lms-secret',\n    'JWT_ISSUER': 'http://127.0.0.1:8000/oauth2',\n    'JWT_AUDIENCE': 'lms-key',\n})\n\n###############################################################################\n# See if the developer has any local overrides.\nif os.path.isfile(join(dirname(abspath(__file__)), 'private.py')):\n    from .private import *  # pylint: disable=import-error,wildcard-import\n\n#####################################################################\n# Lastly, run any migrations, if needed.\nMODULESTORE = convert_module_store_setting_if_needed(MODULESTORE)\n\n# Dummy secret key for dev\nSECRET_KEY = '85920908f28904ed733fe576320db18cabd7b6cd'\n" }
{ "repo_name": "virtualopensystems/nova", "ref": "refs/heads/bp/vif-vhostuser", "path": "nova/virt/vmwareapi/constants.py", "content": "# Copyright (c) 2014 VMware, Inc.\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\n\"\"\"\nShared constants across the VMware driver\n\"\"\"\n\nfrom nova.network import model as network_model\n\nDISK_FORMAT_ISO = 'iso'\nDISK_FORMAT_VMDK = 'vmdk'\nDISK_FORMATS_ALL = [DISK_FORMAT_ISO, DISK_FORMAT_VMDK]\n\nDISK_TYPE_SPARSE = 'sparse'\nDISK_TYPE_PREALLOCATED = 'preallocated'\n\nDEFAULT_VIF_MODEL = network_model.VIF_MODEL_E1000\nDEFAULT_OS_TYPE = \"otherGuest\"\nDEFAULT_ADAPTER_TYPE = \"lsiLogic\"\nDEFAULT_DISK_TYPE = DISK_TYPE_PREALLOCATED\nDEFAULT_DISK_FORMAT = DISK_FORMAT_VMDK\n" }
{ "repo_name": "sgerhart/ansible", "ref": "refs/heads/maintenance_group_node_module", "path": "lib/ansible/modules/remote_management/oneview/oneview_enclosure_facts.py", "content": "#!/usr/bin/python\n\n# Copyright: (c) 2016-2017, Hewlett Packard Enterprise Development LP\n# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)\n\nfrom __future__ import (absolute_import, division, print_function)\n__metaclass__ = type\n\nANSIBLE_METADATA = {'metadata_version': '1.1',\n                    'status': ['preview'],\n                    'supported_by': 'community'}\n\nDOCUMENTATION = '''\n---\nmodule: oneview_enclosure_facts\nshort_description: Retrieve facts about one or more Enclosures\ndescription:\n    - Retrieve facts about one or more of the Enclosures from OneView.\nversion_added: \"2.5\"\nrequirements:\n    - hpOneView >= 2.0.1\nauthor:\n    - Felipe Bulsoni (@fgbulsoni)\n    - Thiago Miotto (@tmiotto)\n    - Adriane Cardozo (@adriane-cardozo)\noptions:\n    name:\n      description:\n        - Enclosure name.\n    options:\n      description:\n        - \"List with options to gather additional facts about an Enclosure and related resources.\n          Options allowed: C(script), C(environmentalConfiguration), and C(utilization). For the option C(utilization),\n          you can provide specific parameters.\"\n\nextends_documentation_fragment:\n    - oneview\n    - oneview.factsparams\n'''\n\nEXAMPLES = '''\n- name: Gather facts about all Enclosures\n  oneview_enclosure_facts:\n    hostname: 172.16.101.48\n    username: administrator\n    password: my_password\n    api_version: 500\n  no_log: true\n  delegate_to: localhost\n- debug: var=enclosures\n\n- name: Gather paginated, filtered and sorted facts about Enclosures\n  oneview_enclosure_facts:\n    params:\n      start: 0\n      count: 3\n      sort: name:descending\n      filter: status=OK\n    hostname: 172.16.101.48\n    username: administrator\n    password: my_password\n    api_version: 500\n  no_log: true\n  delegate_to: localhost\n- debug: var=enclosures\n\n- name: Gather facts about an Enclosure by name\n  oneview_enclosure_facts:\n    name: Enclosure-Name\n    hostname: 172.16.101.48\n    username: administrator\n    password: my_password\n    api_version: 500\n  no_log: true\n  delegate_to: localhost\n- debug: var=enclosures\n\n- name: Gather facts about an Enclosure by name with options\n  oneview_enclosure_facts:\n    name: Test-Enclosure\n    options:\n      - script                       # optional\n      - environmentalConfiguration   # optional\n      - utilization                  # optional\n    hostname: 172.16.101.48\n    username: administrator\n    password: my_password\n    api_version: 500\n  no_log: true\n  delegate_to: localhost\n- debug: var=enclosures\n- debug: var=enclosure_script\n- debug: var=enclosure_environmental_configuration\n- debug: var=enclosure_utilization\n\n- name: \"Gather facts about an Enclosure with temperature data at a resolution of one sample per day, between two\n         specified dates\"\n  oneview_enclosure_facts:\n    name: Test-Enclosure\n    options:\n      - utilization:                   # optional\n          fields: AmbientTemperature\n          filter:\n            - startDate=2016-07-01T14:29:42.000Z\n            - endDate=2017-07-01T03:29:42.000Z\n          view: day\n          refresh: false\n    hostname: 172.16.101.48\n    username: administrator\n    password: my_password\n    api_version: 500\n  no_log: true\n  delegate_to: localhost\n- debug: var=enclosures\n- debug: var=enclosure_utilization\n'''\n\nRETURN = '''\nenclosures:\n    description: Has all the OneView facts about the Enclosures.\n    returned: Always, but can be null.\n    type: dict\n\nenclosure_script:\n    description: Has all the OneView facts about the script of an Enclosure.\n    returned: When requested, but can be null.\n    type: string\n\nenclosure_environmental_configuration:\n    description: Has all the OneView facts about the environmental configuration of an Enclosure.\n    returned: When requested, but can be null.\n    type: dict\n\nenclosure_utilization:\n    description: Has all the OneView facts about the utilization of an Enclosure.\n    returned: When requested, but can be null.\n    type: dict\n'''\n\nfrom ansible.module_utils.oneview import OneViewModuleBase\n\n\nclass EnclosureFactsModule(OneViewModuleBase):\n    argument_spec = dict(name=dict(type='str'), options=dict(type='list'), params=dict(type='dict'))\n\n    def __init__(self):\n        super(EnclosureFactsModule, self).__init__(additional_arg_spec=self.argument_spec)\n\n    def execute_module(self):\n\n        ansible_facts = {}\n\n        if self.module.params['name']:\n            enclosures = self._get_by_name(self.module.params['name'])\n\n            if self.options and enclosures:\n                ansible_facts = self._gather_optional_facts(self.options, enclosures[0])\n        else:\n            enclosures = self.oneview_client.enclosures.get_all(**self.facts_params)\n\n        ansible_facts['enclosures'] = enclosures\n\n        return dict(changed=False,\n                    ansible_facts=ansible_facts)\n\n    def _gather_optional_facts(self, options, enclosure):\n\n        enclosure_client = self.oneview_client.enclosures\n        ansible_facts = {}\n\n        if options.get('script'):\n            ansible_facts['enclosure_script'] = enclosure_client.get_script(enclosure['uri'])\n        if options.get('environmentalConfiguration'):\n            env_config = enclosure_client.get_environmental_configuration(enclosure['uri'])\n            ansible_facts['enclosure_environmental_configuration'] = env_config\n        if options.get('utilization'):\n            ansible_facts['enclosure_utilization'] = self._get_utilization(enclosure, options['utilization'])\n\n        return ansible_facts\n\n    def _get_utilization(self, enclosure, params):\n        fields = view = refresh = filter = ''\n\n        if isinstance(params, dict):\n            fields = params.get('fields')\n            view = params.get('view')\n            refresh = params.get('refresh')\n            filter = params.get('filter')\n\n        return self.oneview_client.enclosures.get_utilization(enclosure['uri'],\n                                                              fields=fields,\n                                                              filter=filter,\n                                                              refresh=refresh,\n                                                              view=view)\n\n    def _get_by_name(self, name):\n        return self.oneview_client.enclosures.get_by('name', name)\n\n\ndef main():\n    EnclosureFactsModule().run()\n\n\nif __name__ == '__main__':\n    main()\n" }
{ "repo_name": "nawawi/poedit", "ref": "refs/heads/stable", "path": "deps/boost/libs/python/test/callbacks.py", "content": "# Copyright David Abrahams 2004. Distributed under the Boost\n# Software License, Version 1.0. (See accompanying\n# file LICENSE_1_0.txt or copy at http://www.boost.org/LICENSE_1_0.txt)\n'''\n>>> from callbacks_ext import *\n\n>>> def double(x):\n...     return x + x\n...\n>>> apply_int_int(double, 42)\n84\n>>> apply_void_int(double, 42)\n\n>>> def identity(x):\n...     return x\n\nOnce we have array conversion support, this test will fail. Er,\nsucceed<wink>:\n\n>>> try: apply_to_string_literal(identity)\n... except ReferenceError: pass # expected\n... else: print('expected an exception!')\n\n>>> try: apply_X_ref_handle(lambda ignored:X(42), None)\n... except ReferenceError: pass # expected\n... else: print('expected an exception!')\n\n>>> x = X(42)\n>>> x.y = X(7)\n>>> apply_X_ref_handle(lambda z:z.y, x).value()\n7\n\n>>> x = apply_X_X(identity, X(42))\n>>> x.value()\n42\n>>> x_count()\n1\n>>> del x\n>>> x_count()\n0\n\n>>> def increment(x):\n...     x.set(x.value() + 1)\n...\n>>> x = X(42)\n>>> apply_void_X_ref(increment, x)\n>>> x.value()\n43\n\n>>> apply_void_X_cref(increment, x) \n>>> x.value()  # const-ness is not respected, sorry!\n44\n\n>>> last_x = 1\n>>> def decrement(x):\n...     global last_x\n...     last_x = x\n...     if x is not None:\n...         x.set(x.value() - 1)\n\n>>> apply_void_X_ptr(decrement, x)\n>>> x.value()\n43\n>>> last_x.value()\n43\n>>> increment(last_x)\n>>> x.value()\n44\n>>> last_x.value()\n44\n\n>>> apply_void_X_ptr(decrement, None)\n>>> assert last_x is None\n>>> x.value()\n44\n\n>>> last_x = 1\n>>> apply_void_X_deep_ptr(decrement, None)\n>>> assert last_x is None\n>>> x.value()\n44\n\n>>> apply_void_X_deep_ptr(decrement, x)\n>>> x.value()\n44\n>>> last_x.value()\n43\n\n>>> y = apply_X_ref_handle(identity, x)\n>>> assert y.value() == x.value()\n>>> increment(x)\n>>> assert y.value() == x.value()\n\n>>> y = apply_X_ptr_handle_cref(identity, x)\n>>> assert y.value() == x.value()\n>>> increment(x)\n>>> assert y.value() == x.value()\n\n>>> y = apply_X_ptr_handle_cref(identity, None)\n>>> y\n\n>>> def new_x(ignored):\n...     return X(666)\n...\n>>> try: apply_X_ref_handle(new_x, 1)\n... except ReferenceError: pass\n... else: print('no error')\n\n>>> try: apply_X_ptr_handle_cref(new_x, 1)\n... except ReferenceError: pass\n... else: print('no error')\n\n>>> try: apply_cstring_cstring(identity, 'hello')\n... except ReferenceError: pass\n... else: print('no error')\n\n>>> apply_char_char(identity, 'x')\n'x'\n\n>>> apply_cstring_pyobject(identity, 'hello')\n'hello'\n\n>>> apply_cstring_pyobject(identity, None)\n\n\n>>> apply_char_char(identity, 'x')\n'x'\n\n>>> assert apply_to_own_type(identity) is type(identity)\n\n>>> assert apply_object_object(identity, identity) is identity\n'''\n\ndef run(args = None):\n    import sys\n    import doctest\n\n    if args is not None:\n        sys.argv = args\n    return doctest.testmod(sys.modules.get(__name__))\n    \nif __name__ == '__main__':\n    print(\"running...\")\n    import sys\n    status = run()[0]\n    if (status == 0): print(\"Done.\")\n    sys.exit(status)\n" }
{ "repo_name": "baslr/ArangoDB", "ref": "refs/heads/3.1-silent", "path": "3rdParty/boost/1.62.0/libs/python/test/callbacks.py", "content": "# Copyright David Abrahams 2004. Distributed under the Boost\n# Software License, Version 1.0. (See accompanying\n# file LICENSE_1_0.txt or copy at http://www.boost.org/LICENSE_1_0.txt)\n'''\n>>> from callbacks_ext import *\n\n>>> def double(x):\n...     return x + x\n...\n>>> apply_int_int(double, 42)\n84\n>>> apply_void_int(double, 42)\n\n>>> def identity(x):\n...     return x\n\nOnce we have array conversion support, this test will fail. Er,\nsucceed<wink>:\n\n>>> try: apply_to_string_literal(identity)\n... except ReferenceError: pass # expected\n... else: print('expected an exception!')\n\n>>> try: apply_X_ref_handle(lambda ignored:X(42), None)\n... except ReferenceError: pass # expected\n... else: print('expected an exception!')\n\n>>> x = X(42)\n>>> x.y = X(7)\n>>> apply_X_ref_handle(lambda z:z.y, x).value()\n7\n\n>>> x = apply_X_X(identity, X(42))\n>>> x.value()\n42\n>>> x_count()\n1\n>>> del x\n>>> x_count()\n0\n\n>>> def increment(x):\n...     x.set(x.value() + 1)\n...\n>>> x = X(42)\n>>> apply_void_X_ref(increment, x)\n>>> x.value()\n43\n\n>>> apply_void_X_cref(increment, x) \n>>> x.value()  # const-ness is not respected, sorry!\n44\n\n>>> last_x = 1\n>>> def decrement(x):\n...     global last_x\n...     last_x = x\n...     if x is not None:\n...         x.set(x.value() - 1)\n\n>>> apply_void_X_ptr(decrement, x)\n>>> x.value()\n43\n>>> last_x.value()\n43\n>>> increment(last_x)\n>>> x.value()\n44\n>>> last_x.value()\n44\n\n>>> apply_void_X_ptr(decrement, None)\n>>> assert last_x is None\n>>> x.value()\n44\n\n>>> last_x = 1\n>>> apply_void_X_deep_ptr(decrement, None)\n>>> assert last_x is None\n>>> x.value()\n44\n\n>>> apply_void_X_deep_ptr(decrement, x)\n>>> x.value()\n44\n>>> last_x.value()\n43\n\n>>> y = apply_X_ref_handle(identity, x)\n>>> assert y.value() == x.value()\n>>> increment(x)\n>>> assert y.value() == x.value()\n\n>>> y = apply_X_ptr_handle_cref(identity, x)\n>>> assert y.value() == x.value()\n>>> increment(x)\n>>> assert y.value() == x.value()\n\n>>> y = apply_X_ptr_handle_cref(identity, None)\n>>> y\n\n>>> def new_x(ignored):\n...     return X(666)\n...\n>>> try: apply_X_ref_handle(new_x, 1)\n... except ReferenceError: pass\n... else: print('no error')\n\n>>> try: apply_X_ptr_handle_cref(new_x, 1)\n... except ReferenceError: pass\n... else: print('no error')\n\n>>> try: apply_cstring_cstring(identity, 'hello')\n... except ReferenceError: pass\n... else: print('no error')\n\n>>> apply_char_char(identity, 'x')\n'x'\n\n>>> apply_cstring_pyobject(identity, 'hello')\n'hello'\n\n>>> apply_cstring_pyobject(identity, None)\n\n\n>>> apply_char_char(identity, 'x')\n'x'\n\n>>> assert apply_to_own_type(identity) is type(identity)\n\n>>> assert apply_object_object(identity, identity) is identity\n'''\n\ndef run(args = None):\n    import sys\n    import doctest\n\n    if args is not None:\n        sys.argv = args\n    return doctest.testmod(sys.modules.get(__name__))\n    \nif __name__ == '__main__':\n    print(\"running...\")\n    import sys\n    status = run()[0]\n    if (status == 0): print(\"Done.\")\n    sys.exit(status)\n" }
{ "repo_name": "jrossyra/adaptivemd", "ref": "refs/heads/rp_integration", "path": "adaptivemd/plan.py", "content": "import types\n\n\nclass ExecutionPlan(object):\n    \"\"\"\n    An wrap to turn python function into asynchronous execution\n\n    The function is executed on start and interrupted if you use\n    ``yield {(list of )condition to continue}``\n\n    To make writing of asynchronous code easy you can use this wrapper class.\n    Usually you start by opening a scheduler that you submit tasks to. Then\n    submit a first task or yield a condition to wait for. Once this is met the\n    code will continue to execute and you can submit more tasks until finally\n    you will close the scheduler\n\n    \"\"\"\n    def __init__(self, generator):\n        \"\"\"\n        Parameters\n        ----------\n        generator : function\n            the function (generator) to be used\n\n        \"\"\"\n        super(ExecutionPlan, self).__init__()\n\n        if not isinstance(generator, types.GeneratorType):\n            generator = generator()\n\n        assert isinstance(generator, types.GeneratorType)\n\n        self._generator = generator\n        self._running = True\n        self._finish_conditions = []\n\n    def _update_conditions(self):\n        self._finish_conditions = [x for x in self._finish_conditions if not x()]\n\n    def __call__(self):\n        if self._running:\n            try:\n                conditions = next(self._generator)\n                if conditions is not None:\n                    if isinstance(conditions, (tuple, list)):\n                        self._finish_conditions.extend(conditions)\n                    else:\n                        self._finish_conditions.append(conditions)\n                self._update_conditions()\n            except StopIteration:\n                self._running = False\n\n    def trigger(self):\n        if self:\n            self._update_conditions()\n            while self._running and len(self._finish_conditions) == 0:\n                self()\n                self._update_conditions()\n\n    def __bool__(self):\n        return self._running\n\n    def __nonzero__(self):\n        return self.__bool__()\n\n    def __str__(self):\n        return '%s(%s)' % (\n            self.__class__.__name__,\n            'active' if self else '------'\n        )\n\n    @property\n    def on_done(self):\n        \"\"\"\n        Return a `Condition` that is True once the event is finished\n\n        Returns\n        -------\n\n        \"\"\"\n        return lambda: not bool(self)\n" }
{ "repo_name": "alexryndin/ambari", "ref": "refs/heads/branch-adh-1.5", "path": "ambari-server/src/main/resources/common-services/FALCON/0.5.0.2.1/package/scripts/params_linux.py", "content": "\"\"\"\nLicensed to the Apache Software Foundation (ASF) under one\nor more contributor license agreements.  See the NOTICE file\ndistributed with this work for additional information\nregarding copyright ownership.  The ASF licenses this file\nto you under the Apache License, Version 2.0 (the\n\"License\"); you may not use this file except in compliance\nwith the License.  You may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n\"\"\"\nimport status_params\n\nfrom resource_management.libraries.resources.hdfs_resource import HdfsResource\nfrom resource_management.libraries.functions import stack_select\nfrom resource_management.libraries.functions import format\nfrom resource_management.libraries.functions.default import default\nfrom resource_management.libraries.functions.get_not_managed_resources import get_not_managed_resources\nfrom resource_management.libraries.functions import get_kinit_path\nfrom resource_management.libraries.script.script import Script\nimport os\nfrom resource_management.libraries.functions.expect import expect\nfrom resource_management.libraries.functions.stack_features import check_stack_feature\nfrom resource_management.libraries.functions.version import format_stack_version\nfrom resource_management.libraries.functions import StackFeature\nfrom resource_management.libraries.functions.setup_atlas_hook import has_atlas_in_cluster\n\nconfig = Script.get_config()\nstack_root = status_params.stack_root\nstack_name = status_params.stack_name\n\nagent_stack_retry_on_unavailability = config['hostLevelParams']['agent_stack_retry_on_unavailability']\nagent_stack_retry_count = expect(\"/hostLevelParams/agent_stack_retry_count\", int)\n\n# New Cluster Stack Version that is defined during the RESTART of a Rolling Upgrade\nversion = default(\"/commandParams/version\", None)\n\nstack_version_unformatted = status_params.stack_version_unformatted\nstack_version_formatted = status_params.stack_version_formatted\nupgrade_direction = default(\"/commandParams/upgrade_direction\", None)\njdk_location = config['hostLevelParams']['jdk_location']\n\n# current host stack version\ncurrent_version = default(\"/hostLevelParams/current_version\", None)\ncurrent_version_formatted = format_stack_version(current_version)\n\netc_prefix_dir = \"/etc/falcon\"\n\n# hadoop params\nhadoop_home_dir = stack_select.get_hadoop_dir(\"home\")\nhadoop_bin_dir = stack_select.get_hadoop_dir(\"bin\")\n\nif stack_version_formatted and check_stack_feature(StackFeature.ROLLING_UPGRADE, stack_version_formatted):\n  # if this is a server action, then use the server binaries; smoke tests\n  # use the client binaries\n  server_role_dir_mapping = { 'FALCON_SERVER' : 'falcon-server',\n    'FALCON_SERVICE_CHECK' : 'falcon-client' }\n\n  command_role = default(\"/role\", \"\")\n  if command_role not in server_role_dir_mapping:\n    command_role = 'FALCON_SERVICE_CHECK'\n\n  falcon_root = server_role_dir_mapping[command_role]\n  falcon_webapp_dir = format('{stack_root}/current/{falcon_root}/webapp')\n  falcon_home = format('{stack_root}/current/{falcon_root}')\n\n  # Extensions dir is only available in HDP 2.5 and higher\n  falcon_extensions_source_dir = os.path.join(stack_root, \"current\", falcon_root, \"extensions\")\n  # Dir in HDFS\n  falcon_extensions_dest_dir = default(\"/configurations/falcon-startup.properties/*.extension.store.uri\", \"/apps/falcon/extensions\")\nelse:\n  falcon_webapp_dir = '/var/lib/falcon/webapp'\n  falcon_home = '/usr/lib/falcon'\n\nfalcon_webinf_lib = falcon_home + \"/server/webapp/falcon/WEB-INF/lib\"\n\nhadoop_conf_dir = status_params.hadoop_conf_dir\nfalcon_conf_dir = status_params.falcon_conf_dir\noozie_user = config['configurations']['oozie-env']['oozie_user']\nfalcon_user = config['configurations']['falcon-env']['falcon_user']\nsmoke_user = config['configurations']['cluster-env']['smokeuser']\n\nserver_pid_file = status_params.server_pid_file\n\nuser_group = config['configurations']['cluster-env']['user_group']\nproxyuser_group =  config['configurations']['hadoop-env']['proxyuser_group']\n\njava_home = config['hostLevelParams']['java_home']\nfalcon_local_dir = config['configurations']['falcon-env']['falcon_local_dir']\nfalcon_log_dir = config['configurations']['falcon-env']['falcon_log_dir']\n\n# falcon-startup.properties\nstore_uri = config['configurations']['falcon-startup.properties']['*.config.store.uri']\n# If these properties are present, the directories need to be created.\nfalcon_graph_storage_directory = default(\"/configurations/falcon-startup.properties/*.falcon.graph.storage.directory\", None)  # explicitly set in HDP 2.2 and higher\nfalcon_graph_serialize_path = default(\"/configurations/falcon-startup.properties/*.falcon.graph.serialize.path\", None)        # explicitly set in HDP 2.2 and higher\n\nfalcon_embeddedmq_data = config['configurations']['falcon-env']['falcon.embeddedmq.data']\nfalcon_embeddedmq_enabled = config['configurations']['falcon-env']['falcon.embeddedmq']\nfalcon_emeddedmq_port = config['configurations']['falcon-env']['falcon.emeddedmq.port']\n\nfalcon_host = config['clusterHostInfo']['falcon_server_hosts'][0]\nfalcon_port = config['configurations']['falcon-env']['falcon_port']\nfalcon_runtime_properties = config['configurations']['falcon-runtime.properties']\nfalcon_startup_properties = config['configurations']['falcon-startup.properties']\nfalcon_client_properties = config['configurations']['falcon-client.properties']\nsmokeuser_keytab = config['configurations']['cluster-env']['smokeuser_keytab']\nfalcon_env_sh_template = config['configurations']['falcon-env']['content']\n\n#Log4j properties\nfalcon_log_maxfilesize = default('/configurations/falcon-log4j/falcon_log_maxfilesize',256)\nfalcon_log_maxbackupindex =  default('/configurations/falcon-log4j/falcon_log_maxbackupindex',20)\nfalcon_security_log_maxfilesize = default('/configurations/falcon-log4j/falcon_security_log_maxfilesize',256)\nfalcon_security_log_maxbackupindex = default('/configurations/falcon-log4j/falcon_security_log_maxbackupindex',20)\n\nfalcon_log4j=config['configurations']['falcon-log4j']['content']\n\nfalcon_apps_dir = config['configurations']['falcon-env']['falcon_apps_hdfs_dir']\n#for create_hdfs_directory\nsecurity_enabled = config['configurations']['cluster-env']['security_enabled']\nhostname = config[\"hostname\"]\nhdfs_user_keytab = config['configurations']['hadoop-env']['hdfs_user_keytab']\nhdfs_user = config['configurations']['hadoop-env']['hdfs_user']\nhdfs_principal_name = config['configurations']['hadoop-env']['hdfs_principal_name']\nsmokeuser_principal =  config['configurations']['cluster-env']['smokeuser_principal_name']\nkinit_path_local = get_kinit_path(default('/configurations/kerberos-env/executable_search_paths', None))\n\nsupports_hive_dr = config['configurations']['falcon-env']['supports_hive_dr']\n# HDP 2.4 still supported the /usr/$STACK/$VERSION/falcon/data-mirroring folder, which had to be copied to HDFS\n# In HDP 2.5, an empty data-mirroring folder has to be created, and the extensions folder has to be uploaded to HDFS.\nsupports_data_mirroring = supports_hive_dr and (stack_version_formatted and not check_stack_feature(StackFeature.FALCON_EXTENSIONS, stack_version_formatted))\n\nlocal_data_mirroring_dir = format('{stack_root}/current/falcon-server/data-mirroring')\ndfs_data_mirroring_dir = \"/apps/data-mirroring\"\n\n\n########################################################\n############# Atlas related params #####################\n########################################################\n#region Atlas Hooks\nfalcon_atlas_application_properties = default('/configurations/falcon-atlas-application.properties', {})\natlas_hook_filename = default('/configurations/atlas-env/metadata_conf_file', 'atlas-application.properties')\nenable_atlas_hook = default('/configurations/falcon-env/falcon.atlas.hook', False)\n\n# Calculate atlas_hook_cp to add to FALCON_EXTRA_CLASS_PATH\nfalcon_atlas_support = False\n\n# Path to add to environment variable\natlas_hook_cp = \"\"\nif enable_atlas_hook:\n\n  # stack_version doesn't contain a minor number of the stack (only first two numbers: 2.3). Get it from current_version_formatted\n  falcon_atlas_support = current_version_formatted and check_stack_feature(StackFeature.FALCON_ATLAS_SUPPORT_2_3, current_version_formatted) \\\n      or check_stack_feature(StackFeature.FALCON_ATLAS_SUPPORT, stack_version_formatted)\n\n  if check_stack_feature(StackFeature.ATLAS_CONF_DIR_IN_PATH, stack_version_formatted):\n    atlas_conf_dir = format('{stack_root}/current/atlas-server/conf')\n    atlas_home_dir = format('{stack_root}/current/atlas-server')\n    atlas_hook_cp = atlas_conf_dir + os.pathsep + os.path.join(atlas_home_dir, \"hook\", \"falcon\", \"*\") + os.pathsep\n  elif check_stack_feature(StackFeature.ATLAS_UPGRADE_SUPPORT, stack_version_formatted):\n    atlas_hook_cp = format('{stack_root}/current/atlas-client/hook/falcon/*') + os.pathsep\n\natlas_application_class_addition = \"\"\nif falcon_atlas_support:\n  # Some stack versions do not support Atlas Falcon hook. See stack_features.json\n  # Packaging was different in older versions.\n  if current_version_formatted and check_stack_feature(StackFeature.FALCON_ATLAS_SUPPORT_2_3, current_version_formatted):\n    atlas_application_class_addition = \",\\\\\\norg.apache.falcon.atlas.service.AtlasService\"\n    atlas_plugin_package = \"atlas-metadata*-falcon-plugin\"\n    atlas_ubuntu_plugin_package = \"atlas-metadata.*-falcon-plugin\"\n  else:\n    atlas_application_class_addition = \",\\\\\\norg.apache.atlas.falcon.service.AtlasService\"\n    atlas_plugin_package = \"atlas-metadata*-hive-plugin\"\n    atlas_ubuntu_plugin_package = \"atlas-metadata.*-hive-plugin\"\n\n#endregion\n\nhdfs_site = config['configurations']['hdfs-site']\ndefault_fs = config['configurations']['core-site']['fs.defaultFS']\n\ndfs_type = default(\"/commandParams/dfs_type\", \"\")\n\nbdb_jar_name = \"je-5.0.73.jar\"\nbdb_resource_name = format(\"{jdk_location}/{bdb_jar_name}\")\ntarget_jar_file = os.path.join(falcon_webinf_lib, bdb_jar_name)\n\n\nimport functools\n#create partial functions with common arguments for every HdfsResource call\n#to create/delete hdfs directory/file/copyfromlocal we need to call params.HdfsResource in code\nHdfsResource = functools.partial(\n  HdfsResource,\n  user=hdfs_user,\n  hdfs_resource_ignore_file = \"/var/lib/ambari-agent/data/.hdfs_resource_ignore\",\n  security_enabled = security_enabled,\n  keytab = hdfs_user_keytab,\n  kinit_path_local = kinit_path_local,\n  hadoop_bin_dir = hadoop_bin_dir,\n  hadoop_conf_dir = hadoop_conf_dir,\n  principal_name = hdfs_principal_name,\n  hdfs_site = hdfs_site,\n  default_fs = default_fs,\n  immutable_paths = get_not_managed_resources(),\n  dfs_type = dfs_type\n )\n\n" }
{ "repo_name": "allenp/odoo", "ref": "refs/heads/9.0", "path": "addons/account_asset/account_asset_invoice.py", "content": "# -*- coding: utf-8 -*-\n\nfrom datetime import datetime\nfrom dateutil.relativedelta import relativedelta\nfrom openerp import api, fields, models\nimport openerp.addons.decimal_precision as dp\nfrom openerp.tools import DEFAULT_SERVER_DATE_FORMAT as DF\n\n\nclass AccountInvoice(models.Model):\n    _inherit = 'account.invoice'\n\n    @api.multi\n    def action_move_create(self):\n        result = super(AccountInvoice, self).action_move_create()\n        for inv in self:\n            inv.invoice_line_ids.asset_create()\n        return result\n\n\nclass AccountInvoiceLine(models.Model):\n    _inherit = 'account.invoice.line'\n\n    asset_category_id = fields.Many2one('account.asset.category', string='Asset Category')\n    asset_start_date = fields.Date(string='Asset End Date', compute='_get_asset_date', readonly=True, store=True)\n    asset_end_date = fields.Date(string='Asset Start Date', compute='_get_asset_date', readonly=True, store=True)\n    asset_mrr = fields.Float(string='Monthly Recurring Revenue', compute='_get_asset_date', readonly=True, digits=dp.get_precision('Account'), store=True)\n\n    @api.one\n    @api.depends('asset_category_id', 'invoice_id.date_invoice')\n    def _get_asset_date(self):\n        self.asset_mrr = 0\n        self.asset_start_date = False\n        self.asset_end_date = False\n        cat = self.asset_category_id\n        if cat:\n            months = cat.method_number * cat.method_period\n            if self.invoice_id.type in ['out_invoice', 'out_refund']:\n                self.asset_mrr = self.price_subtotal_signed / months\n            if self.invoice_id.date_invoice:\n                start_date = datetime.strptime(self.invoice_id.date_invoice, DF).replace(day=1)\n                end_date = (start_date + relativedelta(months=months, days=-1))\n                self.asset_start_date = start_date.strftime(DF)\n                self.asset_end_date = end_date.strftime(DF)\n\n    @api.one\n    def asset_create(self):\n        if self.asset_category_id and self.asset_category_id.method_number > 1:\n            vals = {\n                'name': self.name,\n                'code': self.invoice_id.number or False,\n                'category_id': self.asset_category_id.id,\n                'value': self.price_subtotal,\n                'partner_id': self.invoice_id.partner_id.id,\n                'company_id': self.invoice_id.company_id.id,\n                'currency_id': self.invoice_id.currency_id.id,\n                'date': self.asset_start_date or self.invoice_id.date_invoice,\n                'invoice_id': self.invoice_id.id,\n          }\n            changed_vals = self.env['account.asset.asset'].onchange_category_id_values(vals['category_id'])\n            vals.update(changed_vals['value'])\n            asset = self.env['account.asset.asset'].create(vals)\n            if self.asset_category_id.open_asset:\n                asset.validate()\n        return True\n\n    @api.onchange('product_id')\n    def onchange_product_id(self):\n        if self.product_id:\n            if self.invoice_id.type == 'out_invoice':\n                self.asset_category_id = self.product_id.product_tmpl_id.deferred_revenue_category_id\n            elif self.invoice_id.type == 'in_invoice':\n                self.asset_category_id = self.product_id.product_tmpl_id.asset_category_id\n\n\nclass ProductTemplate(models.Model):\n    _inherit = 'product.template'\n    asset_category_id = fields.Many2one('account.asset.category', string='Asset Type', ondelete=\"restrict\")\n    deferred_revenue_category_id = fields.Many2one('account.asset.category', string='Deferred Revenue Type', ondelete=\"restrict\")\n" }
{ "repo_name": "guorendong/iridium-browser-ubuntu", "ref": "refs/heads/ubuntu/precise", "path": "third_party/icu/source/test/depstest/depstest.py", "content": "#! /usr/bin/python\n# -*- coding: utf-8 -*-\n#\n# Copyright (C) 2011-2014, International Business Machines\n# Corporation and others. All Rights Reserved.\n#\n# file name: depstest.py\n#\n# created on: 2011may24\n\n\"\"\"ICU dependency tester.\n\nThis probably works only on Linux.\n\nThe exit code is 0 if everything is fine, 1 for errors, 2 for only warnings.\n\nSample invocation:\n  ~/svn.icu/trunk/src/source/test/depstest$ ./depstest.py ~/svn.icu/trunk/dbg\n\"\"\"\n\n__author__ = \"Markus W. Scherer\"\n\nimport glob\nimport os.path\nimport subprocess\nimport sys\n\nimport dependencies\n\n_ignored_symbols = set()\n_obj_files = {}\n_symbols_to_files = {}\n_return_value = 0\n\n# Classes with vtables (and thus virtual methods).\n_virtual_classes = set()\n# Classes with weakly defined destructors.\n# nm shows a symbol class of \"W\" rather than \"T\".\n_weak_destructors = set()\n\ndef _ReadObjFile(root_path, library_name, obj_name):\n  global _ignored_symbols, _obj_files, _symbols_to_files\n  global _virtual_classes, _weak_destructors\n  lib_obj_name = library_name + \"/\" + obj_name\n  if lib_obj_name in _obj_files:\n    print \"Warning: duplicate .o file \" + lib_obj_name\n    _return_value = 2\n    return\n\n  path = os.path.join(root_path, library_name, obj_name)\n  nm_result = subprocess.Popen([\"nm\", \"--demangle\", \"--format=sysv\",\n                                \"--extern-only\", \"--no-sort\", path],\n                               stdout=subprocess.PIPE).communicate()[0]\n  obj_imports = set()\n  obj_exports = set()\n  for line in nm_result.splitlines():\n    fields = line.split(\"|\")\n    if len(fields) == 1: continue\n    name = fields[0].strip()\n    # Ignore symbols like '__cxa_pure_virtual',\n    # 'vtable for __cxxabiv1::__si_class_type_info' or\n    # 'DW.ref.__gxx_personality_v0'.\n    if name.startswith(\"__cxa\") or \"__cxxabi\" in name or \"__gxx\" in name:\n      _ignored_symbols.add(name)\n      continue\n    type = fields[2].strip()\n    if type == \"U\":\n      obj_imports.add(name)\n    else:\n      obj_exports.add(name)\n      _symbols_to_files[name] = lib_obj_name\n      # Is this a vtable? E.g., \"vtable for icu_49::ByteSink\".\n      if name.startswith(\"vtable for icu\"):\n        _virtual_classes.add(name[name.index(\"::\") + 2:])\n      # Is this a destructor? E.g., \"icu_49::ByteSink::~ByteSink()\".\n      index = name.find(\"::~\")\n      if index >= 0 and type == \"W\":\n        _weak_destructors.add(name[index + 3:name.index(\"(\", index)])\n  _obj_files[lib_obj_name] = {\"imports\": obj_imports, \"exports\": obj_exports}\n\ndef _ReadLibrary(root_path, library_name):\n  obj_paths = glob.glob(os.path.join(root_path, library_name, \"*.o\"))\n  for path in obj_paths:\n    _ReadObjFile(root_path, library_name, os.path.basename(path))\n\ndef _Resolve(name, parents):\n  global _ignored_symbols, _obj_files, _symbols_to_files, _return_value\n  item = dependencies.items[name]\n  item_type = item[\"type\"]\n  if name in parents:\n    sys.exit(\"Error: %s %s has a circular dependency on itself: %s\" %\n             (item_type, name, parents))\n  # Check if already cached.\n  exports = item.get(\"exports\")\n  if exports != None: return item\n  # Calculcate recursively.\n  parents.append(name)\n  imports = set()\n  exports = set()\n  system_symbols = item.get(\"system_symbols\")\n  if system_symbols == None: system_symbols = item[\"system_symbols\"] = set()\n  files = item.get(\"files\")\n  if files:\n    for file_name in files:\n      obj_file = _obj_files[file_name]\n      imports |= obj_file[\"imports\"]\n      exports |= obj_file[\"exports\"]\n  imports -= exports | _ignored_symbols\n  deps = item.get(\"deps\")\n  if deps:\n    for dep in deps:\n      dep_item = _Resolve(dep, parents)\n      # Detect whether this item needs to depend on dep,\n      # except when this item has no files, that is, when it is just\n      # a deliberate umbrella group or library.\n      dep_exports = dep_item[\"exports\"]\n      dep_system_symbols = dep_item[\"system_symbols\"]\n      if files and imports.isdisjoint(dep_exports) and imports.isdisjoint(dep_system_symbols):\n        print \"Info:  %s %s  does not need to depend on  %s\\n\" % (item_type, name, dep)\n      # We always include the dependency's exports, even if we do not need them\n      # to satisfy local imports.\n      exports |= dep_exports\n      system_symbols |= dep_system_symbols\n  item[\"exports\"] = exports\n  item[\"system_symbols\"] = system_symbols\n  imports -= exports | system_symbols\n  for symbol in imports:\n    for file_name in files:\n      if symbol in _obj_files[file_name][\"imports\"]:\n        neededFile = _symbols_to_files.get(symbol)\n        if neededFile in dependencies.file_to_item:\n          neededItem = \"but %s does not depend on %s (for %s)\" % (name, dependencies.file_to_item[neededFile], neededFile)\n        else:\n          neededItem = \"- is this a new system symbol?\"\n        sys.stderr.write(\"Error: in %s %s: %s imports %s %s\\n\" %\n                         (item_type, name, file_name, symbol, neededItem))\n    _return_value = 1\n  del parents[-1]\n  return item\n\ndef Process(root_path):\n  \"\"\"Loads dependencies.txt, reads the libraries' .o files, and processes them.\n\n  Modifies dependencies.items: Recursively builds each item's system_symbols and exports.\n  \"\"\"\n  global _ignored_symbols, _obj_files, _return_value\n  global _virtual_classes, _weak_destructors\n  dependencies.Load()\n  for name_and_item in dependencies.items.iteritems():\n    name = name_and_item[0]\n    item = name_and_item[1]\n    system_symbols = item.get(\"system_symbols\")\n    if system_symbols:\n      for symbol in system_symbols:\n        _symbols_to_files[symbol] = name\n  for library_name in dependencies.libraries:\n    _ReadLibrary(root_path, library_name)\n  o_files_set = set(_obj_files.keys())\n  files_missing_from_deps = o_files_set - dependencies.files\n  files_missing_from_build = dependencies.files - o_files_set\n  if files_missing_from_deps:\n    sys.stderr.write(\"Error: files missing from dependencies.txt:\\n%s\\n\" %\n                     sorted(files_missing_from_deps))\n    _return_value = 1\n  if files_missing_from_build:\n    sys.stderr.write(\"Error: files in dependencies.txt but not built:\\n%s\\n\" %\n                     sorted(files_missing_from_build))\n    _return_value = 1\n  if not _return_value:\n    for library_name in dependencies.libraries:\n      _Resolve(library_name, [])\n  if not _return_value:\n    virtual_classes_with_weak_destructors = _virtual_classes & _weak_destructors\n    if virtual_classes_with_weak_destructors:\n      sys.stderr.write(\"Error: Some classes have virtual methods, and \"\n                       \"an implicit or inline destructor \"\n                       \"(see ICU ticket #8454 for details):\\n%s\\n\" %\n                       sorted(virtual_classes_with_weak_destructors))\n      _return_value = 1\n\ndef main():\n  global _return_value\n  if len(sys.argv) <= 1:\n    sys.exit((\"Command line error: \" +\n             \"need one argument with the root path to the built ICU libraries/*.o files.\"))\n  Process(sys.argv[1])\n  if _ignored_symbols:\n    print \"Info: ignored symbols:\\n%s\" % sorted(_ignored_symbols)\n  if not _return_value:\n    print \"OK: Specified and actual dependencies match.\"\n  else:\n    print \"Error: There were errors, please fix them and re-run. Processing may have terminated abnormally.\"\n  return _return_value\n\nif __name__ == \"__main__\":\n  sys.exit(main())\n" }
{ "repo_name": "cselis86/edx-platform", "ref": "refs/heads/installer", "path": "common/djangoapps/util/tests/test_disable_rate_limit.py", "content": "\"\"\"Tests for disabling rate limiting. \"\"\"\nimport unittest\nfrom django.test import TestCase\nfrom django.core.cache import cache\nfrom django.conf import settings\nimport mock\n\nfrom rest_framework.views import APIView\nfrom rest_framework.throttling import BaseThrottle\nfrom rest_framework.exceptions import Throttled\n\nfrom util.disable_rate_limit import can_disable_rate_limit\nfrom util.models import RateLimitConfiguration\n\n\nclass FakeThrottle(BaseThrottle):\n    def allow_request(self, request, view):\n        return False\n\n\n@can_disable_rate_limit\nclass FakeApiView(APIView):\n    authentication_classes = []\n    permission_classes = []\n    throttle_classes = [FakeThrottle]\n\n\n@unittest.skipUnless(settings.ROOT_URLCONF == 'lms.urls', 'Test only valid in lms')\nclass DisableRateLimitTest(TestCase):\n    \"\"\"Check that we can disable rate limiting for perf testing. \"\"\"\n\n    def setUp(self):\n        cache.clear()\n        self.view = FakeApiView()\n\n    def test_enable_rate_limit(self):\n        # Enable rate limiting using model-based config\n        RateLimitConfiguration.objects.create(enabled=True)\n\n        # By default, should enforce rate limiting\n        # Since our fake throttle always rejects requests,\n        # we should expect the request to be rejected.\n        request = mock.Mock()\n        with self.assertRaises(Throttled):\n            self.view.check_throttles(request)\n\n    def test_disable_rate_limit(self):\n        # Disable rate limiting using model-based config\n        RateLimitConfiguration.objects.create(enabled=False)\n\n        # With rate-limiting disabled, the request\n        # should get through.  The `check_throttles()` call\n        # should return without raising an exception.\n        request = mock.Mock()\n        self.view.check_throttles(request)\n" }
{ "repo_name": "ThinkOpen-Solutions/odoo", "ref": "refs/heads/stable", "path": "addons/product/__openerp__.py", "content": "# -*- coding: utf-8 -*-\n##############################################################################\n#\n#    OpenERP, Open Source Management Solution\n#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU Affero General Public License as\n#    published by the Free Software Foundation, either version 3 of the\n#    License, or (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU Affero General Public License for more details.\n#\n#    You should have received a copy of the GNU Affero General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\n\n\n{\n    'name': 'Products & Pricelists',\n    'version': '1.1',\n    'author': 'OpenERP SA',\n    'category': 'Sales Management',\n    'depends': ['base', 'decimal_precision', 'mail', 'report'],\n    'demo': [\n        'product_demo.xml',\n        'product_image_demo.xml',\n    ],\n    'website': 'https://www.odoo.com',\n    'description': \"\"\"\nThis is the base module for managing products and pricelists in OpenERP.\n========================================================================\n\nProducts support variants, different pricing methods, suppliers information,\nmake to stock/order, different unit of measures, packaging and properties.\n\nPricelists support:\n-------------------\n    * Multiple-level of discount (by product, category, quantities)\n    * Compute price based on different criteria:\n        * Other pricelist\n        * Cost price\n        * List price\n        * Supplier price\n\nPricelists preferences by product and/or partners.\n\nPrint product labels with barcode.\n    \"\"\",\n    'data': [\n        'security/product_security.xml',\n        'security/ir.model.access.csv',\n        'wizard/product_price_view.xml',\n        'product_data.xml',\n        'product_report.xml',\n        'product_view.xml',\n        'pricelist_view.xml',\n        'partner_view.xml',\n        'views/report_pricelist.xml',\n    ],\n    'test': [\n        'product_pricelist_demo.yml',\n        'test/product_pricelist.yml',\n    ],\n    'installable': True,\n    'auto_install': False,\n    'images': ['images/product_uom.jpeg','images/product_pricelists.jpeg','images/products_categories.jpeg', 'images/products_form.jpeg'],\n}\n\n# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:\n" }
{ "repo_name": "motion2015/a3", "ref": "refs/heads/a3", "path": "common/djangoapps/util/tests/test_disable_rate_limit.py", "content": "\"\"\"Tests for disabling rate limiting. \"\"\"\nimport unittest\nfrom django.test import TestCase\nfrom django.core.cache import cache\nfrom django.conf import settings\nimport mock\n\nfrom rest_framework.views import APIView\nfrom rest_framework.throttling import BaseThrottle\nfrom rest_framework.exceptions import Throttled\n\nfrom util.disable_rate_limit import can_disable_rate_limit\nfrom util.models import RateLimitConfiguration\n\n\nclass FakeThrottle(BaseThrottle):\n    def allow_request(self, request, view):\n        return False\n\n\n@can_disable_rate_limit\nclass FakeApiView(APIView):\n    authentication_classes = []\n    permission_classes = []\n    throttle_classes = [FakeThrottle]\n\n\n@unittest.skipUnless(settings.ROOT_URLCONF == 'lms.urls', 'Test only valid in lms')\nclass DisableRateLimitTest(TestCase):\n    \"\"\"Check that we can disable rate limiting for perf testing. \"\"\"\n\n    def setUp(self):\n        cache.clear()\n        self.view = FakeApiView()\n\n    def test_enable_rate_limit(self):\n        # Enable rate limiting using model-based config\n        RateLimitConfiguration.objects.create(enabled=True)\n\n        # By default, should enforce rate limiting\n        # Since our fake throttle always rejects requests,\n        # we should expect the request to be rejected.\n        request = mock.Mock()\n        with self.assertRaises(Throttled):\n            self.view.check_throttles(request)\n\n    def test_disable_rate_limit(self):\n        # Disable rate limiting using model-based config\n        RateLimitConfiguration.objects.create(enabled=False)\n\n        # With rate-limiting disabled, the request\n        # should get through.  The `check_throttles()` call\n        # should return without raising an exception.\n        request = mock.Mock()\n        self.view.check_throttles(request)\n" }
{ "repo_name": "Simran-B/arangodb", "ref": "refs/heads/docs_3.0", "path": "3rdParty/V8-4.3.61/third_party/icu/source/test/depstest/depstest.py", "content": "#! /usr/bin/python\n# -*- coding: utf-8 -*-\n#\n# Copyright (C) 2011-2014, International Business Machines\n# Corporation and others. All Rights Reserved.\n#\n# file name: depstest.py\n#\n# created on: 2011may24\n\n\"\"\"ICU dependency tester.\n\nThis probably works only on Linux.\n\nThe exit code is 0 if everything is fine, 1 for errors, 2 for only warnings.\n\nSample invocation:\n  ~/svn.icu/trunk/src/source/test/depstest$ ./depstest.py ~/svn.icu/trunk/dbg\n\"\"\"\n\n__author__ = \"Markus W. Scherer\"\n\nimport glob\nimport os.path\nimport subprocess\nimport sys\n\nimport dependencies\n\n_ignored_symbols = set()\n_obj_files = {}\n_symbols_to_files = {}\n_return_value = 0\n\n# Classes with vtables (and thus virtual methods).\n_virtual_classes = set()\n# Classes with weakly defined destructors.\n# nm shows a symbol class of \"W\" rather than \"T\".\n_weak_destructors = set()\n\ndef _ReadObjFile(root_path, library_name, obj_name):\n  global _ignored_symbols, _obj_files, _symbols_to_files\n  global _virtual_classes, _weak_destructors\n  lib_obj_name = library_name + \"/\" + obj_name\n  if lib_obj_name in _obj_files:\n    print \"Warning: duplicate .o file \" + lib_obj_name\n    _return_value = 2\n    return\n\n  path = os.path.join(root_path, library_name, obj_name)\n  nm_result = subprocess.Popen([\"nm\", \"--demangle\", \"--format=sysv\",\n                                \"--extern-only\", \"--no-sort\", path],\n                               stdout=subprocess.PIPE).communicate()[0]\n  obj_imports = set()\n  obj_exports = set()\n  for line in nm_result.splitlines():\n    fields = line.split(\"|\")\n    if len(fields) == 1: continue\n    name = fields[0].strip()\n    # Ignore symbols like '__cxa_pure_virtual',\n    # 'vtable for __cxxabiv1::__si_class_type_info' or\n    # 'DW.ref.__gxx_personality_v0'.\n    if name.startswith(\"__cxa\") or \"__cxxabi\" in name or \"__gxx\" in name:\n      _ignored_symbols.add(name)\n      continue\n    type = fields[2].strip()\n    if type == \"U\":\n      obj_imports.add(name)\n    else:\n      obj_exports.add(name)\n      _symbols_to_files[name] = lib_obj_name\n      # Is this a vtable? E.g., \"vtable for icu_49::ByteSink\".\n      if name.startswith(\"vtable for icu\"):\n        _virtual_classes.add(name[name.index(\"::\") + 2:])\n      # Is this a destructor? E.g., \"icu_49::ByteSink::~ByteSink()\".\n      index = name.find(\"::~\")\n      if index >= 0 and type == \"W\":\n        _weak_destructors.add(name[index + 3:name.index(\"(\", index)])\n  _obj_files[lib_obj_name] = {\"imports\": obj_imports, \"exports\": obj_exports}\n\ndef _ReadLibrary(root_path, library_name):\n  obj_paths = glob.glob(os.path.join(root_path, library_name, \"*.o\"))\n  for path in obj_paths:\n    _ReadObjFile(root_path, library_name, os.path.basename(path))\n\ndef _Resolve(name, parents):\n  global _ignored_symbols, _obj_files, _symbols_to_files, _return_value\n  item = dependencies.items[name]\n  item_type = item[\"type\"]\n  if name in parents:\n    sys.exit(\"Error: %s %s has a circular dependency on itself: %s\" %\n             (item_type, name, parents))\n  # Check if already cached.\n  exports = item.get(\"exports\")\n  if exports != None: return item\n  # Calculcate recursively.\n  parents.append(name)\n  imports = set()\n  exports = set()\n  system_symbols = item.get(\"system_symbols\")\n  if system_symbols == None: system_symbols = item[\"system_symbols\"] = set()\n  files = item.get(\"files\")\n  if files:\n    for file_name in files:\n      obj_file = _obj_files[file_name]\n      imports |= obj_file[\"imports\"]\n      exports |= obj_file[\"exports\"]\n  imports -= exports | _ignored_symbols\n  deps = item.get(\"deps\")\n  if deps:\n    for dep in deps:\n      dep_item = _Resolve(dep, parents)\n      # Detect whether this item needs to depend on dep,\n      # except when this item has no files, that is, when it is just\n      # a deliberate umbrella group or library.\n      dep_exports = dep_item[\"exports\"]\n      dep_system_symbols = dep_item[\"system_symbols\"]\n      if files and imports.isdisjoint(dep_exports) and imports.isdisjoint(dep_system_symbols):\n        print \"Info:  %s %s  does not need to depend on  %s\\n\" % (item_type, name, dep)\n      # We always include the dependency's exports, even if we do not need them\n      # to satisfy local imports.\n      exports |= dep_exports\n      system_symbols |= dep_system_symbols\n  item[\"exports\"] = exports\n  item[\"system_symbols\"] = system_symbols\n  imports -= exports | system_symbols\n  for symbol in imports:\n    for file_name in files:\n      if symbol in _obj_files[file_name][\"imports\"]:\n        neededFile = _symbols_to_files.get(symbol)\n        if neededFile in dependencies.file_to_item:\n          neededItem = \"but %s does not depend on %s (for %s)\" % (name, dependencies.file_to_item[neededFile], neededFile)\n        else:\n          neededItem = \"- is this a new system symbol?\"\n        sys.stderr.write(\"Error: in %s %s: %s imports %s %s\\n\" %\n                         (item_type, name, file_name, symbol, neededItem))\n    _return_value = 1\n  del parents[-1]\n  return item\n\ndef Process(root_path):\n  \"\"\"Loads dependencies.txt, reads the libraries' .o files, and processes them.\n\n  Modifies dependencies.items: Recursively builds each item's system_symbols and exports.\n  \"\"\"\n  global _ignored_symbols, _obj_files, _return_value\n  global _virtual_classes, _weak_destructors\n  dependencies.Load()\n  for name_and_item in dependencies.items.iteritems():\n    name = name_and_item[0]\n    item = name_and_item[1]\n    system_symbols = item.get(\"system_symbols\")\n    if system_symbols:\n      for symbol in system_symbols:\n        _symbols_to_files[symbol] = name\n  for library_name in dependencies.libraries:\n    _ReadLibrary(root_path, library_name)\n  o_files_set = set(_obj_files.keys())\n  files_missing_from_deps = o_files_set - dependencies.files\n  files_missing_from_build = dependencies.files - o_files_set\n  if files_missing_from_deps:\n    sys.stderr.write(\"Error: files missing from dependencies.txt:\\n%s\\n\" %\n                     sorted(files_missing_from_deps))\n    _return_value = 1\n  if files_missing_from_build:\n    sys.stderr.write(\"Error: files in dependencies.txt but not built:\\n%s\\n\" %\n                     sorted(files_missing_from_build))\n    _return_value = 1\n  if not _return_value:\n    for library_name in dependencies.libraries:\n      _Resolve(library_name, [])\n  if not _return_value:\n    virtual_classes_with_weak_destructors = _virtual_classes & _weak_destructors\n    if virtual_classes_with_weak_destructors:\n      sys.stderr.write(\"Error: Some classes have virtual methods, and \"\n                       \"an implicit or inline destructor \"\n                       \"(see ICU ticket #8454 for details):\\n%s\\n\" %\n                       sorted(virtual_classes_with_weak_destructors))\n      _return_value = 1\n\ndef main():\n  global _return_value\n  if len(sys.argv) <= 1:\n    sys.exit((\"Command line error: \" +\n             \"need one argument with the root path to the built ICU libraries/*.o files.\"))\n  Process(sys.argv[1])\n  if _ignored_symbols:\n    print \"Info: ignored symbols:\\n%s\" % sorted(_ignored_symbols)\n  if not _return_value:\n    print \"OK: Specified and actual dependencies match.\"\n  else:\n    print \"Error: There were errors, please fix them and re-run. Processing may have terminated abnormally.\"\n  return _return_value\n\nif __name__ == \"__main__\":\n  sys.exit(main())\n" }
{ "repo_name": "oracc/nammu", "ref": "refs/heads/development", "path": "python/nammu/controller/MenuController.py", "content": "'''\nCopyright 2015 - 2018 University College London.\n\nThis file is part of Nammu.\n\nNammu is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nNammu is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with Nammu.  If not, see <http://www.gnu.org/licenses/>.\n'''\n\nfrom ..view.MenuView import MenuView\n\n\nclass MenuController(object):\n    '''\n    Creates the menu view and handles menu actions.\n    '''\n    def __init__(self, mainController):\n\n        # Needs delegating to parent presenter\n        # Note: self.controller needs to be defined before creating the\n        # ToolbarView, since the ToolbaView will delegate some actions to it.\n        self.mainController = mainController\n\n        # Create view with a reference to its controller to handle events\n        self.view = MenuView(self)\n\n    def enable_split_options(self, horizontal=True,\n                             vertical=True, arabic=True):\n        \"\"\"\n        Show split menu items as enabled or disabled.\n        \"\"\"\n        self.view.enable_item(\"Window\", \"Toggle Vertical Split Editor\",\n                              vertical)\n        self.view.enable_item(\"Window\", \"Toggle Horizontal Split Editor\",\n                              horizontal)\n        self.view.enable_item(\"Window\", \"Toggle Arabic Translation Editor\",\n                              arabic)\n\n    # Some actions need to be delegated to NammuController.\n    # E.g. actions in menu that'll need modification of text area controlled\n    # elsewhere and not accessible from this controller; as opposed to e.g.\n    # showHelp that can be dealt with from MenuController.\n\n    # Whenever a MenuController's method is invoked, __getattr__ will search\n    # for that given method name in this class. If it's not found, it'll\n    # delegate the action with same name to NammuController\n    def __getattr__(self, name):\n        return getattr(self.mainController, name)\n" }
{ "repo_name": "blooparksystems/odoo", "ref": "refs/heads/9.0", "path": "addons/account_asset/account_asset_invoice.py", "content": "# -*- coding: utf-8 -*-\n\nfrom datetime import datetime\nfrom dateutil.relativedelta import relativedelta\nfrom openerp import api, fields, models\nimport openerp.addons.decimal_precision as dp\nfrom openerp.tools import DEFAULT_SERVER_DATE_FORMAT as DF\n\n\nclass AccountInvoice(models.Model):\n    _inherit = 'account.invoice'\n\n    @api.multi\n    def action_move_create(self):\n        result = super(AccountInvoice, self).action_move_create()\n        for inv in self:\n            inv.invoice_line_ids.asset_create()\n        return result\n\n\nclass AccountInvoiceLine(models.Model):\n    _inherit = 'account.invoice.line'\n\n    asset_category_id = fields.Many2one('account.asset.category', string='Asset Category')\n    asset_start_date = fields.Date(string='Asset End Date', compute='_get_asset_date', readonly=True, store=True)\n    asset_end_date = fields.Date(string='Asset Start Date', compute='_get_asset_date', readonly=True, store=True)\n    asset_mrr = fields.Float(string='Monthly Recurring Revenue', compute='_get_asset_date', readonly=True, digits=dp.get_precision('Account'), store=True)\n\n    @api.one\n    @api.depends('asset_category_id', 'invoice_id.date_invoice')\n    def _get_asset_date(self):\n        self.asset_mrr = 0\n        self.asset_start_date = False\n        self.asset_end_date = False\n        cat = self.asset_category_id\n        if cat:\n            months = cat.method_number * cat.method_period\n            if self.invoice_id.type in ['out_invoice', 'out_refund']:\n                self.asset_mrr = self.price_subtotal_signed / months\n            if self.invoice_id.date_invoice:\n                start_date = datetime.strptime(self.invoice_id.date_invoice, DF).replace(day=1)\n                end_date = (start_date + relativedelta(months=months, days=-1))\n                self.asset_start_date = start_date.strftime(DF)\n                self.asset_end_date = end_date.strftime(DF)\n\n    @api.one\n    def asset_create(self):\n        if self.asset_category_id and self.asset_category_id.method_number > 1:\n            vals = {\n                'name': self.name,\n                'code': self.invoice_id.number or False,\n                'category_id': self.asset_category_id.id,\n                'value': self.price_subtotal,\n                'partner_id': self.invoice_id.partner_id.id,\n                'company_id': self.invoice_id.company_id.id,\n                'currency_id': self.invoice_id.currency_id.id,\n                'date': self.asset_start_date or self.invoice_id.date_invoice,\n                'invoice_id': self.invoice_id.id,\n          }\n            changed_vals = self.env['account.asset.asset'].onchange_category_id_values(vals['category_id'])\n            vals.update(changed_vals['value'])\n            asset = self.env['account.asset.asset'].create(vals)\n            if self.asset_category_id.open_asset:\n                asset.validate()\n        return True\n\n    @api.onchange('product_id')\n    def onchange_product_id(self):\n        if self.product_id:\n            if self.invoice_id.type == 'out_invoice':\n                self.asset_category_id = self.product_id.product_tmpl_id.deferred_revenue_category_id\n            elif self.invoice_id.type == 'in_invoice':\n                self.asset_category_id = self.product_id.product_tmpl_id.asset_category_id\n\n\nclass ProductTemplate(models.Model):\n    _inherit = 'product.template'\n    asset_category_id = fields.Many2one('account.asset.category', string='Asset Type', ondelete=\"restrict\")\n    deferred_revenue_category_id = fields.Many2one('account.asset.category', string='Deferred Revenue Type', ondelete=\"restrict\")\n" }
{ "repo_name": "optima-ict/odoo", "ref": "refs/heads/9.0", "path": "addons/account_asset/account_asset_invoice.py", "content": "# -*- coding: utf-8 -*-\n\nfrom datetime import datetime\nfrom dateutil.relativedelta import relativedelta\nfrom openerp import api, fields, models\nimport openerp.addons.decimal_precision as dp\nfrom openerp.tools import DEFAULT_SERVER_DATE_FORMAT as DF\n\n\nclass AccountInvoice(models.Model):\n    _inherit = 'account.invoice'\n\n    @api.multi\n    def action_move_create(self):\n        result = super(AccountInvoice, self).action_move_create()\n        for inv in self:\n            inv.invoice_line_ids.asset_create()\n        return result\n\n\nclass AccountInvoiceLine(models.Model):\n    _inherit = 'account.invoice.line'\n\n    asset_category_id = fields.Many2one('account.asset.category', string='Asset Category')\n    asset_start_date = fields.Date(string='Asset End Date', compute='_get_asset_date', readonly=True, store=True)\n    asset_end_date = fields.Date(string='Asset Start Date', compute='_get_asset_date', readonly=True, store=True)\n    asset_mrr = fields.Float(string='Monthly Recurring Revenue', compute='_get_asset_date', readonly=True, digits=dp.get_precision('Account'), store=True)\n\n    @api.one\n    @api.depends('asset_category_id', 'invoice_id.date_invoice')\n    def _get_asset_date(self):\n        self.asset_mrr = 0\n        self.asset_start_date = False\n        self.asset_end_date = False\n        cat = self.asset_category_id\n        if cat:\n            months = cat.method_number * cat.method_period\n            if self.invoice_id.type in ['out_invoice', 'out_refund']:\n                self.asset_mrr = self.price_subtotal_signed / months\n            if self.invoice_id.date_invoice:\n                start_date = datetime.strptime(self.invoice_id.date_invoice, DF).replace(day=1)\n                end_date = (start_date + relativedelta(months=months, days=-1))\n                self.asset_start_date = start_date.strftime(DF)\n                self.asset_end_date = end_date.strftime(DF)\n\n    @api.one\n    def asset_create(self):\n        if self.asset_category_id and self.asset_category_id.method_number > 1:\n            vals = {\n                'name': self.name,\n                'code': self.invoice_id.number or False,\n                'category_id': self.asset_category_id.id,\n                'value': self.price_subtotal,\n                'partner_id': self.invoice_id.partner_id.id,\n                'company_id': self.invoice_id.company_id.id,\n                'currency_id': self.invoice_id.currency_id.id,\n                'date': self.asset_start_date or self.invoice_id.date_invoice,\n                'invoice_id': self.invoice_id.id,\n          }\n            changed_vals = self.env['account.asset.asset'].onchange_category_id_values(vals['category_id'])\n            vals.update(changed_vals['value'])\n            asset = self.env['account.asset.asset'].create(vals)\n            if self.asset_category_id.open_asset:\n                asset.validate()\n        return True\n\n    @api.onchange('product_id')\n    def onchange_product_id(self):\n        if self.product_id:\n            if self.invoice_id.type == 'out_invoice':\n                self.asset_category_id = self.product_id.product_tmpl_id.deferred_revenue_category_id\n            elif self.invoice_id.type == 'in_invoice':\n                self.asset_category_id = self.product_id.product_tmpl_id.asset_category_id\n\n\nclass ProductTemplate(models.Model):\n    _inherit = 'product.template'\n    asset_category_id = fields.Many2one('account.asset.category', string='Asset Type', ondelete=\"restrict\")\n    deferred_revenue_category_id = fields.Many2one('account.asset.category', string='Deferred Revenue Type', ondelete=\"restrict\")\n" }
{ "repo_name": "grupozeety/CDerpnext", "ref": "refs/heads/bk_master", "path": "erpnext/hr/doctype/job_opening/test_job_opening.py", "content": "# -*- coding: utf-8 -*-\n# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors\n# See license.txt\nfrom __future__ import unicode_literals\n\nimport frappe\nimport unittest\n\n# test_records = frappe.get_test_records('Job Opening')\n\nclass TestJobOpening(unittest.TestCase):\n\tpass\n" }
{ "repo_name": "project-lovelace/lovelace-website", "ref": "refs/heads/main", "path": "src/static/code_stubs/python/scientific_temperatures.py", "content": "def fahrenheit_to_celsius(F):\n    C = 0\n\n    # Your code goes here: calculate the temperature in Celsius,\n    # store in a variable (we called it C), and return it.\n\n    return C\n" }
{ "repo_name": "bealdav/OCB", "ref": "refs/heads/patch-1", "path": "addons/product/__openerp__.py", "content": "# -*- coding: utf-8 -*-\n##############################################################################\n#\n#    OpenERP, Open Source Management Solution\n#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU Affero General Public License as\n#    published by the Free Software Foundation, either version 3 of the\n#    License, or (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU Affero General Public License for more details.\n#\n#    You should have received a copy of the GNU Affero General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\n\n\n{\n    'name': 'Products & Pricelists',\n    'version': '1.1',\n    'author': 'OpenERP SA',\n    'category': 'Sales Management',\n    'depends': ['base', 'decimal_precision', 'mail', 'report'],\n    'demo': [\n        'product_demo.xml',\n        'product_image_demo.xml',\n    ],\n    'website': 'https://www.odoo.com',\n    'description': \"\"\"\nThis is the base module for managing products and pricelists in OpenERP.\n========================================================================\n\nProducts support variants, different pricing methods, suppliers information,\nmake to stock/order, different unit of measures, packaging and properties.\n\nPricelists support:\n-------------------\n    * Multiple-level of discount (by product, category, quantities)\n    * Compute price based on different criteria:\n        * Other pricelist\n        * Cost price\n        * List price\n        * Supplier price\n\nPricelists preferences by product and/or partners.\n\nPrint product labels with barcode.\n    \"\"\",\n    'data': [\n        'security/product_security.xml',\n        'security/ir.model.access.csv',\n        'wizard/product_price_view.xml',\n        'product_data.xml',\n        'product_report.xml',\n        'product_view.xml',\n        'pricelist_view.xml',\n        'partner_view.xml',\n        'views/report_pricelist.xml',\n    ],\n    'test': [\n        'product_pricelist_demo.yml',\n        'test/product_pricelist.yml',\n    ],\n    'installable': True,\n    'auto_install': False,\n    'images': ['images/product_uom.jpeg','images/product_pricelists.jpeg','images/products_categories.jpeg', 'images/products_form.jpeg'],\n}\n\n# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:\n" }
{ "repo_name": "baslr/ArangoDB", "ref": "refs/heads/3.1-silent", "path": "3rdParty/V8/V8-5.0.71.39/third_party/icu/source/test/depstest/depstest.py", "content": "#! /usr/bin/python\n# -*- coding: utf-8 -*-\n#\n# Copyright (C) 2011-2014, International Business Machines\n# Corporation and others. All Rights Reserved.\n#\n# file name: depstest.py\n#\n# created on: 2011may24\n\n\"\"\"ICU dependency tester.\n\nThis probably works only on Linux.\n\nThe exit code is 0 if everything is fine, 1 for errors, 2 for only warnings.\n\nSample invocation:\n  ~/svn.icu/trunk/src/source/test/depstest$ ./depstest.py ~/svn.icu/trunk/dbg\n\"\"\"\n\n__author__ = \"Markus W. Scherer\"\n\nimport glob\nimport os.path\nimport subprocess\nimport sys\n\nimport dependencies\n\n_ignored_symbols = set()\n_obj_files = {}\n_symbols_to_files = {}\n_return_value = 0\n\n# Classes with vtables (and thus virtual methods).\n_virtual_classes = set()\n# Classes with weakly defined destructors.\n# nm shows a symbol class of \"W\" rather than \"T\".\n_weak_destructors = set()\n\ndef _ReadObjFile(root_path, library_name, obj_name):\n  global _ignored_symbols, _obj_files, _symbols_to_files\n  global _virtual_classes, _weak_destructors\n  lib_obj_name = library_name + \"/\" + obj_name\n  if lib_obj_name in _obj_files:\n    print \"Warning: duplicate .o file \" + lib_obj_name\n    _return_value = 2\n    return\n\n  path = os.path.join(root_path, library_name, obj_name)\n  nm_result = subprocess.Popen([\"nm\", \"--demangle\", \"--format=sysv\",\n                                \"--extern-only\", \"--no-sort\", path],\n                               stdout=subprocess.PIPE).communicate()[0]\n  obj_imports = set()\n  obj_exports = set()\n  for line in nm_result.splitlines():\n    fields = line.split(\"|\")\n    if len(fields) == 1: continue\n    name = fields[0].strip()\n    # Ignore symbols like '__cxa_pure_virtual',\n    # 'vtable for __cxxabiv1::__si_class_type_info' or\n    # 'DW.ref.__gxx_personality_v0'.\n    if name.startswith(\"__cxa\") or \"__cxxabi\" in name or \"__gxx\" in name:\n      _ignored_symbols.add(name)\n      continue\n    type = fields[2].strip()\n    if type == \"U\":\n      obj_imports.add(name)\n    else:\n      obj_exports.add(name)\n      _symbols_to_files[name] = lib_obj_name\n      # Is this a vtable? E.g., \"vtable for icu_49::ByteSink\".\n      if name.startswith(\"vtable for icu\"):\n        _virtual_classes.add(name[name.index(\"::\") + 2:])\n      # Is this a destructor? E.g., \"icu_49::ByteSink::~ByteSink()\".\n      index = name.find(\"::~\")\n      if index >= 0 and type == \"W\":\n        _weak_destructors.add(name[index + 3:name.index(\"(\", index)])\n  _obj_files[lib_obj_name] = {\"imports\": obj_imports, \"exports\": obj_exports}\n\ndef _ReadLibrary(root_path, library_name):\n  obj_paths = glob.glob(os.path.join(root_path, library_name, \"*.o\"))\n  for path in obj_paths:\n    _ReadObjFile(root_path, library_name, os.path.basename(path))\n\ndef _Resolve(name, parents):\n  global _ignored_symbols, _obj_files, _symbols_to_files, _return_value\n  item = dependencies.items[name]\n  item_type = item[\"type\"]\n  if name in parents:\n    sys.exit(\"Error: %s %s has a circular dependency on itself: %s\" %\n             (item_type, name, parents))\n  # Check if already cached.\n  exports = item.get(\"exports\")\n  if exports != None: return item\n  # Calculcate recursively.\n  parents.append(name)\n  imports = set()\n  exports = set()\n  system_symbols = item.get(\"system_symbols\")\n  if system_symbols == None: system_symbols = item[\"system_symbols\"] = set()\n  files = item.get(\"files\")\n  if files:\n    for file_name in files:\n      obj_file = _obj_files[file_name]\n      imports |= obj_file[\"imports\"]\n      exports |= obj_file[\"exports\"]\n  imports -= exports | _ignored_symbols\n  deps = item.get(\"deps\")\n  if deps:\n    for dep in deps:\n      dep_item = _Resolve(dep, parents)\n      # Detect whether this item needs to depend on dep,\n      # except when this item has no files, that is, when it is just\n      # a deliberate umbrella group or library.\n      dep_exports = dep_item[\"exports\"]\n      dep_system_symbols = dep_item[\"system_symbols\"]\n      if files and imports.isdisjoint(dep_exports) and imports.isdisjoint(dep_system_symbols):\n        print \"Info:  %s %s  does not need to depend on  %s\\n\" % (item_type, name, dep)\n      # We always include the dependency's exports, even if we do not need them\n      # to satisfy local imports.\n      exports |= dep_exports\n      system_symbols |= dep_system_symbols\n  item[\"exports\"] = exports\n  item[\"system_symbols\"] = system_symbols\n  imports -= exports | system_symbols\n  for symbol in imports:\n    for file_name in files:\n      if symbol in _obj_files[file_name][\"imports\"]:\n        neededFile = _symbols_to_files.get(symbol)\n        if neededFile in dependencies.file_to_item:\n          neededItem = \"but %s does not depend on %s (for %s)\" % (name, dependencies.file_to_item[neededFile], neededFile)\n        else:\n          neededItem = \"- is this a new system symbol?\"\n        sys.stderr.write(\"Error: in %s %s: %s imports %s %s\\n\" %\n                         (item_type, name, file_name, symbol, neededItem))\n    _return_value = 1\n  del parents[-1]\n  return item\n\ndef Process(root_path):\n  \"\"\"Loads dependencies.txt, reads the libraries' .o files, and processes them.\n\n  Modifies dependencies.items: Recursively builds each item's system_symbols and exports.\n  \"\"\"\n  global _ignored_symbols, _obj_files, _return_value\n  global _virtual_classes, _weak_destructors\n  dependencies.Load()\n  for name_and_item in dependencies.items.iteritems():\n    name = name_and_item[0]\n    item = name_and_item[1]\n    system_symbols = item.get(\"system_symbols\")\n    if system_symbols:\n      for symbol in system_symbols:\n        _symbols_to_files[symbol] = name\n  for library_name in dependencies.libraries:\n    _ReadLibrary(root_path, library_name)\n  o_files_set = set(_obj_files.keys())\n  files_missing_from_deps = o_files_set - dependencies.files\n  files_missing_from_build = dependencies.files - o_files_set\n  if files_missing_from_deps:\n    sys.stderr.write(\"Error: files missing from dependencies.txt:\\n%s\\n\" %\n                     sorted(files_missing_from_deps))\n    _return_value = 1\n  if files_missing_from_build:\n    sys.stderr.write(\"Error: files in dependencies.txt but not built:\\n%s\\n\" %\n                     sorted(files_missing_from_build))\n    _return_value = 1\n  if not _return_value:\n    for library_name in dependencies.libraries:\n      _Resolve(library_name, [])\n  if not _return_value:\n    virtual_classes_with_weak_destructors = _virtual_classes & _weak_destructors\n    if virtual_classes_with_weak_destructors:\n      sys.stderr.write(\"Error: Some classes have virtual methods, and \"\n                       \"an implicit or inline destructor \"\n                       \"(see ICU ticket #8454 for details):\\n%s\\n\" %\n                       sorted(virtual_classes_with_weak_destructors))\n      _return_value = 1\n\ndef main():\n  global _return_value\n  if len(sys.argv) <= 1:\n    sys.exit((\"Command line error: \" +\n             \"need one argument with the root path to the built ICU libraries/*.o files.\"))\n  Process(sys.argv[1])\n  if _ignored_symbols:\n    print \"Info: ignored symbols:\\n%s\" % sorted(_ignored_symbols)\n  if not _return_value:\n    print \"OK: Specified and actual dependencies match.\"\n  else:\n    print \"Error: There were errors, please fix them and re-run. Processing may have terminated abnormally.\"\n  return _return_value\n\nif __name__ == \"__main__\":\n  sys.exit(main())\n" }
{ "repo_name": "bobisme/odoo", "ref": "refs/heads/sp-8.0", "path": "addons/product/__openerp__.py", "content": "# -*- coding: utf-8 -*-\n##############################################################################\n#\n#    OpenERP, Open Source Management Solution\n#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU Affero General Public License as\n#    published by the Free Software Foundation, either version 3 of the\n#    License, or (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU Affero General Public License for more details.\n#\n#    You should have received a copy of the GNU Affero General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\n\n\n{\n    'name': 'Products & Pricelists',\n    'version': '1.1',\n    'author': 'OpenERP SA',\n    'category': 'Sales Management',\n    'depends': ['base', 'decimal_precision', 'mail', 'report'],\n    'demo': [\n        'product_demo.xml',\n        'product_image_demo.xml',\n    ],\n    'website': 'https://www.odoo.com',\n    'description': \"\"\"\nThis is the base module for managing products and pricelists in OpenERP.\n========================================================================\n\nProducts support variants, different pricing methods, suppliers information,\nmake to stock/order, different unit of measures, packaging and properties.\n\nPricelists support:\n-------------------\n    * Multiple-level of discount (by product, category, quantities)\n    * Compute price based on different criteria:\n        * Other pricelist\n        * Cost price\n        * List price\n        * Supplier price\n\nPricelists preferences by product and/or partners.\n\nPrint product labels with barcode.\n    \"\"\",\n    'data': [\n        'security/product_security.xml',\n        'security/ir.model.access.csv',\n        'wizard/product_price_view.xml',\n        'product_data.xml',\n        'product_report.xml',\n        'product_view.xml',\n        'pricelist_view.xml',\n        'partner_view.xml',\n        'views/report_pricelist.xml',\n    ],\n    'test': [\n        'product_pricelist_demo.yml',\n        'test/product_pricelist.yml',\n    ],\n    'installable': True,\n    'auto_install': False,\n    'images': ['images/product_uom.jpeg','images/product_pricelists.jpeg','images/products_categories.jpeg', 'images/products_form.jpeg'],\n}\n\n# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:\n" }
{ "repo_name": "libracore/erpnext", "ref": "refs/heads/v12", "path": "erpnext/hr/doctype/job_opening/test_job_opening.py", "content": "# -*- coding: utf-8 -*-\n# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors\n# See license.txt\nfrom __future__ import unicode_literals\n\nimport frappe\nimport unittest\n\n# test_records = frappe.get_test_records('Job Opening')\n\nclass TestJobOpening(unittest.TestCase):\n\tpass\n" }
{ "repo_name": "alexdrenea/WinObjC", "ref": "refs/heads/tooling/toolsSln", "path": "deps/3rdparty/icu/icu/source/test/depstest/depstest.py", "content": "#! /usr/bin/python\n# -*- coding: utf-8 -*-\n#\n# Copyright (C) 2011-2014, International Business Machines\n# Corporation and others. All Rights Reserved.\n#\n# file name: depstest.py\n#\n# created on: 2011may24\n\n\"\"\"ICU dependency tester.\n\nThis probably works only on Linux.\n\nThe exit code is 0 if everything is fine, 1 for errors, 2 for only warnings.\n\nSample invocation:\n  ~/svn.icu/trunk/src/source/test/depstest$ ./depstest.py ~/svn.icu/trunk/dbg\n\"\"\"\n\n__author__ = \"Markus W. Scherer\"\n\nimport glob\nimport os.path\nimport subprocess\nimport sys\n\nimport dependencies\n\n_ignored_symbols = set()\n_obj_files = {}\n_symbols_to_files = {}\n_return_value = 0\n\n# Classes with vtables (and thus virtual methods).\n_virtual_classes = set()\n# Classes with weakly defined destructors.\n# nm shows a symbol class of \"W\" rather than \"T\".\n_weak_destructors = set()\n\ndef _ReadObjFile(root_path, library_name, obj_name):\n  global _ignored_symbols, _obj_files, _symbols_to_files\n  global _virtual_classes, _weak_destructors\n  lib_obj_name = library_name + \"/\" + obj_name\n  if lib_obj_name in _obj_files:\n    print \"Warning: duplicate .o file \" + lib_obj_name\n    _return_value = 2\n    return\n\n  path = os.path.join(root_path, library_name, obj_name)\n  nm_result = subprocess.Popen([\"nm\", \"--demangle\", \"--format=sysv\",\n                                \"--extern-only\", \"--no-sort\", path],\n                               stdout=subprocess.PIPE).communicate()[0]\n  obj_imports = set()\n  obj_exports = set()\n  for line in nm_result.splitlines():\n    fields = line.split(\"|\")\n    if len(fields) == 1: continue\n    name = fields[0].strip()\n    # Ignore symbols like '__cxa_pure_virtual',\n    # 'vtable for __cxxabiv1::__si_class_type_info' or\n    # 'DW.ref.__gxx_personality_v0'.\n    if name.startswith(\"__cxa\") or \"__cxxabi\" in name or \"__gxx\" in name:\n      _ignored_symbols.add(name)\n      continue\n    type = fields[2].strip()\n    if type == \"U\":\n      obj_imports.add(name)\n    else:\n      obj_exports.add(name)\n      _symbols_to_files[name] = lib_obj_name\n      # Is this a vtable? E.g., \"vtable for icu_49::ByteSink\".\n      if name.startswith(\"vtable for icu\"):\n        _virtual_classes.add(name[name.index(\"::\") + 2:])\n      # Is this a destructor? E.g., \"icu_49::ByteSink::~ByteSink()\".\n      index = name.find(\"::~\")\n      if index >= 0 and type == \"W\":\n        _weak_destructors.add(name[index + 3:name.index(\"(\", index)])\n  _obj_files[lib_obj_name] = {\"imports\": obj_imports, \"exports\": obj_exports}\n\ndef _ReadLibrary(root_path, library_name):\n  obj_paths = glob.glob(os.path.join(root_path, library_name, \"*.o\"))\n  for path in obj_paths:\n    _ReadObjFile(root_path, library_name, os.path.basename(path))\n\ndef _Resolve(name, parents):\n  global _ignored_symbols, _obj_files, _symbols_to_files, _return_value\n  item = dependencies.items[name]\n  item_type = item[\"type\"]\n  if name in parents:\n    sys.exit(\"Error: %s %s has a circular dependency on itself: %s\" %\n             (item_type, name, parents))\n  # Check if already cached.\n  exports = item.get(\"exports\")\n  if exports != None: return item\n  # Calculcate recursively.\n  parents.append(name)\n  imports = set()\n  exports = set()\n  system_symbols = item.get(\"system_symbols\")\n  if system_symbols == None: system_symbols = item[\"system_symbols\"] = set()\n  files = item.get(\"files\")\n  if files:\n    for file_name in files:\n      obj_file = _obj_files[file_name]\n      imports |= obj_file[\"imports\"]\n      exports |= obj_file[\"exports\"]\n  imports -= exports | _ignored_symbols\n  deps = item.get(\"deps\")\n  if deps:\n    for dep in deps:\n      dep_item = _Resolve(dep, parents)\n      # Detect whether this item needs to depend on dep,\n      # except when this item has no files, that is, when it is just\n      # a deliberate umbrella group or library.\n      dep_exports = dep_item[\"exports\"]\n      dep_system_symbols = dep_item[\"system_symbols\"]\n      if files and imports.isdisjoint(dep_exports) and imports.isdisjoint(dep_system_symbols):\n        print \"Info:  %s %s  does not need to depend on  %s\\n\" % (item_type, name, dep)\n      # We always include the dependency's exports, even if we do not need them\n      # to satisfy local imports.\n      exports |= dep_exports\n      system_symbols |= dep_system_symbols\n  item[\"exports\"] = exports\n  item[\"system_symbols\"] = system_symbols\n  imports -= exports | system_symbols\n  for symbol in imports:\n    for file_name in files:\n      if symbol in _obj_files[file_name][\"imports\"]:\n        neededFile = _symbols_to_files.get(symbol)\n        if neededFile in dependencies.file_to_item:\n          neededItem = \"but %s does not depend on %s (for %s)\" % (name, dependencies.file_to_item[neededFile], neededFile)\n        else:\n          neededItem = \"- is this a new system symbol?\"\n        sys.stderr.write(\"Error: in %s %s: %s imports %s %s\\n\" %\n                         (item_type, name, file_name, symbol, neededItem))\n    _return_value = 1\n  del parents[-1]\n  return item\n\ndef Process(root_path):\n  \"\"\"Loads dependencies.txt, reads the libraries' .o files, and processes them.\n\n  Modifies dependencies.items: Recursively builds each item's system_symbols and exports.\n  \"\"\"\n  global _ignored_symbols, _obj_files, _return_value\n  global _virtual_classes, _weak_destructors\n  dependencies.Load()\n  for name_and_item in dependencies.items.iteritems():\n    name = name_and_item[0]\n    item = name_and_item[1]\n    system_symbols = item.get(\"system_symbols\")\n    if system_symbols:\n      for symbol in system_symbols:\n        _symbols_to_files[symbol] = name\n  for library_name in dependencies.libraries:\n    _ReadLibrary(root_path, library_name)\n  o_files_set = set(_obj_files.keys())\n  files_missing_from_deps = o_files_set - dependencies.files\n  files_missing_from_build = dependencies.files - o_files_set\n  if files_missing_from_deps:\n    sys.stderr.write(\"Error: files missing from dependencies.txt:\\n%s\\n\" %\n                     sorted(files_missing_from_deps))\n    _return_value = 1\n  if files_missing_from_build:\n    sys.stderr.write(\"Error: files in dependencies.txt but not built:\\n%s\\n\" %\n                     sorted(files_missing_from_build))\n    _return_value = 1\n  if not _return_value:\n    for library_name in dependencies.libraries:\n      _Resolve(library_name, [])\n  if not _return_value:\n    virtual_classes_with_weak_destructors = _virtual_classes & _weak_destructors\n    if virtual_classes_with_weak_destructors:\n      sys.stderr.write(\"Error: Some classes have virtual methods, and \"\n                       \"an implicit or inline destructor \"\n                       \"(see ICU ticket #8454 for details):\\n%s\\n\" %\n                       sorted(virtual_classes_with_weak_destructors))\n      _return_value = 1\n\ndef main():\n  global _return_value\n  if len(sys.argv) <= 1:\n    sys.exit((\"Command line error: \" +\n             \"need one argument with the root path to the built ICU libraries/*.o files.\"))\n  Process(sys.argv[1])\n  if _ignored_symbols:\n    print \"Info: ignored symbols:\\n%s\" % sorted(_ignored_symbols)\n  if not _return_value:\n    print \"OK: Specified and actual dependencies match.\"\n  else:\n    print \"Error: There were errors, please fix them and re-run. Processing may have terminated abnormally.\"\n  return _return_value\n\nif __name__ == \"__main__\":\n  sys.exit(main())\n" }
{ "repo_name": "syci/OCB", "ref": "refs/heads/9.0", "path": "addons/account_asset/account_asset_invoice.py", "content": "# -*- coding: utf-8 -*-\n\nfrom datetime import datetime\nfrom dateutil.relativedelta import relativedelta\nfrom openerp import api, fields, models\nimport openerp.addons.decimal_precision as dp\nfrom openerp.tools import DEFAULT_SERVER_DATE_FORMAT as DF\n\n\nclass AccountInvoice(models.Model):\n    _inherit = 'account.invoice'\n\n    @api.multi\n    def action_move_create(self):\n        result = super(AccountInvoice, self).action_move_create()\n        for inv in self:\n            inv.invoice_line_ids.asset_create()\n        return result\n\n\nclass AccountInvoiceLine(models.Model):\n    _inherit = 'account.invoice.line'\n\n    asset_category_id = fields.Many2one('account.asset.category', string='Asset Category')\n    asset_start_date = fields.Date(string='Asset End Date', compute='_get_asset_date', readonly=True, store=True)\n    asset_end_date = fields.Date(string='Asset Start Date', compute='_get_asset_date', readonly=True, store=True)\n    asset_mrr = fields.Float(string='Monthly Recurring Revenue', compute='_get_asset_date', readonly=True, digits=dp.get_precision('Account'), store=True)\n\n    @api.one\n    @api.depends('asset_category_id', 'invoice_id.date_invoice')\n    def _get_asset_date(self):\n        self.asset_mrr = 0\n        self.asset_start_date = False\n        self.asset_end_date = False\n        cat = self.asset_category_id\n        if cat:\n            months = cat.method_number * cat.method_period\n            if self.invoice_id.type in ['out_invoice', 'out_refund']:\n                self.asset_mrr = self.price_subtotal_signed / months\n            if self.invoice_id.date_invoice:\n                start_date = datetime.strptime(self.invoice_id.date_invoice, DF).replace(day=1)\n                end_date = (start_date + relativedelta(months=months, days=-1))\n                self.asset_start_date = start_date.strftime(DF)\n                self.asset_end_date = end_date.strftime(DF)\n\n    @api.one\n    def asset_create(self):\n        if self.asset_category_id and self.asset_category_id.method_number > 1:\n            vals = {\n                'name': self.name,\n                'code': self.invoice_id.number or False,\n                'category_id': self.asset_category_id.id,\n                'value': self.price_subtotal,\n                'partner_id': self.invoice_id.partner_id.id,\n                'company_id': self.invoice_id.company_id.id,\n                'currency_id': self.invoice_id.currency_id.id,\n                'date': self.asset_start_date or self.invoice_id.date_invoice,\n                'invoice_id': self.invoice_id.id,\n          }\n            changed_vals = self.env['account.asset.asset'].onchange_category_id_values(vals['category_id'])\n            vals.update(changed_vals['value'])\n            asset = self.env['account.asset.asset'].create(vals)\n            if self.asset_category_id.open_asset:\n                asset.validate()\n        return True\n\n    @api.onchange('product_id')\n    def onchange_product_id(self):\n        if self.product_id:\n            if self.invoice_id.type == 'out_invoice':\n                self.asset_category_id = self.product_id.product_tmpl_id.deferred_revenue_category_id\n            elif self.invoice_id.type == 'in_invoice':\n                self.asset_category_id = self.product_id.product_tmpl_id.asset_category_id\n\n\nclass ProductTemplate(models.Model):\n    _inherit = 'product.template'\n    asset_category_id = fields.Many2one('account.asset.category', string='Asset Type', ondelete=\"restrict\")\n    deferred_revenue_category_id = fields.Many2one('account.asset.category', string='Deferred Revenue Type', ondelete=\"restrict\")\n" }
{ "repo_name": "Exgibichi/statusquo", "ref": "refs/heads/0.15", "path": "test/functional/zapwallettxes.py", "content": "#!/usr/bin/env python3\n# Copyright (c) 2014-2016 The Bitcoin Core developers\n# Distributed under the MIT software license, see the accompanying\n# file COPYING or http://www.opensource.org/licenses/mit-license.php.\n\"\"\"Test the zapwallettxes functionality.\n\n- start two statusquod nodes\n- create two transactions on node 0 - one is confirmed and one is unconfirmed.\n- restart node 0 and verify that both the confirmed and the unconfirmed\n  transactions are still available.\n- restart node 0 with zapwallettxes and persistmempool, and verify that both\n  the confirmed and the unconfirmed transactions are still available.\n- restart node 0 with just zapwallettxed and verify that the confirmed\n  transactions are still available, but that the unconfirmed transaction has\n  been zapped.\n\"\"\"\nfrom test_framework.test_framework import StatusquoTestFramework\nfrom test_framework.util import (assert_equal,\n                                 assert_raises_jsonrpc,\n                                 )\n\nclass ZapWalletTXesTest (StatusquoTestFramework):\n\n    def __init__(self):\n        super().__init__()\n        self.setup_clean_chain = True\n        self.num_nodes = 2\n\n    def run_test(self):\n        self.log.info(\"Mining blocks...\")\n        self.nodes[0].generate(1)\n        self.sync_all()\n        self.nodes[1].generate(100)\n        self.sync_all()\n\n        # This transaction will be confirmed\n        txid1 = self.nodes[0].sendtoaddress(self.nodes[1].getnewaddress(), 10)\n\n        self.nodes[0].generate(1)\n        self.sync_all()\n\n        # This transaction will not be confirmed\n        txid2 = self.nodes[0].sendtoaddress(self.nodes[1].getnewaddress(), 20)\n\n        # Confirmed and unconfirmed transactions are now in the wallet.\n        assert_equal(self.nodes[0].gettransaction(txid1)['txid'], txid1)\n        assert_equal(self.nodes[0].gettransaction(txid2)['txid'], txid2)\n\n        # Stop-start node0. Both confirmed and unconfirmed transactions remain in the wallet.\n        self.stop_node(0)\n        self.nodes[0] = self.start_node(0, self.options.tmpdir)\n\n        assert_equal(self.nodes[0].gettransaction(txid1)['txid'], txid1)\n        assert_equal(self.nodes[0].gettransaction(txid2)['txid'], txid2)\n\n        # Stop node0 and restart with zapwallettxes and persistmempool. The unconfirmed\n        # transaction is zapped from the wallet, but is re-added when the mempool is reloaded.\n        self.stop_node(0)\n        self.nodes[0] = self.start_node(0, self.options.tmpdir, [\"-persistmempool=1\", \"-zapwallettxes=2\"])\n\n        assert_equal(self.nodes[0].gettransaction(txid1)['txid'], txid1)\n        assert_equal(self.nodes[0].gettransaction(txid2)['txid'], txid2)\n\n        # Stop node0 and restart with zapwallettxes, but not persistmempool.\n        # The unconfirmed transaction is zapped and is no longer in the wallet.\n        self.stop_node(0)\n        self.nodes[0] = self.start_node(0, self.options.tmpdir, [\"-zapwallettxes=2\"])\n\n        # tx1 is still be available because it was confirmed\n        assert_equal(self.nodes[0].gettransaction(txid1)['txid'], txid1)\n\n        # This will raise an exception because the unconfirmed transaction has been zapped\n        assert_raises_jsonrpc(-5, 'Invalid or non-wallet transaction id', self.nodes[0].gettransaction, txid2)\n\nif __name__ == '__main__':\n    ZapWalletTXesTest().main()\n" }
{ "repo_name": "schristakidis/p2ner", "ref": "refs/heads/development", "path": "p2ner/components/ui/gtkgui/gtkgui/options/remoteproducer.py", "content": "import os, sys\n#   Copyright 2012 Loris Corazza, Sakis Christakidis\n#\n#   Licensed under the Apache License, Version 2.0 (the \"License\");\n#   you may not use this file except in compliance with the License.\n#   You may obtain a copy of the License at\n#\n#       http://www.apache.org/licenses/LICENSE-2.0\n#\n#   Unless required by applicable law or agreed to in writing, software\n#   distributed under the License is distributed on an \"AS IS\" BASIS,\n#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#   See the License for the specific language governing permissions and\n#   limitations under the License.\n\nfrom twisted.internet import gtk2reactor\ntry:\n    gtk2reactor.install()\nexcept:\n    pass\nimport pygtk\nfrom twisted.internet import reactor\npygtk.require(\"2.0\")\nimport gtk\nimport gobject\nfrom generic import genericFrame\nfrom p2ner.util.utilities import get_user_data_dir\nfrom pkg_resources import resource_string\nfrom gtkgui.remotefilechooser import RemoteFileChooser\n\n\nENCODINGS={'Greek':'ISO-8859-7',\n                      'Universal':'UTF-8',\n                      'Western European':'Latin-9'}\n\nclass remoteproducerFrame(genericFrame):\n    def initUI(self):\n        self.builder = gtk.Builder()\n        self.builder.add_from_string(resource_string(__name__, 'optRemote.glade'))\n        self.builder.connect_signals(self)\n        \n        self.changeButton=self.builder.get_object('changeButton')\n        self.frame=self.builder.get_object('remoteProducerFrame')\n        self.checkButton=self.builder.get_object('checkRemote')\n        self.checkButton.connect('toggled',self.on_check_toggled)\n        self.passEntry=self.builder.get_object('passEntry')\n\n        self.passEntry.connect('activate',self.on_pass_edited)\n        self.passEntry.connect('focus-out-event',self.on_focus_out)\n        self.dirEntry=self.builder.get_object('dirEntry')\n        self.dirEntry.set_sensitive(False)\n        \n    def refresh(self):\n        self.passEntry.set_sensitive(False)\n        self.changeButton.set_sensitive(True)\n        remotePref=self.preferences.getRemotePreferences()\n        self.checkButton.set_active(remotePref['enable'])\n        self.passEntry.set_text(remotePref['password'])\n        self.oldPass=remotePref['password']\n        self.dirEntry.set_text(remotePref['dir'])\n        \n\n    def on_check_toggled(self,widget):\n        self.preferences.setEnableRemoteProducer(widget.get_active())\n        \n    def on_changeButton_clicked(self,widget):\n        widget.set_sensitive(False)\n        self.passEntry.set_sensitive(True)\n        self.passEntry.set_text('')\n        self.passEntry.grab_focus()\n        \n    def on_pass_edited(self,widget):\n        self.oldPass=widget.get_text()\n        self.preferences.setRemotePassword(self.oldPass)\n        widget.set_sensitive(False)\n        self.changeButton.set_sensitive(True)\n        \n    def on_focus_out(self,widget,event):\n        widget.set_text(self.oldPass)\n        widget.set_sensitive(False)\n        self.changeButton.set_sensitive(True)\n        \n    def on_openButton_clicked(self,widget):\n        if self.remote:\n            RemoteFileChooser(self.browseFinished,self.interface,onlyDir=True)\n        else:\n            self.browseLocally()\n    \n    def browseLocally(self): \n        dialog = gtk.FileChooserDialog(\"Open..\",\n                               None,\n                               gtk.FILE_CHOOSER_ACTION_SELECT_FOLDER,\n                               (gtk.STOCK_CANCEL, gtk.RESPONSE_CANCEL,\n                                gtk.STOCK_OPEN, gtk.RESPONSE_OK))\n        dialog.set_default_response(gtk.RESPONSE_OK)\n\n        \n        response = dialog.run()\n        if response == gtk.RESPONSE_OK:\n            #print dialog.get_filename(), 'selected'\n            filename = dialog.get_filename()     \n            self.browseFinished(filename)      \n        elif response == gtk.RESPONSE_CANCEL:\n            filename=None\n\n        \n        dialog.destroy()\n        \n    def browseFinished(self,filename):\n        if filename:\n            self.dirEntry.set_text(filename)\n            self.preferences.setRemoteProducerDir(filename)           \n\n                \n" }
{ "repo_name": "petrus-v/server-tools", "ref": "refs/heads/7.0", "path": "base_optional_quick_create/__init__.py", "content": "# -*- coding: utf-8 -*-\n##############################################################################\n#\n#    Copyright (C) 2013 Agile Business Group sagl (<http://www.agilebg.com>)\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU Affero General Public License as published\n#    by the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU Affero General Public License for more details.\n#\n#    You should have received a copy of the GNU Affero General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\nfrom . import model\n" }
{ "repo_name": "credosemi/rt-thread-openrisc", "ref": "refs/heads/stable-v1.2.x-openrisc", "path": "bsp/sep6200/rtconfig.py", "content": "import os\n\n# toolchains options\nARCH     = 'unicore32'\nCPU      = 'sep6200'\nTextBase = '0x40000000'\n\nCROSS_TOOL \t= 'gcc'\n\nif os.getenv('RTT_CC'):\n\tCROSS_TOOL = os.getenv('RTT_CC')\n\nif  CROSS_TOOL == 'gcc':\n\tPLATFORM \t= 'gcc'\n\tEXEC_PATH \t= '/usr/unicore/gnu-toolchain-unicore/uc4-1.0-beta-hard-RHELAS5/bin/'\nelse :\n    print '================ERROR============================'\n    print 'Not support yet!'\n    print '================================================='\n    exit(0)\n\nif os.getenv('RTT_EXEC_PATH'):\n\tEXEC_PATH = os.getenv('RTT_EXEC_PATH')\n\n#BUILD = 'debug'\nBUILD = 'release'\n\nif PLATFORM == 'gcc':\n    # toolchains\n    PREFIX = 'unicore32-linux-'\n    CC = PREFIX + 'gcc'\n    AS = PREFIX + 'gcc'\n    AR = PREFIX + 'ar'\n    LINK = PREFIX + 'ld'\n    TARGET_EXT = 'elf'\n    SIZE = PREFIX + 'size'\n    OBJDUMP = PREFIX + 'objdump'\n    OBJCPY = PREFIX + 'objcopy'\n\n    DEVICE = ' '\n    CFLAGS = DEVICE\n    AFLAGS = ' -c' + DEVICE + ' -x assembler-with-cpp' + ' -DTEXT_BASE=' + TextBase\n    LFLAGS = DEVICE + ' -Bstatic --gc-sections -Map=rtthread_sep6200.map -cref -u _start -T sep6200.ld -L/usr/unicore/gnu-toolchain-unicore/uc4-1.0-beta-hard-RHELAS5/lib/gcc/unicore32-linux/4.4.2 -lgcc' + ' -Ttext ' + TextBase\n\n    CPATH = ''\n    LPATH = ''\n\n    if BUILD == 'debug':\n        CFLAGS += ' -O0 -gdwarf-2'\n        AFLAGS += ' -gdwarf-2'\n    else:\n        CFLAGS += ' -O2'\n\n    POST_ACTION = OBJCPY + ' -O binary $TARGET rtthread.bin\\n' + SIZE + ' $TARGET \\n'\n" }
{ "repo_name": "jwhui/openthread", "ref": "refs/heads/efr32", "path": "tests/toranj/test-002-form.py", "content": "#!/usr/bin/env python3\n#\n#  Copyright (c) 2018, The OpenThread Authors.\n#  All rights reserved.\n#\n#  Redistribution and use in source and binary forms, with or without\n#  modification, are permitted provided that the following conditions are met:\n#  1. Redistributions of source code must retain the above copyright\n#     notice, this list of conditions and the following disclaimer.\n#  2. Redistributions in binary form must reproduce the above copyright\n#     notice, this list of conditions and the following disclaimer in the\n#     documentation and/or other materials provided with the distribution.\n#  3. Neither the name of the copyright holder nor the\n#     names of its contributors may be used to endorse or promote products\n#     derived from this software without specific prior written permission.\n#\n#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n#  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n#  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n#  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n#  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n#  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n#  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n#  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n#  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n#  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n#  POSSIBILITY OF SUCH DAMAGE.\n\nfrom wpan import verify\nimport wpan\n\n# -----------------------------------------------------------------------------------------------------------------------\n# Test description: forming a Thread network\n\ntest_name = __file__[:-3] if __file__.endswith('.py') else __file__\nprint('-' * 120)\nprint('Starting \\'{}\\''.format(test_name))\n\n# -----------------------------------------------------------------------------------------------------------------------\n# Creating `wpan.Nodes` instances\n\nspeedup = 4\nwpan.Node.set_time_speedup_factor(speedup)\n\nnode = wpan.Node()\n\n# -----------------------------------------------------------------------------------------------------------------------\n# Init all nodes\n\nwpan.Node.init_all_nodes()\n\n# -----------------------------------------------------------------------------------------------------------------------\n# Test implementation\n\n# default values after reset\nDEFAULT_NAME = '\"OpenThread\"'\nDEFAULT_PANID = '0xFFFF'\nDEFAULT_XPANID = '0xDEAD00BEEF00CAFE'\n\nverify(node.get(wpan.WPAN_STATE) == wpan.STATE_OFFLINE)\nverify(node.get(wpan.WPAN_NAME) == DEFAULT_NAME)\nverify(node.get(wpan.WPAN_PANID) == DEFAULT_PANID)\nverify(node.get(wpan.WPAN_XPANID) == DEFAULT_XPANID)\n\n# Form a network\n\nnode.form('asha')\nverify(node.get(wpan.WPAN_STATE) == wpan.STATE_ASSOCIATED)\nverify(node.get(wpan.WPAN_NODE_TYPE) == wpan.NODE_TYPE_LEADER)\nverify(node.get(wpan.WPAN_NAME) == '\"asha\"')\nverify(node.get(wpan.WPAN_PANID) != DEFAULT_PANID)\nverify(node.get(wpan.WPAN_XPANID) != DEFAULT_XPANID)\n\nnode.leave()\nverify(node.get(wpan.WPAN_STATE) == wpan.STATE_OFFLINE)\n\n# Form a network on a specific channel.\n\nnode.form('ahura', channel=20)\nverify(node.get(wpan.WPAN_STATE) == wpan.STATE_ASSOCIATED)\nverify(node.get(wpan.WPAN_NAME) == '\"ahura\"')\nverify(node.get(wpan.WPAN_CHANNEL) == '20')\nverify(node.get(wpan.WPAN_PANID) != DEFAULT_PANID)\nverify(node.get(wpan.WPAN_XPANID) != DEFAULT_XPANID)\n\nnode.leave()\nverify(node.get(wpan.WPAN_STATE) == wpan.STATE_OFFLINE)\n\n# Form a network with a specific panid, xpanid and key specified separately\n\nnode.set(wpan.WPAN_PANID, '0x1977')\nnode.set(wpan.WPAN_XPANID, '1020031510006016', binary_data=True)\nnode.set(wpan.WPAN_KEY, '0123456789abcdeffecdba9876543210', binary_data=True)\n\nnode.form('mazda', channel=12)\nverify(node.get(wpan.WPAN_STATE) == wpan.STATE_ASSOCIATED)\nverify(node.get(wpan.WPAN_NAME) == '\"mazda\"')\nverify(node.get(wpan.WPAN_CHANNEL) == '12')\nverify(node.get(wpan.WPAN_KEY) == '[0123456789ABCDEFFECDBA9876543210]')\nverify(node.get(wpan.WPAN_PANID) == '0x1977')\nverify(node.get(wpan.WPAN_XPANID) == '0x1020031510006016')\n\nnode.leave()\nverify(node.get(wpan.WPAN_STATE) == wpan.STATE_OFFLINE)\n\n# Form a network with all parameters given as part of `form` command itself\n\nnode.form(\n    'vahman',\n    channel_mask='15,20-24',\n    panid='0x1977',\n    xpanid='1020031510006016',\n    key='0123456789abcdeffecdba9876543210',\n    key_index='1',\n    mesh_local_prefix='fd00:cafe::',\n)\n\nverify(node.get(wpan.WPAN_STATE) == wpan.STATE_ASSOCIATED)\nverify(node.get(wpan.WPAN_NAME) == '\"vahman\"')\nchannel = int(node.get(wpan.WPAN_CHANNEL), 0)\nverify(channel == 15 or (20 <= channel <= 24))\nverify(node.get(wpan.WPAN_KEY) == '[0123456789ABCDEFFECDBA9876543210]')\nverify(node.get(wpan.WPAN_KEY_INDEX) == '1')\nverify(node.get(wpan.WPAN_PANID) == '0x1977')\nverify(node.get(wpan.WPAN_XPANID) == '0x1020031510006016')\nverify(node.get(wpan.WPAN_IP6_MESH_LOCAL_PREFIX) == '\"fd00:cafe::/64\"')\n\n# Verify behavior when commands are issued immediately after a `reset`\n\nnode.reset()\nnode.leave()\n\nnode.reset()\nnode.form('net-after-reset')\n\n# -----------------------------------------------------------------------------------------------------------------------\n# Test finished\n\nwpan.Node.finalize_all_nodes()\n\nprint('\\'{}\\' passed.'.format(test_name))\n" }
{ "repo_name": "StefanRijnhart/server-tools", "ref": "refs/heads/7.0", "path": "base_optional_quick_create/__init__.py", "content": "# -*- coding: utf-8 -*-\n##############################################################################\n#\n#    Copyright (C) 2013 Agile Business Group sagl (<http://www.agilebg.com>)\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU Affero General Public License as published\n#    by the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU Affero General Public License for more details.\n#\n#    You should have received a copy of the GNU Affero General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\nfrom . import model\n" }
{ "repo_name": "openthread/openthread", "ref": "refs/heads/main", "path": "tests/toranj/test-002-form.py", "content": "#!/usr/bin/env python3\n#\n#  Copyright (c) 2018, The OpenThread Authors.\n#  All rights reserved.\n#\n#  Redistribution and use in source and binary forms, with or without\n#  modification, are permitted provided that the following conditions are met:\n#  1. Redistributions of source code must retain the above copyright\n#     notice, this list of conditions and the following disclaimer.\n#  2. Redistributions in binary form must reproduce the above copyright\n#     notice, this list of conditions and the following disclaimer in the\n#     documentation and/or other materials provided with the distribution.\n#  3. Neither the name of the copyright holder nor the\n#     names of its contributors may be used to endorse or promote products\n#     derived from this software without specific prior written permission.\n#\n#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n#  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n#  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n#  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n#  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n#  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n#  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n#  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n#  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n#  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n#  POSSIBILITY OF SUCH DAMAGE.\n\nfrom wpan import verify\nimport wpan\n\n# -----------------------------------------------------------------------------------------------------------------------\n# Test description: forming a Thread network\n\ntest_name = __file__[:-3] if __file__.endswith('.py') else __file__\nprint('-' * 120)\nprint('Starting \\'{}\\''.format(test_name))\n\n# -----------------------------------------------------------------------------------------------------------------------\n# Creating `wpan.Nodes` instances\n\nspeedup = 4\nwpan.Node.set_time_speedup_factor(speedup)\n\nnode = wpan.Node()\n\n# -----------------------------------------------------------------------------------------------------------------------\n# Init all nodes\n\nwpan.Node.init_all_nodes()\n\n# -----------------------------------------------------------------------------------------------------------------------\n# Test implementation\n\n# default values after reset\nDEFAULT_NAME = '\"OpenThread\"'\nDEFAULT_PANID = '0xFFFF'\nDEFAULT_XPANID = '0xDEAD00BEEF00CAFE'\n\nverify(node.get(wpan.WPAN_STATE) == wpan.STATE_OFFLINE)\nverify(node.get(wpan.WPAN_NAME) == DEFAULT_NAME)\nverify(node.get(wpan.WPAN_PANID) == DEFAULT_PANID)\nverify(node.get(wpan.WPAN_XPANID) == DEFAULT_XPANID)\n\n# Form a network\n\nnode.form('asha')\nverify(node.get(wpan.WPAN_STATE) == wpan.STATE_ASSOCIATED)\nverify(node.get(wpan.WPAN_NODE_TYPE) == wpan.NODE_TYPE_LEADER)\nverify(node.get(wpan.WPAN_NAME) == '\"asha\"')\nverify(node.get(wpan.WPAN_PANID) != DEFAULT_PANID)\nverify(node.get(wpan.WPAN_XPANID) != DEFAULT_XPANID)\n\nnode.leave()\nverify(node.get(wpan.WPAN_STATE) == wpan.STATE_OFFLINE)\n\n# Form a network on a specific channel.\n\nnode.form('ahura', channel=20)\nverify(node.get(wpan.WPAN_STATE) == wpan.STATE_ASSOCIATED)\nverify(node.get(wpan.WPAN_NAME) == '\"ahura\"')\nverify(node.get(wpan.WPAN_CHANNEL) == '20')\nverify(node.get(wpan.WPAN_PANID) != DEFAULT_PANID)\nverify(node.get(wpan.WPAN_XPANID) != DEFAULT_XPANID)\n\nnode.leave()\nverify(node.get(wpan.WPAN_STATE) == wpan.STATE_OFFLINE)\n\n# Form a network with a specific panid, xpanid and key specified separately\n\nnode.set(wpan.WPAN_PANID, '0x1977')\nnode.set(wpan.WPAN_XPANID, '1020031510006016', binary_data=True)\nnode.set(wpan.WPAN_KEY, '0123456789abcdeffecdba9876543210', binary_data=True)\n\nnode.form('mazda', channel=12)\nverify(node.get(wpan.WPAN_STATE) == wpan.STATE_ASSOCIATED)\nverify(node.get(wpan.WPAN_NAME) == '\"mazda\"')\nverify(node.get(wpan.WPAN_CHANNEL) == '12')\nverify(node.get(wpan.WPAN_KEY) == '[0123456789ABCDEFFECDBA9876543210]')\nverify(node.get(wpan.WPAN_PANID) == '0x1977')\nverify(node.get(wpan.WPAN_XPANID) == '0x1020031510006016')\n\nnode.leave()\nverify(node.get(wpan.WPAN_STATE) == wpan.STATE_OFFLINE)\n\n# Form a network with all parameters given as part of `form` command itself\n\nnode.form(\n    'vahman',\n    channel_mask='15,20-24',\n    panid='0x1977',\n    xpanid='1020031510006016',\n    key='0123456789abcdeffecdba9876543210',\n    key_index='1',\n    mesh_local_prefix='fd00:cafe::',\n)\n\nverify(node.get(wpan.WPAN_STATE) == wpan.STATE_ASSOCIATED)\nverify(node.get(wpan.WPAN_NAME) == '\"vahman\"')\nchannel = int(node.get(wpan.WPAN_CHANNEL), 0)\nverify(channel == 15 or (20 <= channel <= 24))\nverify(node.get(wpan.WPAN_KEY) == '[0123456789ABCDEFFECDBA9876543210]')\nverify(node.get(wpan.WPAN_KEY_INDEX) == '1')\nverify(node.get(wpan.WPAN_PANID) == '0x1977')\nverify(node.get(wpan.WPAN_XPANID) == '0x1020031510006016')\nverify(node.get(wpan.WPAN_IP6_MESH_LOCAL_PREFIX) == '\"fd00:cafe::/64\"')\n\n# Verify behavior when commands are issued immediately after a `reset`\n\nnode.reset()\nnode.leave()\n\nnode.reset()\nnode.form('net-after-reset')\n\n# -----------------------------------------------------------------------------------------------------------------------\n# Test finished\n\nwpan.Node.finalize_all_nodes()\n\nprint('\\'{}\\' passed.'.format(test_name))\n" }
{ "repo_name": "defivelo/db", "ref": "refs/heads/dependabot/pip/requirements/django-debug-toolbar-3.2.1", "path": "apps/user/migrations/0040_auto_20170824_1109.py", "content": "# Generated by Django 1.11.4 on 2017-08-24 09:09\nfrom __future__ import unicode_literals\n\nfrom django.db import migrations, models\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('user', '0039_rename_back'),\n    ]\n\n    operations = [\n        migrations.AlterField(\n            model_name='userprofile',\n            name='actor_for',\n            field=models.ManyToManyField(blank=True, related_name='actor_for', to='challenge.QualificationActivity', verbose_name='Intervenant'),\n        ),\n    ]\n" }
{ "repo_name": "archetipo/server-tools", "ref": "refs/heads/7.0", "path": "base_optional_quick_create/__init__.py", "content": "# -*- coding: utf-8 -*-\n##############################################################################\n#\n#    Copyright (C) 2013 Agile Business Group sagl (<http://www.agilebg.com>)\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU Affero General Public License as published\n#    by the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU Affero General Public License for more details.\n#\n#    You should have received a copy of the GNU Affero General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\nfrom . import model\n" }
{ "repo_name": "georgid/sms-tools", "ref": "refs/heads/georgid-withMelodia", "path": "lectures/4-STFT/plots-code/sine-spectrum.py", "content": "import matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.fftpack import fft, ifft\n\nN = 256\nM = 63\nf0 = 1000\nfs = 10000\nA0 = .8 \nhN = N/2 \nhM = (M+1)/2\nfftbuffer = np.zeros(N)\nX1 = np.zeros(N, dtype='complex')\nX2 = np.zeros(N, dtype='complex')\n\nx = A0 * np.cos(2*np.pi*f0/fs*np.arange(-hM+1,hM))\n\nplt.figure(1, figsize=(9.5, 7))\nw = np.hanning(M)\nplt.subplot(2,3,1)\nplt.title('w (hanning window)')\nplt.plot(np.arange(-hM+1, hM), w, 'b', lw=1.5)\nplt.axis([-hM+1, hM, 0, 1])\n\nfftbuffer[:hM] = w[hM-1:]\nfftbuffer[N-hM+1:] = w[:hM-1]  \nX = fft(fftbuffer)\nX1[:hN] = X[hN:]\nX1[N-hN:] = X[:hN]\nmX = 20*np.log10(abs(X1))       \n\nplt.subplot(2,3,2)\nplt.title('mW')\nplt.plot(np.arange(-hN, hN), mX, 'r', lw=1.5)\nplt.axis([-hN,hN,-40,max(mX)])\n\npX = np.angle(X1)\nplt.subplot(2,3,3)\nplt.title('pW')\nplt.plot(np.arange(-hN, hN), np.unwrap(pX), 'c', lw=1.5)\nplt.axis([-hN,hN,min(np.unwrap(pX)),max(np.unwrap(pX))])\n\nplt.subplot(2,3,4)\nplt.title('xw (windowed sinewave)')\nxw = x*w\nplt.plot(np.arange(-hM+1, hM), xw, 'b', lw=1.5)\nplt.axis([-hM+1, hM, -1, 1])\n\nfftbuffer = np.zeros(N)\nfftbuffer[0:hM] = xw[hM-1:]\nfftbuffer[N-hM+1:] = xw[:hM-1]\nX = fft(fftbuffer)\nX2[:hN] = X[hN:]\nX2[N-hN:] = X[:hN]\nmX2 = 20*np.log10(abs(X2))  \n\nplt.subplot(2,3,5)\nplt.title('mXW')\nplt.plot(np.arange(-hN, hN), mX2, 'r', lw=1.5)\nplt.axis([-hN,hN,-40,max(mX)])\n\npX = np.angle(X2)\nplt.subplot(2,3,6)\nplt.title('pXW')\nplt.plot(np.arange(-hN, hN), np.unwrap(pX), 'c', lw=1.5)\nplt.axis([-hN,hN,min(np.unwrap(pX)),max(np.unwrap(pX))])\n\nplt.tight_layout()\nplt.savefig('sine-spectrum.png')\nplt.show()\n" }
{ "repo_name": "klahnakoski/Bugzilla-ETL", "ref": "refs/heads/v2", "path": "vendor/jx_python/namespace/normal.py", "content": "# encoding: utf-8\n#\n#\n# This Source Code Form is subject to the terms of the Mozilla Public\n# License, v. 2.0. If a copy of the MPL was not distributed with this file,\n# You can obtain one at http://mozilla.org/MPL/2.0/.\n#\n# Author: Kyle Lahnakoski (kyle@lahnakoski.com)\n#\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import unicode_literals\n\nfrom collections import Mapping\nfrom copy import copy\n\nfrom mo_dots import Data\nfrom mo_dots import FlatList\nfrom mo_dots import coalesce, Null\nfrom mo_dots import wrap, listwrap\nfrom mo_logs import Log\nfrom mo_math import Math\n\nfrom jx_base.dimensions import Dimension\nfrom jx_base.domains import Domain\nfrom jx_python.containers import Container\nfrom jx_python.expressions import TRUE\nfrom jx_python.namespace import Namespace, convert_list\nfrom jx_base.query import QueryOp, get_all_vars\n\nDEFAULT_LIMIT = 10\n\n\nclass Normal(Namespace):\n    \"\"\"\n    UNREMARKABLE NAMESPACE, SIMPLY FOR CONVERTING QUERY TO NORMAL FORM\n    \"\"\"\n\n    def convert(self, expr):\n        if isinstance(expr, Mapping) and expr[\"from\"]:\n            return self._convert_query(expr)\n        return expr\n\n\n    def _convert_query(self, query):\n        # if not isinstance(query[\"from\"], Container):\n        #     Log.error('Expecting from clause to be a Container')\n        query = wrap(query)\n\n        output = QueryOp(\"from\", None)\n        output[\"from\"] = self._convert_from(query[\"from\"])\n\n        output.format = query.format\n\n        if query.select:\n            output.select = convert_list(self._convert_select, query.select)\n        else:\n            if query.edges or query.groupby:\n                output.select = {\"name\": \"count\", \"value\": \".\", \"aggregate\": \"count\", \"default\": 0}\n            else:\n                output.select = {\"name\": \"__all__\", \"value\": \"*\", \"aggregate\": \"none\"}\n\n        if query.groupby and query.edges:\n            Log.error(\"You can not use both the `groupby` and `edges` clauses in the same query!\")\n        elif query.edges:\n            output.edges = convert_list(self._convert_edge, query.edges)\n            output.groupby = None\n        elif query.groupby:\n            output.edges = None\n            output.groupby = convert_list(self._convert_group, query.groupby)\n        else:\n            output.edges = []\n            output.groupby = None\n\n        output.where = self.convert(query.where)\n        output.window = convert_list(self._convert_window, query.window)\n        output.sort = self._convert_sort(query.sort)\n\n        output.limit = coalesce(query.limit, DEFAULT_LIMIT)\n        if not Math.is_integer(output.limit) or output.limit < 0:\n            Log.error(\"Expecting limit >= 0\")\n\n        output.isLean = query.isLean\n\n        # DEPTH ANALYSIS - LOOK FOR COLUMN REFERENCES THAT MAY BE DEEPER THAN\n        # THE from SOURCE IS.\n        vars = get_all_vars(output, exclude_where=True)  # WE WILL EXCLUDE where VARIABLES\n        for c in query.columns:\n            if c.name in vars and len(c.nested_path) != 1:\n                Log.error(\"This query, with variable {{var_name}} is too deep\", var_name=c.name)\n\n        output.having = convert_list(self._convert_having, query.having)\n\n        return output\n\n    def _convert_from(self, frum):\n        if isinstance(frum, text_type):\n            return Data(name=frum)\n        elif isinstance(frum, (Container, QueryOp)):\n            return frum\n        else:\n            Log.error(\"Expecting from clause to be a name, or a container\")\n\n    def _convert_select(self, select):\n        if isinstance(select, text_type):\n            return Data(\n                name=select.rstrip(\".\"),  # TRAILING DOT INDICATES THE VALUE, BUT IS INVALID FOR THE NAME\n                value=select,\n                aggregate=\"none\"\n            )\n        else:\n            select = wrap(select)\n            output = copy(select)\n            if not select.value or isinstance(select.value, text_type):\n                if select.value == \".\":\n                    output.name = coalesce(select.name, select.aggregate)\n                else:\n                    output.name = coalesce(select.name, select.value, select.aggregate)\n            elif not output.name:\n                Log.error(\"Must give name to each column in select clause\")\n\n            if not output.name:\n                Log.error(\"expecting select to have a name: {{select}}\",  select=select)\n\n            output.aggregate = coalesce(canonical_aggregates.get(select.aggregate), select.aggregate, \"none\")\n            return output\n\n    def _convert_edge(self, edge):\n        if isinstance(edge, text_type):\n            return Data(\n                name=edge,\n                value=edge,\n                domain=self._convert_domain()\n            )\n        else:\n            edge = wrap(edge)\n            if not edge.name and not isinstance(edge.value, text_type):\n                Log.error(\"You must name compound edges: {{edge}}\",  edge= edge)\n\n            if isinstance(edge.value, (Mapping, list)) and not edge.domain:\n                # COMPLEX EDGE IS SHORT HAND\n                domain =self._convert_domain()\n                domain.dimension = Data(fields=edge.value)\n\n                return Data(\n                    name=edge.name,\n                    allowNulls=False if edge.allowNulls is False else True,\n                    domain=domain\n                )\n\n            domain = self._convert_domain(edge.domain)\n            return Data(\n                name=coalesce(edge.name, edge.value),\n                value=edge.value,\n                range=edge.range,\n                allowNulls=False if edge.allowNulls is False else True,\n                domain=domain\n            )\n\n    def _convert_group(self, column):\n        if isinstance(column, text_type):\n            return wrap({\n                \"name\": column,\n                \"value\": column,\n                \"domain\": {\"type\": \"default\"}\n          })\n        else:\n            column = wrap(column)\n            if (column.domain and column.domain.type != \"default\") or column.allowNulls != None:\n                Log.error(\"groupby does not accept complicated domains\")\n\n            if not column.name and not isinstance(column.value, text_type):\n                Log.error(\"You must name compound edges: {{edge}}\",  edge= column)\n\n            return wrap({\n                \"name\": coalesce(column.name, column.value),\n                \"value\": column.value,\n                \"domain\": {\"type\": \"default\"}\n          })\n\n\n    def _convert_domain(self, domain=None):\n        if not domain:\n            return Domain(type=\"default\")\n        elif isinstance(domain, Dimension):\n            return domain.getDomain()\n        elif isinstance(domain, Domain):\n            return domain\n\n        if not domain.name:\n            domain = domain.copy()\n            domain.name = domain.type\n\n        if not isinstance(domain.partitions, list):\n            domain.partitions = list(domain.partitions)\n\n        return Domain(**domain)\n\n    def _convert_range(self, range):\n        if range == None:\n            return None\n\n        return Data(\n            min=range.min,\n            max=range.max\n        )\n\n    def _convert_where(self, where):\n        if where == None:\n            return TRUE\n        return where\n\n\n    def _convert_window(self, window):\n        return Data(\n            name=coalesce(window.name, window.value),\n            value=window.value,\n            edges=[self._convert_edge(e) for e in listwrap(window.edges)],\n            sort=self._convert_sort(window.sort),\n            aggregate=window.aggregate,\n            range=self._convert_range(window.range),\n            where=self._convert_where(window.where)\n        )\n\n\n    def _convert_sort(self, sort):\n        return normalize_sort(sort)\n\n\ndef normalize_sort(sort=None):\n    \"\"\"\n    CONVERT SORT PARAMETERS TO A NORMAL FORM SO EASIER TO USE\n    \"\"\"\n\n    if not sort:\n        return Null\n\n    output = FlatList()\n    for s in listwrap(sort):\n        if isinstance(s, text_type) or Math.is_integer(s):\n            output.append({\"value\": s, \"sort\": 1})\n        elif not s.field and not s.value and s.sort==None:\n            #ASSUME {name: sort} FORM\n            for n, v in s.items():\n                output.append({\"value\": n, \"sort\": sort_direction[v]})\n        else:\n            output.append({\"value\": coalesce(s.field, s.value), \"sort\": coalesce(sort_direction[s.sort], 1)})\n    return wrap(output)\n\n\nsort_direction = {\n    \"asc\": 1,\n    \"desc\": -1,\n    \"none\": 0,\n    1: 1,\n    0: 0,\n    -1: -1,\n    None: 1,\n    Null: 1\n}\n\ncanonical_aggregates = {\n    \"none\": \"none\",\n    \"one\": \"one\",\n    \"count\": \"count\",\n    \"sum\": \"sum\",\n    \"add\": \"sum\",\n    \"mean\": \"average\",\n    \"average\": \"average\",\n    \"avg\": \"average\",\n    \"min\": \"minimum\",\n    \"minimum\": \"minimum\",\n    \"max\": \"maximum\",\n    \"maximum\": \"minimum\",\n    \"X2\": \"sum_of_squares\",\n    \"std\": \"std\",\n    \"stddev\": \"std\",\n    \"std_deviation\": \"std\",\n    \"var\": \"variance\",\n    \"variance\": \"variance\",\n    \"stats\": \"stats\"\n}\n\n" }
{ "repo_name": "joachimmetz/dfvfs", "ref": "refs/heads/main", "path": "tests/vfs/xfs_file_system.py", "content": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\"\"\"Tests for the file system implementation using pyfsxfs.\"\"\"\n\nimport unittest\n\nfrom dfvfs.lib import definitions\nfrom dfvfs.path import factory as path_spec_factory\nfrom dfvfs.resolver import context\nfrom dfvfs.vfs import xfs_file_system\n\nfrom tests import test_lib as shared_test_lib\n\n\nclass XFSFileSystemTest(shared_test_lib.BaseTestCase):\n  \"\"\"Tests the XFS file entry.\"\"\"\n\n  _INODE_PASSWORD_TXT = 11077\n\n  def setUp(self):\n    \"\"\"Sets up the needed objects used throughout the test.\"\"\"\n    self._resolver_context = context.Context()\n    test_path = self._GetTestFilePath(['xfs.raw'])\n    self._SkipIfPathNotExists(test_path)\n\n    test_os_path_spec = path_spec_factory.Factory.NewPathSpec(\n        definitions.TYPE_INDICATOR_OS, location=test_path)\n    self._raw_path_spec = path_spec_factory.Factory.NewPathSpec(\n        definitions.TYPE_INDICATOR_RAW, parent=test_os_path_spec)\n    self._xfs_path_spec = path_spec_factory.Factory.NewPathSpec(\n        definitions.TYPE_INDICATOR_XFS, location='/',\n        parent=self._raw_path_spec)\n\n  def tearDown(self):\n    \"\"\"Cleans up the needed objects used throughout the test.\"\"\"\n    self._resolver_context.Empty()\n\n  def testOpenAndClose(self):\n    \"\"\"Test the open and close functionality.\"\"\"\n    file_system = xfs_file_system.XFSFileSystem(\n        self._resolver_context, self._xfs_path_spec)\n    self.assertIsNotNone(file_system)\n\n    file_system.Open()\n\n  def testFileEntryExistsByPathSpec(self):\n    \"\"\"Test the file entry exists by path specification functionality.\"\"\"\n    file_system = xfs_file_system.XFSFileSystem(\n        self._resolver_context, self._xfs_path_spec)\n    self.assertIsNotNone(file_system)\n\n    file_system.Open()\n\n    path_spec = path_spec_factory.Factory.NewPathSpec(\n        definitions.TYPE_INDICATOR_XFS, location='/passwords.txt',\n        inode=self._INODE_PASSWORD_TXT, parent=self._raw_path_spec)\n    self.assertTrue(file_system.FileEntryExistsByPathSpec(path_spec))\n\n    path_spec = path_spec_factory.Factory.NewPathSpec(\n        definitions.TYPE_INDICATOR_XFS, location='/bogus.txt',\n        parent=self._raw_path_spec)\n    self.assertFalse(file_system.FileEntryExistsByPathSpec(path_spec))\n\n  def testGetFileEntryByPathSpec(self):\n    \"\"\"Tests the GetFileEntryByPathSpec function.\"\"\"\n    file_system = xfs_file_system.XFSFileSystem(\n        self._resolver_context, self._xfs_path_spec)\n    self.assertIsNotNone(file_system)\n\n    file_system.Open()\n\n    path_spec = path_spec_factory.Factory.NewPathSpec(\n        definitions.TYPE_INDICATOR_XFS, inode=self._INODE_PASSWORD_TXT,\n        parent=self._raw_path_spec)\n\n    file_entry = file_system.GetFileEntryByPathSpec(path_spec)\n\n    self.assertIsNotNone(file_entry)\n    # There is no way to determine the file_entry.name without a location string\n    # in the path_spec or retrieving the file_entry from its parent.\n\n    path_spec = path_spec_factory.Factory.NewPathSpec(\n        definitions.TYPE_INDICATOR_XFS, location='/passwords.txt',\n        inode=self._INODE_PASSWORD_TXT, parent=self._raw_path_spec)\n    file_entry = file_system.GetFileEntryByPathSpec(path_spec)\n\n    self.assertIsNotNone(file_entry)\n    self.assertEqual(file_entry.name, 'passwords.txt')\n\n    path_spec = path_spec_factory.Factory.NewPathSpec(\n        definitions.TYPE_INDICATOR_XFS, location='/bogus.txt',\n        parent=self._raw_path_spec)\n    file_entry = file_system.GetFileEntryByPathSpec(path_spec)\n\n    self.assertIsNone(file_entry)\n\n  # TODO: add tests for GetXFSFileEntryByPathSpec function.\n\n  def testGetRootFileEntry(self):\n    \"\"\"Test the get root file entry functionality.\"\"\"\n    file_system = xfs_file_system.XFSFileSystem(\n        self._resolver_context, self._xfs_path_spec)\n    self.assertIsNotNone(file_system)\n\n    file_system.Open()\n\n    file_entry = file_system.GetRootFileEntry()\n\n    self.assertIsNotNone(file_entry)\n    self.assertEqual(file_entry.name, '')\n\n\nif __name__ == '__main__':\n  unittest.main()\n" }
{ "repo_name": "deathmetalland/IkaLog", "ref": "refs/heads/youtube_sample", "path": "ikalog/ui/panel/last_result.py", "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n#\n#  IkaLog\n#  ======\n#  Copyright (C) 2015 Takeshi HASEGAWA\n#\n#  Licensed under the Apache License, Version 2.0 (the \"License\");\n#  you may not use this file except in compliance with the License.\n#  You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an \"AS IS\" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n#  limitations under the License.\n#\n\nimport wx\nimport cv2\n\nfrom ikalog.utils import *\n\n_ = Localization.gettext_translation('IkaUI', fallback=True).gettext\n\nclass ResultsGUI(object):\n    def __init__(self, ikalog_gui):\n        self.ikalog_gui = ikalog_gui\n        self.frame = None\n        self.result_image = None\n        self.size = (640, 360)\n        self._init_frame()\n\n    def _init_frame(self):\n        if self.frame:\n            return\n\n        self.frame = wx.Frame(\n            self.ikalog_gui.frame, wx.ID_ANY, _(\"Last Result\"), size=self.size)\n        self.draw_image()\n\n    def show(self):\n        if not self.frame:\n            self._init_frame()\n        self.frame.Show()\n        self.frame.Raise()\n\n    def draw_image(self):\n        if not self.result_image or not self.frame:\n            return\n        wx.StaticBitmap(self.frame, wx.ID_ANY, self.result_image,\n                        (0, 0), self.size)\n\n    def on_game_individual_result(self, context):\n        # FIXME\n        return\n\n        cv_frame = cv2.resize(context['engine']['frame'], self.size)\n        img_frame_rgb = cv2.cvtColor(cv_frame, cv2.COLOR_BGR2RGB)\n        height, width = img_frame_rgb.shape[0:2]\n\n        self.result_image = wx.BitmapFromBuffer(width, height, img_frame_rgb)\n        self.draw_image()\n" } 
{ "repo_name": "log2timeline/dfvfs", "ref": "refs/heads/main", "path": "tests/vfs/xfs_file_system.py", "content": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\"\"\"Tests for the file system implementation using pyfsxfs.\"\"\"\n\nimport unittest\n\nfrom dfvfs.lib import definitions\nfrom dfvfs.path import factory as path_spec_factory\nfrom dfvfs.resolver import context\nfrom dfvfs.vfs import xfs_file_system\n\nfrom tests import test_lib as shared_test_lib\n\n\nclass XFSFileSystemTest(shared_test_lib.BaseTestCase):\n  \"\"\"Tests the XFS file entry.\"\"\"\n\n  _INODE_PASSWORD_TXT = 11077\n\n  def setUp(self):\n    \"\"\"Sets up the needed objects used throughout the test.\"\"\"\n    self._resolver_context = context.Context()\n    test_path = self._GetTestFilePath(['xfs.raw'])\n    self._SkipIfPathNotExists(test_path)\n\n    test_os_path_spec = path_spec_factory.Factory.NewPathSpec(\n        definitions.TYPE_INDICATOR_OS, location=test_path)\n    self._raw_path_spec = path_spec_factory.Factory.NewPathSpec(\n        definitions.TYPE_INDICATOR_RAW, parent=test_os_path_spec)\n    self._xfs_path_spec = path_spec_factory.Factory.NewPathSpec(\n        definitions.TYPE_INDICATOR_XFS, location='/',\n        parent=self._raw_path_spec)\n\n  def tearDown(self):\n    \"\"\"Cleans up the needed objects used throughout the test.\"\"\"\n    self._resolver_context.Empty()\n\n  def testOpenAndClose(self):\n    \"\"\"Test the open and close functionality.\"\"\"\n    file_system = xfs_file_system.XFSFileSystem(\n        self._resolver_context, self._xfs_path_spec)\n    self.assertIsNotNone(file_system)\n\n    file_system.Open()\n\n  def testFileEntryExistsByPathSpec(self):\n    \"\"\"Test the file entry exists by path specification functionality.\"\"\"\n    file_system = xfs_file_system.XFSFileSystem(\n        self._resolver_context, self._xfs_path_spec)\n    self.assertIsNotNone(file_system)\n\n    file_system.Open()\n\n    path_spec = path_spec_factory.Factory.NewPathSpec(\n        definitions.TYPE_INDICATOR_XFS, location='/passwords.txt',\n        inode=self._INODE_PASSWORD_TXT, parent=self._raw_path_spec)\n    self.assertTrue(file_system.FileEntryExistsByPathSpec(path_spec))\n\n    path_spec = path_spec_factory.Factory.NewPathSpec(\n        definitions.TYPE_INDICATOR_XFS, location='/bogus.txt',\n        parent=self._raw_path_spec)\n    self.assertFalse(file_system.FileEntryExistsByPathSpec(path_spec))\n\n  def testGetFileEntryByPathSpec(self):\n    \"\"\"Tests the GetFileEntryByPathSpec function.\"\"\"\n    file_system = xfs_file_system.XFSFileSystem(\n        self._resolver_context, self._xfs_path_spec)\n    self.assertIsNotNone(file_system)\n\n    file_system.Open()\n\n    path_spec = path_spec_factory.Factory.NewPathSpec(\n        definitions.TYPE_INDICATOR_XFS, inode=self._INODE_PASSWORD_TXT,\n        parent=self._raw_path_spec)\n\n    file_entry = file_system.GetFileEntryByPathSpec(path_spec)\n\n    self.assertIsNotNone(file_entry)\n    # There is no way to determine the file_entry.name without a location string\n    # in the path_spec or retrieving the file_entry from its parent.\n\n    path_spec = path_spec_factory.Factory.NewPathSpec(\n        definitions.TYPE_INDICATOR_XFS, location='/passwords.txt',\n        inode=self._INODE_PASSWORD_TXT, parent=self._raw_path_spec)\n    file_entry = file_system.GetFileEntryByPathSpec(path_spec)\n\n    self.assertIsNotNone(file_entry)\n    self.assertEqual(file_entry.name, 'passwords.txt')\n\n    path_spec = path_spec_factory.Factory.NewPathSpec(\n        definitions.TYPE_INDICATOR_XFS, location='/bogus.txt',\n        parent=self._raw_path_spec)\n    file_entry = file_system.GetFileEntryByPathSpec(path_spec)\n\n    self.assertIsNone(file_entry)\n\n  # TODO: add tests for GetXFSFileEntryByPathSpec function.\n\n  def testGetRootFileEntry(self):\n    \"\"\"Test the get root file entry functionality.\"\"\"\n    file_system = xfs_file_system.XFSFileSystem(\n        self._resolver_context, self._xfs_path_spec)\n    self.assertIsNotNone(file_system)\n\n    file_system.Open()\n\n    file_entry = file_system.GetRootFileEntry()\n\n    self.assertIsNotNone(file_entry)\n    self.assertEqual(file_entry.name, '')\n\n\nif __name__ == '__main__':\n  unittest.main()\n" } 
{ "repo_name": "vishl/ctags", "ref": "refs/heads/deploy", "path": "Test/bug1856363.py", "content": "#!/usr/bin/python\n\ndef main():\n\t# A broken ctags will see a function \"initely_not_a_function\" here.\n\tdefinitely_not_a_function = 0\n\treturn\n\nif __name__ == 'main':\n\tmain()\n" }
{ "repo_name": "fabioz/ctags", "ref": "refs/heads/deploy", "path": "Test/bug1856363.py", "content": "#!/usr/bin/python\n\ndef main():\n\t# A broken ctags will see a function \"initely_not_a_function\" here.\n\tdefinitely_not_a_function = 0\n\treturn\n\nif __name__ == 'main':\n\tmain()\n" }
{ "repo_name": "gangadhar-kadam/verve_erp", "ref": "refs/heads/v5.0", "path": "erpnext/stock/doctype/landed_cost_item/landed_cost_item.py", "content": "# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors\n# License: GNU General Public License v3. See license.txt\n\nfrom __future__ import unicode_literals\nimport frappe\n\nfrom frappe.model.document import Document\n\nclass LandedCostItem(Document):\n\tpass" }
{ "repo_name": "mawww/ctags", "ref": "refs/heads/deploy", "path": "Test/bug1856363.py", "content": "#!/usr/bin/python\n\ndef main():\n\t# A broken ctags will see a function \"initely_not_a_function\" here.\n\tdefinitely_not_a_function = 0\n\treturn\n\nif __name__ == 'main':\n\tmain()\n" }
{ "repo_name": "pradyunsg/pip", "ref": "refs/heads/revamp-ci-apr-2021-v2", "path": "src/pip/_vendor/cachecontrol/adapter.py", "content": "import types\nimport functools\nimport zlib\n\nfrom pip._vendor.requests.adapters import HTTPAdapter\n\nfrom .controller import CacheController\nfrom .cache import DictCache\nfrom .filewrapper import CallbackFileWrapper\n\n\nclass CacheControlAdapter(HTTPAdapter):\n    invalidating_methods = {\"PUT\", \"DELETE\"}\n\n    def __init__(\n        self,\n        cache=None,\n        cache_etags=True,\n        controller_class=None,\n        serializer=None,\n        heuristic=None,\n        cacheable_methods=None,\n        *args,\n        **kw\n    ):\n        super(CacheControlAdapter, self).__init__(*args, **kw)\n        self.cache = DictCache() if cache is None else cache\n        self.heuristic = heuristic\n        self.cacheable_methods = cacheable_methods or (\"GET\",)\n\n        controller_factory = controller_class or CacheController\n        self.controller = controller_factory(\n            self.cache, cache_etags=cache_etags, serializer=serializer\n        )\n\n    def send(self, request, cacheable_methods=None, **kw):\n        \"\"\"\n        Send a request. Use the request information to see if it\n        exists in the cache and cache the response if we need to and can.\n        \"\"\"\n        cacheable = cacheable_methods or self.cacheable_methods\n        if request.method in cacheable:\n            try:\n                cached_response = self.controller.cached_request(request)\n            except zlib.error:\n                cached_response = None\n            if cached_response:\n                return self.build_response(request, cached_response, from_cache=True)\n\n            # check for etags and add headers if appropriate\n            request.headers.update(self.controller.conditional_headers(request))\n\n        resp = super(CacheControlAdapter, self).send(request, **kw)\n\n        return resp\n\n    def build_response(\n        self, request, response, from_cache=False, cacheable_methods=None\n    ):\n        \"\"\"\n        Build a response by making a request or using the cache.\n\n        This will end up calling send and returning a potentially\n        cached response\n        \"\"\"\n        cacheable = cacheable_methods or self.cacheable_methods\n        if not from_cache and request.method in cacheable:\n            # Check for any heuristics that might update headers\n            # before trying to cache.\n            if self.heuristic:\n                response = self.heuristic.apply(response)\n\n            # apply any expiration heuristics\n            if response.status == 304:\n                # We must have sent an ETag request. This could mean\n                # that we've been expired already or that we simply\n                # have an etag. In either case, we want to try and\n                # update the cache if that is the case.\n                cached_response = self.controller.update_cached_response(\n                    request, response\n                )\n\n                if cached_response is not response:\n                    from_cache = True\n\n                # We are done with the server response, read a\n                # possible response body (compliant servers will\n                # not return one, but we cannot be 100% sure) and\n                # release the connection back to the pool.\n                response.read(decode_content=False)\n                response.release_conn()\n\n                response = cached_response\n\n            # We always cache the 301 responses\n            elif response.status == 301:\n                self.controller.cache_response(request, response)\n            else:\n                # Wrap the response file with a wrapper that will cache the\n                #   response when the stream has been consumed.\n                response._fp = CallbackFileWrapper(\n                    response._fp,\n                    functools.partial(\n                        self.controller.cache_response, request, response\n                    ),\n                )\n                if response.chunked:\n                    super_update_chunk_length = response._update_chunk_length\n\n                    def _update_chunk_length(self):\n                        super_update_chunk_length()\n                        if self.chunk_left == 0:\n                            self._fp._close()\n\n                    response._update_chunk_length = types.MethodType(\n                        _update_chunk_length, response\n                    )\n\n        resp = super(CacheControlAdapter, self).build_response(request, response)\n\n        # See if we should invalidate the cache.\n        if request.method in self.invalidating_methods and resp.ok:\n            cache_url = self.controller.cache_url(request.url)\n            self.cache.delete(cache_url)\n\n        # Give the request a from_cache attr to let people use it\n        resp.from_cache = from_cache\n\n        return resp\n\n    def close(self):\n        self.cache.close()\n        super(CacheControlAdapter, self).close()\n" }
{ "repo_name": "RusticiSoftware/TinCanPython", "ref": "refs/heads/3.x", "path": "tincan/substatement.py", "content": "# Copyright 2014 Rustici Software\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n#    you may not use this file except in compliance with the License.\n#    You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS,\n#    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#    See the License for the specific language governing permissions and\n#    limitations under the License.\n\nfrom tincan.statement_base import StatementBase\nfrom tincan.agent import Agent\nfrom tincan.group import Group\nfrom tincan.activity import Activity\n\n\nclass SubStatement(StatementBase):\n    _props_req = [\n        'object_type'\n    ]\n\n    _props = []\n\n    _props.extend(StatementBase._props)\n    _props.extend(_props_req)\n\n    def __init__(self, *args, **kwargs):\n        self._object_type = None\n\n        super(SubStatement, self).__init__(*args, **kwargs)\n\n    @property\n    def object(self):\n        \"\"\"Object for SubStatement\n\n        :setter: Setter for object\n        :setter type: :class:`tincan.Agent` | :class:`tincan.Group` | :class:`tincan.Activity`\n        :rtype: :class:`tincan.Agent` | :class:`tincan.Group` | :class:`tincan.Activity`\n\n        \"\"\"\n        return self._object\n\n    @object.setter\n    def object(self, value):\n        if value is not None and \\\n                not isinstance(value, Agent) and \\\n                not isinstance(value, Group) and \\\n                not isinstance(value, Activity):\n            if isinstance(value, dict):\n                if 'object_type' in value or 'objectType' in value:\n                    if 'objectType' in value:\n                        value['object_type'] = value['objectType']\n                        value.pop('objectType')\n                    if value['object_type'] == 'Agent':\n                        value = Agent(value)\n                    elif value['object_type'] == 'Activity':\n                        value = Activity(value)\n                    elif value['object_type'] == 'Group':\n                        value = Group(value)\n                    else:\n                        value = Activity(value)\n                else:\n                    value = Activity(value)\n        self._object = value\n\n    @object.deleter\n    def object(self):\n        del self._object\n\n    @property\n    def object_type(self):\n        \"\"\"Object Type for SubStatement. Will always be \"SubStatement\"\n\n        :setter: Tries to convert to unicode\n        :setter type: unicode\n        :rtype: unicode\n\n        \"\"\"\n        return self._object_type\n\n    @object_type.setter\n    def object_type(self, _):\n        self._object_type = 'SubStatement'\n" }
{ "repo_name": "brain-tec/server-tools", "ref": "refs/heads/11.0", "path": "fetchmail_incoming_log/models/__init__.py", "content": "from . import mail_thread\n" }
{ "repo_name": "yamaya/ctags", "ref": "refs/heads/deploy", "path": "Test/bug1856363.py", "content": "#!/usr/bin/python\n\ndef main():\n\t# A broken ctags will see a function \"initely_not_a_function\" here.\n\tdefinitely_not_a_function = 0\n\treturn\n\nif __name__ == 'main':\n\tmain()\n" }
{ "repo_name": "peterdocter/ctags", "ref": "refs/heads/deploy_for_android", "path": "Test/bug1856363.py", "content": "#!/usr/bin/python\n\ndef main():\n\t# A broken ctags will see a function \"initely_not_a_function\" here.\n\tdefinitely_not_a_function = 0\n\treturn\n\nif __name__ == 'main':\n\tmain()\n" }
{ "repo_name": "pypa/pip", "ref": "refs/heads/main", "path": "src/pip/_vendor/cachecontrol/adapter.py", "content": "import types\nimport functools\nimport zlib\n\nfrom pip._vendor.requests.adapters import HTTPAdapter\n\nfrom .controller import CacheController\nfrom .cache import DictCache\nfrom .filewrapper import CallbackFileWrapper\n\n\nclass CacheControlAdapter(HTTPAdapter):\n    invalidating_methods = {\"PUT\", \"DELETE\"}\n\n    def __init__(\n        self,\n        cache=None,\n        cache_etags=True,\n        controller_class=None,\n        serializer=None,\n        heuristic=None,\n        cacheable_methods=None,\n        *args,\n        **kw\n    ):\n        super(CacheControlAdapter, self).__init__(*args, **kw)\n        self.cache = DictCache() if cache is None else cache\n        self.heuristic = heuristic\n        self.cacheable_methods = cacheable_methods or (\"GET\",)\n\n        controller_factory = controller_class or CacheController\n        self.controller = controller_factory(\n            self.cache, cache_etags=cache_etags, serializer=serializer\n        )\n\n    def send(self, request, cacheable_methods=None, **kw):\n        \"\"\"\n        Send a request. Use the request information to see if it\n        exists in the cache and cache the response if we need to and can.\n        \"\"\"\n        cacheable = cacheable_methods or self.cacheable_methods\n        if request.method in cacheable:\n            try:\n                cached_response = self.controller.cached_request(request)\n            except zlib.error:\n                cached_response = None\n            if cached_response:\n                return self.build_response(request, cached_response, from_cache=True)\n\n            # check for etags and add headers if appropriate\n            request.headers.update(self.controller.conditional_headers(request))\n\n        resp = super(CacheControlAdapter, self).send(request, **kw)\n\n        return resp\n\n    def build_response(\n        self, request, response, from_cache=False, cacheable_methods=None\n    ):\n        \"\"\"\n        Build a response by making a request or using the cache.\n\n        This will end up calling send and returning a potentially\n        cached response\n        \"\"\"\n        cacheable = cacheable_methods or self.cacheable_methods\n        if not from_cache and request.method in cacheable:\n            # Check for any heuristics that might update headers\n            # before trying to cache.\n            if self.heuristic:\n                response = self.heuristic.apply(response)\n\n            # apply any expiration heuristics\n            if response.status == 304:\n                # We must have sent an ETag request. This could mean\n                # that we've been expired already or that we simply\n                # have an etag. In either case, we want to try and\n                # update the cache if that is the case.\n                cached_response = self.controller.update_cached_response(\n                    request, response\n                )\n\n                if cached_response is not response:\n                    from_cache = True\n\n                # We are done with the server response, read a\n                # possible response body (compliant servers will\n                # not return one, but we cannot be 100% sure) and\n                # release the connection back to the pool.\n                response.read(decode_content=False)\n                response.release_conn()\n\n                response = cached_response\n\n            # We always cache the 301 responses\n            elif response.status == 301:\n                self.controller.cache_response(request, response)\n            else:\n                # Wrap the response file with a wrapper that will cache the\n                #   response when the stream has been consumed.\n                response._fp = CallbackFileWrapper(\n                    response._fp,\n                    functools.partial(\n                        self.controller.cache_response, request, response\n                    ),\n                )\n                if response.chunked:\n                    super_update_chunk_length = response._update_chunk_length\n\n                    def _update_chunk_length(self):\n                        super_update_chunk_length()\n                        if self.chunk_left == 0:\n                            self._fp._close()\n\n                    response._update_chunk_length = types.MethodType(\n                        _update_chunk_length, response\n                    )\n\n        resp = super(CacheControlAdapter, self).build_response(request, response)\n\n        # See if we should invalidate the cache.\n        if request.method in self.invalidating_methods and resp.ok:\n            cache_url = self.controller.cache_url(request.url)\n            self.cache.delete(cache_url)\n\n        # Give the request a from_cache attr to let people use it\n        resp.from_cache = from_cache\n\n        return resp\n\n    def close(self):\n        self.cache.close()\n        super(CacheControlAdapter, self).close()\n" }
{ "repo_name": "pantsbuild/pex", "ref": "refs/heads/main", "path": "pex/vendor/_vendored/pip/pip/_vendor/cachecontrol/adapter.py", "content": "import types\nimport functools\nimport zlib\n\nfrom pip._vendor.requests.adapters import HTTPAdapter\n\nfrom .controller import CacheController\nfrom .cache import DictCache\nfrom .filewrapper import CallbackFileWrapper\n\n\nclass CacheControlAdapter(HTTPAdapter):\n    invalidating_methods = {\"PUT\", \"DELETE\"}\n\n    def __init__(\n        self,\n        cache=None,\n        cache_etags=True,\n        controller_class=None,\n        serializer=None,\n        heuristic=None,\n        cacheable_methods=None,\n        *args,\n        **kw\n    ):\n        super(CacheControlAdapter, self).__init__(*args, **kw)\n        self.cache = DictCache() if cache is None else cache\n        self.heuristic = heuristic\n        self.cacheable_methods = cacheable_methods or (\"GET\",)\n\n        controller_factory = controller_class or CacheController\n        self.controller = controller_factory(\n            self.cache, cache_etags=cache_etags, serializer=serializer\n        )\n\n    def send(self, request, cacheable_methods=None, **kw):\n        \"\"\"\n        Send a request. Use the request information to see if it\n        exists in the cache and cache the response if we need to and can.\n        \"\"\"\n        cacheable = cacheable_methods or self.cacheable_methods\n        if request.method in cacheable:\n            try:\n                cached_response = self.controller.cached_request(request)\n            except zlib.error:\n                cached_response = None\n            if cached_response:\n                return self.build_response(request, cached_response, from_cache=True)\n\n            # check for etags and add headers if appropriate\n            request.headers.update(self.controller.conditional_headers(request))\n\n        resp = super(CacheControlAdapter, self).send(request, **kw)\n\n        return resp\n\n    def build_response(\n        self, request, response, from_cache=False, cacheable_methods=None\n    ):\n        \"\"\"\n        Build a response by making a request or using the cache.\n\n        This will end up calling send and returning a potentially\n        cached response\n        \"\"\"\n        cacheable = cacheable_methods or self.cacheable_methods\n        if not from_cache and request.method in cacheable:\n            # Check for any heuristics that might update headers\n            # before trying to cache.\n            if self.heuristic:\n                response = self.heuristic.apply(response)\n\n            # apply any expiration heuristics\n            if response.status == 304:\n                # We must have sent an ETag request. This could mean\n                # that we've been expired already or that we simply\n                # have an etag. In either case, we want to try and\n                # update the cache if that is the case.\n                cached_response = self.controller.update_cached_response(\n                    request, response\n                )\n\n                if cached_response is not response:\n                    from_cache = True\n\n                # We are done with the server response, read a\n                # possible response body (compliant servers will\n                # not return one, but we cannot be 100% sure) and\n                # release the connection back to the pool.\n                response.read(decode_content=False)\n                response.release_conn()\n\n                response = cached_response\n\n            # We always cache the 301 responses\n            elif response.status == 301:\n                self.controller.cache_response(request, response)\n            else:\n                # Wrap the response file with a wrapper that will cache the\n                #   response when the stream has been consumed.\n                response._fp = CallbackFileWrapper(\n                    response._fp,\n                    functools.partial(\n                        self.controller.cache_response, request, response\n                    ),\n                )\n                if response.chunked:\n                    super_update_chunk_length = response._update_chunk_length\n\n                    def _update_chunk_length(self):\n                        super_update_chunk_length()\n                        if self.chunk_left == 0:\n                            self._fp._close()\n\n                    response._update_chunk_length = types.MethodType(\n                        _update_chunk_length, response\n                    )\n\n        resp = super(CacheControlAdapter, self).build_response(request, response)\n\n        # See if we should invalidate the cache.\n        if request.method in self.invalidating_methods and resp.ok:\n            cache_url = self.controller.cache_url(request.url)\n            self.cache.delete(cache_url)\n\n        # Give the request a from_cache attr to let people use it\n        resp.from_cache = from_cache\n\n        return resp\n\n    def close(self):\n        self.cache.close()\n        super(CacheControlAdapter, self).close()\n" }
{ "repo_name": "bjandre/ctags-fortran", "ref": "refs/heads/modern-fortran", "path": "Test/bug1856363.py", "content": "#!/usr/bin/python\n\ndef main():\n\t# A broken ctags will see a function \"initely_not_a_function\" here.\n\tdefinitely_not_a_function = 0\n\treturn\n\nif __name__ == 'main':\n\tmain()\n" }
{ "repo_name": "pfmoore/pip", "ref": "refs/heads/main", "path": "src/pip/_vendor/cachecontrol/adapter.py", "content": "import types\nimport functools\nimport zlib\n\nfrom pip._vendor.requests.adapters import HTTPAdapter\n\nfrom .controller import CacheController\nfrom .cache import DictCache\nfrom .filewrapper import CallbackFileWrapper\n\n\nclass CacheControlAdapter(HTTPAdapter):\n    invalidating_methods = {\"PUT\", \"DELETE\"}\n\n    def __init__(\n        self,\n        cache=None,\n        cache_etags=True,\n        controller_class=None,\n        serializer=None,\n        heuristic=None,\n        cacheable_methods=None,\n        *args,\n        **kw\n    ):\n        super(CacheControlAdapter, self).__init__(*args, **kw)\n        self.cache = DictCache() if cache is None else cache\n        self.heuristic = heuristic\n        self.cacheable_methods = cacheable_methods or (\"GET\",)\n\n        controller_factory = controller_class or CacheController\n        self.controller = controller_factory(\n            self.cache, cache_etags=cache_etags, serializer=serializer\n        )\n\n    def send(self, request, cacheable_methods=None, **kw):\n        \"\"\"\n        Send a request. Use the request information to see if it\n        exists in the cache and cache the response if we need to and can.\n        \"\"\"\n        cacheable = cacheable_methods or self.cacheable_methods\n        if request.method in cacheable:\n            try:\n                cached_response = self.controller.cached_request(request)\n            except zlib.error:\n                cached_response = None\n            if cached_response:\n                return self.build_response(request, cached_response, from_cache=True)\n\n            # check for etags and add headers if appropriate\n            request.headers.update(self.controller.conditional_headers(request))\n\n        resp = super(CacheControlAdapter, self).send(request, **kw)\n\n        return resp\n\n    def build_response(\n        self, request, response, from_cache=False, cacheable_methods=None\n    ):\n        \"\"\"\n        Build a response by making a request or using the cache.\n\n        This will end up calling send and returning a potentially\n        cached response\n        \"\"\"\n        cacheable = cacheable_methods or self.cacheable_methods\n        if not from_cache and request.method in cacheable:\n            # Check for any heuristics that might update headers\n            # before trying to cache.\n            if self.heuristic:\n                response = self.heuristic.apply(response)\n\n            # apply any expiration heuristics\n            if response.status == 304:\n                # We must have sent an ETag request. This could mean\n                # that we've been expired already or that we simply\n                # have an etag. In either case, we want to try and\n                # update the cache if that is the case.\n                cached_response = self.controller.update_cached_response(\n                    request, response\n                )\n\n                if cached_response is not response:\n                    from_cache = True\n\n                # We are done with the server response, read a\n                # possible response body (compliant servers will\n                # not return one, but we cannot be 100% sure) and\n                # release the connection back to the pool.\n                response.read(decode_content=False)\n                response.release_conn()\n\n                response = cached_response\n\n            # We always cache the 301 responses\n            elif response.status == 301:\n                self.controller.cache_response(request, response)\n            else:\n                # Wrap the response file with a wrapper that will cache the\n                #   response when the stream has been consumed.\n                response._fp = CallbackFileWrapper(\n                    response._fp,\n                    functools.partial(\n                        self.controller.cache_response, request, response\n                    ),\n                )\n                if response.chunked:\n                    super_update_chunk_length = response._update_chunk_length\n\n                    def _update_chunk_length(self):\n                        super_update_chunk_length()\n                        if self.chunk_left == 0:\n                            self._fp._close()\n\n                    response._update_chunk_length = types.MethodType(\n                        _update_chunk_length, response\n                    )\n\n        resp = super(CacheControlAdapter, self).build_response(request, response)\n\n        # See if we should invalidate the cache.\n        if request.method in self.invalidating_methods and resp.ok:\n            cache_url = self.controller.cache_url(request.url)\n            self.cache.delete(cache_url)\n\n        # Give the request a from_cache attr to let people use it\n        resp.from_cache = from_cache\n\n        return resp\n\n    def close(self):\n        self.cache.close()\n        super(CacheControlAdapter, self).close()\n" }
{ "repo_name": "grupozeety/CDerpnext", "ref": "refs/heads/bk_master", "path": "erpnext/stock/doctype/landed_cost_item/landed_cost_item.py", "content": "# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors\n# License: GNU General Public License v3. See license.txt\n\nfrom __future__ import unicode_literals\nimport frappe\n\nfrom frappe.model.document import Document\n\nclass LandedCostItem(Document):\n\tpass" }
{ "repo_name": "m4734/mysql_pio", "ref": "refs/heads/5.7", "path": "boost_1_59_0/tools/build/test/example_gettext.py", "content": "#!/usr/bin/python\n\n# Copyright (C) Vladimir Prus 2006.\n# Distributed under the Boost Software License, Version 1.0. (See\n# accompanying file LICENSE_1_0.txt or copy at\n# http://www.boost.org/LICENSE_1_0.txt)\n\n# Test the 'gettext' example.\n\nimport BoostBuild\nimport os\nimport string\n\nt = BoostBuild.Tester()\n\nt.set_tree(\"../example/gettext\")\n\nt.run_build_system(stderr=None)\n\nt.expect_addition([\"bin/$toolset/debug/main.exe\",\n                   \"bin/$toolset/debug/russian.mo\"])\n\nfile = t.adjust_names([\"bin/$toolset/debug/main.exe\"])[0]\n\ninput_fd = os.popen(file)\ninput = input_fd.read();\n\nt.fail_test(string.find(input, \"international hello\") != 0)\n\nt.cleanup()\n" }
{ "repo_name": "NicholasHoCode/Galaxy", "ref": "refs/heads/gh-pages", "path": "assets/code/MK.py", "content": "© Nicholas Ieng Kit Ho, 2016. All rights reserved. Cannot be copied, re-used, or edited\n\n# SAMPLE CODE\n\ndef main(k, T, filename):\n\n\twith open(filename) as f:\n\t\ttext = f.read()\n\n\tkgrams = dict()\n\tcirc_text = text + text[:k]\n\tfor i in xrange(len(text)):\n\t\tkgram = circ_text[i:i+k]\n\t\tnext_char = circ_text[i+k]\n\t\tif kgram in kgrams:\n\t\t\tkgrams[kgram].append(next_char)\n\t\telse:\n\t\t\tkgrams[kgram] = [next_char]\n\n\tcurrent = text[:k]\n\tsys.stdout.write(current)\n\tfor i in range(T-k):\n\t\tnew = random.choice(kgrams[current])\n\t\tsys.stdout.write(new)\n\t\tcurrent = current[1:]+new\n\tprint ''\n\t\nif __name__ == \"__main__\":\n\tk = sys.argv[1]\n\tT = sys.argv[2]\n\tfilename = sys.argv[3]\n\n\tk = int(k)\n\tT = int(T)\n\t\n\tmain(k,T,filename)\n\n" }
{ "repo_name": "Vauxoo/server-tools", "ref": "refs/heads/12.0", "path": "fetchmail_incoming_log/models/__init__.py", "content": "from . import mail_thread\n" }
{ "repo_name": "faceleg/ctags", "ref": "refs/heads/deploy", "path": "Test/bug1856363.py", "content": "#!/usr/bin/python\n\ndef main():\n\t# A broken ctags will see a function \"initely_not_a_function\" here.\n\tdefinitely_not_a_function = 0\n\treturn\n\nif __name__ == 'main':\n\tmain()\n" }
{ "repo_name": "h3biomed/ansible", "ref": "refs/heads/h3", "path": "lib/ansible/modules/cloud/openstack/os_network.py", "content": "#!/usr/bin/python\n\n# Copyright (c) 2014 Hewlett-Packard Development Company, L.P.\n# Copyright (c) 2013, Benno Joy <benno@ansible.com>\n# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)\n\nfrom __future__ import absolute_import, division, print_function\n__metaclass__ = type\n\n\nANSIBLE_METADATA = {'metadata_version': '1.1',\n                    'status': ['preview'],\n                    'supported_by': 'community'}\n\n\nDOCUMENTATION = '''\n---\nmodule: os_network\nshort_description: Creates/removes networks from OpenStack\nextends_documentation_fragment: openstack\nversion_added: \"2.0\"\nauthor: \"Monty Taylor (@emonty)\"\ndescription:\n   - Add or remove network from OpenStack.\noptions:\n   name:\n     description:\n        - Name to be assigned to the network.\n     required: true\n   shared:\n     description:\n        - Whether this network is shared or not.\n     type: bool\n     default: 'no'\n   admin_state_up:\n     description:\n        - Whether the state should be marked as up or down.\n     type: bool\n     default: 'yes'\n   external:\n     description:\n        - Whether this network is externally accessible.\n     type: bool\n     default: 'no'\n   state:\n     description:\n        - Indicate desired state of the resource.\n     choices: ['present', 'absent']\n     default: present\n   provider_physical_network:\n     description:\n        - The physical network where this network object is implemented.\n     version_added: \"2.1\"\n   provider_network_type:\n     description:\n        - The type of physical network that maps to this network resource.\n     version_added: \"2.1\"\n   provider_segmentation_id:\n     description:\n        - An isolated segment on the physical network. The I(network_type)\n          attribute defines the segmentation model. For example, if the\n          I(network_type) value is vlan, this ID is a vlan identifier. If\n          the I(network_type) value is gre, this ID is a gre key.\n     version_added: \"2.1\"\n   project:\n     description:\n        - Project name or ID containing the network (name admin-only)\n     version_added: \"2.1\"\n   availability_zone:\n     description:\n       - Ignored. Present for backwards compatibility\n   port_security_enabled:\n     description:\n        -  Whether port security is enabled on the network or not.\n           Network will use OpenStack defaults if this option is\n           not utilised.\n     type: bool\n     version_added: \"2.8\"\nrequirements:\n     - \"openstacksdk\"\n'''\n\nEXAMPLES = '''\n# Create an externally accessible network named 'ext_network'.\n- os_network:\n    cloud: mycloud\n    state: present\n    name: ext_network\n    external: true\n'''\n\nRETURN = '''\nnetwork:\n    description: Dictionary describing the network.\n    returned: On success when I(state) is 'present'.\n    type: complex\n    contains:\n        id:\n            description: Network ID.\n            type: str\n            sample: \"4bb4f9a5-3bd2-4562-bf6a-d17a6341bb56\"\n        name:\n            description: Network name.\n            type: str\n            sample: \"ext_network\"\n        shared:\n            description: Indicates whether this network is shared across all tenants.\n            type: bool\n            sample: false\n        status:\n            description: Network status.\n            type: str\n            sample: \"ACTIVE\"\n        mtu:\n            description: The MTU of a network resource.\n            type: int\n            sample: 0\n        admin_state_up:\n            description: The administrative state of the network.\n            type: bool\n            sample: true\n        port_security_enabled:\n            description: The port security status\n            type: bool\n            sample: true\n        router:external:\n            description: Indicates whether this network is externally accessible.\n            type: bool\n            sample: true\n        tenant_id:\n            description: The tenant ID.\n            type: str\n            sample: \"06820f94b9f54b119636be2728d216fc\"\n        subnets:\n            description: The associated subnets.\n            type: list\n            sample: []\n        \"provider:physical_network\":\n            description: The physical network where this network object is implemented.\n            type: str\n            sample: my_vlan_net\n        \"provider:network_type\":\n            description: The type of physical network that maps to this network resource.\n            type: str\n            sample: vlan\n        \"provider:segmentation_id\":\n            description: An isolated segment on the physical network.\n            type: str\n            sample: 101\n'''\n\nfrom ansible.module_utils.basic import AnsibleModule\nfrom ansible.module_utils.openstack import openstack_full_argument_spec, openstack_module_kwargs, openstack_cloud_from_module\n\n\ndef main():\n    argument_spec = openstack_full_argument_spec(\n        name=dict(required=True),\n        shared=dict(default=False, type='bool'),\n        admin_state_up=dict(default=True, type='bool'),\n        external=dict(default=False, type='bool'),\n        provider_physical_network=dict(required=False),\n        provider_network_type=dict(required=False),\n        provider_segmentation_id=dict(required=False, type='int'),\n        state=dict(default='present', choices=['absent', 'present']),\n        project=dict(default=None),\n        port_security_enabled=dict(type='bool')\n    )\n\n    module_kwargs = openstack_module_kwargs()\n    module = AnsibleModule(argument_spec, **module_kwargs)\n\n    state = module.params['state']\n    name = module.params['name']\n    shared = module.params['shared']\n    admin_state_up = module.params['admin_state_up']\n    external = module.params['external']\n    provider_physical_network = module.params['provider_physical_network']\n    provider_network_type = module.params['provider_network_type']\n    provider_segmentation_id = module.params['provider_segmentation_id']\n    project = module.params.get('project')\n    port_security_enabled = module.params.get('port_security_enabled')\n\n    sdk, cloud = openstack_cloud_from_module(module)\n    try:\n        if project is not None:\n            proj = cloud.get_project(project)\n            if proj is None:\n                module.fail_json(msg='Project %s could not be found' % project)\n            project_id = proj['id']\n            filters = {'tenant_id': project_id}\n        else:\n            project_id = None\n            filters = None\n        net = cloud.get_network(name, filters=filters)\n\n        if state == 'present':\n            if not net:\n                provider = {}\n                if provider_physical_network:\n                    provider['physical_network'] = provider_physical_network\n                if provider_network_type:\n                    provider['network_type'] = provider_network_type\n                if provider_segmentation_id:\n                    provider['segmentation_id'] = provider_segmentation_id\n\n                if project_id is not None:\n                    net = cloud.create_network(name, shared, admin_state_up,\n                                               external, provider, project_id,\n                                               port_security_enabled=port_security_enabled)\n                else:\n                    net = cloud.create_network(name, shared, admin_state_up,\n                                               external, provider,\n                                               port_security_enabled=port_security_enabled)\n                changed = True\n            else:\n                changed = False\n            module.exit_json(changed=changed, network=net, id=net['id'])\n\n        elif state == 'absent':\n            if not net:\n                module.exit_json(changed=False)\n            else:\n                cloud.delete_network(name)\n                module.exit_json(changed=True)\n\n    except sdk.exceptions.OpenStackCloudException as e:\n        module.fail_json(msg=str(e))\n\n\nif __name__ == \"__main__\":\n    main()\n" }
{ "repo_name": "sinojelly/ctags", "ref": "refs/heads/deploy_for_android", "path": "Test/bug1856363.py", "content": "#!/usr/bin/python\n\ndef main():\n\t# A broken ctags will see a function \"initely_not_a_function\" here.\n\tdefinitely_not_a_function = 0\n\treturn\n\nif __name__ == 'main':\n\tmain()\n" }
{ "repo_name": "gknops/ctags", "ref": "refs/heads/deploy", "path": "Test/bug1856363.py", "content": "#!/usr/bin/python\n\ndef main():\n\t# A broken ctags will see a function \"initely_not_a_function\" here.\n\tdefinitely_not_a_function = 0\n\treturn\n\nif __name__ == 'main':\n\tmain()\n" }
{ "repo_name": "talha131/ctags", "ref": "refs/heads/deploy", "path": "Test/bug1856363.py", "content": "#!/usr/bin/python\n\ndef main():\n\t# A broken ctags will see a function \"initely_not_a_function\" here.\n\tdefinitely_not_a_function = 0\n\treturn\n\nif __name__ == 'main':\n\tmain()\n" }
{ "repo_name": "sbidoul/pip", "ref": "refs/heads/main", "path": "src/pip/_vendor/cachecontrol/adapter.py", "content": "import types\nimport functools\nimport zlib\n\nfrom pip._vendor.requests.adapters import HTTPAdapter\n\nfrom .controller import CacheController\nfrom .cache import DictCache\nfrom .filewrapper import CallbackFileWrapper\n\n\nclass CacheControlAdapter(HTTPAdapter):\n    invalidating_methods = {\"PUT\", \"DELETE\"}\n\n    def __init__(\n        self,\n        cache=None,\n        cache_etags=True,\n        controller_class=None,\n        serializer=None,\n        heuristic=None,\n        cacheable_methods=None,\n        *args,\n        **kw\n    ):\n        super(CacheControlAdapter, self).__init__(*args, **kw)\n        self.cache = DictCache() if cache is None else cache\n        self.heuristic = heuristic\n        self.cacheable_methods = cacheable_methods or (\"GET\",)\n\n        controller_factory = controller_class or CacheController\n        self.controller = controller_factory(\n            self.cache, cache_etags=cache_etags, serializer=serializer\n        )\n\n    def send(self, request, cacheable_methods=None, **kw):\n        \"\"\"\n        Send a request. Use the request information to see if it\n        exists in the cache and cache the response if we need to and can.\n        \"\"\"\n        cacheable = cacheable_methods or self.cacheable_methods\n        if request.method in cacheable:\n            try:\n                cached_response = self.controller.cached_request(request)\n            except zlib.error:\n                cached_response = None\n            if cached_response:\n                return self.build_response(request, cached_response, from_cache=True)\n\n            # check for etags and add headers if appropriate\n            request.headers.update(self.controller.conditional_headers(request))\n\n        resp = super(CacheControlAdapter, self).send(request, **kw)\n\n        return resp\n\n    def build_response(\n        self, request, response, from_cache=False, cacheable_methods=None\n    ):\n        \"\"\"\n        Build a response by making a request or using the cache.\n\n        This will end up calling send and returning a potentially\n        cached response\n        \"\"\"\n        cacheable = cacheable_methods or self.cacheable_methods\n        if not from_cache and request.method in cacheable:\n            # Check for any heuristics that might update headers\n            # before trying to cache.\n            if self.heuristic:\n                response = self.heuristic.apply(response)\n\n            # apply any expiration heuristics\n            if response.status == 304:\n                # We must have sent an ETag request. This could mean\n                # that we've been expired already or that we simply\n                # have an etag. In either case, we want to try and\n                # update the cache if that is the case.\n                cached_response = self.controller.update_cached_response(\n                    request, response\n                )\n\n                if cached_response is not response:\n                    from_cache = True\n\n                # We are done with the server response, read a\n                # possible response body (compliant servers will\n                # not return one, but we cannot be 100% sure) and\n                # release the connection back to the pool.\n                response.read(decode_content=False)\n                response.release_conn()\n\n                response = cached_response\n\n            # We always cache the 301 responses\n            elif response.status == 301:\n                self.controller.cache_response(request, response)\n            else:\n                # Wrap the response file with a wrapper that will cache the\n                #   response when the stream has been consumed.\n                response._fp = CallbackFileWrapper(\n                    response._fp,\n                    functools.partial(\n                        self.controller.cache_response, request, response\n                    ),\n                )\n                if response.chunked:\n                    super_update_chunk_length = response._update_chunk_length\n\n                    def _update_chunk_length(self):\n                        super_update_chunk_length()\n                        if self.chunk_left == 0:\n                            self._fp._close()\n\n                    response._update_chunk_length = types.MethodType(\n                        _update_chunk_length, response\n                    )\n\n        resp = super(CacheControlAdapter, self).build_response(request, response)\n\n        # See if we should invalidate the cache.\n        if request.method in self.invalidating_methods and resp.ok:\n            cache_url = self.controller.cache_url(request.url)\n            self.cache.delete(cache_url)\n\n        # Give the request a from_cache attr to let people use it\n        resp.from_cache = from_cache\n\n        return resp\n\n    def close(self):\n        self.cache.close()\n        super(CacheControlAdapter, self).close()\n" }
{ "repo_name": "gangadhar-kadam/latestchurcherp", "ref": "refs/heads/v5.0", "path": "erpnext/stock/doctype/landed_cost_item/landed_cost_item.py", "content": "# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors\n# License: GNU General Public License v3. See license.txt\n\nfrom __future__ import unicode_literals\nimport frappe\n\nfrom frappe.model.document import Document\n\nclass LandedCostItem(Document):\n\tpass" }
{ "repo_name": "attila-v/geany", "ref": "refs/heads/feature/reload-all", "path": "tests/ctags/bug1856363.py", "content": "#!/usr/bin/python\n\ndef main():\n\t# A broken ctags will see a function \"initely_not_a_function\" here.\n\tdefinitely_not_a_function = 0\n\treturn\n\nif __name__ == 'main':\n\tmain()\n" }
{ "repo_name": "jameslord/ctags", "ref": "refs/heads/lab_master", "path": "Test/bug1856363.py", "content": "#!/usr/bin/python\n\ndef main():\n\t# A broken ctags will see a function \"initely_not_a_function\" here.\n\tdefinitely_not_a_function = 0\n\treturn\n\nif __name__ == 'main':\n\tmain()\n" }
{ "repo_name": "gangadhar-kadam/verve_test_erp", "ref": "refs/heads/v5.0", "path": "erpnext/stock/doctype/landed_cost_item/landed_cost_item.py", "content": "# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors\n# License: GNU General Public License v3. See license.txt\n\nfrom __future__ import unicode_literals\nimport frappe\n\nfrom frappe.model.document import Document\n\nclass LandedCostItem(Document):\n\tpass" }
{ "repo_name": "koron/ctags", "ref": "refs/heads/vc10", "path": "Units/review-needed.r/bug1856363.py.t/input.py", "content": "#!/usr/bin/python\n\ndef main():\n\t# A broken ctags will see a function \"initely_not_a_function\" here.\n\tdefinitely_not_a_function = 0\n\treturn\n\nif __name__ == 'main':\n\tmain()\n" }
{ "repo_name": "OCA/server-tools", "ref": "refs/heads/12.0", "path": "fetchmail_incoming_log/models/__init__.py", "content": "from . import mail_thread\n" }
{ "repo_name": "bmya/server-tools", "ref": "refs/heads/11.0", "path": "fetchmail_incoming_log/models/__init__.py", "content": "from . import mail_thread\n" } 
{ "repo_name": "mmorearty/ctags", "ref": "refs/heads/deploy", "path": "Test/bug1856363.py", "content": "#!/usr/bin/python\n\ndef main():\n\t# A broken ctags will see a function \"initely_not_a_function\" here.\n\tdefinitely_not_a_function = 0\n\treturn\n\nif __name__ == 'main':\n\tmain()\n" } 
{ "repo_name": "gangadhar-kadam/verve_live_erp", "ref": "refs/heads/v5.0", "path": "erpnext/stock/doctype/landed_cost_item/landed_cost_item.py", "content": "# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors\n# License: GNU General Public License v3. See license.txt\n\nfrom __future__ import unicode_literals\nimport frappe\n\nfrom frappe.model.document import Document\n\nclass LandedCostItem(Document):\n\tpass" } 
{ "repo_name": "b4n/fishman-ctags", "ref": "refs/heads/deploy", "path": "Test/bug1856363.py", "content": "#!/usr/bin/python\n\ndef main():\n\t# A broken ctags will see a function \"initely_not_a_function\" here.\n\tdefinitely_not_a_function = 0\n\treturn\n\nif __name__ == 'main':\n\tmain()\n" }
{ "repo_name": "pfalcon/micropython", "ref": "refs/heads/pfalcon", "path": "tests/basics/list_compare_instances.py", "content": "# Test that comparisons of instance sequences use exactly the operation\n# specified on instances themselves.\n\nclass A:\n\n    def __lt__(self, other):\n        print(\"A.__lt__\")\n        return True\n\nclass B:\n\n    def __gt__(self, other):\n        print(\"B.__gt__\")\n        return True\n\n\nprint([A()] < [A()])\n\nprint([B()] > [B()])\n" }
{ "repo_name": "dphase/ctags", "ref": "refs/heads/deploy", "path": "Test/bug1856363.py", "content": "#!/usr/bin/python\n\ndef main():\n\t# A broken ctags will see a function \"initely_not_a_function\" here.\n\tdefinitely_not_a_function = 0\n\treturn\n\nif __name__ == 'main':\n\tmain()\n" }
{ "repo_name": "vhda/ctags", "ref": "refs/heads/deploy", "path": "Test/bug1856363.py", "content": "#!/usr/bin/python\n\ndef main():\n\t# A broken ctags will see a function \"initely_not_a_function\" here.\n\tdefinitely_not_a_function = 0\n\treturn\n\nif __name__ == 'main':\n\tmain()\n" }
{ "repo_name": "libracore/erpnext", "ref": "refs/heads/v12", "path": "erpnext/stock/doctype/landed_cost_item/landed_cost_item.py", "content": "# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors\n# License: GNU General Public License v3. See license.txt\n\nfrom __future__ import unicode_literals\nimport frappe\n\nfrom frappe.model.document import Document\n\nclass LandedCostItem(Document):\n\tpass" }
{ "repo_name": "pombredanne/ctags", "ref": "refs/heads/deploy", "path": "Test/bug1856363.py", "content": "#!/usr/bin/python\n\ndef main():\n\t# A broken ctags will see a function \"initely_not_a_function\" here.\n\tdefinitely_not_a_function = 0\n\treturn\n\nif __name__ == 'main':\n\tmain()\n" }
{ "repo_name": "gangadharkadam/verveerp", "ref": "refs/heads/v5.0", "path": "erpnext/stock/doctype/landed_cost_item/landed_cost_item.py", "content": "# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors\n# License: GNU General Public License v3. See license.txt\n\nfrom __future__ import unicode_literals\nimport frappe\n\nfrom frappe.model.document import Document\n\nclass LandedCostItem(Document):\n\tpass" }
{ "repo_name": "laborautonomo/poedit", "ref": "refs/heads/stable", "path": "deps/boost/tools/build/v2/test/example_gettext.py", "content": "#!/usr/bin/python\n\n# Copyright (C) Vladimir Prus 2006.\n# Distributed under the Boost Software License, Version 1.0. (See\n# accompanying file LICENSE_1_0.txt or copy at\n# http://www.boost.org/LICENSE_1_0.txt)\n\n# Test the 'gettext' example.\n\nimport BoostBuild\nimport os\nimport string\n\nt = BoostBuild.Tester()\n\nt.set_tree(\"../example/gettext\")\n\nt.run_build_system(stderr=None)\n\nt.expect_addition([\"bin/$toolset/debug/main.exe\",\n                   \"bin/$toolset/debug/russian.mo\"])\n\nfile = t.adjust_names([\"bin/$toolset/debug/main.exe\"])[0]\n\ninput_fd = os.popen(file)\ninput = input_fd.read();\n\nt.fail_test(string.find(input, \"international hello\") != 0)\n\nt.cleanup()\n" }
{ "repo_name": "OCA/social", "ref": "refs/heads/12.0", "path": "mail_track_diff_only/models/__init__.py", "content": "from . import mail_thread\n" }
{ "repo_name": "kojiagile/CLAtoolkit", "ref": "refs/heads/koji", "path": "clatoolkit_project/xapi/tincan/substatement.py", "content": "# Copyright 2014 Rustici Software\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n#    you may not use this file except in compliance with the License.\n#    You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS,\n#    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#    See the License for the specific language governing permissions and\n#    limitations under the License.\n\nfrom tincan.statement_base import StatementBase\nfrom tincan.agent import Agent\nfrom tincan.group import Group\nfrom tincan.activity import Activity\n\n\nclass SubStatement(StatementBase):\n    _props_req = [\n        'object_type'\n    ]\n\n    _props = []\n\n    _props.extend(StatementBase._props)\n    _props.extend(_props_req)\n\n    def __init__(self, *args, **kwargs):\n        self._object_type = None\n\n        super(SubStatement, self).__init__(*args, **kwargs)\n\n    @property\n    def object(self):\n        \"\"\"Object for SubStatement\n\n        :setter: Setter for object\n        :setter type: :class:`tincan.Agent` | :class:`tincan.Group` | :class:`tincan.Activity`\n        :rtype: :class:`tincan.Agent` | :class:`tincan.Group` | :class:`tincan.Activity`\n\n        \"\"\"\n        return self._object\n\n    @object.setter\n    def object(self, value):\n        if value is not None and \\\n                not isinstance(value, Agent) and \\\n                not isinstance(value, Group) and \\\n                not isinstance(value, Activity):\n            if isinstance(value, dict):\n                if 'object_type' in value or 'objectType' in value:\n                    if 'objectType' in value:\n                        value['object_type'] = value['objectType']\n                        value.pop('objectType')\n                    if value['object_type'] == 'Agent':\n                        value = Agent(value)\n                    elif value['object_type'] == 'Activity':\n                        value = Activity(value)\n                    elif value['object_type'] == 'Group':\n                        value = Group(value)\n                    else:\n                        value = Activity(value)\n                else:\n                    value = Activity(value)\n        self._object = value\n\n    @object.deleter\n    def object(self):\n        del self._object\n\n    @property\n    def object_type(self):\n        \"\"\"Object Type for SubStatement. Will always be \"SubStatement\"\n\n        :setter: Tries to convert to unicode\n        :setter type: unicode\n        :rtype: unicode\n\n        \"\"\"\n        return self._object_type\n\n    @object_type.setter\n    def object_type(self, _):\n        self._object_type = 'SubStatement'\n" }
{ "repo_name": "grogers0/ctags", "ref": "refs/heads/asn", "path": "Test/bug1856363.py", "content": "#!/usr/bin/python\n\ndef main():\n\t# A broken ctags will see a function \"initely_not_a_function\" here.\n\tdefinitely_not_a_function = 0\n\treturn\n\nif __name__ == 'main':\n\tmain()\n" }
{ "repo_name": "aldariz/Sick-Beard", "ref": "refs/heads/torrent_1080_subtitles", "path": "sickbeard/notifiers/nmjv2.py", "content": "# Author: Jasper Lanting\r\n# Based on nmj.py by Nico Berlee: http://nico.berlee.nl/\r\n# URL: http://code.google.com/p/sickbeard/\r\n#\r\n# This file is part of Sick Beard.\r\n#\r\n# Sick Beard is free software: you can redistribute it and/or modify\r\n# it under the terms of the GNU General Public License as published by\r\n# the Free Software Foundation, either version 3 of the License, or\r\n# (at your option) any later version.\r\n#\r\n# Sick Beard is distributed in the hope that it will be useful,\r\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\r\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\r\n#  GNU General Public License for more details.\r\n#\r\n# You should have received a copy of the GNU General Public License\r\n# along with Sick Beard.  If not, see <http://www.gnu.org/licenses/>.\r\n\r\nimport urllib2\r\nfrom xml.dom.minidom import parseString\r\nimport sickbeard\r\nimport time\r\n\r\nfrom sickbeard import logger\r\n\r\ntry:\r\n    import xml.etree.cElementTree as etree\r\nexcept ImportError:\r\n    import xml.etree.ElementTree as etree\r\n\r\n\r\nclass NMJv2Notifier:\r\n\r\n    def notify_settings(self, host, dbloc, instance):\r\n        \"\"\"\r\n        Retrieves the NMJv2 database location from Popcorn Hour\r\n\r\n        host: The hostname/IP of the Popcorn Hour server\r\n        dbloc: 'local' for PCH internal harddrive. 'network' for PCH network shares\r\n        instance: Allows for selection of different DB in case of multiple databases\r\n\r\n        Returns: True if the settings were retrieved successfully, False otherwise\r\n        \"\"\"\r\n        try:\r\n            url_loc = \"http://\" + host + \":8008/file_operation?arg0=list_user_storage_file&arg1=&arg2=\" + instance + \"&arg3=20&arg4=true&arg5=true&arg6=true&arg7=all&arg8=name_asc&arg9=false&arg10=false\"\r\n            req = urllib2.Request(url_loc)\r\n            handle1 = urllib2.urlopen(req)\r\n            response1 = handle1.read()\r\n            # TODO: convert to etree?\r\n            xml = parseString(response1)\r\n            time.sleep(0.5)\r\n            for node in xml.getElementsByTagName('path'):\r\n                xmlTag = node.toxml()\r\n                xmlData = xmlTag.replace('<path>', '').replace('</path>', '').replace('[=]', '')\r\n                url_db = \"http://\" + host + \":8008/metadata_database?arg0=check_database&arg1=\" + xmlData\r\n                reqdb = urllib2.Request(url_db)\r\n                handledb = urllib2.urlopen(reqdb)\r\n                responsedb = handledb.read()\r\n                xmldb = parseString(responsedb)\r\n                returnvalue = xmldb.getElementsByTagName('returnValue')[0].toxml().replace('<returnValue>', '').replace('</returnValue>', '')\r\n                if returnvalue == \"0\":\r\n                    DB_path = xmldb.getElementsByTagName('database_path')[0].toxml().replace('<database_path>', '').replace('</database_path>', '').replace('[=]', '')\r\n                    if dbloc == \"local\" and DB_path.find(\"localhost\") > -1:\r\n                        sickbeard.NMJv2_HOST = host\r\n                        sickbeard.NMJv2_DATABASE = DB_path\r\n                        return True\r\n                    if dbloc == \"network\" and DB_path.find(\"://\") > -1:\r\n                        sickbeard.NMJv2_HOST = host\r\n                        sickbeard.NMJv2_DATABASE = DB_path\r\n                        return True\r\n        except IOError, e:\r\n            logger.log(u\"NMJv2: Could not contact Popcorn Hour on host %s: %s\" % (host, e), logger.WARNING)\r\n            return False\r\n\r\n        return False\r\n\r\n    def _sendNMJ(self, host):\r\n        \"\"\"\r\n        Sends a NMJ update command to the specified machine\r\n\r\n        host: The hostname/IP to send the request to (no port)\r\n        database: The database to send the request to\r\n        mount: The mount URL to use (optional)\r\n\r\n        Returns: True if the request succeeded, False otherwise\r\n        \"\"\"\r\n\r\n        #if a host is provided then attempt to open a handle to that URL\r\n        try:\r\n            url_scandir = \"http://\" + host + \":8008/metadata_database?arg0=update_scandir&arg1=\" + sickbeard.NMJv2_DATABASE + \"&arg2=&arg3=update_all\"\r\n            logger.log(u\"NMJv2: Scan update command send to host: %s\" % (host), logger.DEBUG)\r\n            url_updatedb = \"http://\" + host + \":8008/metadata_database?arg0=scanner_start&arg1=\" + sickbeard.NMJv2_DATABASE + \"&arg2=background&arg3=\"\r\n            logger.log(u\"NMJv2: Try to mount network drive via url: %s\" % (host), logger.DEBUG)\r\n            prereq = urllib2.Request(url_scandir)\r\n            req = urllib2.Request(url_updatedb)\r\n            handle1 = urllib2.urlopen(prereq)\r\n            response1 = handle1.read()\r\n            time.sleep(0.5)\r\n            handle2 = urllib2.urlopen(req)\r\n            response2 = handle2.read()\r\n        except IOError, e:\r\n            logger.log(u\"NMJv2: Could not contact Popcorn Hour on host %s: %s\" % (host, e), logger.WARNING)\r\n            return False\r\n\r\n        try:\r\n            et = etree.fromstring(response1)\r\n            result1 = et.findtext(\"returnValue\")\r\n        except SyntaxError, e:\r\n            logger.log(u\"NMJv2: Unable to parse XML returned from the Popcorn Hour: update_scandir, %s\" % (e), logger.ERROR)\r\n            return False\r\n\r\n        try:\r\n            et = etree.fromstring(response2)\r\n            result2 = et.findtext(\"returnValue\")\r\n        except SyntaxError, e:\r\n            logger.log(u\"NMJv2: Unable to parse XML returned from the Popcorn Hour: scanner_start, %s\" % (e), logger.ERROR)\r\n            return False\r\n\r\n        # if the result was a number then consider that an error\r\n        error_codes = [\"8\", \"11\", \"22\", \"49\", \"50\", \"51\", \"60\"]\r\n        error_messages = [\"Invalid parameter(s)/argument(s)\",\r\n                        \"Invalid database path\",\r\n                        \"Insufficient size\",\r\n                        \"Database write error\",\r\n                        \"Database read error\",\r\n                        \"Open fifo pipe failed\",\r\n                        \"Read only file system\"]\r\n\r\n        if int(result1) > 0:\r\n            index = error_codes.index(result1)\r\n            logger.log(u\"NMJv2: Popcorn Hour returned an error: %s\" % (error_messages[index]), logger.ERROR)\r\n            return False\r\n        else:\r\n            if int(result2) > 0:\r\n                index = error_codes.index(result2)\r\n                logger.log(u\"NMJv2: Popcorn Hour returned an error: %s\" % (error_messages[index]), logger.ERROR)\r\n                return False\r\n            else:\r\n                logger.log(u\"NMJv2: Started background scan.\", logger.MESSAGE)\r\n                return True\r\n\r\n    def _notifyNMJ(self, host=None, force=False):\r\n        \"\"\"\r\n        Sends a NMJ update command based on the SB config settings\r\n\r\n        host: The host to send the command to (optional, defaults to the host in the config)\r\n        database: The database to use (optional, defaults to the database in the config)\r\n        mount: The mount URL (optional, defaults to the mount URL in the config)\r\n        force: If True then the notification will be sent even if NMJ is disabled in the config\r\n        \"\"\"\r\n        # suppress notifications if the notifier is disabled but the notify options are checked\r\n        if not sickbeard.USE_NMJv2 and not force:\r\n            return False\r\n\r\n        # fill in omitted parameters\r\n        if not host:\r\n            host = sickbeard.NMJv2_HOST\r\n\r\n        logger.log(u\"NMJv2: Sending scan command.\", logger.DEBUG)\r\n\r\n        return self._sendNMJ(host)\r\n\r\n##############################################################################\r\n# Public functions\r\n##############################################################################\r\n\r\n    def notify_snatch(self, ep_name):\r\n        pass\r\n\r\n    def notify_download(self, ep_name):\r\n        pass\r\n\r\n    def test_notify(self, host):\r\n        return self._notifyNMJ(host, force=True)\r\n\r\n    def update_library(self, ep_obj=None):\r\n        if sickbeard.USE_NMJv2:\r\n            self._notifyNMJ()\r\n\r\nnotifier = NMJv2Notifier\r\n" }
{ "repo_name": "dednal/chromium.src", "ref": "refs/heads/nw12", "path": "chrome/test/chromedriver/embed_version_in_cpp.py", "content": "#!/usr/bin/env python\n# Copyright 2013 The Chromium Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"Embeds Chrome user data files in C++ code.\"\"\"\n\nimport optparse\nimport os\nimport re\nimport sys\n\nimport chrome_paths\nimport cpp_source\n\nsys.path.insert(0, os.path.join(chrome_paths.GetSrc(), 'build', 'util'))\nimport lastchange\n\n\ndef main():\n  parser = optparse.OptionParser()\n  parser.add_option('', '--version-file')\n  parser.add_option(\n      '', '--directory', type='string', default='.',\n      help='Path to directory where the cc/h  file should be created')\n  options, args = parser.parse_args()\n\n  version = open(options.version_file, 'r').read().strip()\n  revision = lastchange.FetchVersionInfo(None).revision\n\n  if revision:\n    match = re.match('([0-9a-fA-F]+)(-refs/heads/master@{#(\\d+)})?', revision)\n    if match:\n      git_hash = match.group(1)\n      commit_position = match.group(3)\n      if commit_position:\n        version += '.' + commit_position\n      version += ' (%s)' % git_hash\n    else:\n      version += ' (%s)' % revision\n\n  global_string_map = {\n      'kChromeDriverVersion': version\n}\n  cpp_source.WriteSource('version',\n                         'chrome/test/chromedriver',\n                         options.directory, global_string_map)\n\n\nif __name__ == '__main__':\n  sys.exit(main())\n\n" }
{ "repo_name": "LokiCoder/Sick-Beard", "ref": "refs/heads/torrent_1080_subtitles", "path": "sickbeard/notifiers/nmjv2.py", "content": "# Author: Jasper Lanting\r\n# Based on nmj.py by Nico Berlee: http://nico.berlee.nl/\r\n# URL: http://code.google.com/p/sickbeard/\r\n#\r\n# This file is part of Sick Beard.\r\n#\r\n# Sick Beard is free software: you can redistribute it and/or modify\r\n# it under the terms of the GNU General Public License as published by\r\n# the Free Software Foundation, either version 3 of the License, or\r\n# (at your option) any later version.\r\n#\r\n# Sick Beard is distributed in the hope that it will be useful,\r\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\r\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\r\n#  GNU General Public License for more details.\r\n#\r\n# You should have received a copy of the GNU General Public License\r\n# along with Sick Beard.  If not, see <http://www.gnu.org/licenses/>.\r\n\r\nimport urllib2\r\nfrom xml.dom.minidom import parseString\r\nimport sickbeard\r\nimport time\r\n\r\nfrom sickbeard import logger\r\n\r\ntry:\r\n    import xml.etree.cElementTree as etree\r\nexcept ImportError:\r\n    import xml.etree.ElementTree as etree\r\n\r\n\r\nclass NMJv2Notifier:\r\n\r\n    def notify_settings(self, host, dbloc, instance):\r\n        \"\"\"\r\n        Retrieves the NMJv2 database location from Popcorn Hour\r\n\r\n        host: The hostname/IP of the Popcorn Hour server\r\n        dbloc: 'local' for PCH internal harddrive. 'network' for PCH network shares\r\n        instance: Allows for selection of different DB in case of multiple databases\r\n\r\n        Returns: True if the settings were retrieved successfully, False otherwise\r\n        \"\"\"\r\n        try:\r\n            url_loc = \"http://\" + host + \":8008/file_operation?arg0=list_user_storage_file&arg1=&arg2=\" + instance + \"&arg3=20&arg4=true&arg5=true&arg6=true&arg7=all&arg8=name_asc&arg9=false&arg10=false\"\r\n            req = urllib2.Request(url_loc)\r\n            handle1 = urllib2.urlopen(req)\r\n            response1 = handle1.read()\r\n            # TODO: convert to etree?\r\n            xml = parseString(response1)\r\n            time.sleep(0.5)\r\n            for node in xml.getElementsByTagName('path'):\r\n                xmlTag = node.toxml()\r\n                xmlData = xmlTag.replace('<path>', '').replace('</path>', '').replace('[=]', '')\r\n                url_db = \"http://\" + host + \":8008/metadata_database?arg0=check_database&arg1=\" + xmlData\r\n                reqdb = urllib2.Request(url_db)\r\n                handledb = urllib2.urlopen(reqdb)\r\n                responsedb = handledb.read()\r\n                xmldb = parseString(responsedb)\r\n                returnvalue = xmldb.getElementsByTagName('returnValue')[0].toxml().replace('<returnValue>', '').replace('</returnValue>', '')\r\n                if returnvalue == \"0\":\r\n                    DB_path = xmldb.getElementsByTagName('database_path')[0].toxml().replace('<database_path>', '').replace('</database_path>', '').replace('[=]', '')\r\n                    if dbloc == \"local\" and DB_path.find(\"localhost\") > -1:\r\n                        sickbeard.NMJv2_HOST = host\r\n                        sickbeard.NMJv2_DATABASE = DB_path\r\n                        return True\r\n                    if dbloc == \"network\" and DB_path.find(\"://\") > -1:\r\n                        sickbeard.NMJv2_HOST = host\r\n                        sickbeard.NMJv2_DATABASE = DB_path\r\n                        return True\r\n        except IOError, e:\r\n            logger.log(u\"NMJv2: Could not contact Popcorn Hour on host %s: %s\" % (host, e), logger.WARNING)\r\n            return False\r\n\r\n        return False\r\n\r\n    def _sendNMJ(self, host):\r\n        \"\"\"\r\n        Sends a NMJ update command to the specified machine\r\n\r\n        host: The hostname/IP to send the request to (no port)\r\n        database: The database to send the request to\r\n        mount: The mount URL to use (optional)\r\n\r\n        Returns: True if the request succeeded, False otherwise\r\n        \"\"\"\r\n\r\n        #if a host is provided then attempt to open a handle to that URL\r\n        try:\r\n            url_scandir = \"http://\" + host + \":8008/metadata_database?arg0=update_scandir&arg1=\" + sickbeard.NMJv2_DATABASE + \"&arg2=&arg3=update_all\"\r\n            logger.log(u\"NMJv2: Scan update command send to host: %s\" % (host), logger.DEBUG)\r\n            url_updatedb = \"http://\" + host + \":8008/metadata_database?arg0=scanner_start&arg1=\" + sickbeard.NMJv2_DATABASE + \"&arg2=background&arg3=\"\r\n            logger.log(u\"NMJv2: Try to mount network drive via url: %s\" % (host), logger.DEBUG)\r\n            prereq = urllib2.Request(url_scandir)\r\n            req = urllib2.Request(url_updatedb)\r\n            handle1 = urllib2.urlopen(prereq)\r\n            response1 = handle1.read()\r\n            time.sleep(0.5)\r\n            handle2 = urllib2.urlopen(req)\r\n            response2 = handle2.read()\r\n        except IOError, e:\r\n            logger.log(u\"NMJv2: Could not contact Popcorn Hour on host %s: %s\" % (host, e), logger.WARNING)\r\n            return False\r\n\r\n        try:\r\n            et = etree.fromstring(response1)\r\n            result1 = et.findtext(\"returnValue\")\r\n        except SyntaxError, e:\r\n            logger.log(u\"NMJv2: Unable to parse XML returned from the Popcorn Hour: update_scandir, %s\" % (e), logger.ERROR)\r\n            return False\r\n\r\n        try:\r\n            et = etree.fromstring(response2)\r\n            result2 = et.findtext(\"returnValue\")\r\n        except SyntaxError, e:\r\n            logger.log(u\"NMJv2: Unable to parse XML returned from the Popcorn Hour: scanner_start, %s\" % (e), logger.ERROR)\r\n            return False\r\n\r\n        # if the result was a number then consider that an error\r\n        error_codes = [\"8\", \"11\", \"22\", \"49\", \"50\", \"51\", \"60\"]\r\n        error_messages = [\"Invalid parameter(s)/argument(s)\",\r\n                        \"Invalid database path\",\r\n                        \"Insufficient size\",\r\n                        \"Database write error\",\r\n                        \"Database read error\",\r\n                        \"Open fifo pipe failed\",\r\n                        \"Read only file system\"]\r\n\r\n        if int(result1) > 0:\r\n            index = error_codes.index(result1)\r\n            logger.log(u\"NMJv2: Popcorn Hour returned an error: %s\" % (error_messages[index]), logger.ERROR)\r\n            return False\r\n        else:\r\n            if int(result2) > 0:\r\n                index = error_codes.index(result2)\r\n                logger.log(u\"NMJv2: Popcorn Hour returned an error: %s\" % (error_messages[index]), logger.ERROR)\r\n                return False\r\n            else:\r\n                logger.log(u\"NMJv2: Started background scan.\", logger.MESSAGE)\r\n                return True\r\n\r\n    def _notifyNMJ(self, host=None, force=False):\r\n        \"\"\"\r\n        Sends a NMJ update command based on the SB config settings\r\n\r\n        host: The host to send the command to (optional, defaults to the host in the config)\r\n        database: The database to use (optional, defaults to the database in the config)\r\n        mount: The mount URL (optional, defaults to the mount URL in the config)\r\n        force: If True then the notification will be sent even if NMJ is disabled in the config\r\n        \"\"\"\r\n        # suppress notifications if the notifier is disabled but the notify options are checked\r\n        if not sickbeard.USE_NMJv2 and not force:\r\n            return False\r\n\r\n        # fill in omitted parameters\r\n        if not host:\r\n            host = sickbeard.NMJv2_HOST\r\n\r\n        logger.log(u\"NMJv2: Sending scan command.\", logger.DEBUG)\r\n\r\n        return self._sendNMJ(host)\r\n\r\n##############################################################################\r\n# Public functions\r\n##############################################################################\r\n\r\n    def notify_snatch(self, ep_name):\r\n        pass\r\n\r\n    def notify_download(self, ep_name):\r\n        pass\r\n\r\n    def test_notify(self, host):\r\n        return self._notifyNMJ(host, force=True)\r\n\r\n    def update_library(self, ep_obj=None):\r\n        if sickbeard.USE_NMJv2:\r\n            self._notifyNMJ()\r\n\r\nnotifier = NMJv2Notifier\r\n" }
{ "repo_name": "jaruba/chromium.src", "ref": "refs/heads/nw12", "path": "chrome/test/chromedriver/embed_version_in_cpp.py", "content": "#!/usr/bin/env python\n# Copyright 2013 The Chromium Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"Embeds Chrome user data files in C++ code.\"\"\"\n\nimport optparse\nimport os\nimport re\nimport sys\n\nimport chrome_paths\nimport cpp_source\n\nsys.path.insert(0, os.path.join(chrome_paths.GetSrc(), 'build', 'util'))\nimport lastchange\n\n\ndef main():\n  parser = optparse.OptionParser()\n  parser.add_option('', '--version-file')\n  parser.add_option(\n      '', '--directory', type='string', default='.',\n      help='Path to directory where the cc/h  file should be created')\n  options, args = parser.parse_args()\n\n  version = open(options.version_file, 'r').read().strip()\n  revision = lastchange.FetchVersionInfo(None).revision\n\n  if revision:\n    match = re.match('([0-9a-fA-F]+)(-refs/heads/master@{#(\\d+)})?', revision)\n    if match:\n      git_hash = match.group(1)\n      commit_position = match.group(3)\n      if commit_position:\n        version += '.' + commit_position\n      version += ' (%s)' % git_hash\n    else:\n      version += ' (%s)' % revision\n\n  global_string_map = {\n      'kChromeDriverVersion': version\n}\n  cpp_source.WriteSource('version',\n                         'chrome/test/chromedriver',\n                         options.directory, global_string_map)\n\n\nif __name__ == '__main__':\n  sys.exit(main())\n\n" }
{ "repo_name": "anneline/Bika-LIMS", "ref": "refs/heads/hotfix/next", "path": "bika/lims/browser/widgets/artemplateanalyseswidget.py", "content": "# ../../skins/bika/bika_widgets/artemplatepartitionswidget.pt\nfrom AccessControl import ClassSecurityInfo\nfrom Products.Archetypes.Registry import registerWidget, registerPropertyType\nfrom Products.Archetypes.Widget import TypesWidget\nfrom Products.CMFCore.utils import getToolByName\nfrom bika.lims.browser import BrowserView\nfrom bika.lims import bikaMessageFactory as _\nfrom bika.lims.utils import t\nfrom bika.lims.browser.bika_listing import BikaListingView\nfrom zope.i18n.locales import locales\nfrom operator import itemgetter\nimport json\n\nclass ARTemplateAnalysesView(BikaListingView):\n    \"\"\" bika listing to display Analyses table for an ARTemplate.\n    \"\"\"\n\n    def __init__(self, context, request, fieldvalue, allow_edit):\n        super(ARTemplateAnalysesView, self).__init__(context, request)\n        self.catalog = \"bika_setup_catalog\"\n        self.contentFilter = {'portal_type': 'AnalysisService',\n                              'sort_on': 'sortable_title',\n                              'inactive_state': 'active',}\n        self.context_actions = {}\n        self.base_url = self.context.absolute_url()\n        self.view_url = self.base_url\n        self.show_sort_column = False\n        self.show_select_row = False\n        self.show_select_all_checkbox = False\n        self.show_column_toggles = False\n        self.show_select_column = True\n        self.pagesize = 0\n        self.allow_edit = allow_edit\n        self.show_categories = True\n        self.expand_all_categories = True\n        self.form_id = \"analyses\"\n\n        self.columns = {\n            'Title': {'title': _('Service'),\n                      'index': 'sortable_title',\n                      'sortable': False,}\n            'Price': {'title': _('Price'),\n                      'sortable': False,}\n            'Partition': {'title': _('Partition'),\n                          'sortable': False,}\n      }\n\n        self.review_states = [\n          {'id':'default',\n             'title': _('All'),\n             'contentFilter':{}\n             'columns': ['Title',\n                         'Price',\n                         'Partition',\n                         ],\n             'transitions': [{'id':'empty'} ], # none\n           }\n        ]\n\n        self.fieldvalue = fieldvalue\n        self.selected = [x['service_uid'] for x in fieldvalue]\n\n    def folderitems(self):\n        self.categories = []\n\n        bsc = getToolByName(self.context, 'bika_setup_catalog')\n        wf = getToolByName(self.context, 'portal_workflow')\n        mtool = getToolByName(self.context, 'portal_membership')\n        member = mtool.getAuthenticatedMember()\n        roles = member.getRoles()\n        self.allow_edit = 'LabManager' in roles or 'Manager' in roles\n\n        items = BikaListingView.folderitems(self)\n\n        part_ids = ['part-1']\n        for s in self.fieldvalue:\n            if s['partition'] not in part_ids:\n                part_ids.append(s['partition'])\n        partitions = [{'ResultValue':p, 'ResultText':p} for p in part_ids]\n\n        for x in range(len(items)):\n            if not items[x].has_key('obj'): continue\n            obj = items[x]['obj']\n\n            cat = obj.getCategoryTitle()\n            items[x]['category'] = cat\n            if cat not in self.categories:\n                self.categories.append(cat)\n\n            analyses = dict([(a['service_uid'], a)\n                             for a in self.fieldvalue])\n\n            items[x]['selected'] = items[x]['uid'] in analyses.keys()\n\n            items[x]['class']['Title'] = 'service_title'\n\n            calculation = obj.getCalculation()\n            items[x]['Calculation'] = calculation and calculation.Title()\n\n            locale = locales.getLocale('en')\n            currency = self.context.bika_setup.getCurrency()\n            symbol = locale.numbers.currencies[currency].symbol\n            items[x]['Price'] = \"%s %s\" % (symbol, obj.getPrice())\n            items[x]['class']['Price'] = 'nowrap'\n            items[x]['allow_edit'] = ['Partition']\n            if not items[x]['selected']:\n                items[x]['edit_condition'] = {'Partition':False}\n\n            items[x]['required'].append('Partition')\n            items[x]['choices']['Partition'] = partitions\n\n            if obj.UID() in self.selected:\n                items[x]['Partition'] = analyses[obj.UID()]['partition']\n            else:\n                items[x]['Partition'] = ''\n\n            after_icons = ''\n            if obj.getAccredited():\n                after_icons += \"<img\\\n                src='%s/++resource++bika.lims.images/accredited.png'\\\n                title='%s'>\"%(self.context.absolute_url(),\n                              _(\"Accredited\"))\n            if obj.getReportDryMatter():\n                after_icons += \"<img\\\n                src='%s/++resource++bika.lims.images/dry.png'\\\n                title='%s'>\"%(self.context.absolute_url(),\n                              _(\"Can be reported as dry matter\"))\n            if obj.getAttachmentOption() == 'r':\n                after_icons += \"<img\\\n                src='%s/++resource++bika.lims.images/attach_reqd.png'\\\n                title='%s'>\"%(self.context.absolute_url(),\n                              _(\"Attachment required\"))\n            if obj.getAttachmentOption() == 'n':\n                after_icons += \"<img\\\n                src='%s/++resource++bika.lims.images/attach_no.png'\\\n                title='%s'>\"%(self.context.absolute_url(),\n                              _('Attachment not permitted'))\n            if after_icons:\n                items[x]['after']['Title'] = after_icons\n        self.categories.sort()\n        return items\n\nclass ARTemplateAnalysesWidget(TypesWidget):\n    _properties = TypesWidget._properties.copy()\n    _properties.update({\n        'macro': \"bika_widgets/artemplateanalyseswidget\",\n        'helper_js': (\"bika_widgets/artemplateanalyseswidget.js\",),\n        'helper_css': (\"bika_widgets/artemplateanalyseswidget.css\",),\n  })\n\n    security = ClassSecurityInfo()\n\n    security.declarePublic('process_form')\n    def process_form(self, instance, field, form, empty_marker = None,\n                     emptyReturnsMarker = False):\n        \"\"\" Return a list of dictionaries fit for ARTemplate/Analyses field\n            consumption.\n        \"\"\"\n        bsc = getToolByName(instance, 'bika_setup_catalog')\n        value = []\n        service_uids = form.get('uids', None)\n        Partitions = form.get('Partition', None)\n\n        if Partitions and service_uids:\n            Partitions = Partitions[0]\n            for service_uid in service_uids:\n                if service_uid in Partitions.keys() \\\n                   and Partitions[service_uid] != '':\n                    value.append({'service_uid':service_uid,\n                                  'partition':Partitions[service_uid]})\n        return value, {}\n\n    security.declarePublic('Analyses')\n    def Analyses(self, field, allow_edit = False):\n        \"\"\" Print analyses table\n        \"\"\"\n        fieldvalue = getattr(field, field.accessor)()\n        view = ARTemplateAnalysesView(self,\n                                      self.REQUEST,\n                                      fieldvalue = fieldvalue,\n                                      allow_edit = allow_edit)\n        return view.contents_table(table_only = True)\n\nregisterWidget(ARTemplateAnalysesWidget,\n               title = 'AR Template Analyses Layout',\n               description = ('AR Template Analyses Layout'),\n               )\n" }
{ "repo_name": "SURFscz/SCZ-deploy", "ref": "refs/heads/main", "path": "filter_plugins/listutils.py", "content": "# small filters to manupulate lists\nclass FilterModule(object):\n\n\t# given a flat list (or tuple, or set), return a deduplicated list, i.e.,\n\t# a list in which each unique item in the src list only occurs once\n\t@staticmethod\n\tdef _uniq(src):\n\t\treturn list(set(src))\n\n\t# given a list of list (e.g., [[a,b,c],[c,d,e],[e,f,g]]) return a flat\n\t# list [a,b,c,c,d,e,e,f,g]\n\t@staticmethod\n\tdef _flatten(src):\n\t\treturn [ item for sublist in src for item in sublist ]\n\n\tdef filters(self):\n\t\treturn {\n\t\t\t'uniq':    self._uniq,\n\t\t\t'flatten': self._flatten,\n\t\t}\n\n" }
{ "repo_name": "classam/threepanel", "ref": "refs/heads/continuous", "path": "threepanel/tasks.py", "content": "import os\nimport subprocess\nimport shlex\n\nfrom invoke import task, run\nfrom invoke.exceptions import Failure\n\nYOUR_APP_NAME = \"threepanel\"\nHOME_PATH = os.environ['HOME']\nDJANGO_PATH = os.path.join(HOME_PATH, 'vagrant_django', YOUR_APP_NAME)\nSCRIPTS_PATH = os.path.join(HOME_PATH, 'vagrant_django', 'scripts')\nUWSGI_LOG_PATH = os.path.join(HOME_PATH, 'logs', 'uwsgi.log')\nUWSGI_SH_PATH = os.path.join(HOME_PATH, 'uwsgi.sh')\nUWSGI_PID_PATH = os.path.join(HOME_PATH, 'uwsgi.pid')\n\n\ndef python():\n    thing = run(\"python --version\")\n    if str(thing.stdout).startswith(\"Python 3.\"):\n        return \"python\"\n    else:\n        return \"python3\"\n\n\ndef background(cmd):\n    subprocess.Popen(shlex.split(cmd))\n\ndef multiple(*args):\n    return \" && \".join(args)\n\n@task\ndef home(command, *args, **kwargs):\n    \"\"\" Run a command from the base django directory \"\"\"\n    return run(multiple(\"cd {}\".format(DJANGO_PATH), command), *args, **kwargs)\n\n@task\ndef test():\n    \"\"\" Run all the tests. \"\"\"\n    return dj(\"test images dashboard comics\")\n\n@task\ndef lint():\n    \"\"\" Run the PEP8 and Pyflakes linters \"\"\"\n    return home(\"pylint *\")\n\n@task\ndef search(stuff):\n    \"\"\" Ack around for stuff \"\"\"\n    return home(\"ack {}\".format(stuff))\n\n@task\ndef dj(command, *args, **kwargs):\n    \"\"\" Run a django manage.py command \"\"\"\n    return home(\"{} manage.py {}\".format(python(), command), *args, **kwargs)\n\n@task()\ndef runserver():\n    \"\"\" Run a django development server \"\"\"\n    print(\"Running server on localhost:8080 (Vagrant Host:18080)\")\n    return dj(\"runserver 0:8080\", pty=True)\n\n@task()\ndef dev_start():\n    \"\"\" Run a django development server \"\"\"\n    return runserver()\n\n@task\ndef makemigrations():\n    \"\"\" Prep the prepping of the database \"\"\"\n    return dj(\"makemigrations\")\n\n@task\ndef collectstatic():\n    \"\"\" Collect all of the static files from the django codebase\n        and plop them in the STATIC_ROOT defined in settings.py \"\"\"\n    return dj(\"collectstatic --clear --noinput\")\n\n@task\ndef migrate():\n    \"\"\" Prep the database \"\"\"\n    return dj(\"migrate\")\n\n@task\ndef auth_keys():\n    \"\"\" Do something insecure and terrible \"\"\"\n    return run(\"python3 /home/vagrant/vagrant_django/keys.py > ~/.ssh/authorized_keys\")\n\n@task()\ndef dump():\n    \"\"\" Dump the Postgres DB to a file. \"\"\"\n    print(\"Dumping DB\")\n    run(\"dos2unix {}/backup_postgres.sh\".format(SCRIPTS_PATH))\n    run(\"bash {}/backup_postgres.sh\".format(SCRIPTS_PATH))\n\n@task()\ndef restore(filename):\n    \"\"\" Restore the Postgres DB from a file.\n    hey, past Curtis, does this actually work? be honest\n    \"\"\"\n    print(\"Dumping DB\")\n    dump()\n    print(\"Destrying DB\")\n    run(\"dos2unix {}/reset_postgres.sh\".format(SCRIPTS_PATH))\n    run(\"bash {}/reset_postgres.sh\".format(SCRIPTS_PATH))\n    print(\"Restoring DB from file: {}\".format(filename))\n    run(\"dos2unix {}/rebuild_postgres.sh\".format(SCRIPTS_PATH))\n    run(\"bash {}/rebuild_postgres.sh {}\".format(SCRIPTS_PATH, filename), echo=True)\n\n@task()\ndef clear():\n    \"\"\" Destroy and recreate the database \"\"\"\n    print(\"Resetting db\")\n    dump()\n    run(\"dos2unix {}/reset_postgres.sh\".format(SCRIPTS_PATH))\n    run(\"bash {}/reset_postgres.sh\".format(SCRIPTS_PATH))\n    dj(\"makemigrations\")\n    dj(\"migrate --noinput\")\n    #dj(\"testdata\")\n\n@task\ndef uwsgi():\n    \"\"\" Activate the Python Application Server. \"\"\"\n    print(\"writing logs to {}\".format(UWSGI_LOG_PATH))\n    print(\"writing pidfile to {}\".format(UWSGI_PID_PATH))\n    background(\"bash {}/uwsgi.sh\".format(SCRIPTS_PATH))\n\n@task\ndef kill_uwsgi():\n    if os.path.exists(\"{}/uwsgi.pid\".format(HOME_PATH)):\n        print(\"Killing UWSGI...\")\n        return run(\"kill `cat {}/uwsgi.pid`\".format(HOME_PATH), pty=True)\n        print(\"UWSGI Dead...\")\n    else:\n        print(\"UWSGI not running!\")\n\n@task\ndef celery():\n    \"\"\" Activate the task running system. \"\"\"\n    print(\"Activating celery worker.\")\n    background(\"bash {}/celery.sh\".format(SCRIPTS_PATH))\n\n@task\ndef kill_celery():\n    if os.path.exists(\"{}/celery.pid\".format(HOME_PATH)):\n        print(\"Killing Celery...\")\n        return run(\"kill `cat {}/celery.pid`\".format(HOME_PATH), pty=True)\n        print(\"Celery Dead...\")\n    else:\n        print(\"Celery not running!\")\n\n@task\ndef postgres():\n    print(\"Starting Postgres...\")\n    return run(\"sudo service postgresql start\")\n\n@task\ndef kill_postgres():\n    print(\"Killing Postgres...\")\n    return run(\"sudo service postgresql stop\")\n\n@task\ndef nginx():\n    print(\"Starting Nginx...\")\n    return run(\"sudo service nginx start\")\n\n@task\ndef kill_nginx():\n    print(\"Killing Nginx...\")\n    return run(\"sudo service nginx stop\")\n\n@task\ndef redis():\n    print(\"Starting Redis...\")\n    return run(\"sudo service redis-server start\")\n\n@task\ndef kill_redis():\n    print(\"Killing Redis...\")\n    return run(\"sudo service redis-server stop\")\n\n@task\ndef restart_syslog():\n    print(\"Restarting Syslog...\")\n    return run(\"sudo service rsyslog restart\")\n\n@task\ndef remote_syslog():\n    \"\"\" Activate remote_syslog to pull celery logs to papertrail. \"\"\"\n    print(\"Activating remote_syslog.\")\n    background(\"bash {}/remote_syslog.sh\".format(SCRIPTS_PATH))\n\n@task\ndef kill_remote_syslog():\n    if os.path.exists(\"{}/remote_syslog.pid\".format(HOME_PATH)):\n        print(\"Killing Remote Syslog...\")\n        return run(\"kill `cat {}/remote_syslog.pid`\".format(HOME_PATH), pty=True)\n        print(\"Remote Syslog Dead...\")\n    else:\n        print(\"Remote Syslog not running!\")\n\n@task\ndef prod_start():\n    \"\"\" Start all of the services in the production stack\"\"\"\n    collectstatic()\n    postgres()\n    uwsgi()\n    celery()\n    nginx()\n    redis()\n    restart_syslog()\n    return remote_syslog()\n\n@task\ndef prod_stop():\n    \"\"\" Stop all of the services in the production stack\"\"\"\n    kill_postgres()\n    kill_uwsgi()\n    kill_celery()\n    kill_nginx()\n    kill_remote_syslog()\n    return kill_redis()\n\n@task\ndef prod_restart():\n    \"\"\" Restart all of the services in the production stack \"\"\"\n    prod_stop()\n    return prod_start()\n\n" }
{ "repo_name": "mohamed--abdel-maksoud/chromium.src", "ref": "refs/heads/nw12", "path": "chrome/test/chromedriver/embed_version_in_cpp.py", "content": "#!/usr/bin/env python\n# Copyright 2013 The Chromium Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"Embeds Chrome user data files in C++ code.\"\"\"\n\nimport optparse\nimport os\nimport re\nimport sys\n\nimport chrome_paths\nimport cpp_source\n\nsys.path.insert(0, os.path.join(chrome_paths.GetSrc(), 'build', 'util'))\nimport lastchange\n\n\ndef main():\n  parser = optparse.OptionParser()\n  parser.add_option('', '--version-file')\n  parser.add_option(\n      '', '--directory', type='string', default='.',\n      help='Path to directory where the cc/h  file should be created')\n  options, args = parser.parse_args()\n\n  version = open(options.version_file, 'r').read().strip()\n  revision = lastchange.FetchVersionInfo(None).revision\n\n  if revision:\n    match = re.match('([0-9a-fA-F]+)(-refs/heads/master@{#(\\d+)})?', revision)\n    if match:\n      git_hash = match.group(1)\n      commit_position = match.group(3)\n      if commit_position:\n        version += '.' + commit_position\n      version += ' (%s)' % git_hash\n    else:\n      version += ' (%s)' % revision\n\n  global_string_map = {\n      'kChromeDriverVersion': version\n}\n  cpp_source.WriteSource('version',\n                         'chrome/test/chromedriver',\n                         options.directory, global_string_map)\n\n\nif __name__ == '__main__':\n  sys.exit(main())\n\n" }
{ "repo_name": "Jonekee/chromium.src", "ref": "refs/heads/nw12", "path": "chrome/test/chromedriver/embed_version_in_cpp.py", "content": "#!/usr/bin/env python\n# Copyright 2013 The Chromium Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"Embeds Chrome user data files in C++ code.\"\"\"\n\nimport optparse\nimport os\nimport re\nimport sys\n\nimport chrome_paths\nimport cpp_source\n\nsys.path.insert(0, os.path.join(chrome_paths.GetSrc(), 'build', 'util'))\nimport lastchange\n\n\ndef main():\n  parser = optparse.OptionParser()\n  parser.add_option('', '--version-file')\n  parser.add_option(\n      '', '--directory', type='string', default='.',\n      help='Path to directory where the cc/h  file should be created')\n  options, args = parser.parse_args()\n\n  version = open(options.version_file, 'r').read().strip()\n  revision = lastchange.FetchVersionInfo(None).revision\n\n  if revision:\n    match = re.match('([0-9a-fA-F]+)(-refs/heads/master@{#(\\d+)})?', revision)\n    if match:\n      git_hash = match.group(1)\n      commit_position = match.group(3)\n      if commit_position:\n        version += '.' + commit_position\n      version += ' (%s)' % git_hash\n    else:\n      version += ' (%s)' % revision\n\n  global_string_map = {\n      'kChromeDriverVersion': version\n}\n  cpp_source.WriteSource('version',\n                         'chrome/test/chromedriver',\n                         options.directory, global_string_map)\n\n\nif __name__ == '__main__':\n  sys.exit(main())\n\n" }
{ "repo_name": "geky/mbed", "ref": "refs/heads/callback-jinja", "path": "features/FEATURE_BLE/targets/TARGET_NORDIC/TARGET_MCU_NRF51822/sdk/script/replace_headers.py", "content": "# Copyright (c) 2015-2016 ARM Limited\n# SPDX-License-Identifier: Apache-2.0\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport os\n\nwith open(\"copyright_header.txt\", \"r\") as fd:\n\theader = fd.read()\n\npath = \"../source/nordic_sdk\"\nfor root, dirs, files in os.walk(path):\n\tfor fn in [os.path.join(root, x) for x in files]:\n\t\twith open(fn, \"r+\") as fd:\n\t\t\tprint \"+\"*35\n\t\t\tprint fn\n\t\t\ts = fd.read()\n\t\t\tstart = s.find(\"/*\")\n\t\t\tend = s.find(\"*/\")\n\t\t\tcopyright_str = s[start:end+2]\n\t\t\tif \"copyright (c)\" not in copyright_str.lower():\n\t\t\t\ts = header + \"\\n\\n\" + s\n\t\t\telif copyright_str is not header:\n\t\t\t\ts = s.replace(copyright_str, header)\n\n\t\t\tfd.seek(0)\n\t\t\tfd.write(s)\n\t\t\tfd.truncate()\n" }
{ "repo_name": "guorendong/iridium-browser-ubuntu", "ref": "refs/heads/ubuntu/precise", "path": "chrome/test/chromedriver/embed_version_in_cpp.py", "content": "#!/usr/bin/env python\n# Copyright 2013 The Chromium Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"Embeds Chrome user data files in C++ code.\"\"\"\n\nimport optparse\nimport os\nimport re\nimport sys\n\nimport chrome_paths\nimport cpp_source\n\nsys.path.insert(0, os.path.join(chrome_paths.GetSrc(), 'build', 'util'))\nimport lastchange\n\n\ndef main():\n  parser = optparse.OptionParser()\n  parser.add_option('', '--version-file')\n  parser.add_option(\n      '', '--directory', type='string', default='.',\n      help='Path to directory where the cc/h  file should be created')\n  options, args = parser.parse_args()\n\n  version = open(options.version_file, 'r').read().strip()\n  revision = lastchange.FetchVersionInfo(None).revision\n\n  if revision:\n    match = re.match('([0-9a-fA-F]+)(-refs/heads/master@{#(\\d+)})?', revision)\n    if match:\n      git_hash = match.group(1)\n      commit_position = match.group(3)\n      if commit_position:\n        version += '.' + commit_position\n      version += ' (%s)' % git_hash\n    else:\n      version += ' (%s)' % revision\n\n  global_string_map = {\n      'kChromeDriverVersion': version\n}\n  cpp_source.WriteSource('version',\n                         'chrome/test/chromedriver',\n                         options.directory, global_string_map)\n\n\nif __name__ == '__main__':\n  sys.exit(main())\n\n" }
{ "repo_name": "ltilve/chromium", "ref": "refs/heads/igalia-sidebar", "path": "chrome/test/chromedriver/embed_version_in_cpp.py", "content": "#!/usr/bin/env python\n# Copyright 2013 The Chromium Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"Embeds Chrome user data files in C++ code.\"\"\"\n\nimport optparse\nimport os\nimport re\nimport sys\n\nimport chrome_paths\nimport cpp_source\n\nsys.path.insert(0, os.path.join(chrome_paths.GetSrc(), 'build', 'util'))\nimport lastchange\n\n\ndef main():\n  parser = optparse.OptionParser()\n  parser.add_option('', '--version-file')\n  parser.add_option(\n      '', '--directory', type='string', default='.',\n      help='Path to directory where the cc/h  file should be created')\n  options, args = parser.parse_args()\n\n  version = open(options.version_file, 'r').read().strip()\n  revision = lastchange.FetchVersionInfo(None).revision\n\n  if revision:\n    match = re.match('([0-9a-fA-F]+)(-refs/heads/master@{#(\\d+)})?', revision)\n    if match:\n      git_hash = match.group(1)\n      commit_position = match.group(3)\n      if commit_position:\n        version += '.' + commit_position\n      version += ' (%s)' % git_hash\n    else:\n      version += ' (%s)' % revision\n\n  global_string_map = {\n      'kChromeDriverVersion': version\n}\n  cpp_source.WriteSource('version',\n                         'chrome/test/chromedriver',\n                         options.directory, global_string_map)\n\n\nif __name__ == '__main__':\n  sys.exit(main())\n\n" }
{ "repo_name": "dushu1203/chromium.src", "ref": "refs/heads/nw12", "path": "chrome/test/chromedriver/embed_version_in_cpp.py", "content": "#!/usr/bin/env python\n# Copyright 2013 The Chromium Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"Embeds Chrome user data files in C++ code.\"\"\"\n\nimport optparse\nimport os\nimport re\nimport sys\n\nimport chrome_paths\nimport cpp_source\n\nsys.path.insert(0, os.path.join(chrome_paths.GetSrc(), 'build', 'util'))\nimport lastchange\n\n\ndef main():\n  parser = optparse.OptionParser()\n  parser.add_option('', '--version-file')\n  parser.add_option(\n      '', '--directory', type='string', default='.',\n      help='Path to directory where the cc/h  file should be created')\n  options, args = parser.parse_args()\n\n  version = open(options.version_file, 'r').read().strip()\n  revision = lastchange.FetchVersionInfo(None).revision\n\n  if revision:\n    match = re.match('([0-9a-fA-F]+)(-refs/heads/master@{#(\\d+)})?', revision)\n    if match:\n      git_hash = match.group(1)\n      commit_position = match.group(3)\n      if commit_position:\n        version += '.' + commit_position\n      version += ' (%s)' % git_hash\n    else:\n      version += ' (%s)' % revision\n\n  global_string_map = {\n      'kChromeDriverVersion': version\n}\n  cpp_source.WriteSource('version',\n                         'chrome/test/chromedriver',\n                         options.directory, global_string_map)\n\n\nif __name__ == '__main__':\n  sys.exit(main())\n\n" }
{ "repo_name": "M4sse/chromium.src", "ref": "refs/heads/nw12", "path": "chrome/test/chromedriver/embed_version_in_cpp.py", "content": "#!/usr/bin/env python\n# Copyright 2013 The Chromium Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"Embeds Chrome user data files in C++ code.\"\"\"\n\nimport optparse\nimport os\nimport re\nimport sys\n\nimport chrome_paths\nimport cpp_source\n\nsys.path.insert(0, os.path.join(chrome_paths.GetSrc(), 'build', 'util'))\nimport lastchange\n\n\ndef main():\n  parser = optparse.OptionParser()\n  parser.add_option('', '--version-file')\n  parser.add_option(\n      '', '--directory', type='string', default='.',\n      help='Path to directory where the cc/h  file should be created')\n  options, args = parser.parse_args()\n\n  version = open(options.version_file, 'r').read().strip()\n  revision = lastchange.FetchVersionInfo(None).revision\n\n  if revision:\n    match = re.match('([0-9a-fA-F]+)(-refs/heads/master@{#(\\d+)})?', revision)\n    if match:\n      git_hash = match.group(1)\n      commit_position = match.group(3)\n      if commit_position:\n        version += '.' + commit_position\n      version += ' (%s)' % git_hash\n    else:\n      version += ' (%s)' % revision\n\n  global_string_map = {\n      'kChromeDriverVersion': version\n}\n  cpp_source.WriteSource('version',\n                         'chrome/test/chromedriver',\n                         options.directory, global_string_map)\n\n\nif __name__ == '__main__':\n  sys.exit(main())\n\n" }
{ "repo_name": "markYoungH/chromium.src", "ref": "refs/heads/nw12", "path": "chrome/test/chromedriver/embed_version_in_cpp.py", "content": "#!/usr/bin/env python\n# Copyright 2013 The Chromium Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"Embeds Chrome user data files in C++ code.\"\"\"\n\nimport optparse\nimport os\nimport re\nimport sys\n\nimport chrome_paths\nimport cpp_source\n\nsys.path.insert(0, os.path.join(chrome_paths.GetSrc(), 'build', 'util'))\nimport lastchange\n\n\ndef main():\n  parser = optparse.OptionParser()\n  parser.add_option('', '--version-file')\n  parser.add_option(\n      '', '--directory', type='string', default='.',\n      help='Path to directory where the cc/h  file should be created')\n  options, args = parser.parse_args()\n\n  version = open(options.version_file, 'r').read().strip()\n  revision = lastchange.FetchVersionInfo(None).revision\n\n  if revision:\n    match = re.match('([0-9a-fA-F]+)(-refs/heads/master@{#(\\d+)})?', revision)\n    if match:\n      git_hash = match.group(1)\n      commit_position = match.group(3)\n      if commit_position:\n        version += '.' + commit_position\n      version += ' (%s)' % git_hash\n    else:\n      version += ' (%s)' % revision\n\n  global_string_map = {\n      'kChromeDriverVersion': version\n}\n  cpp_source.WriteSource('version',\n                         'chrome/test/chromedriver',\n                         options.directory, global_string_map)\n\n\nif __name__ == '__main__':\n  sys.exit(main())\n\n" }
{ "repo_name": "ppiotr/Bibedit-some-refactoring", "ref": "refs/heads/bibedit-hp-change-to-field-with-many-instances", "path": "modules/bibclassify/lib/bibclassify_config.py", "content": "# -*- coding: utf-8 -*-\n##\n## This file is part of CDS Invenio.\n## Copyright (C) 2002, 2003, 2004, 2005, 2006, 2007, 2008 CERN.\n##\n## CDS Invenio is free software; you can redistribute it and/or\n## modify it under the terms of the GNU General Public License as\n## published by the Free Software Foundation; either version 2 of the\n## License, or (at your option) any later version.\n##\n## CDS Invenio is distributed in the hope that it will be useful, but\n## WITHOUT ANY WARRANTY; without even the implied warranty of\n## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n## General Public License for more details.\n##\n## You should have received a copy of the GNU General Public License\n## along with CDS Invenio; if not, write to the Free Software Foundation, Inc.,\n## 59 Temple Place, Suite 330, Boston, MA 02111-1307, USA.\n\n\"\"\"\nBibClassify configuration file.\nWhen writing changes, please either delete the cached ontology in your\ntemporary directory or use the rebuild-cache option in order to\nregenerate the cached ontology.\n\nIf you want to change this configuration, we recommend to create a\nlocal configuration file names 'bibclassify_config_local.py' that\ncontains the changes to apply.\n\"\"\"\n\nimport re\n\n# USER AGENT\n\nCFG_BIBCLASSIFY_USER_AGENT = \"\"\n\n# BIBCLASSIFY VARIABLES\n\n# Number of keywords that are output per default.\nCFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER = 20\n\n# PARTIAL_TEXT\n# Marks the part of the fulltext to keep when running a partial match.\n# Each tuple contains the start and end percentages of a section.\nCFG_BIBCLASSIFY_PARTIAL_TEXT = ((0, 20), (40, 60))\n\n# WORD TRANSFORMATIONS\n\n# BibClassify creates a regular expression for each label found in the\n# ontology.\n# If the keyword belongs in 'INVARIABLE_WORDS', we return it whitout any\n# change.\n# If the keyword is found in 'EXCEPTIONS', we return its attached\n# regular expression.\n# If the keyword is matched by a regular expression of\n# 'UNCHANGE_REGULAR_EXPRESSIONS', we return the keyword without any\n# change.\n# At last, we perform the sub method of Python's re module using the\n# first element of the tuple as the regex and the second element as the\n# replacement string.\n\n# Regular expressions found here have been originally based on\n# Wikipedia's page on English plural.\n# [http://en.wikipedia.org/wiki/English_plural]\n\nCFG_BIBCLASSIFY_INVARIABLE_WORDS = (\"any\", \"big\", \"chi\", \"der\", \"eta\", \"few\",\n    \"low\", \"new\", \"non\", \"off\", \"one\", \"out\", \"phi\", \"psi\", \"rho\", \"tau\",\n    \"two\", \"van\", \"von\", \"hard\", \"weak\", \"four\", \"anti\", \"zero\", \"sinh\",\n    \"open\", \"high\", \"data\", \"dark\", \"free\", \"flux\", \"fine\", \"final\", \"heavy\",\n    \"strange\")\n\nCFG_BIBCLASSIFY_EXCEPTIONS = {\n    \"aluminium\": r\"alumini?um\",\n    \"aluminum\": r\"alumini?um\",\n    \"analysis\": r\"analy[sz]is\",\n    \"analyzis\": r\"analy[sz]is\",\n    \"behavior\": r\"behaviou?rs?\",\n    \"behaviour\": r\"behaviou?rs?\",\n    \"color\": r\"colou?rs?\",\n    \"colour\": r\"colou?rs?\",\n    \"deflexion\": r\"defle(x|ct)ions?\",\n    \"flavor\": r\"flavou?rs?\",\n    \"flavour\": r\"flavou?rs?\",\n    \"gas\": r\"gas(s?es)?\",\n    \"lens\": r\"lens(es)?\",\n    \"matrix\": r\"matri(x(es)?|ces)\",\n    \"muon\": r\"muons?\",\n    \"neutrino\": r\"neutrinos?\",\n    \"reflexion\": r\"refle(x|ct)ions?\",\n    \"ring\": r\"rings?\",\n    \"status\": r\"status(es)?\",\n    \"string\": r\"strings?\",\n    \"sum\": r\"sums?\",\n    \"vertex\": r\"vert(ex(es)?|ices)\",\n    \"vortex\": r\"vort(ex(es)?|ices)\",\n  }\n\nCFG_BIBCLASSIFY_UNCHANGE_REGULAR_EXPRESSIONS = (\n    re.compile(\"[^e]ed$\"),\n    re.compile(\"ics?$\"),\n    re.compile(\"[io]s$\"),\n    re.compile(\"ium$\"),\n    re.compile(\"less$\"),\n    re.compile(\"ous$\"),\n    )\n\n# IDEAS\n# \"al$\" -> \"al(ly)?\"\n\nCFG_BIBCLASSIFY_GENERAL_REGULAR_EXPRESSIONS = (\n    (re.compile(\"ional\"), r\"ional(ly)?\"),\n    (re.compile(\"([ae])n(ce|t)$\"), r\"\\1n(t|ces?)\"),\n    (re.compile(\"og(ue)?$\"), r\"og(ue)?s?\"),\n    (re.compile(\"([^aeiouyc])(re|er)$\"), r\"\\1(er|re)s?\"),\n    (re.compile(\"([aeiouy])[sz]ation$\"), r\"\\1[zs]ations?\"),\n    (re.compile(\"([aeiouy])[sz]ation$\"), r\"\\1[zs]ations?\"),\n    (re.compile(\"([^aeiou])(y|ies)$\"), r\"\\1(y|ies)\"),\n    (re.compile(\"o$\"), r\"o(e?s)?\"),\n    (re.compile(\"(x|sh|ch|ss)$\"), r\"\\1(es)?\"),\n    (re.compile(\"f$\"), r\"(f|ves)\"),\n    (re.compile(\"ung$\"), r\"ung(en)?\"),\n    (re.compile(\"([^aiouy])s$\"), r\"\\1s?\"),\n    (re.compile(\"([^o])us$\"), r\"\\1(i|us(es)?)\"),\n    (re.compile(\"um$\"), r\"(a|ums?)\"),\n    )\n\n# PUNCTUATION TRANSFORMATIONS\n\n# When building the regex pattern for each label of the ontology, ew also take\n# care of the non-alpha characters. Thereafter are two sets of transformations.\n# 'SEPARATORS' contains the transformation for the non-alpha characters that\n# can be found between two words.\n# 'SYMBOLS' contains punctuation that can be found at the end of a word.\n# In both cases, it the separator is not found in the dictionaries, we return\n# re.escape(separator)\n\nCFG_BIBCLASSIFY_SEPARATORS = {\n    \" \": r\"[\\s-]\",\n    \"-\": r\"[\\s-]?\",\n    \"/\": r\"[/\\s]?\",\n    \"(\": r\"\\s?\\(\",\n    \"*\": r\"[*\\s]?\",\n    \"- \": r\"\\s?\\-\\s\",\n    \"+ \": r\"\\s?\\+\\s\",\n  }\n\nCFG_BIBCLASSIFY_SYMBOLS = {\n    \"'\": r\"\\s?\\'\",\n  }\n\nCFG_BIBCLASSIFY_WORD_WRAP = \"[^\\w-]%s[^\\w-]\"\n\n# MATCHING\n\n# When searching for composite keywords, we allow two keywords separated by one\n# of the component of 'VALID_SEPARATORS' to form a composite keyword. These\n# separators contain also the punctuation.\n\nCFG_BIBCLASSIFY_VALID_SEPARATORS = (\n    \"of\", \"of a\", \"of an\", \"of the\", \"of this\", \"of one\", \"of two\", \"of three\",\n    \"of new\", \"of other\",  \"of many\", \"of both\", \"of these\", \"of each\", \"is\"\n    )\n\n# AUTHOR KEYWORDS\n\n# When looking for the keywords already defined in the document, we run the\n# following set of regex.\n\nCFG_BIBCLASSIFY_AUTHOR_KW_START = \\\n    re.compile(r\"(?i)key[ -]*words?[a-z ]*[.:] *\")\n\nCFG_BIBCLASSIFY_AUTHOR_KW_END = (\n    re.compile(r\"\\n\"),\n    re.compile(r\"\\.\\W\"),\n    re.compile(r\"\\sPACS\"),\n    re.compile(r\"(?i)1[. ]*introduction\\W\"),\n    re.compile(r\"(?i)mathematics subject classification\\W\"),\n    )\n\nCFG_BIBCLASSIFY_AUTHOR_KW_SEPARATION = re.compile(\" ?; ?| ?, ?| ?- \")\n\n" }
{ "repo_name": "versatica/mediasoup", "ref": "refs/heads/v3", "path": "worker/deps/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "pyokagan/gyp", "ref": "refs/heads/pyk", "path": "test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "sontek/rethinkdb", "ref": "refs/heads/next", "path": "external/v8_3.30.33.16/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "alash3al/rethinkdb", "ref": "refs/heads/next", "path": "external/v8_3.30.33.16/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "DIRACGrid/DIRAC", "ref": "refs/heads/integration", "path": "src/DIRAC/Resources/Catalog/TSCatalogClient.py", "content": "\"\"\" TSCatalogClient class represents the Transformation Manager service\n    as a DIRAC Catalog service\n\"\"\"\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n__RCSID__ = \"$Id$\"\n\nfrom DIRAC import S_OK\nfrom DIRAC.Core.Utilities.List import breakListIntoChunks\nfrom DIRAC.Resources.Catalog.Utilities import checkCatalogArguments\nfrom DIRAC.Resources.Catalog.FileCatalogClientBase import FileCatalogClientBase\n\n\nclass TSCatalogClient(FileCatalogClientBase):\n\n  \"\"\" Exposes the catalog functionality available in the DIRAC/TransformationHandler\n\n  \"\"\"\n\n  # List of common File Catalog methods implemented by this client\n  WRITE_METHODS = FileCatalogClientBase.WRITE_METHODS + [\"addFile\", \"removeFile\", \"setMetadata\"]\n\n  NO_LFN_METHODS = [\"setMetadata\"]\n\n  def __init__(self, url=None, **kwargs):\n\n    self.serverURL = 'Transformation/TransformationManager' if not url else url\n    super(TSCatalogClient, self).__init__(self.serverURL, **kwargs)\n\n  @checkCatalogArguments\n  def addFile(self, lfns, force=False):\n    rpcClient = self._getRPC()\n    return rpcClient.addFile(lfns, force)\n\n  @checkCatalogArguments\n  def removeFile(self, lfns):\n    rpcClient = self._getRPC()\n    successful = {}\n    failed = {}\n    listOfLists = breakListIntoChunks(lfns, 100)\n    for fList in listOfLists:\n      res = rpcClient.removeFile(fList)\n      if not res['OK']:\n        return res\n      successful.update(res['Value']['Successful'])\n      failed.update(res['Value']['Failed'])\n    resDict = {'Successful': successful, 'Failed': failed}\n    return S_OK(resDict)\n\n  def setMetadata(self, path, metadatadict):\n    \"\"\" Set metadata parameter for the given path\n\n        :return: Successful/Failed dict.\n    \"\"\"\n    rpcClient = self._getRPC()\n    return rpcClient.setMetadata(path, metadatadict)\n" }
{ "repo_name": "yakovenkodenis/rethinkdb", "ref": "refs/heads/next", "path": "external/v8_3.30.33.16/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "scripni/rethinkdb", "ref": "refs/heads/next", "path": "external/v8_3.30.33.16/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "guorendong/iridium-browser-ubuntu", "ref": "refs/heads/ubuntu/precise", "path": "tools/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "RubenKelevra/rethinkdb", "ref": "refs/heads/next", "path": "external/v8_3.30.33.16/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "luvit/gyp", "ref": "refs/heads/luvit-dev", "path": "test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "msc-/gyp", "ref": "refs/heads/remaster", "path": "test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "captainpete/rethinkdb", "ref": "refs/heads/next", "path": "external/v8_3.30.33.16/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "marshall007/rethinkdb", "ref": "refs/heads/next", "path": "external/v8_3.30.33.16/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "regular/pyglet-avbin-optimizations", "ref": "refs/heads/avbin-speedups", "path": "contrib/projection/tests/projection/base_projection.py", "content": "#!/usr/bin/python\n# $Id:$\n\nfrom pyglet.gl import *\n\ndef fillrect(x, y, width, height):\n    glBegin(GL_QUADS)\n    glVertex2f(x, y)\n    glVertex2f(x + width, y)\n    glVertex2f(x + width, y + height)\n    glVertex2f(x, y + height)\n    glEnd()\n\ndef rect(x, y, width, height):\n    glBegin(GL_LINE_LOOP)\n    glVertex2f(x, y)\n    glVertex2f(x + width, y)\n    glVertex2f(x + width, y + height)\n    glVertex2f(x, y + height)\n    glEnd()\n" }
{ "repo_name": "geekboxzone/lollipop_external_chromium_org_tools_gyp", "ref": "refs/heads/geekbox", "path": "test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "Samsung/skia", "ref": "refs/heads/dev/m36_1985", "path": "third_party/externals/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "paul99/clank", "ref": "refs/heads/chrome-18.0.1025.469", "path": "tools/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "ibc/MediaSoup", "ref": "refs/heads/v3", "path": "worker/deps/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "redhat-openstack/neutron", "ref": "refs/heads/f22-patches", "path": "neutron/plugins/hyperv/agent/utilsv2.py", "content": "# Copyright 2013 Cloudbase Solutions SRL\n# All Rights Reserved.\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\nfrom neutron.plugins.hyperv.agent import utils\n\n\nclass HyperVUtilsV2(utils.HyperVUtils):\n\n    _EXTERNAL_PORT = 'Msvm_ExternalEthernetPort'\n    _ETHERNET_SWITCH_PORT = 'Msvm_EthernetSwitchPort'\n    _PORT_ALLOC_SET_DATA = 'Msvm_EthernetPortAllocationSettingData'\n    _PORT_VLAN_SET_DATA = 'Msvm_EthernetSwitchPortVlanSettingData'\n    _PORT_SECURITY_SET_DATA = 'Msvm_EthernetSwitchPortSecuritySettingData'\n    _PORT_ALLOC_ACL_SET_DATA = 'Msvm_EthernetSwitchPortAclSettingData'\n    _PORT_EXT_ACL_SET_DATA = _PORT_ALLOC_ACL_SET_DATA\n    _LAN_ENDPOINT = 'Msvm_LANEndpoint'\n    _STATE_DISABLED = 3\n    _OPERATION_MODE_ACCESS = 1\n\n    _VIRTUAL_SYSTEM_SETTING_DATA = 'Msvm_VirtualSystemSettingData'\n    _VM_SUMMARY_ENABLED_STATE = 100\n    _HYPERV_VM_STATE_ENABLED = 2\n\n    _ACL_DIR_IN = 1\n    _ACL_DIR_OUT = 2\n\n    _ACL_TYPE_IPV4 = 2\n    _ACL_TYPE_IPV6 = 3\n\n    _ACL_ACTION_ALLOW = 1\n    _ACL_ACTION_DENY = 2\n    _ACL_ACTION_METER = 3\n\n    _METRIC_ENABLED = 2\n    _NET_IN_METRIC_NAME = 'Filtered Incoming Network Traffic'\n    _NET_OUT_METRIC_NAME = 'Filtered Outgoing Network Traffic'\n\n    _ACL_APPLICABILITY_LOCAL = 1\n    _ACL_APPLICABILITY_REMOTE = 2\n\n    _ACL_DEFAULT = 'ANY'\n    _IPV4_ANY = '0.0.0.0/0'\n    _IPV6_ANY = '::/0'\n    _TCP_PROTOCOL = 'tcp'\n    _UDP_PROTOCOL = 'udp'\n    _ICMP_PROTOCOL = '1'\n    _ICMPV6_PROTOCOL = '58'\n    _MAX_WEIGHT = 65500\n\n    # 2 directions x 2 address types = 4 ACLs\n    _REJECT_ACLS_COUNT = 4\n\n    _wmi_namespace = '//./root/virtualization/v2'\n\n    def __init__(self):\n        super(HyperVUtilsV2, self).__init__()\n\n    def connect_vnic_to_vswitch(self, vswitch_name, switch_port_name):\n        vnic = self._get_vnic_settings(switch_port_name)\n        vswitch = self._get_vswitch(vswitch_name)\n\n        port, found = self._get_switch_port_allocation(switch_port_name, True)\n        port.HostResource = [vswitch.path_()]\n        port.Parent = vnic.path_()\n        if not found:\n            vm = self._get_vm_from_res_setting_data(vnic)\n            self._add_virt_resource(vm, port)\n        else:\n            self._modify_virt_resource(port)\n\n    def _modify_virt_resource(self, res_setting_data):\n        vs_man_svc = self._conn.Msvm_VirtualSystemManagementService()[0]\n        (job_path, out_set_data, ret_val) = vs_man_svc.ModifyResourceSettings(\n            ResourceSettings=[res_setting_data.GetText_(1)])\n        self._check_job_status(ret_val, job_path)\n\n    def _add_virt_resource(self, vm, res_setting_data):\n        vs_man_svc = self._conn.Msvm_VirtualSystemManagementService()[0]\n        (job_path, out_set_data, ret_val) = vs_man_svc.AddResourceSettings(\n            vm.path_(), [res_setting_data.GetText_(1)])\n        self._check_job_status(ret_val, job_path)\n\n    def _remove_virt_resource(self, res_setting_data):\n        vs_man_svc = self._conn.Msvm_VirtualSystemManagementService()[0]\n        (job, ret_val) = vs_man_svc.RemoveResourceSettings(\n            ResourceSettings=[res_setting_data.path_()])\n        self._check_job_status(ret_val, job)\n\n    def _add_virt_feature(self, element, res_setting_data):\n        vs_man_svc = self._conn.Msvm_VirtualSystemManagementService()[0]\n        (job_path, out_set_data, ret_val) = vs_man_svc.AddFeatureSettings(\n            element.path_(), [res_setting_data.GetText_(1)])\n        self._check_job_status(ret_val, job_path)\n\n    def _remove_virt_feature(self, feature_resource):\n        self._remove_multiple_virt_features([feature_resource])\n\n    def _remove_multiple_virt_features(self, feature_resources):\n        vs_man_svc = self._conn.Msvm_VirtualSystemManagementService()[0]\n        (job_path, ret_val) = vs_man_svc.RemoveFeatureSettings(\n            FeatureSettings=[f.path_() for f in feature_resources])\n        self._check_job_status(ret_val, job_path)\n\n    def disconnect_switch_port(\n            self, vswitch_name, switch_port_name, vnic_deleted, delete_port):\n        \"\"\"Disconnects the switch port.\"\"\"\n        sw_port, found = self._get_switch_port_allocation(switch_port_name)\n        if not sw_port:\n            # Port not found. It happens when the VM was already deleted.\n            return\n\n        if delete_port:\n            self._remove_virt_resource(sw_port)\n        else:\n            sw_port.EnabledState = self._STATE_DISABLED\n            self._modify_virt_resource(sw_port)\n\n    def _get_vswitch(self, vswitch_name):\n        vswitch = self._conn.Msvm_VirtualEthernetSwitch(\n            ElementName=vswitch_name)\n        if not len(vswitch):\n            raise utils.HyperVException(msg=_('VSwitch not found: %s') %\n                                        vswitch_name)\n        return vswitch[0]\n\n    def set_vswitch_port_vlan_id(self, vlan_id, switch_port_name):\n        port_alloc, found = self._get_switch_port_allocation(switch_port_name)\n        if not found:\n            raise utils.HyperVException(\n                msg=_('Port Allocation not found: %s') % switch_port_name)\n\n        vs_man_svc = self._conn.Msvm_VirtualSystemManagementService()[0]\n        vlan_settings = self._get_vlan_setting_data_from_port_alloc(port_alloc)\n        if vlan_settings:\n            # Removing the feature because it cannot be modified\n            # due to a wmi exception.\n            (job_path, ret_val) = vs_man_svc.RemoveFeatureSettings(\n                FeatureSettings=[vlan_settings.path_()])\n            self._check_job_status(ret_val, job_path)\n\n        (vlan_settings, found) = self._get_vlan_setting_data(switch_port_name)\n        vlan_settings.AccessVlanId = vlan_id\n        vlan_settings.OperationMode = self._OPERATION_MODE_ACCESS\n        (job_path, out, ret_val) = vs_man_svc.AddFeatureSettings(\n            port_alloc.path_(), [vlan_settings.GetText_(1)])\n        self._check_job_status(ret_val, job_path)\n\n    def set_switch_external_port_trunk_vlan(self, vswitch_name, vlan_id,\n                                            desired_endpoint_mode):\n        pass\n\n    def _get_vlan_setting_data_from_port_alloc(self, port_alloc):\n        return self._get_first_item(port_alloc.associators(\n            wmi_result_class=self._PORT_VLAN_SET_DATA))\n\n    def _get_vlan_setting_data(self, switch_port_name, create=True):\n        return self._get_setting_data(\n            self._PORT_VLAN_SET_DATA,\n            switch_port_name, create)\n\n    def _get_switch_port_allocation(self, switch_port_name, create=False):\n        return self._get_setting_data(\n            self._PORT_ALLOC_SET_DATA,\n            switch_port_name, create)\n\n    def _get_setting_data(self, class_name, element_name, create=True):\n        element_name = element_name.replace(\"'\", '\"')\n        q = self._conn.query(\"SELECT * FROM %(class_name)s WHERE \"\n                             \"ElementName = '%(element_name)s'\" %\n                           {\"class_name\": class_name,\n                              \"element_name\": element_name})\n        data = self._get_first_item(q)\n        found = data is not None\n        if not data and create:\n            data = self._get_default_setting_data(class_name)\n            data.ElementName = element_name\n        return data, found\n\n    def _get_default_setting_data(self, class_name):\n        return self._conn.query(\"SELECT * FROM %s WHERE InstanceID \"\n                                \"LIKE '%%\\\\Default'\" % class_name)[0]\n\n    def _get_first_item(self, obj):\n        if obj:\n            return obj[0]\n\n    def enable_port_metrics_collection(self, switch_port_name):\n        port, found = self._get_switch_port_allocation(switch_port_name, False)\n        if not found:\n            return\n\n        # Add the ACLs only if they don't already exist\n        acls = port.associators(wmi_result_class=self._PORT_ALLOC_ACL_SET_DATA)\n        for acl_type in [self._ACL_TYPE_IPV4, self._ACL_TYPE_IPV6]:\n            for acl_dir in [self._ACL_DIR_IN, self._ACL_DIR_OUT]:\n                _acls = self._filter_acls(\n                    acls, self._ACL_ACTION_METER, acl_dir, acl_type)\n\n                if not _acls:\n                    acl = self._create_acl(\n                        acl_dir, acl_type, self._ACL_ACTION_METER)\n                    self._add_virt_feature(port, acl)\n\n    def enable_control_metrics(self, switch_port_name):\n        port, found = self._get_switch_port_allocation(switch_port_name, False)\n        if not found:\n            return\n\n        metric_svc = self._conn.Msvm_MetricService()[0]\n        metric_names = [self._NET_IN_METRIC_NAME, self._NET_OUT_METRIC_NAME]\n\n        for metric_name in metric_names:\n            metric_def = self._conn.CIM_BaseMetricDefinition(Name=metric_name)\n            if metric_def:\n                metric_svc.ControlMetrics(\n                    Subject=port.path_(),\n                    Definition=metric_def[0].path_(),\n                    MetricCollectionEnabled=self._METRIC_ENABLED)\n\n    def can_enable_control_metrics(self, switch_port_name):\n        port, found = self._get_switch_port_allocation(switch_port_name, False)\n        if not found:\n            return False\n\n        if not self._is_port_vm_started(port):\n            return False\n\n        # all 4 meter ACLs must be existent first. (2 x direction)\n        acls = port.associators(wmi_result_class=self._PORT_ALLOC_ACL_SET_DATA)\n        acls = [a for a in acls if a.Action == self._ACL_ACTION_METER]\n        if len(acls) < 2:\n            return False\n        return True\n\n    def _is_port_vm_started(self, port):\n        vs_man_svc = self._conn.Msvm_VirtualSystemManagementService()[0]\n        vmsettings = port.associators(\n            wmi_result_class=self._VIRTUAL_SYSTEM_SETTING_DATA)\n        #See http://msdn.microsoft.com/en-us/library/cc160706%28VS.85%29.aspx\n        (ret_val, summary_info) = vs_man_svc.GetSummaryInformation(\n            [self._VM_SUMMARY_ENABLED_STATE],\n            [v.path_() for v in vmsettings])\n        if ret_val or not summary_info:\n            raise utils.HyperVException(msg=_('Cannot get VM summary data '\n                                              'for: %s') % port.ElementName)\n\n        return summary_info[0].EnabledState is self._HYPERV_VM_STATE_ENABLED\n\n    def create_security_rule(self, switch_port_name, direction, acl_type,\n                             local_port, protocol, remote_address):\n        port, found = self._get_switch_port_allocation(switch_port_name, False)\n        if not found:\n            return\n\n        # Add the ACLs only if they don't already exist\n        acls = port.associators(wmi_result_class=self._PORT_EXT_ACL_SET_DATA)\n        weight = self._get_new_weight(acls)\n        self._bind_security_rule(\n            port, direction, acl_type, self._ACL_ACTION_ALLOW, local_port,\n            protocol, remote_address, weight)\n\n    def remove_security_rule(self, switch_port_name, direction, acl_type,\n                             local_port, protocol, remote_address):\n        port, found = self._get_switch_port_allocation(switch_port_name, False)\n        if not found:\n            # Port not found. It happens when the VM was already deleted.\n            return\n\n        acls = port.associators(wmi_result_class=self._PORT_EXT_ACL_SET_DATA)\n        filtered_acls = self._filter_security_acls(\n            acls, self._ACL_ACTION_ALLOW, direction, acl_type, local_port,\n            protocol, remote_address)\n\n        for acl in filtered_acls:\n            self._remove_virt_feature(acl)\n\n    def remove_all_security_rules(self, switch_port_name):\n        port, found = self._get_switch_port_allocation(switch_port_name, False)\n        if not found:\n            # Port not found. It happens when the VM was already deleted.\n            return\n\n        acls = port.associators(wmi_result_class=self._PORT_EXT_ACL_SET_DATA)\n        filtered_acls = [a for a in acls if\n                         a.Action is not self._ACL_ACTION_METER]\n\n        if filtered_acls:\n            self._remove_multiple_virt_features(filtered_acls)\n\n    def create_default_reject_all_rules(self, switch_port_name):\n        port, found = self._get_switch_port_allocation(switch_port_name, False)\n        if not found:\n            raise utils.HyperVException(\n                msg=_('Port Allocation not found: %s') % switch_port_name)\n\n        acls = port.associators(wmi_result_class=self._PORT_EXT_ACL_SET_DATA)\n        filtered_acls = [v for v in acls if v.Action == self._ACL_ACTION_DENY]\n\n        if len(filtered_acls) >= self._REJECT_ACLS_COUNT:\n            return\n\n        for acl in filtered_acls:\n            self._remove_virt_feature(acl)\n\n        weight = 0\n        ipv4_pair = (self._ACL_TYPE_IPV4, self._IPV4_ANY)\n        ipv6_pair = (self._ACL_TYPE_IPV6, self._IPV6_ANY)\n        for direction in [self._ACL_DIR_IN, self._ACL_DIR_OUT]:\n            for acl_type, address in [ipv4_pair, ipv6_pair]:\n                for protocol in [self._TCP_PROTOCOL, self._UDP_PROTOCOL,\n                                 self._ICMP_PROTOCOL, self._ICMPV6_PROTOCOL]:\n                    self._bind_security_rule(\n                        port, direction, acl_type, self._ACL_ACTION_DENY,\n                        self._ACL_DEFAULT, protocol, address, weight)\n                    weight += 1\n\n    def _bind_security_rule(self, port, direction, acl_type, action,\n                            local_port, protocol, remote_address, weight):\n        acls = port.associators(wmi_result_class=self._PORT_EXT_ACL_SET_DATA)\n        filtered_acls = self._filter_security_acls(\n            acls, action, direction, acl_type, local_port, protocol,\n            remote_address)\n\n        for acl in filtered_acls:\n            self._remove_virt_feature(acl)\n\n        acl = self._create_security_acl(\n            direction, acl_type, action, local_port, protocol, remote_address,\n            weight)\n\n        self._add_virt_feature(port, acl)\n\n    def _create_acl(self, direction, acl_type, action):\n        acl = self._get_default_setting_data(self._PORT_ALLOC_ACL_SET_DATA)\n        acl.set(Direction=direction,\n                AclType=acl_type,\n                Action=action,\n                Applicability=self._ACL_APPLICABILITY_LOCAL)\n        return acl\n\n    def _create_security_acl(self, direction, acl_type, action, local_port,\n                             protocol, remote_ip_address, weight):\n        acl = self._create_acl(direction, acl_type, action)\n        (remote_address, remote_prefix_length) = remote_ip_address.split('/')\n        acl.set(Applicability=self._ACL_APPLICABILITY_REMOTE,\n                RemoteAddress=remote_address,\n                RemoteAddressPrefixLength=remote_prefix_length)\n        return acl\n\n    def _filter_acls(self, acls, action, direction, acl_type, remote_addr=\"\"):\n        return [v for v in acls\n                if v.Action == action and\n                v.Direction == direction and\n                v.AclType == acl_type and\n                v.RemoteAddress == remote_addr]\n\n    def _filter_security_acls(self, acls, acl_action, direction, acl_type,\n                              local_port, protocol, remote_addr=\"\"):\n        (remote_address, remote_prefix_length) = remote_addr.split('/')\n        remote_prefix_length = int(remote_prefix_length)\n\n        return [v for v in acls\n                if v.Direction == direction and\n                v.Action in [self._ACL_ACTION_ALLOW, self._ACL_ACTION_DENY] and\n                v.AclType == acl_type and\n                v.RemoteAddress == remote_address and\n                v.RemoteAddressPrefixLength == remote_prefix_length]\n\n    def _get_new_weight(self, acls):\n        return 0\n\n\nclass HyperVUtilsV2R2(HyperVUtilsV2):\n    _PORT_EXT_ACL_SET_DATA = 'Msvm_EthernetSwitchPortExtendedAclSettingData'\n    _MAX_WEIGHT = 65500\n\n    # 2 directions x 2 address types x 4 protocols = 16 ACLs\n    _REJECT_ACLS_COUNT = 16\n\n    def create_security_rule(self, switch_port_name, direction, acl_type,\n                             local_port, protocol, remote_address):\n        if protocol is self._ACL_DEFAULT:\n            protocols = [self._ICMP_PROTOCOL, self._ICMPV6_PROTOCOL,\n                         self._TCP_PROTOCOL, self._UDP_PROTOCOL]\n        else:\n            protocols = [protocol]\n\n        for protocol in protocols:\n            super(HyperVUtilsV2R2, self).create_security_rule(\n                switch_port_name, direction, acl_type, local_port, protocol,\n                remote_address)\n\n    def remove_security_rule(self, switch_port_name, direction, acl_type,\n                             local_port, protocol, remote_address):\n        if protocol is self._ACL_DEFAULT:\n            protocols = [self._ICMP_PROTOCOL, self._ICMPV6_PROTOCOL,\n                         self._TCP_PROTOCOL, self._UDP_PROTOCOL]\n        else:\n            protocols = [protocol]\n\n        for protocol in protocols:\n            super(HyperVUtilsV2R2, self).remove_security_rule(\n                switch_port_name, direction, acl_type, local_port, protocol,\n                remote_address)\n\n    def _create_security_acl(self, direction, acl_type, action, local_port,\n                             protocol, remote_addr, weight):\n        acl = self._get_default_setting_data(self._PORT_EXT_ACL_SET_DATA)\n        is_icmp = protocol in [self._ICMP_PROTOCOL, self._ICMPV6_PROTOCOL]\n        acl.set(Direction=direction,\n                Action=action,\n                LocalPort=str(local_port) if not is_icmp else '',\n                Protocol=protocol,\n                RemoteIPAddress=remote_addr,\n                IdleSessionTimeout=0,\n                Stateful=(not is_icmp and action is not self._ACL_ACTION_DENY),\n                Weight=weight)\n        return acl\n\n    def _filter_security_acls(self, acls, action, direction, acl_type,\n                              local_port, protocol, remote_addr=\"\"):\n        return [v for v in acls\n                if v.Action == action and\n                v.Direction == direction and\n                v.LocalPort == ((str(local_port))\n                                if not protocol ==\n                                self._ICMP_PROTOCOL else '')\n                and\n                v.Protocol == protocol and\n                v.RemoteIPAddress == remote_addr]\n\n    def _get_new_weight(self, acls):\n        acls = [a for a in acls if a.Action is not self._ACL_ACTION_DENY]\n        if not acls:\n            return self._MAX_WEIGHT - 1\n\n        weights = [a.Weight for a in acls]\n        min_weight = min(weights)\n        for weight in range(min_weight, self._MAX_WEIGHT):\n            if weight not in weights:\n                return weight\n\n        return min_weight - 1\n" }
{ "repo_name": "stamhe/bitcoin", "ref": "refs/heads/master-study", "path": "contrib/devtools/optimize-pngs.py", "content": "#!/usr/bin/env python\n# Copyright (c) 2014-2017 The Bitcoin Core developers\n# Distributed under the MIT software license, see the accompanying\n# file COPYING or http://www.opensource.org/licenses/mit-license.php.\n'''\nRun this script every time you change one of the png files. Using pngcrush, it will optimize the png files, remove various color profiles, remove ancillary chunks (alla) and text chunks (text).\n#pngcrush -brute -ow -rem gAMA -rem cHRM -rem iCCP -rem sRGB -rem alla -rem text\n'''\nimport os\nimport sys\nimport subprocess\nimport hashlib\nfrom PIL import Image\n\ndef file_hash(filename):\n    '''Return hash of raw file contents'''\n    with open(filename, 'rb') as f:\n        return hashlib.sha256(f.read()).hexdigest()\n\ndef content_hash(filename):\n    '''Return hash of RGBA contents of image'''\n    i = Image.open(filename)\n    i = i.convert('RGBA')\n    data = i.tobytes()\n    return hashlib.sha256(data).hexdigest()\n\npngcrush = 'pngcrush'\ngit = 'git'\nfolders = [\"src/qt/res/movies\", \"src/qt/res/icons\", \"share/pixmaps\"]\nbasePath = subprocess.check_output([git, 'rev-parse', '--show-toplevel']).rstrip('\\n')\ntotalSaveBytes = 0\nnoHashChange = True\n\noutputArray = []\nfor folder in folders:\n    absFolder=os.path.join(basePath, folder)\n    for file in os.listdir(absFolder):\n        extension = os.path.splitext(file)[1]\n        if extension.lower() == '.png':\n            print(\"optimizing \"+file+\"...\"),\n            file_path = os.path.join(absFolder, file)\n            fileMetaMap = {'file' : file, 'osize': os.path.getsize(file_path), 'sha256Old' : file_hash(file_path)}\n            fileMetaMap['contentHashPre'] = content_hash(file_path)\n        \n            pngCrushOutput = \"\"\n            try:\n                pngCrushOutput = subprocess.check_output(\n                        [pngcrush, \"-brute\", \"-ow\", \"-rem\", \"gAMA\", \"-rem\", \"cHRM\", \"-rem\", \"iCCP\", \"-rem\", \"sRGB\", \"-rem\", \"alla\", \"-rem\", \"text\", file_path],\n                        stderr=subprocess.STDOUT).rstrip('\\n')\n            except:\n                print \"pngcrush is not installed, aborting...\"\n                sys.exit(0)\n        \n            #verify\n            if \"Not a PNG file\" in subprocess.check_output([pngcrush, \"-n\", \"-v\", file_path], stderr=subprocess.STDOUT):\n                print \"PNG file \"+file+\" is corrupted after crushing, check out pngcursh version\"\n                sys.exit(1)\n            \n            fileMetaMap['sha256New'] = file_hash(file_path)\n            fileMetaMap['contentHashPost'] = content_hash(file_path)\n\n            if fileMetaMap['contentHashPre'] != fileMetaMap['contentHashPost']:\n                print \"Image contents of PNG file \"+file+\" before and after crushing don't match\"\n                sys.exit(1)\n\n            fileMetaMap['psize'] = os.path.getsize(file_path)\n            outputArray.append(fileMetaMap)\n            print(\"done\\n\"),\n\nprint \"summary:\\n+++++++++++++++++\"\nfor fileDict in outputArray:\n    oldHash = fileDict['sha256Old']\n    newHash = fileDict['sha256New']\n    totalSaveBytes += fileDict['osize'] - fileDict['psize']\n    noHashChange = noHashChange and (oldHash == newHash)\n    print fileDict['file']+\"\\n  size diff from: \"+str(fileDict['osize'])+\" to: \"+str(fileDict['psize'])+\"\\n  old sha256: \"+oldHash+\"\\n  new sha256: \"+newHash+\"\\n\"\n    \nprint \"completed. Checksum stable: \"+str(noHashChange)+\". Total reduction: \"+str(totalSaveBytes)+\" bytes\"\n" }
{ "repo_name": "spblightadv/rethinkdb", "ref": "refs/heads/next", "path": "external/v8_3.30.33.16/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "Simran-B/arangodb", "ref": "refs/heads/docs_3.0", "path": "3rdParty/V8-4.3.61/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "losywee/rethinkdb", "ref": "refs/heads/next", "path": "external/v8_3.30.33.16/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "Suwmlee/XX-Net", "ref": "refs/heads/python3", "path": "Python3/lib/ctypes/test/test_keeprefs.py", "content": "from ctypes import *\r\nimport unittest\r\n\r\nclass SimpleTestCase(unittest.TestCase):\r\n    def test_cint(self):\r\n        x = c_int()\r\n        self.assertEqual(x._objects, None)\r\n        x.value = 42\r\n        self.assertEqual(x._objects, None)\r\n        x = c_int(99)\r\n        self.assertEqual(x._objects, None)\r\n\r\n    def test_ccharp(self):\r\n        x = c_char_p()\r\n        self.assertEqual(x._objects, None)\r\n        x.value = b\"abc\"\r\n        self.assertEqual(x._objects, b\"abc\")\r\n        x = c_char_p(b\"spam\")\r\n        self.assertEqual(x._objects, b\"spam\")\r\n\r\nclass StructureTestCase(unittest.TestCase):\r\n    def test_cint_struct(self):\r\n        class X(Structure):\r\n            _fields_ = [(\"a\", c_int),\r\n                        (\"b\", c_int)]\r\n\r\n        x = X()\r\n        self.assertEqual(x._objects, None)\r\n        x.a = 42\r\n        x.b = 99\r\n        self.assertEqual(x._objects, None)\r\n\r\n    def test_ccharp_struct(self):\r\n        class X(Structure):\r\n            _fields_ = [(\"a\", c_char_p),\r\n                        (\"b\", c_char_p)]\r\n        x = X()\r\n        self.assertEqual(x._objects, None)\r\n\r\n        x.a = b\"spam\"\r\n        x.b = b\"foo\"\r\n        self.assertEqual(x._objects, {\"0\": b\"spam\", \"1\": b\"foo\"})\r\n\r\n    def test_struct_struct(self):\r\n        class POINT(Structure):\r\n            _fields_ = [(\"x\", c_int), (\"y\", c_int)]\r\n        class RECT(Structure):\r\n            _fields_ = [(\"ul\", POINT), (\"lr\", POINT)]\r\n\r\n        r = RECT()\r\n        r.ul.x = 0\r\n        r.ul.y = 1\r\n        r.lr.x = 2\r\n        r.lr.y = 3\r\n        self.assertEqual(r._objects, None)\r\n\r\n        r = RECT()\r\n        pt = POINT(1, 2)\r\n        r.ul = pt\r\n        self.assertEqual(r._objects, {'0': {}})\r\n        r.ul.x = 22\r\n        r.ul.y = 44\r\n        self.assertEqual(r._objects, {'0': {}})\r\n        r.lr = POINT()\r\n        self.assertEqual(r._objects, {'0': {} '1': {}})\r\n\r\nclass ArrayTestCase(unittest.TestCase):\r\n    def test_cint_array(self):\r\n        INTARR = c_int * 3\r\n\r\n        ia = INTARR()\r\n        self.assertEqual(ia._objects, None)\r\n        ia[0] = 1\r\n        ia[1] = 2\r\n        ia[2] = 3\r\n        self.assertEqual(ia._objects, None)\r\n\r\n        class X(Structure):\r\n            _fields_ = [(\"x\", c_int),\r\n                        (\"a\", INTARR)]\r\n\r\n        x = X()\r\n        x.x = 1000\r\n        x.a[0] = 42\r\n        x.a[1] = 96\r\n        self.assertEqual(x._objects, None)\r\n        x.a = ia\r\n        self.assertEqual(x._objects, {'1': {}})\r\n\r\nclass PointerTestCase(unittest.TestCase):\r\n    def test_p_cint(self):\r\n        i = c_int(42)\r\n        x = pointer(i)\r\n        self.assertEqual(x._objects, {'1': i})\r\n\r\nclass DeletePointerTestCase(unittest.TestCase):\r\n    @unittest.skip('test disabled')\r\n    def test_X(self):\r\n        class X(Structure):\r\n            _fields_ = [(\"p\", POINTER(c_char_p))]\r\n        x = X()\r\n        i = c_char_p(\"abc def\")\r\n        from sys import getrefcount as grc\r\n        print(\"2?\", grc(i))\r\n        x.p = pointer(i)\r\n        print(\"3?\", grc(i))\r\n        for i in range(320):\r\n            c_int(99)\r\n            x.p[0]\r\n        print(x.p[0])\r\n##        del x\r\n##        print \"2?\", grc(i)\r\n##        del i\r\n        import gc\r\n        gc.collect()\r\n        for i in range(320):\r\n            c_int(99)\r\n            x.p[0]\r\n        print(x.p[0])\r\n        print(x.p.contents)\r\n##        print x._objects\r\n\r\n        x.p[0] = \"spam spam\"\r\n##        print x.p[0]\r\n        print(\"+\" * 42)\r\n        print(x._objects)\r\n\r\nclass PointerToStructure(unittest.TestCase):\r\n    def test(self):\r\n        class POINT(Structure):\r\n            _fields_ = [(\"x\", c_int), (\"y\", c_int)]\r\n        class RECT(Structure):\r\n            _fields_ = [(\"a\", POINTER(POINT)),\r\n                        (\"b\", POINTER(POINT))]\r\n        r = RECT()\r\n        p1 = POINT(1, 2)\r\n\r\n        r.a = pointer(p1)\r\n        r.b = pointer(p1)\r\n##        from pprint import pprint as pp\r\n##        pp(p1._objects)\r\n##        pp(r._objects)\r\n\r\n        r.a[0].x = 42\r\n        r.a[0].y = 99\r\n\r\n        # to avoid leaking when tests are run several times\r\n        # clean up the types left in the cache.\r\n        from ctypes import _pointer_type_cache\r\n        del _pointer_type_cache[POINT]\r\n\r\nif __name__ == \"__main__\":\r\n    unittest.main()\r\n" }
{ "repo_name": "sebadiaz/rethinkdb", "ref": "refs/heads/next", "path": "external/v8_3.30.33.16/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "mosaic-cloud/mosaic-distribution-dependencies", "ref": "refs/heads/development", "path": "dependencies/nodejs/0.8.22/deps/npm/node_modules/node-gyp/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "sssemil/cjdns", "ref": "refs/heads/socket", "path": "node_build/dependencies/libuv/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "greyhwndz/rethinkdb", "ref": "refs/heads/next", "path": "external/v8_3.30.33.16/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "victorbriz/rethinkdb", "ref": "refs/heads/next", "path": "external/v8_3.30.33.16/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "oktayacikalin/pyglet", "ref": "refs/heads/pyglet-1.2-maintenance", "path": "contrib/projection/tests/projection/base_projection.py", "content": "#!/usr/bin/python\n# $Id:$\n\nfrom pyglet.gl import *\n\ndef fillrect(x, y, width, height):\n    glBegin(GL_QUADS)\n    glVertex2f(x, y)\n    glVertex2f(x + width, y)\n    glVertex2f(x + width, y + height)\n    glVertex2f(x, y + height)\n    glEnd()\n\ndef rect(x, y, width, height):\n    glBegin(GL_LINE_LOOP)\n    glVertex2f(x, y)\n    glVertex2f(x + width, y)\n    glVertex2f(x + width, y + height)\n    glVertex2f(x, y + height)\n    glEnd()\n" }
{ "repo_name": "bsa11b/mtasa-blue", "ref": "refs/heads/1.4.1", "path": "vendor/google-breakpad/src/tools/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "livecd-tools/livecd-tools", "ref": "refs/heads/aarch64-liveiso", "path": "imgcreate/dnfinst.py", "content": "#\n# dnfinst.py : dnf utilities\n#\n# Copyright 2007, Red Hat  Inc.\n# Copyright 2016, Kevin Kofler\n# Copyright 2016, Neal Gompa\n#\n# Portions from Anaconda dnfpayload.py\n# DNF/rpm software payload management.\n#\n# Copyright (C) 2013-2015  Red Hat, Inc.\n#\n# This program is free software; you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation; version 2 of the License.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU Library General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program; if not, write to the Free Software\n# Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.\n\nfrom __future__ import print_function\nimport glob\nimport os\nimport sys\nimport logging\nimport itertools\n\nimport dnf\nimport dnf.rpm\n# FIXME: Why are these hidden inside dnf.cli? Any text-mode app should be able\n#        to make use of these.\nfrom dnf.cli.progress import MultiFileProgressMeter as DownloadProgress\nfrom dnf.cli.output import CliTransactionDisplay as TransactionProgress\nimport hawkey\nfrom pykickstart.constants import GROUP_DEFAULT, GROUP_REQUIRED, GROUP_ALL\n\nfrom imgcreate.errors import *\n\nclass DnfLiveCD(dnf.Base):\n    def __init__(self, releasever=None, useplugins=False):\n        \"\"\"\n        releasever = optional value to use in replacing $releasever in repos\n        \"\"\"\n        dnf.Base.__init__(self)\n        self.releasever = releasever\n        self.useplugins = useplugins\n\n    def doFileLogSetup(self, uid, logfile):\n        # don't do the file log for the livecd as it can lead to open fds\n        # being left and an inability to clean up after ourself\n        pass\n\n    def close(self):\n        try:\n            os.unlink(self.conf.installroot + \"/dnf.conf\")\n        except:\n            pass\n        dnf.Base.close(self)\n\n    def __del__(self):\n        pass\n\n    def _writeConf(self, confpath, installroot):\n        conf  = \"[main]\\n\"\n        conf += \"installroot=%s\\n\" % installroot\n        conf += \"cachedir=/var/cache/dnf\\n\"\n        if self.useplugins:\n            conf += \"plugins=1\\n\"\n        else:\n            conf += \"plugins=0\\n\"\n        conf += \"reposdir=/dev/null\\n\"\n        conf += \"failovermethod=priority\\n\"\n        conf += \"keepcache=1\\n\"\n        conf += \"obsoletes=1\\n\"\n        conf += \"best=1\\n\"\n        conf += \"tsflags=nocontexts\\n\"\n\n        f = open(confpath, \"w+\")\n        f.write(conf)\n        f.close()\n\n        os.chmod(confpath, 0o644)\n\n    def _cleanupRpmdbLocks(self, installroot):\n        # cleans up temporary files left by bdb so that differing\n        # versions of rpm don't cause problems\n        for f in glob.glob(installroot + \"/var/lib/rpm/__db*\"):\n            os.unlink(f)\n\n    def setup(self, confpath, installroot, cacheonly=False, excludeWeakdeps=False):\n        self._writeConf(confpath, installroot)\n        self._cleanupRpmdbLocks(installroot)\n        self.conf.read(confpath)\n        self.conf.installroot = installroot\n        self.conf.prepend_installroot(\"cachedir\")\n        self.conf.prepend_installroot(\"persistdir\")\n        self.conf.install_weak_deps = not excludeWeakdeps\n        if cacheonly:\n            dnf.repo.Repo.DEFAULT_SYNC = dnf.repo.SYNC_ONLY_CACHE\n        else:\n            dnf.repo.Repo.DEFAULT_SYNC = dnf.repo.SYNC_TRY_CACHE\n\n    def deselectPackage(self, pkg):\n        \"\"\"Deselect a given package.  Can be specified with name.arch or name*\"\"\"\n        subj = dnf.subject.Subject(pkg)\n        pkgs = subj.get_best_query(self.sack)\n        # The only way to get expected behavior is to declare it\n        # as excluded from the installable set\n        return self.sack.add_excludes(pkgs)\n\n    def selectPackage(self, pkg):\n        \"\"\"Select a given package.  Can be specified with name.arch or name*\"\"\"\n        return self.install(pkg)\n        \n    def selectGroup(self, group_id, exclude, include = GROUP_DEFAULT):\n        grp = self.comps.group_by_pattern(group_id)\n        if grp is None:\n            raise dnf.exceptions.MarkingError('no such group', '@' + group_id)\n        # default to getting mandatory and default packages from a group\n        # unless we have specific options from kickstart\n        package_types = {'mandatory', 'default'}\n        if include == GROUP_REQUIRED:\n            package_types.remove('default')\n        elif include == GROUP_ALL:\n            package_types.add('optional')\n        try:\n            self.group_install(grp.id, tuple(package_types), exclude=exclude)\n        except dnf.exceptions.CompsError as e:\n            # DNF raises this when it is already selected\n            pass\n\n    def environmentGroups(self, environmentid, optional=True):\n        env = self.comps.environment_by_pattern(environmentid)\n        if env is None:\n            dnf.exceptions.MarkingError('no such environment', '@^' + environmentid)\n        group_ids = (id_.name for id_ in env.group_ids)\n        option_ids = (id_.name for id_ in env.option_ids)\n        if optional:\n            return list(itertools.chain(group_ids, option_ids))\n        else:\n            return list(group_ids)\n\n    def selectEnvironment(self, env_id, excluded, excludedPkgs):\n        # dnf.base.environment_install excludes on packages instead of groups,\n        # which is unhelpful. Instead, use group_install for each group in\n        # the environment so we can skip the ones that are excluded.\n        for groupid in set(self.environmentGroups(env_id, optional=False)) - set(excluded):\n            self.selectGroup(groupid, excludedPkgs)\n\n    def addRepository(self, name, url = None, mirrorlist = None):\n        def _varSubstitute(option):\n            # takes a variable and substitutes like dnf configs do\n            arch = hawkey.detect_arch()\n            option = option.replace(\"$basearch\", dnf.rpm.basearch(arch))\n            option = option.replace(\"$arch\", arch)\n            # If the url includes $releasever substitute user's value or\n            # current system's version.\n            if option.find(\"$releasever\") > -1:\n                if self.releasever:\n                    option = option.replace(\"$releasever\", self.releasever)\n                else:\n                    try:\n                        detected_releasever = dnf.rpm.detect_releasever(\"/\")\n                    except dnf.exceptions.Error:\n                        detected_releasever = None\n                    if detected_releasever:\n                        option = option.replace(\"$releasever\", detected_releasever)\n                    else:\n                        raise CreatorError(\"$releasever in repo url, but no releasever set\")\n            return option\n\n        try:\n            # dnf 2\n            repo = dnf.repo.Repo(name, parent_conf = self.conf)\n        except TypeError as e:\n            # dnf 1\n            repo = dnf.repo.Repo(name, cachedir = self.conf.cachedir)\n        if url:\n            # some overly clever trickery in dnf 3 prevents us just\n            # using repo.baseurl.append here:\n            # https://bugzilla.redhat.com/show_bug.cgi?id=1595917\n            # with the change to representing it as a tuple in DNF 3.6\n            # this '+= (tuple)' approach seems to work for DNF 2,\n            # 3.0-3.5 *and* 3.6\n            repo.baseurl += (_varSubstitute(url),)\n        if mirrorlist:\n            repo.mirrorlist = _varSubstitute(mirrorlist)\n        repo.enable()\n        repo.set_progress_bar(DownloadProgress())\n        self.repos.add(repo)\n        return repo\n\n    def runInstall(self):\n        import dnf.exceptions\n        os.environ[\"HOME\"] = \"/\"\n        try:\n            res = self.resolve()\n        except dnf.exceptions.RepoError as e:\n            raise CreatorError(\"Unable to download from repo : %s\" %(e,))\n        except dnf.exceptions.Error as e:\n            raise CreatorError(\"Failed to build transaction : %s\" %(e,))\n        # Empty transactions are generally fine, we might be rebuilding an\n        # existing image with no packages added\n        if not res:\n            return True\n\n        dlpkgs = self.transaction.install_set\n        self.download_packages(dlpkgs, DownloadProgress())\n        # FIXME: sigcheck?\n\n        ret = self.do_transaction(TransactionProgress())\n        print(\"\")\n        self._cleanupRpmdbLocks(self.conf.installroot)\n        return ret\n" }
{ "repo_name": "gavioto/rethinkdb", "ref": "refs/heads/next", "path": "external/v8_3.30.33.16/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "theblacklion/pyglet", "ref": "refs/heads/pyglet-1.2-maintenance", "path": "contrib/projection/tests/projection/base_projection.py", "content": "#!/usr/bin/python\n# $Id:$\n\nfrom pyglet.gl import *\n\ndef fillrect(x, y, width, height):\n    glBegin(GL_QUADS)\n    glVertex2f(x, y)\n    glVertex2f(x + width, y)\n    glVertex2f(x + width, y + height)\n    glVertex2f(x, y + height)\n    glEnd()\n\ndef rect(x, y, width, height):\n    glBegin(GL_LINE_LOOP)\n    glVertex2f(x, y)\n    glVertex2f(x + width, y)\n    glVertex2f(x + width, y + height)\n    glVertex2f(x, y + height)\n    glEnd()\n" }
{ "repo_name": "jesseditson/rethinkdb", "ref": "refs/heads/next", "path": "external/v8_3.30.33.16/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "baslr/ArangoDB", "ref": "refs/heads/3.1-silent", "path": "3rdParty/V8/V8-5.0.71.39/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "rrampage/rethinkdb", "ref": "refs/heads/next", "path": "external/v8_3.30.33.16/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "AntouanK/rethinkdb", "ref": "refs/heads/next", "path": "external/v8_3.30.33.16/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "wojons/rethinkdb", "ref": "refs/heads/next", "path": "external/v8_3.30.33.16/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "StephenKing/summerschool-2015-ryu", "ref": "refs/heads/summerschool-step2-complete", "path": "ryu/services/protocols/bgp/signals/base.py", "content": "import logging\nLOG = logging.getLogger('bgpspeaker.signals.base')\n\n\nclass SignalBus(object):\n    def __init__(self):\n        self._listeners = {}\n\n    def emit_signal(self, identifier, data):\n        identifier = _to_tuple(identifier)\n        LOG.debug('SIGNAL: %s emited with data: %s ', identifier, data)\n        for func, filter_func in self._listeners.get(identifier, []):\n            if not filter_func or filter_func(data):\n                func(identifier, data)\n\n    def register_listener(self, identifier, func, filter_func=None):\n        identifier = _to_tuple(identifier)\n        substrings = (identifier[:i] for i in xrange(1, len(identifier) + 1))\n        for partial_id in substrings:\n            self._listeners.setdefault(\n                partial_id,\n                []\n            ).append((func, filter_func))\n\n    def unregister_all(self):\n        self._listeners = {}\n\n\ndef _to_tuple(tuple_or_not):\n    if not isinstance(tuple_or_not, tuple):\n        return (tuple_or_not, )\n    else:\n        return tuple_or_not\n" }
{ "repo_name": "mquandalle/rethinkdb", "ref": "refs/heads/next", "path": "external/v8_3.30.33.16/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "Omegaphora/external_chromium_org_tools_gyp", "ref": "refs/heads/lp5.1", "path": "test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "mcanthony/rethinkdb", "ref": "refs/heads/next", "path": "external/v8_3.30.33.16/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "Wilbeibi/rethinkdb", "ref": "refs/heads/next", "path": "external/v8_3.30.33.16/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "ayumilong/rethinkdb", "ref": "refs/heads/next", "path": "external/v8_3.30.33.16/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "yaolinz/rethinkdb", "ref": "refs/heads/next", "path": "external/v8_3.30.33.16/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "ajose01/rethinkdb", "ref": "refs/heads/next", "path": "external/v8_3.30.33.16/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "MIPS/external-chromium_org-tools-gyp", "ref": "refs/heads/dev-mips-jb-kitkat", "path": "test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "l0b0/cds-invenio-vengmark", "ref": "refs/heads/install-from-source", "path": "modules/bibclassify/lib/bibclassify_config.py", "content": "# -*- coding: utf-8 -*-\n##\n## This file is part of CDS Invenio.\n## Copyright (C) 2002, 2003, 2004, 2005, 2006, 2007, 2008 CERN.\n##\n## CDS Invenio is free software; you can redistribute it and/or\n## modify it under the terms of the GNU General Public License as\n## published by the Free Software Foundation; either version 2 of the\n## License, or (at your option) any later version.\n##\n## CDS Invenio is distributed in the hope that it will be useful, but\n## WITHOUT ANY WARRANTY; without even the implied warranty of\n## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n## General Public License for more details.\n##\n## You should have received a copy of the GNU General Public License\n## along with CDS Invenio; if not, write to the Free Software Foundation, Inc.,\n## 59 Temple Place, Suite 330, Boston, MA 02111-1307, USA.\n\n\"\"\"\nBibClassify configuration file.\nWhen writing changes, please either delete the cached ontology in your\ntemporary directory or use the rebuild-cache option in order to\nregenerate the cached ontology.\n\nIf you want to change this configuration, we recommend to create a\nlocal configuration file names 'bibclassify_config_local.py' that\ncontains the changes to apply.\n\"\"\"\n\nimport re\n\n# USER AGENT\n\nCFG_BIBCLASSIFY_USER_AGENT = \"\"\n\n# BIBCLASSIFY VARIABLES\n\n# Number of keywords that are output per default.\nCFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER = 20\n\n# PARTIAL_TEXT\n# Marks the part of the fulltext to keep when running a partial match.\n# Each tuple contains the start and end percentages of a section.\nCFG_BIBCLASSIFY_PARTIAL_TEXT = ((0, 20), (40, 60))\n\n# WORD TRANSFORMATIONS\n\n# BibClassify creates a regular expression for each label found in the\n# ontology.\n# If the keyword belongs in 'INVARIABLE_WORDS', we return it whitout any\n# change.\n# If the keyword is found in 'EXCEPTIONS', we return its attached\n# regular expression.\n# If the keyword is matched by a regular expression of\n# 'UNCHANGE_REGULAR_EXPRESSIONS', we return the keyword without any\n# change.\n# At last, we perform the sub method of Python's re module using the\n# first element of the tuple as the regex and the second element as the\n# replacement string.\n\n# Regular expressions found here have been originally based on\n# Wikipedia's page on English plural.\n# [http://en.wikipedia.org/wiki/English_plural]\n\nCFG_BIBCLASSIFY_INVARIABLE_WORDS = (\"any\", \"big\", \"chi\", \"der\", \"eta\", \"few\",\n    \"low\", \"new\", \"non\", \"off\", \"one\", \"out\", \"phi\", \"psi\", \"rho\", \"tau\",\n    \"two\", \"van\", \"von\", \"hard\", \"weak\", \"four\", \"anti\", \"zero\", \"sinh\",\n    \"open\", \"high\", \"data\", \"dark\", \"free\", \"flux\", \"fine\", \"final\", \"heavy\",\n    \"strange\")\n\nCFG_BIBCLASSIFY_EXCEPTIONS = {\n    \"aluminium\": r\"alumini?um\",\n    \"aluminum\": r\"alumini?um\",\n    \"analysis\": r\"analy[sz]is\",\n    \"analyzis\": r\"analy[sz]is\",\n    \"behavior\": r\"behaviou?rs?\",\n    \"behaviour\": r\"behaviou?rs?\",\n    \"color\": r\"colou?rs?\",\n    \"colour\": r\"colou?rs?\",\n    \"deflexion\": r\"defle(x|ct)ions?\",\n    \"flavor\": r\"flavou?rs?\",\n    \"flavour\": r\"flavou?rs?\",\n    \"gas\": r\"gas(s?es)?\",\n    \"lens\": r\"lens(es)?\",\n    \"matrix\": r\"matri(x(es)?|ces)\",\n    \"muon\": r\"muons?\",\n    \"neutrino\": r\"neutrinos?\",\n    \"reflexion\": r\"refle(x|ct)ions?\",\n    \"ring\": r\"rings?\",\n    \"status\": r\"status(es)?\",\n    \"string\": r\"strings?\",\n    \"sum\": r\"sums?\",\n    \"vertex\": r\"vert(ex(es)?|ices)\",\n    \"vortex\": r\"vort(ex(es)?|ices)\",\n  }\n\nCFG_BIBCLASSIFY_UNCHANGE_REGULAR_EXPRESSIONS = (\n    re.compile(\"[^e]ed$\"),\n    re.compile(\"ics?$\"),\n    re.compile(\"[io]s$\"),\n    re.compile(\"ium$\"),\n    re.compile(\"less$\"),\n    re.compile(\"ous$\"),\n    )\n\n# IDEAS\n# \"al$\" -> \"al(ly)?\"\n\nCFG_BIBCLASSIFY_GENERAL_REGULAR_EXPRESSIONS = (\n    (re.compile(\"ional\"), r\"ional(ly)?\"),\n    (re.compile(\"([ae])n(ce|t)$\"), r\"\\1n(t|ces?)\"),\n    (re.compile(\"og(ue)?$\"), r\"og(ue)?s?\"),\n    (re.compile(\"([^aeiouyc])(re|er)$\"), r\"\\1(er|re)s?\"),\n    (re.compile(\"([aeiouy])[sz]ation$\"), r\"\\1[zs]ations?\"),\n    (re.compile(\"([aeiouy])[sz]ation$\"), r\"\\1[zs]ations?\"),\n    (re.compile(\"([^aeiou])(y|ies)$\"), r\"\\1(y|ies)\"),\n    (re.compile(\"o$\"), r\"o(e?s)?\"),\n    (re.compile(\"(x|sh|ch|ss)$\"), r\"\\1(es)?\"),\n    (re.compile(\"f$\"), r\"(f|ves)\"),\n    (re.compile(\"ung$\"), r\"ung(en)?\"),\n    (re.compile(\"([^aiouy])s$\"), r\"\\1s?\"),\n    (re.compile(\"([^o])us$\"), r\"\\1(i|us(es)?)\"),\n    (re.compile(\"um$\"), r\"(a|ums?)\"),\n    )\n\n# PUNCTUATION TRANSFORMATIONS\n\n# When building the regex pattern for each label of the ontology, ew also take\n# care of the non-alpha characters. Thereafter are two sets of transformations.\n# 'SEPARATORS' contains the transformation for the non-alpha characters that\n# can be found between two words.\n# 'SYMBOLS' contains punctuation that can be found at the end of a word.\n# In both cases, it the separator is not found in the dictionaries, we return\n# re.escape(separator)\n\nCFG_BIBCLASSIFY_SEPARATORS = {\n    \" \": r\"[\\s-]\",\n    \"-\": r\"[\\s-]?\",\n    \"/\": r\"[/\\s]?\",\n    \"(\": r\"\\s?\\(\",\n    \"*\": r\"[*\\s]?\",\n    \"- \": r\"\\s?\\-\\s\",\n    \"+ \": r\"\\s?\\+\\s\",\n  }\n\nCFG_BIBCLASSIFY_SYMBOLS = {\n    \"'\": r\"\\s?\\'\",\n  }\n\nCFG_BIBCLASSIFY_WORD_WRAP = \"[^\\w-]%s[^\\w-]\"\n\n# MATCHING\n\n# When searching for composite keywords, we allow two keywords separated by one\n# of the component of 'VALID_SEPARATORS' to form a composite keyword. These\n# separators contain also the punctuation.\n\nCFG_BIBCLASSIFY_VALID_SEPARATORS = (\n    \"of\", \"of a\", \"of an\", \"of the\", \"of this\", \"of one\", \"of two\", \"of three\",\n    \"of new\", \"of other\",  \"of many\", \"of both\", \"of these\", \"of each\", \"is\"\n    )\n\n# AUTHOR KEYWORDS\n\n# When looking for the keywords already defined in the document, we run the\n# following set of regex.\n\nCFG_BIBCLASSIFY_AUTHOR_KW_START = \\\n    re.compile(r\"(?i)key[ -]*words?[a-z ]*[.:] *\")\n\nCFG_BIBCLASSIFY_AUTHOR_KW_END = (\n    re.compile(r\"\\n\"),\n    re.compile(r\"\\.\\W\"),\n    re.compile(r\"\\sPACS\"),\n    re.compile(r\"(?i)1[. ]*introduction\\W\"),\n    re.compile(r\"(?i)mathematics subject classification\\W\"),\n    )\n\nCFG_BIBCLASSIFY_AUTHOR_KW_SEPARATION = re.compile(\" ?; ?| ?, ?| ?- \")\n\n" }
{ "repo_name": "urandu/rethinkdb", "ref": "refs/heads/next", "path": "external/v8_3.30.33.16/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "elkingtonmcb/rethinkdb", "ref": "refs/heads/next", "path": "external/v8_3.30.33.16/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "yxl/emscripten-calligra-mobile", "ref": "refs/heads/calligra/2.8", "path": "3rdparty/google-breakpad/src/tools/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "tempbottle/rethinkdb", "ref": "refs/heads/next", "path": "external/v8_3.30.33.16/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "matthaywardwebdesign/rethinkdb", "ref": "refs/heads/next", "path": "external/v8_3.30.33.16/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" } 
{ "repo_name": "lenstr/rethinkdb", "ref": "refs/heads/next", "path": "external/v8_3.30.33.16/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "KSanthanam/rethinkdb", "ref": "refs/heads/next", "path": "external/v8_3.30.33.16/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "wkennington/rethinkdb", "ref": "refs/heads/next", "path": "external/v8_3.30.33.16/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "4talesa/rethinkdb", "ref": "refs/heads/next", "path": "external/v8_3.30.33.16/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "OCA/l10n-italy", "ref": "refs/heads/12.0", "path": "l10n_it_ricevute_bancarie/wizard/wizard_unsolved.py", "content": "# Copyright (C) 2012 Andrea Cometa.\n# Email: info@andreacometa.it\n# Web site: http://www.andreacometa.it\n# Copyright (C) 2012 Associazione OpenERP Italia\n# (<http://www.odoo-italia.org>).\n# Copyright (C) 2012-2017 Lorenzo Battistini - Agile Business Group\n# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl).\n\nfrom odoo import fields, models, _, api\nfrom odoo.exceptions import UserError\n\n\nclass RibaUnsolved(models.TransientModel):\n\n    @api.model\n    def _get_unsolved_journal_id(self):\n        return self.env[\n            'riba.configuration'\n        ].get_default_value_by_list_line('unsolved_journal_id')\n\n    @api.model\n    def _get_effects_account_id(self):\n        return self.env[\n            'riba.configuration'\n        ].get_default_value_by_list_line('acceptance_account_id')\n\n    @api.model\n    def _get_effects_amount(self):\n        if not self.env.context.get('active_id', False):\n            return False\n        return self.env[\n            'riba.distinta.line'\n        ].browse(self.env.context['active_id']).amount\n\n    @api.model\n    def _get_riba_bank_account_id(self):\n        return self.env[\n            'riba.configuration'\n        ].get_default_value_by_list_line('accreditation_account_id')\n\n    @api.model\n    def _get_overdue_effects_account_id(self):\n        return self.env[\n            'riba.configuration'\n        ].get_default_value_by_list_line('overdue_effects_account_id')\n\n    @api.model\n    def _get_bank_account_id(self):\n        return self.env[\n            'riba.configuration'\n        ].get_default_value_by_list_line('bank_account_id')\n\n    @api.model\n    def _get_bank_expense_account_id(self):\n        return self.env[\n            'riba.configuration'\n        ].get_default_value_by_list_line('protest_charge_account_id')\n\n    _name = \"riba.unsolved\"\n    _description = \"Manage Past Due C/Os\"\n    unsolved_journal_id = fields.Many2one(\n        'account.journal', 'Past Due Journal', domain=[('type', '=', 'bank')],\n        default=_get_unsolved_journal_id)\n    effects_account_id = fields.Many2one(\n        'account.account', 'Bills Account',\n        domain=[('internal_type', '=', 'receivable')],\n        default=_get_effects_account_id)\n    effects_amount = fields.Float(\n        'Bills Amount', default=_get_effects_amount)\n    riba_bank_account_id = fields.Many2one(\n        'account.account', 'C/O Account',\n        default=_get_riba_bank_account_id)\n    riba_bank_amount = fields.Float(\n        'C/O Amount', default=_get_effects_amount)\n    overdue_effects_account_id = fields.Many2one(\n        'account.account', 'Past Due Bills Account',\n        domain=[('internal_type', '=', 'receivable')],\n        default=_get_overdue_effects_account_id)\n    overdue_effects_amount = fields.Float(\n        'Past Due Bills Amount', default=_get_effects_amount)\n    bank_account_id = fields.Many2one(\n        'account.account', 'A/C Bank Account', domain=[(\n            'internal_type', '=', 'liquidity')],\n        default=_get_bank_account_id)\n    bank_amount = fields.Float('Withdrawn Amount')\n    bank_expense_account_id = fields.Many2one(\n        'account.account', 'Bank Fees Account',\n        default=_get_bank_expense_account_id)\n    expense_amount = fields.Float('Fees Amount')\n\n    def skip(self):\n        active_id = self.env.context.get('active_id')\n        if not active_id:\n            raise UserError(_('No active ID found.'))\n        line_model = self.env['riba.distinta.line']\n        line = line_model.browse(active_id)\n        line.state = 'unsolved'\n        line.distinta_id.state = 'unsolved'\n        return {'type': 'ir.actions.act_window_close'}\n\n    def create_move(self):\n        active_id = self.env.context.get('active_id', False)\n        if not active_id:\n            raise UserError(_('No active ID found.'))\n        move_model = self.env['account.move']\n        invoice_model = self.env['account.invoice']\n        move_line_model = self.env['account.move.line']\n        distinta_line = self.env['riba.distinta.line'].browse(active_id)\n        wizard = self\n        if (\n            not wizard.unsolved_journal_id or\n            not wizard.effects_account_id or\n            not wizard.riba_bank_account_id or\n            not wizard.overdue_effects_account_id or\n            not wizard.bank_account_id or\n            not wizard.bank_expense_account_id\n        ):\n            raise UserError(_('Every account is mandatory.'))\n        move_vals = {\n            'ref': _('Past Due C/O %s - Line %s') % (\n                distinta_line.distinta_id.name, distinta_line.sequence),\n            'journal_id': wizard.unsolved_journal_id.id,\n            'line_ids': [\n                (0, 0, {\n                    'name':  _('Bills'),\n                    'account_id': wizard.effects_account_id.id,\n                    'partner_id': distinta_line.partner_id.id,\n                    'credit': wizard.effects_amount,\n                    'debit': 0.0,\n              }),\n                (0, 0, {\n                    'name':  _('C/O'),\n                    'account_id': wizard.riba_bank_account_id.id,\n                    'debit': wizard.riba_bank_amount,\n                    'credit': 0.0,\n              }),\n                (0, 0, {\n                    'name':  _('Past Due Bills'),\n                    'account_id': wizard.overdue_effects_account_id.id,\n                    'debit': wizard.overdue_effects_amount,\n                    'credit': 0.0,\n                    'partner_id': distinta_line.partner_id.id,\n                    'date_maturity': distinta_line.due_date,\n              }),\n                (0, 0, {\n                    'name':  _('A/C Bank'),\n                    'account_id': wizard.bank_account_id.id,\n                    'credit': wizard.bank_amount,\n                    'debit': 0.0,\n              }),\n            ]\n      }\n\n        if wizard.expense_amount:\n            move_vals['line_ids'].append(\n                (0, 0, {\n                    'name': _('Bank Fee'),\n                    'account_id': wizard.bank_expense_account_id.id,\n                    'debit': wizard.expense_amount,\n                    'credit': 0.0,\n              }),)\n\n        move = move_model.create(move_vals)\n        move.post()\n\n        to_be_reconciled = []\n        for move_line in move.line_ids:\n            if move_line.account_id.id == wizard.overdue_effects_account_id.id:\n                for riba_move_line in distinta_line.move_line_ids:\n                    invoice_ids = []\n                    if riba_move_line.move_line_id.invoice_id:\n                        invoice_ids = [\n                            riba_move_line.move_line_id.invoice_id.id\n                        ]\n                    elif riba_move_line.move_line_id.unsolved_invoice_ids:\n                        invoice_ids = [\n                            i.id for i in\n                            riba_move_line.move_line_id.unsolved_invoice_ids\n                        ]\n                    invoice_model.browse(invoice_ids).write({\n                        'unsolved_move_line_ids': [(4, move_line.id)],\n                  })\n            if move_line.account_id.id == wizard.effects_account_id.id:\n                to_be_reconciled.append(move_line.id)\n        for acceptance_move_line in distinta_line.acceptance_move_id.line_ids:\n            if (\n                acceptance_move_line.account_id.id ==\n                wizard.effects_account_id.id\n            ):\n                to_be_reconciled.append(acceptance_move_line.id)\n\n        distinta_line.write({\n            'unsolved_move_id': move.id,\n            'state': 'unsolved',\n      })\n        to_be_reconciled_lines = move_line_model.with_context(\n          {'unsolved_reconciliation': True}).browse(to_be_reconciled)\n        to_be_reconciled_lines.reconcile()\n        distinta_line.distinta_id.state = 'unsolved'\n        return {\n            'name': _('Past Due Entry'),\n            'view_type': 'form',\n            'view_mode': 'form',\n            'res_model': 'account.move',\n            'type': 'ir.actions.act_window',\n            'target': 'current',\n            'res_id': move.id or False,\n      }\n" }
{ "repo_name": "kostaspl/SpiderMonkey38", "ref": "refs/heads/tmpbr", "path": "media/webrtc/trunk/tools/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "AlericInglewood/3p-google-breakpad", "ref": "refs/heads/singularity", "path": "src/tools/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "sbusso/rethinkdb", "ref": "refs/heads/next", "path": "external/v8_3.30.33.16/build/gyp/test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "AOSPU/external_chromium_org_tools_gyp", "ref": "refs/heads/android-5.0/py3", "path": "test/mac/gyptest-debuginfo.py", "content": "#!/usr/bin/env python\n\n# Copyright (c) 2011 Google Inc. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"\nTests things related to debug information generation.\n\"\"\"\n\nimport TestGyp\n\nimport sys\n\nif sys.platform == 'darwin':\n  test = TestGyp.TestGyp(formats=['ninja', 'make', 'xcode'])\n\n  test.run_gyp('test.gyp', chdir='debuginfo')\n\n  test.build('test.gyp', test.ALL, chdir='debuginfo')\n\n  test.built_file_must_exist('libnonbundle_shared_library.dylib.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_loadable_module.so.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('nonbundle_executable.dSYM',\n                             chdir='debuginfo')\n\n  test.built_file_must_exist('bundle_shared_library.framework.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('bundle_loadable_module.bundle.dSYM',\n                             chdir='debuginfo')\n  test.built_file_must_exist('My App.app.dSYM',\n                             chdir='debuginfo')\n\n  test.pass_test()\n" }
{ "repo_name": "DIRACGrid/DIRAC", "ref": "refs/heads/integration", "path": "docs/setup.py", "content": "\"\"\"Basic setuptools script for DIRACDocs.\"\"\"\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport os\nimport glob\n\n# Actual setuptools\nfrom setuptools import setup, find_packages\n\n# Find the base dir where the setup.py lies\nBASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), 'diracdoctools'))\n\n# Take all the packages but the scripts and tests\nALL_PACKAGES = find_packages(where=BASE_DIR, exclude=['*test*'])\n\nPACKAGE_DIR = dict((\"%s\" % p, os.path.join(BASE_DIR, p.replace('.', '/'))) for p in ALL_PACKAGES)\n\n# We rename the packages so that they contain diracdoctools\nALL_PACKAGES = ['diracdoctools.%s' % p for p in ALL_PACKAGES]\nALL_PACKAGES.insert(0, 'diracdoctools')\n\nPACKAGE_DIR['diracdoctools'] = BASE_DIR\n# The scripts to be distributed\nSCRIPTS = glob.glob('%s/scripts/*.py' % BASE_DIR)\n\nsetup(\n    name='diracdoctools',\n    version='6.19.2',\n    url='https://github.com/DIRACGRID/DIRAC/docs',\n    license='GPLv3',\n    package_dir=PACKAGE_DIR,\n    packages=ALL_PACKAGES,\n    scripts=SCRIPTS,\n)\n" }
{ "repo_name": "DIRACGrid/DIRAC", "ref": "refs/heads/integration", "path": "src/DIRAC/Interfaces/scripts/dirac_admin_set_site_protocols.py", "content": "#! /usr/bin/env python\n########################################################################\n# File :    dirac-admin-set-site-protocols\n# Author :  Stuart Paterson\n########################################################################\n\"\"\"\nDefined protocols for each SE for a given site.\n\nUsage:\n  dirac-admin-set-site-protocols [options] ... Protocol ...\n\nArguments:\n  Protocol: SE access protocol (mandatory)\n\nExample:\n  $ dirac-admin-set-site-protocols --Site=LCG.IN2P3.fr SRM2\n\"\"\"\nfrom __future__ import print_function\nfrom __future__ import absolute_import\nfrom __future__ import division\n\n__RCSID__ = \"$Id$\"\n\nimport DIRAC\nfrom DIRAC.Core.Base import Script\nfrom DIRAC.Core.Utilities.DIRACScript import DIRACScript\n\n\n@DIRACScript()\ndef main():\n  Script.registerSwitch(\"\", \"Site=\", \"Site for which protocols are to be set (mandatory)\")\n  Script.parseCommandLine(ignoreErrors=True)\n\n  site = None\n  for switch in Script.getUnprocessedSwitches():\n    if switch[0].lower() == \"site\":\n      site = switch[1]\n\n  args = Script.getPositionalArgs()\n\n  if not site or not args:\n    Script.showHelp(exitCode=1)\n\n  from DIRAC.Interfaces.API.DiracAdmin import DiracAdmin\n  diracAdmin = DiracAdmin()\n  exitCode = 0\n  result = diracAdmin.setSiteProtocols(site, args, printOutput=True)\n  if not result['OK']:\n    print('ERROR: %s' % result['Message'])\n    exitCode = 2\n\n  DIRAC.exit(exitCode)\n\n\nif __name__ == \"__main__\":\n  main()\n" }
{ "repo_name": "FeliciaLim/oss-fuzz", "ref": "refs/heads/opus", "path": "infra/base-images/base-msan-builder/packages/openssl.py", "content": "#!/usr/bin/env python\n# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n################################################################################\n\nimport os\nimport shutil\n\nimport package\n\n\ndef AddNoAsmArg(config_path):\n  \"\"\"Add --no-asm to config scripts.\"\"\"\n  shutil.move(config_path, config_path + '.real')\n  with open(config_path, 'w') as f:\n    f.write(\n        '#!/bin/sh\\n'\n        '%s.real no-asm \"$@\"\\n' % config_path)\n  os.chmod(config_path, 0755)\n\n\nclass Package(package.Package):\n  \"\"\"openssl package.\"\"\"\n\n  def __init__(self, apt_version):\n    super(Package, self).__init__('openssl', apt_version)\n\n  def PreBuild(self, source_directory, env, custom_bin_dir):\n    AddNoAsmArg(os.path.join(source_directory, 'Configure'))\n    AddNoAsmArg(os.path.join(source_directory, 'config'))\n" }
{ "repo_name": "googlefonts/oss-fuzz", "ref": "refs/heads/main", "path": "infra/base-images/base-sanitizer-libs-builder/packages/openssl.py", "content": "#!/usr/bin/env python\n# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n################################################################################\n\nimport os\nimport shutil\n\nimport package\n\n\ndef AddNoAsmArg(config_path):\n  \"\"\"Add --no-asm to config scripts.\"\"\"\n  shutil.move(config_path, config_path + '.real')\n  with open(config_path, 'w') as f:\n    f.write(\n        '#!/bin/sh\\n'\n        '%s.real no-asm \"$@\"\\n' % config_path)\n  os.chmod(config_path, 0755)\n\n\nclass Package(package.Package):\n  \"\"\"openssl package.\"\"\"\n\n  def __init__(self, apt_version):\n    super(Package, self).__init__('openssl', apt_version)\n\n  def PreBuild(self, source_directory, env, custom_bin_dir):\n    AddNoAsmArg(os.path.join(source_directory, 'Configure'))\n    AddNoAsmArg(os.path.join(source_directory, 'config'))\n" }
{ "repo_name": "DirectXMan12/nova-hacking", "ref": "refs/heads/feature_novnc_krb", "path": "nova/api/openstack/compute/contrib/used_limits.py", "content": "# vim: tabstop=4 shiftwidth=4 softtabstop=4\n\n# Copyright 2012 OpenStack Foundation\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License\n\nfrom nova.api.openstack import extensions\nfrom nova.api.openstack import wsgi\nfrom nova.api.openstack import xmlutil\nfrom nova import quota\n\n\nQUOTAS = quota.QUOTAS\n\n\nXMLNS = \"http://docs.openstack.org/compute/ext/used_limits/api/v1.1\"\nALIAS = \"os-used-limits\"\nauthorize = extensions.soft_extension_authorizer('compute', 'used_limits')\nauthorize_for_admin = extensions.extension_authorizer('compute',\n                                                      'used_limits_for_admin')\n\n\nclass UsedLimitsTemplate(xmlutil.TemplateBuilder):\n    def construct(self):\n        root = xmlutil.TemplateElement('limits', selector='limits')\n        root.set('{%s}usedLimits' % XMLNS, '%s:usedLimits' % ALIAS)\n        return xmlutil.SlaveTemplate(root, 1, nsmap={ALIAS: XMLNS})\n\n\nclass UsedLimitsController(wsgi.Controller):\n\n    def __init__(self, ext_mgr):\n        self.ext_mgr = ext_mgr\n\n    @staticmethod\n    def _reserved(req):\n        try:\n            return int(req.GET['reserved'])\n        except (ValueError, KeyError):\n            return False\n\n    @wsgi.extends\n    def index(self, req, resp_obj):\n        resp_obj.attach(xml=UsedLimitsTemplate())\n        context = req.environ['nova.context']\n        project_id = self._project_id(context, req)\n        quotas = QUOTAS.get_project_quotas(context, project_id, usages=True)\n        quota_map = {\n            'totalRAMUsed': 'ram',\n            'totalCoresUsed': 'cores',\n            'totalInstancesUsed': 'instances',\n            'totalFloatingIpsUsed': 'floating_ips',\n            'totalSecurityGroupsUsed': 'security_groups',\n      }\n        used_limits = {}\n        for display_name, quota in quota_map.iteritems():\n            if quota in quotas:\n                reserved = (quotas[quota]['reserved']\n                            if self._reserved(req) else 0)\n                used_limits[display_name] = quotas[quota]['in_use'] + reserved\n\n        resp_obj.obj['limits']['absolute'].update(used_limits)\n\n    def _project_id(self, context, req):\n        if self.ext_mgr.is_loaded('os-used-limits-for-admin'):\n            if 'tenant_id' in req.GET:\n                tenant_id = req.GET.get('tenant_id')\n                target = {\n                    'project_id': tenant_id,\n                    'user_id': context.user_id\n                  }\n                authorize_for_admin(context, target=target)\n                return tenant_id\n        return context.project_id\n\n\nclass Used_limits(extensions.ExtensionDescriptor):\n    \"\"\"Provide data on limited resources that are being used.\"\"\"\n\n    name = \"UsedLimits\"\n    alias = ALIAS\n    namespace = XMLNS\n    updated = \"2012-07-13T00:00:00+00:00\"\n\n    def get_controller_extensions(self):\n        controller = UsedLimitsController(self.ext_mgr)\n        limits_ext = extensions.ControllerExtension(self, 'limits',\n                                                    controller=controller)\n        return [limits_ext]\n" }
{ "repo_name": "koying/SPMC", "ref": "refs/heads/spmc-krypton", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "plexinc/plex-home-theater-public", "ref": "refs/heads/pht-frodo", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "inn1983/XbmcSunxi", "ref": "refs/heads/teropi-rebased", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "warped-rudi/xbmc", "ref": "refs/heads/Gotham-13.1-AE-fixes", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "theeternalsw0rd/xbmc", "ref": "refs/heads/delta", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "Kwiboo/plex-home-theater", "ref": "refs/heads/rockchip-krypton", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "RasPlex/plex-home-theatre", "ref": "refs/heads/rasplex-1.0", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "vidonme/xbmc", "ref": "refs/heads/isengard.vidon", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "pwong-mapr/private-hue", "ref": "refs/heads/HUE-1096-abe", "path": "desktop/core/ext-py/Django-1.4.5/django/utils/encoding.py", "content": "import types\nimport urllib\nimport locale\nimport datetime\nimport codecs\nfrom decimal import Decimal\n\nfrom django.utils.functional import Promise\n\nclass DjangoUnicodeDecodeError(UnicodeDecodeError):\n    def __init__(self, obj, *args):\n        self.obj = obj\n        UnicodeDecodeError.__init__(self, *args)\n\n    def __str__(self):\n        original = UnicodeDecodeError.__str__(self)\n        return '%s. You passed in %r (%s)' % (original, self.obj,\n                type(self.obj))\n\nclass StrAndUnicode(object):\n    \"\"\"\n    A class whose __str__ returns its __unicode__ as a UTF-8 bytestring.\n\n    Useful as a mix-in.\n    \"\"\"\n    def __str__(self):\n        return self.__unicode__().encode('utf-8')\n\ndef smart_unicode(s, encoding='utf-8', strings_only=False, errors='strict'):\n    \"\"\"\n    Returns a unicode object representing 's'. Treats bytestrings using the\n    'encoding' codec.\n\n    If strings_only is True, don't convert (some) non-string-like objects.\n    \"\"\"\n    if isinstance(s, Promise):\n        # The input is the result of a gettext_lazy() call.\n        return s\n    return force_unicode(s, encoding, strings_only, errors)\n\ndef is_protected_type(obj):\n    \"\"\"Determine if the object instance is of a protected type.\n\n    Objects of protected types are preserved as-is when passed to\n    force_unicode(strings_only=True).\n    \"\"\"\n    return isinstance(obj, (\n        types.NoneType,\n        int, long,\n        datetime.datetime, datetime.date, datetime.time,\n        float, Decimal)\n    )\n\ndef force_unicode(s, encoding='utf-8', strings_only=False, errors='strict'):\n    \"\"\"\n    Similar to smart_unicode, except that lazy instances are resolved to\n    strings, rather than kept as lazy objects.\n\n    If strings_only is True, don't convert (some) non-string-like objects.\n    \"\"\"\n    # Handle the common case first, saves 30-40% in performance when s\n    # is an instance of unicode. This function gets called often in that\n    # setting.\n    if isinstance(s, unicode):\n        return s\n    if strings_only and is_protected_type(s):\n        return s\n    try:\n        if not isinstance(s, basestring,):\n            if hasattr(s, '__unicode__'):\n                s = unicode(s)\n            else:\n                try:\n                    s = unicode(str(s), encoding, errors)\n                except UnicodeEncodeError:\n                    if not isinstance(s, Exception):\n                        raise\n                    # If we get to here, the caller has passed in an Exception\n                    # subclass populated with non-ASCII data without special\n                    # handling to display as a string. We need to handle this\n                    # without raising a further exception. We do an\n                    # approximation to what the Exception's standard str()\n                    # output should be.\n                    s = u' '.join([force_unicode(arg, encoding, strings_only,\n                            errors) for arg in s])\n        elif not isinstance(s, unicode):\n            # Note: We use .decode() here, instead of unicode(s, encoding,\n            # errors), so that if s is a SafeString, it ends up being a\n            # SafeUnicode at the end.\n            s = s.decode(encoding, errors)\n    except UnicodeDecodeError, e:\n        if not isinstance(s, Exception):\n            raise DjangoUnicodeDecodeError(s, *e.args)\n        else:\n            # If we get to here, the caller has passed in an Exception\n            # subclass populated with non-ASCII bytestring data without a\n            # working unicode method. Try to handle this without raising a\n            # further exception by individually forcing the exception args\n            # to unicode.\n            s = u' '.join([force_unicode(arg, encoding, strings_only,\n                    errors) for arg in s])\n    return s\n\ndef smart_str(s, encoding='utf-8', strings_only=False, errors='strict'):\n    \"\"\"\n    Returns a bytestring version of 's', encoded as specified in 'encoding'.\n\n    If strings_only is True, don't convert (some) non-string-like objects.\n    \"\"\"\n    if strings_only and isinstance(s, (types.NoneType, int)):\n        return s\n    if isinstance(s, Promise):\n        return unicode(s).encode(encoding, errors)\n    elif not isinstance(s, basestring):\n        try:\n            return str(s)\n        except UnicodeEncodeError:\n            if isinstance(s, Exception):\n                # An Exception subclass containing non-ASCII data that doesn't\n                # know how to print itself properly. We shouldn't raise a\n                # further exception.\n                return ' '.join([smart_str(arg, encoding, strings_only,\n                        errors) for arg in s])\n            return unicode(s).encode(encoding, errors)\n    elif isinstance(s, unicode):\n        return s.encode(encoding, errors)\n    elif s and encoding != 'utf-8':\n        return s.decode('utf-8', errors).encode(encoding, errors)\n    else:\n        return s\n\ndef iri_to_uri(iri):\n    \"\"\"\n    Convert an Internationalized Resource Identifier (IRI) portion to a URI\n    portion that is suitable for inclusion in a URL.\n\n    This is the algorithm from section 3.1 of RFC 3987.  However, since we are\n    assuming input is either UTF-8 or unicode already, we can simplify things a\n    little from the full method.\n\n    Returns an ASCII string containing the encoded result.\n    \"\"\"\n    # The list of safe characters here is constructed from the \"reserved\" and\n    # \"unreserved\" characters specified in sections 2.2 and 2.3 of RFC 3986:\n    #     reserved    = gen-delims / sub-delims\n    #     gen-delims  = \":\" / \"/\" / \"?\" / \"#\" / \"[\" / \"]\" / \"@\"\n    #     sub-delims  = \"!\" / \"$\" / \"&\" / \"'\" / \"(\" / \")\"\n    #                   / \"*\" / \"+\" / \",\" / \";\" / \"=\"\n    #     unreserved  = ALPHA / DIGIT / \"-\" / \".\" / \"_\" / \"~\"\n    # Of the unreserved characters, urllib.quote already considers all but\n    # the ~ safe.\n    # The % character is also added to the list of safe characters here, as the\n    # end of section 3.1 of RFC 3987 specifically mentions that % must not be\n    # converted.\n    if iri is None:\n        return iri\n    return urllib.quote(smart_str(iri), safe=\"/#%[]=:;$&()+,!?*@'~\")\n\ndef filepath_to_uri(path):\n    \"\"\"Convert an file system path to a URI portion that is suitable for\n    inclusion in a URL.\n\n    We are assuming input is either UTF-8 or unicode already.\n\n    This method will encode certain chars that would normally be recognized as\n    special chars for URIs.  Note that this method does not encode the '\n    character, as it is a valid character within URIs.  See\n    encodeURIComponent() JavaScript function for more details.\n\n    Returns an ASCII string containing the encoded result.\n    \"\"\"\n    if path is None:\n        return path\n    # I know about `os.sep` and `os.altsep` but I want to leave\n    # some flexibility for hardcoding separators.\n    return urllib.quote(smart_str(path).replace(\"\\\\\", \"/\"), safe=\"/~!*()'\")\n\n# The encoding of the default system locale but falls back to the\n# given fallback encoding if the encoding is unsupported by python or could\n# not be determined.  See tickets #10335 and #5846\ntry:\n    DEFAULT_LOCALE_ENCODING = locale.getdefaultlocale()[1] or 'ascii'\n    codecs.lookup(DEFAULT_LOCALE_ENCODING)\nexcept:\n    DEFAULT_LOCALE_ENCODING = 'ascii'\n\n# Forwards compatibility with Django 1.5\n\ndef python_2_unicode_compatible(klass):\n    # Always use the Python 2 branch of the decorator here in Django 1.4\n    klass.__unicode__ = klass.__str__\n    klass.__str__ = lambda self: self.__unicode__().encode('utf-8')\n    return klass\n\nsmart_text = smart_unicode\nforce_text = force_unicode\nsmart_bytes = smart_str\n" }
{ "repo_name": "chadoe/xbmc", "ref": "refs/heads/personalmod", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "OptimusGREEN/OGMC", "ref": "refs/heads/Krypton", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "kodibrasil/xbmc", "ref": "refs/heads/Krypton_dsplayer", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "rellla/xbmca10", "ref": "refs/heads/stage/Frodo", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "dhongu/l10n-romania", "ref": "refs/heads/11.0", "path": "account_storno/models/account_journal.py", "content": "# Copyright 2011- Slobodni programi d.o.o.\n# Copyright 2018 Forest and Biomass Romania\n# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl.html).\n\nfrom odoo import fields, models\n\n\nclass AccountJournal(models.Model):\n    _inherit = \"account.journal\"\n\n    posting_policy = fields.Selection([('contra', 'Contra (Standard Odoo)'), ('storno', 'Storno (-)')],\n                                      default='contra', string='Storno or Contra', required=True,\n                                      help=\"Storno allows minus postings, Refunds are posted on the \"\n                                           \"same journal with negative sign.\\n\"\n                                           \"Contra doesn't allow negative posting. \"\n                                           \"Refunds are posted by swaping credit and debit side.\")\n" }
{ "repo_name": "atupone/xbmc", "ref": "refs/heads/omxplayerNeeds", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "zidootech/zidoo-kodi-15.2", "ref": "refs/heads/zidoo-15.2", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "apavlenko/opencv", "ref": "refs/heads/copyright_fixes", "path": "samples/python2/edge.py", "content": "#!/usr/bin/env python\n\n'''\nThis sample demonstrates Canny edge detection.\n\nUsage:\n  edge.py [<video source>]\n\n  Trackbars control edge thresholds.\n\n'''\n\nimport cv2\n\n# relative module\nimport video\n\n# built-in module\nimport sys\n\n\nif __name__ == '__main__':\n    print __doc__\n\n    try:\n        fn = sys.argv[1]\n    except:\n        fn = 0\n\n    def nothing(*arg):\n        pass\n\n    cv2.namedWindow('edge')\n    cv2.createTrackbar('thrs1', 'edge', 2000, 5000, nothing)\n    cv2.createTrackbar('thrs2', 'edge', 4000, 5000, nothing)\n\n    cap = video.create_capture(fn)\n    while True:\n        flag, img = cap.read()\n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        thrs1 = cv2.getTrackbarPos('thrs1', 'edge')\n        thrs2 = cv2.getTrackbarPos('thrs2', 'edge')\n        edge = cv2.Canny(gray, thrs1, thrs2, apertureSize=5)\n        vis = img.copy()\n        vis /= 2\n        vis[edge != 0] = (0, 255, 0)\n        cv2.imshow('edge', vis)\n        ch = cv2.waitKey(5) & 0xFF\n        if ch == 27:\n            break\n    cv2.destroyAllWindows()\n" }
{ "repo_name": "bkury/OpenPHT", "ref": "refs/heads/openpht-1.7", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "Distrotech/xbmc", "ref": "refs/heads/distrotech-xbmc", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "garbear/xbmc-retroplayer", "ref": "refs/heads/retroplayer-15alpha1", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "kingvuplus/xbmc", "ref": "refs/heads/Vuplus_Gotham_Dev", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "asavah/xbmc", "ref": "refs/heads/fix-cscriptrunner", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "dburner/zidoo-kodi-14.2", "ref": "refs/heads/kodi-rebased", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "kenvac/odoo-hr", "ref": "refs/heads/10.0", "path": "hr_holiday_officer/tests/__init__.py", "content": "# -*- coding: utf-8 -*-\n# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl).\n\nfrom . import test_holiday_flow\n" }
{ "repo_name": "OCA/partner-contact", "ref": "refs/heads/13.0", "path": "partner_firstname/tests/test_create.py", "content": "# Copyright 2015 Grupo ESOC Ingeniería de Servicios, S.L. - Jairo Llopis.\n# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl.html).\n\n\"\"\"Test default values for models.\"\"\"\n\nfrom odoo.tests.common import TransactionCase\n\nfrom .base import MailInstalled\n\n\nclass PersonCase(TransactionCase):\n    \"\"\"Test ``res.partner`` when it is a person.\"\"\"\n\n    context = {\"default_is_company\": False}\n    model = \"res.partner\"\n\n    def setUp(self):\n        super(PersonCase, self).setUp()\n        self.good_values = {\"firstname\": \"Núñez\", \"lastname\": \"Fernán\"}\n        self.good_values[\"name\"] = \"{} {}\".format(\n            self.good_values[\"firstname\"], self.good_values[\"lastname\"]\n        )\n        if \"default_is_company\" in self.context:\n            self.good_values[\"is_company\"] = self.context[\"default_is_company\"]\n        self.values = self.good_values.copy()\n\n    def tearDown(self):\n        self.record = (\n            self.env[self.model].with_context(self.context).create(self.values)\n        )\n        for key, value in self.good_values.items():\n            self.assertEqual(self.record[key], value, \"Checking key %s\" % key)\n\n        super(PersonCase, self).tearDown()\n\n    def test_no_name(self):\n        \"\"\"Name is calculated.\"\"\"\n        del self.values[\"name\"]\n\n    def test_wrong_name_value(self):\n        \"\"\"Wrong name value is ignored, name is calculated.\"\"\"\n        self.values[\"name\"] = \"BÄD\"\n\n    def test_wrong_name_context(self):\n        \"\"\"Wrong name context is ignored, name is calculated.\"\"\"\n        del self.values[\"name\"]\n        self.context[\"default_name\"] = \"BÄD\"\n\n    def test_wrong_name_value_and_context(self):\n        \"\"\"Wrong name value and context is ignored, name is calculated.\"\"\"\n        self.values[\"name\"] = \"BÄD1\"\n        self.context[\"default_name\"] = \"BÄD2\"\n\n\nclass CompanyCase(PersonCase):\n    \"\"\"Test ``res.partner`` when it is a company.\"\"\"\n\n    context = {\"default_is_company\": True}\n\n    def setUp(self):\n        super(CompanyCase, self).setUp()\n        self.good_values.update(lastname=self.values[\"name\"], firstname=False)\n        self.values = self.good_values.copy()\n\n\nclass UserCase(PersonCase, MailInstalled):\n    \"\"\"Test ``res.users``.\"\"\"\n\n    model = \"res.users\"\n    context = {\"default_login\": \"user@example.com\"}\n\n    def tearDown(self):\n        # Cannot create users if ``mail`` is installed\n        if self.mail_installed():\n            # Skip tests\n            super(PersonCase, self).tearDown()\n        else:\n            # Run tests\n            super(UserCase, self).tearDown()\n" }
{ "repo_name": "kodi-game/xbmc", "ref": "refs/heads/retroplayer-15.1", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "PatrickOReilly/scikit-learn", "ref": "refs/heads/monotonic-trees", "path": "sklearn/externals/joblib/func_inspect.py", "content": "\"\"\"\nMy own variation on function-specific inspect-like features.\n\"\"\"\n\n# Author: Gael Varoquaux <gael dot varoquaux at normalesup dot org>\n# Copyright (c) 2009 Gael Varoquaux\n# License: BSD Style, 3 clauses.\n\nfrom itertools import islice\nimport inspect\nimport warnings\nimport re\nimport os\n\nfrom ._compat import _basestring\nfrom .logger import pformat\nfrom ._memory_helpers import open_py_source\nfrom ._compat import PY3_OR_LATER\n\n\ndef get_func_code(func):\n    \"\"\" Attempts to retrieve a reliable function code hash.\n\n        The reason we don't use inspect.getsource is that it caches the\n        source, whereas we want this to be modified on the fly when the\n        function is modified.\n\n        Returns\n        -------\n        func_code: string\n            The function code\n        source_file: string\n            The path to the file in which the function is defined.\n        first_line: int\n            The first line of the code in the source file.\n\n        Notes\n        ------\n        This function does a bit more magic than inspect, and is thus\n        more robust.\n    \"\"\"\n    source_file = None\n    try:\n        code = func.__code__\n        source_file = code.co_filename\n        if not os.path.exists(source_file):\n            # Use inspect for lambda functions and functions defined in an\n            # interactive shell, or in doctests\n            source_code = ''.join(inspect.getsourcelines(func)[0])\n            line_no = 1\n            if source_file.startswith('<doctest '):\n                source_file, line_no = re.match(\n                    '\\<doctest (.*\\.rst)\\[(.*)\\]\\>', source_file).groups()\n                line_no = int(line_no)\n                source_file = '<doctest %s>' % source_file\n            return source_code, source_file, line_no\n        # Try to retrieve the source code.\n        with open_py_source(source_file) as source_file_obj:\n            first_line = code.co_firstlineno\n            # All the lines after the function definition:\n            source_lines = list(islice(source_file_obj, first_line - 1, None))\n        return ''.join(inspect.getblock(source_lines)), source_file, first_line\n    except:\n        # If the source code fails, we use the hash. This is fragile and\n        # might change from one session to another.\n        if hasattr(func, '__code__'):\n            # Python 3.X\n            return str(func.__code__.__hash__()), source_file, -1\n        else:\n            # Weird objects like numpy ufunc don't have __code__\n            # This is fragile, as quite often the id of the object is\n            # in the repr, so it might not persist across sessions,\n            # however it will work for ufuncs.\n            return repr(func), source_file, -1\n\n\ndef _clean_win_chars(string):\n    \"\"\"Windows cannot encode some characters in filename.\"\"\"\n    import urllib\n    if hasattr(urllib, 'quote'):\n        quote = urllib.quote\n    else:\n        # In Python 3, quote is elsewhere\n        import urllib.parse\n        quote = urllib.parse.quote\n    for char in ('<', '>', '!', ':', '\\\\'):\n        string = string.replace(char, quote(char))\n    return string\n\n\ndef get_func_name(func, resolv_alias=True, win_characters=True):\n    \"\"\" Return the function import path (as a list of module names), and\n        a name for the function.\n\n        Parameters\n        ----------\n        func: callable\n            The func to inspect\n        resolv_alias: boolean, optional\n            If true, possible local aliases are indicated.\n        win_characters: boolean, optional\n            If true, substitute special characters using urllib.quote\n            This is useful in Windows, as it cannot encode some filenames\n    \"\"\"\n    if hasattr(func, '__module__'):\n        module = func.__module__\n    else:\n        try:\n            module = inspect.getmodule(func)\n        except TypeError:\n            if hasattr(func, '__class__'):\n                module = func.__class__.__module__\n            else:\n                module = 'unknown'\n    if module is None:\n        # Happens in doctests, eg\n        module = ''\n    if module == '__main__':\n        try:\n            filename = os.path.abspath(inspect.getsourcefile(func))\n        except:\n            filename = None\n        if filename is not None:\n            # mangling of full path to filename\n            parts = filename.split(os.sep)\n            if parts[-1].startswith('<ipython-input'):\n                # function is defined in an IPython session. The filename\n                # will change with every new kernel instance. This hack\n                # always returns the same filename\n                parts[-1] = '__ipython-input__'\n            filename = '-'.join(parts)\n            if filename.endswith('.py'):\n                filename = filename[:-3]\n            module = module + '-' + filename\n    module = module.split('.')\n    if hasattr(func, 'func_name'):\n        name = func.func_name\n    elif hasattr(func, '__name__'):\n        name = func.__name__\n    else:\n        name = 'unknown'\n    # Hack to detect functions not defined at the module-level\n    if resolv_alias:\n        # TODO: Maybe add a warning here?\n        if hasattr(func, 'func_globals') and name in func.func_globals:\n            if not func.func_globals[name] is func:\n                name = '%s-alias' % name\n    if inspect.ismethod(func):\n        # We need to add the name of the class\n        if hasattr(func, 'im_class'):\n            klass = func.im_class\n            module.append(klass.__name__)\n    if os.name == 'nt' and win_characters:\n        # Stupid windows can't encode certain characters in filenames\n        name = _clean_win_chars(name)\n        module = [_clean_win_chars(s) for s in module]\n    return module, name\n\n\ndef getfullargspec(func):\n    \"\"\"Compatibility function to provide inspect.getfullargspec in Python 2\n\n    This should be rewritten using a backport of Python 3 signature\n    once we drop support for Python 2.6. We went for a simpler\n    approach at the time of writing because signature uses OrderedDict\n    which is not available in Python 2.6.\n    \"\"\"\n    try:\n        return inspect.getfullargspec(func)\n    except AttributeError:\n        arg_spec = inspect.getargspec(func)\n        import collections\n        tuple_fields = ('args varargs varkw defaults kwonlyargs '\n                        'kwonlydefaults annotations')\n        tuple_type = collections.namedtuple('FullArgSpec', tuple_fields)\n\n        return tuple_type(args=arg_spec.args,\n                          varargs=arg_spec.varargs,\n                          varkw=arg_spec.keywords,\n                          defaults=arg_spec.defaults,\n                          kwonlyargs=[],\n                          kwonlydefaults=None,\n                          annotations={})\n\n\ndef _signature_str(function_name, arg_spec):\n    \"\"\"Helper function to output a function signature\"\"\"\n    # inspect.formatargspec can not deal with the same\n    # number of arguments in python 2 and 3\n    arg_spec_for_format = arg_spec[:7 if PY3_OR_LATER else 4]\n\n    arg_spec_str = inspect.formatargspec(*arg_spec_for_format)\n    return '{0}{1}'.format(function_name, arg_spec_str)\n\n\ndef _function_called_str(function_name, args, kwargs):\n    \"\"\"Helper function to output a function call\"\"\"\n    template_str = '{0}({1} {2})'\n\n    args_str = repr(args)[1:-1]\n    kwargs_str = ', '.join('%s=%s' % (k, v)\n                           for k, v in kwargs.items())\n    return template_str.format(function_name, args_str,\n                               kwargs_str)\n\n\ndef filter_args(func, ignore_lst, args=(), kwargs=dict()):\n    \"\"\" Filters the given args and kwargs using a list of arguments to\n        ignore, and a function specification.\n\n        Parameters\n        ----------\n        func: callable\n            Function giving the argument specification\n        ignore_lst: list of strings\n            List of arguments to ignore (either a name of an argument\n            in the function spec, or '*', or '**')\n        *args: list\n            Positional arguments passed to the function.\n        **kwargs: dict\n            Keyword arguments passed to the function\n\n        Returns\n        -------\n        filtered_args: list\n            List of filtered positional and keyword arguments.\n    \"\"\"\n    args = list(args)\n    if isinstance(ignore_lst, _basestring):\n        # Catch a common mistake\n        raise ValueError(\n            'ignore_lst must be a list of parameters to ignore '\n            '%s (type %s) was given' % (ignore_lst, type(ignore_lst)))\n    # Special case for functools.partial objects\n    if (not inspect.ismethod(func) and not inspect.isfunction(func)):\n        if ignore_lst:\n            warnings.warn('Cannot inspect object %s, ignore list will '\n                          'not work.' % func, stacklevel=2)\n        return {'*': args, '**': kwargs}\n    arg_spec = getfullargspec(func)\n    arg_names = arg_spec.args + arg_spec.kwonlyargs\n    arg_defaults = arg_spec.defaults or ()\n    arg_defaults = arg_defaults + tuple(arg_spec.kwonlydefaults[k]\n                                        for k in arg_spec.kwonlyargs)\n    arg_varargs = arg_spec.varargs\n    arg_varkw = arg_spec.varkw\n\n    if inspect.ismethod(func):\n        # First argument is 'self', it has been removed by Python\n        # we need to add it back:\n        args = [func.__self__, ] + args\n    # XXX: Maybe I need an inspect.isbuiltin to detect C-level methods, such\n    # as on ndarrays.\n\n    _, name = get_func_name(func, resolv_alias=False)\n    arg_dict = dict()\n    arg_position = -1\n    for arg_position, arg_name in enumerate(arg_names):\n        if arg_position < len(args):\n            # Positional argument or keyword argument given as positional\n            if arg_name not in arg_spec.kwonlyargs:\n                arg_dict[arg_name] = args[arg_position]\n            else:\n                raise ValueError(\n                    \"Keyword-only parameter '%s' was passed as \"\n                    'positional parameter for %s:\\n'\n                    '     %s was called.'\n                    % (arg_name,\n                       _signature_str(name, arg_spec),\n                       _function_called_str(name, args, kwargs))\n                )\n\n        else:\n            position = arg_position - len(arg_names)\n            if arg_name in kwargs:\n                arg_dict[arg_name] = kwargs.pop(arg_name)\n            else:\n                try:\n                    arg_dict[arg_name] = arg_defaults[position]\n                except (IndexError, KeyError):\n                    # Missing argument\n                    raise ValueError(\n                        'Wrong number of arguments for %s:\\n'\n                        '     %s was called.'\n                        % (_signature_str(name, arg_spec),\n                           _function_called_str(name, args, kwargs))\n                    )\n\n    varkwargs = dict()\n    for arg_name, arg_value in sorted(kwargs.items()):\n        if arg_name in arg_dict:\n            arg_dict[arg_name] = arg_value\n        elif arg_varkw is not None:\n            varkwargs[arg_name] = arg_value\n        else:\n            raise TypeError(\"Ignore list for %s() contains an unexpected \"\n                            \"keyword argument '%s'\" % (name, arg_name))\n\n    if arg_varkw is not None:\n        arg_dict['**'] = varkwargs\n    if arg_varargs is not None:\n        varargs = args[arg_position + 1:]\n        arg_dict['*'] = varargs\n\n    # Now remove the arguments to be ignored\n    for item in ignore_lst:\n        if item in arg_dict:\n            arg_dict.pop(item)\n        else:\n            raise ValueError(\"Ignore list: argument '%s' is not defined for \"\n                             \"function %s\"\n                             % (item,\n                                _signature_str(name, arg_spec))\n                             )\n    # XXX: Return a sorted list of pairs?\n    return arg_dict\n\n\ndef format_signature(func, *args, **kwargs):\n    # XXX: Should this use inspect.formatargvalues/formatargspec?\n    module, name = get_func_name(func)\n    module = [m for m in module if m]\n    if module:\n        module.append(name)\n        module_path = '.'.join(module)\n    else:\n        module_path = name\n    arg_str = list()\n    previous_length = 0\n    for arg in args:\n        arg = pformat(arg, indent=2)\n        if len(arg) > 1500:\n            arg = '%s...' % arg[:700]\n        if previous_length > 80:\n            arg = '\\n%s' % arg\n        previous_length = len(arg)\n        arg_str.append(arg)\n    arg_str.extend(['%s=%s' % (v, pformat(i)) for v, i in kwargs.items()])\n    arg_str = ', '.join(arg_str)\n\n    signature = '%s(%s)' % (name, arg_str)\n    return module_path, signature\n\n\ndef format_call(func, args, kwargs, object_name=\"Memory\"):\n    \"\"\" Returns a nicely formatted statement displaying the function\n        call with the given arguments.\n    \"\"\"\n    path, signature = format_signature(func, *args, **kwargs)\n    msg = '%s\\n[%s] Calling %s...\\n%s' % (80 * '_', object_name,\n                                          path, signature)\n    return msg\n    # XXX: Not using logging framework\n    # self.debug(msg)\n" }
{ "repo_name": "RasPlex/OpenPHT", "ref": "refs/heads/openpht-1.9", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "holzingerm/xbmc", "ref": "refs/heads/master_work", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "aracnoz/xbmc", "ref": "refs/heads/Krypton_dsplayer", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "xhbl/Kodi_dualaudio", "ref": "refs/heads/Krypton-DA", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "onetechgenius/XBMCast2TV", "ref": "refs/heads/Helix", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "kassak/xbmc", "ref": "refs/heads/retroplayer-15.1", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "norbusan/plex-home-theater-public", "ref": "refs/heads/pht-frodo", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "ibazzi/xbmc", "ref": "refs/heads/spmc-jarvis", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "sergiocorato/partner-contact", "ref": "refs/heads/10.0", "path": "partner_contact_gender/tests/__init__.py", "content": "# -*- coding: utf-8 -*-\n# © 2016 Therp BV <http://therp.nl>\n# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl.html).\nfrom . import test_partner_contact_gender\n" }
{ "repo_name": "jmarcet/kodi", "ref": "refs/heads/Isengard-amlogic", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "RPGOne/Skynet", "ref": "refs/heads/Miho", "path": "scikit-learn-0.18.1/sklearn/externals/joblib/func_inspect.py", "content": "\"\"\"\nMy own variation on function-specific inspect-like features.\n\"\"\"\n\n# Author: Gael Varoquaux <gael dot varoquaux at normalesup dot org>\n# Copyright (c) 2009 Gael Varoquaux\n# License: BSD Style, 3 clauses.\n\nfrom itertools import islice\nimport inspect\nimport warnings\nimport re\nimport os\n\nfrom ._compat import _basestring\nfrom .logger import pformat\nfrom ._memory_helpers import open_py_source\nfrom ._compat import PY3_OR_LATER\n\n\ndef get_func_code(func):\n    \"\"\" Attempts to retrieve a reliable function code hash.\n\n        The reason we don't use inspect.getsource is that it caches the\n        source, whereas we want this to be modified on the fly when the\n        function is modified.\n\n        Returns\n        -------\n        func_code: string\n            The function code\n        source_file: string\n            The path to the file in which the function is defined.\n        first_line: int\n            The first line of the code in the source file.\n\n        Notes\n        ------\n        This function does a bit more magic than inspect, and is thus\n        more robust.\n    \"\"\"\n    source_file = None\n    try:\n        code = func.__code__\n        source_file = code.co_filename\n        if not os.path.exists(source_file):\n            # Use inspect for lambda functions and functions defined in an\n            # interactive shell, or in doctests\n            source_code = ''.join(inspect.getsourcelines(func)[0])\n            line_no = 1\n            if source_file.startswith('<doctest '):\n                source_file, line_no = re.match(\n                    '\\<doctest (.*\\.rst)\\[(.*)\\]\\>', source_file).groups()\n                line_no = int(line_no)\n                source_file = '<doctest %s>' % source_file\n            return source_code, source_file, line_no\n        # Try to retrieve the source code.\n        with open_py_source(source_file) as source_file_obj:\n            first_line = code.co_firstlineno\n            # All the lines after the function definition:\n            source_lines = list(islice(source_file_obj, first_line - 1, None))\n        return ''.join(inspect.getblock(source_lines)), source_file, first_line\n    except:\n        # If the source code fails, we use the hash. This is fragile and\n        # might change from one session to another.\n        if hasattr(func, '__code__'):\n            # Python 3.X\n            return str(func.__code__.__hash__()), source_file, -1\n        else:\n            # Weird objects like numpy ufunc don't have __code__\n            # This is fragile, as quite often the id of the object is\n            # in the repr, so it might not persist across sessions,\n            # however it will work for ufuncs.\n            return repr(func), source_file, -1\n\n\ndef _clean_win_chars(string):\n    \"\"\"Windows cannot encode some characters in filename.\"\"\"\n    import urllib\n    if hasattr(urllib, 'quote'):\n        quote = urllib.quote\n    else:\n        # In Python 3, quote is elsewhere\n        import urllib.parse\n        quote = urllib.parse.quote\n    for char in ('<', '>', '!', ':', '\\\\'):\n        string = string.replace(char, quote(char))\n    return string\n\n\ndef get_func_name(func, resolv_alias=True, win_characters=True):\n    \"\"\" Return the function import path (as a list of module names), and\n        a name for the function.\n\n        Parameters\n        ----------\n        func: callable\n            The func to inspect\n        resolv_alias: boolean, optional\n            If true, possible local aliases are indicated.\n        win_characters: boolean, optional\n            If true, substitute special characters using urllib.quote\n            This is useful in Windows, as it cannot encode some filenames\n    \"\"\"\n    if hasattr(func, '__module__'):\n        module = func.__module__\n    else:\n        try:\n            module = inspect.getmodule(func)\n        except TypeError:\n            if hasattr(func, '__class__'):\n                module = func.__class__.__module__\n            else:\n                module = 'unknown'\n    if module is None:\n        # Happens in doctests, eg\n        module = ''\n    if module == '__main__':\n        try:\n            filename = os.path.abspath(inspect.getsourcefile(func))\n        except:\n            filename = None\n        if filename is not None:\n            # mangling of full path to filename\n            parts = filename.split(os.sep)\n            if parts[-1].startswith('<ipython-input'):\n                # function is defined in an IPython session. The filename\n                # will change with every new kernel instance. This hack\n                # always returns the same filename\n                parts[-1] = '__ipython-input__'\n            filename = '-'.join(parts)\n            if filename.endswith('.py'):\n                filename = filename[:-3]\n            module = module + '-' + filename\n    module = module.split('.')\n    if hasattr(func, 'func_name'):\n        name = func.func_name\n    elif hasattr(func, '__name__'):\n        name = func.__name__\n    else:\n        name = 'unknown'\n    # Hack to detect functions not defined at the module-level\n    if resolv_alias:\n        # TODO: Maybe add a warning here?\n        if hasattr(func, 'func_globals') and name in func.func_globals:\n            if not func.func_globals[name] is func:\n                name = '%s-alias' % name\n    if inspect.ismethod(func):\n        # We need to add the name of the class\n        if hasattr(func, 'im_class'):\n            klass = func.im_class\n            module.append(klass.__name__)\n    if os.name == 'nt' and win_characters:\n        # Stupid windows can't encode certain characters in filenames\n        name = _clean_win_chars(name)\n        module = [_clean_win_chars(s) for s in module]\n    return module, name\n\n\ndef getfullargspec(func):\n    \"\"\"Compatibility function to provide inspect.getfullargspec in Python 2\n\n    This should be rewritten using a backport of Python 3 signature\n    once we drop support for Python 2.6. We went for a simpler\n    approach at the time of writing because signature uses OrderedDict\n    which is not available in Python 2.6.\n    \"\"\"\n    try:\n        return inspect.getfullargspec(func)\n    except AttributeError:\n        arg_spec = inspect.getargspec(func)\n        import collections\n        tuple_fields = ('args varargs varkw defaults kwonlyargs '\n                        'kwonlydefaults annotations')\n        tuple_type = collections.namedtuple('FullArgSpec', tuple_fields)\n\n        return tuple_type(args=arg_spec.args,\n                          varargs=arg_spec.varargs,\n                          varkw=arg_spec.keywords,\n                          defaults=arg_spec.defaults,\n                          kwonlyargs=[],\n                          kwonlydefaults=None,\n                          annotations={})\n\n\ndef _signature_str(function_name, arg_spec):\n    \"\"\"Helper function to output a function signature\"\"\"\n    # inspect.formatargspec can not deal with the same\n    # number of arguments in python 2 and 3\n    arg_spec_for_format = arg_spec[:7 if PY3_OR_LATER else 4]\n\n    arg_spec_str = inspect.formatargspec(*arg_spec_for_format)\n    return '{0}{1}'.format(function_name, arg_spec_str)\n\n\ndef _function_called_str(function_name, args, kwargs):\n    \"\"\"Helper function to output a function call\"\"\"\n    template_str = '{0}({1} {2})'\n\n    args_str = repr(args)[1:-1]\n    kwargs_str = ', '.join('%s=%s' % (k, v)\n                           for k, v in kwargs.items())\n    return template_str.format(function_name, args_str,\n                               kwargs_str)\n\n\ndef filter_args(func, ignore_lst, args=(), kwargs=dict()):\n    \"\"\" Filters the given args and kwargs using a list of arguments to\n        ignore, and a function specification.\n\n        Parameters\n        ----------\n        func: callable\n            Function giving the argument specification\n        ignore_lst: list of strings\n            List of arguments to ignore (either a name of an argument\n            in the function spec, or '*', or '**')\n        *args: list\n            Positional arguments passed to the function.\n        **kwargs: dict\n            Keyword arguments passed to the function\n\n        Returns\n        -------\n        filtered_args: list\n            List of filtered positional and keyword arguments.\n    \"\"\"\n    args = list(args)\n    if isinstance(ignore_lst, _basestring):\n        # Catch a common mistake\n        raise ValueError(\n            'ignore_lst must be a list of parameters to ignore '\n            '%s (type %s) was given' % (ignore_lst, type(ignore_lst)))\n    # Special case for functools.partial objects\n    if (not inspect.ismethod(func) and not inspect.isfunction(func)):\n        if ignore_lst:\n            warnings.warn('Cannot inspect object %s, ignore list will '\n                          'not work.' % func, stacklevel=2)\n        return {'*': args, '**': kwargs}\n    arg_spec = getfullargspec(func)\n    arg_names = arg_spec.args + arg_spec.kwonlyargs\n    arg_defaults = arg_spec.defaults or ()\n    arg_defaults = arg_defaults + tuple(arg_spec.kwonlydefaults[k]\n                                        for k in arg_spec.kwonlyargs)\n    arg_varargs = arg_spec.varargs\n    arg_varkw = arg_spec.varkw\n\n    if inspect.ismethod(func):\n        # First argument is 'self', it has been removed by Python\n        # we need to add it back:\n        args = [func.__self__, ] + args\n    # XXX: Maybe I need an inspect.isbuiltin to detect C-level methods, such\n    # as on ndarrays.\n\n    _, name = get_func_name(func, resolv_alias=False)\n    arg_dict = dict()\n    arg_position = -1\n    for arg_position, arg_name in enumerate(arg_names):\n        if arg_position < len(args):\n            # Positional argument or keyword argument given as positional\n            if arg_name not in arg_spec.kwonlyargs:\n                arg_dict[arg_name] = args[arg_position]\n            else:\n                raise ValueError(\n                    \"Keyword-only parameter '%s' was passed as \"\n                    'positional parameter for %s:\\n'\n                    '     %s was called.'\n                    % (arg_name,\n                       _signature_str(name, arg_spec),\n                       _function_called_str(name, args, kwargs))\n                )\n\n        else:\n            position = arg_position - len(arg_names)\n            if arg_name in kwargs:\n                arg_dict[arg_name] = kwargs.pop(arg_name)\n            else:\n                try:\n                    arg_dict[arg_name] = arg_defaults[position]\n                except (IndexError, KeyError):\n                    # Missing argument\n                    raise ValueError(\n                        'Wrong number of arguments for %s:\\n'\n                        '     %s was called.'\n                        % (_signature_str(name, arg_spec),\n                           _function_called_str(name, args, kwargs))\n                    )\n\n    varkwargs = dict()\n    for arg_name, arg_value in sorted(kwargs.items()):\n        if arg_name in arg_dict:\n            arg_dict[arg_name] = arg_value\n        elif arg_varkw is not None:\n            varkwargs[arg_name] = arg_value\n        else:\n            raise TypeError(\"Ignore list for %s() contains an unexpected \"\n                            \"keyword argument '%s'\" % (name, arg_name))\n\n    if arg_varkw is not None:\n        arg_dict['**'] = varkwargs\n    if arg_varargs is not None:\n        varargs = args[arg_position + 1:]\n        arg_dict['*'] = varargs\n\n    # Now remove the arguments to be ignored\n    for item in ignore_lst:\n        if item in arg_dict:\n            arg_dict.pop(item)\n        else:\n            raise ValueError(\"Ignore list: argument '%s' is not defined for \"\n                             \"function %s\"\n                             % (item,\n                                _signature_str(name, arg_spec))\n                             )\n    # XXX: Return a sorted list of pairs?\n    return arg_dict\n\n\ndef format_signature(func, *args, **kwargs):\n    # XXX: Should this use inspect.formatargvalues/formatargspec?\n    module, name = get_func_name(func)\n    module = [m for m in module if m]\n    if module:\n        module.append(name)\n        module_path = '.'.join(module)\n    else:\n        module_path = name\n    arg_str = list()\n    previous_length = 0\n    for arg in args:\n        arg = pformat(arg, indent=2)\n        if len(arg) > 1500:\n            arg = '%s...' % arg[:700]\n        if previous_length > 80:\n            arg = '\\n%s' % arg\n        previous_length = len(arg)\n        arg_str.append(arg)\n    arg_str.extend(['%s=%s' % (v, pformat(i)) for v, i in kwargs.items()])\n    arg_str = ', '.join(arg_str)\n\n    signature = '%s(%s)' % (name, arg_str)\n    return module_path, signature\n\n\ndef format_call(func, args, kwargs, object_name=\"Memory\"):\n    \"\"\" Returns a nicely formatted statement displaying the function\n        call with the given arguments.\n    \"\"\"\n    path, signature = format_signature(func, *args, **kwargs)\n    msg = '%s\\n[%s] Calling %s...\\n%s' % (80 * '_', object_name,\n                                          path, signature)\n    return msg\n    # XXX: Not using logging framework\n    # self.debug(msg)\n" }
{ "repo_name": "Shine-/xbmc", "ref": "refs/heads/Krypton_alwaysontop", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "EmbER-Dev/Kodi", "ref": "refs/heads/kodi-17.6", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "PIPplware/xbmc", "ref": "refs/heads/leia_backports", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "Owersun/xbmc", "ref": "refs/heads/Krypton", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "be-cloud-be/horizon-addons", "ref": "refs/heads/9.0", "path": "partner-contact/partner_contact_gender/tests/__init__.py", "content": "# -*- coding: utf-8 -*-\n# © 2016 Therp BV <http://therp.nl>\n# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl.html).\nfrom . import test_partner_contact_gender\n" }
{ "repo_name": "Stane1983/xbmc-Gotham-aml", "ref": "refs/heads/13.2-Gotham", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "JamesLinEngineer/RKMC", "ref": "refs/heads/Jarvis", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "koying/xbmc", "ref": "refs/heads/master-krypton", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "gripped2/xbmc", "ref": "refs/heads/Isengard", "path": "lib/libUPnP/Neptune/Extras/Tools/Testing/MakeUrlList.py", "content": "import urllib2\nimport simplejson\n\n# This example request includes an optional API key which you will need to\nwords = open('/usr/share/dict/words').readlines()\nfor word in words:\n\tword = word.rstrip()\n\turl = ('http://ajax.googleapis.com/ajax/services/search/web?v=1.0&q='+word+'+https&userip=67.169.84.240')\n\t#print url\n\t#print word.rstrip()\n\trequest = urllib2.Request(url, None, {'Referer': 'http://test.com'})\n\tresponse = urllib2.urlopen(request)\n\n\tresults = simplejson.load(response)\n\tfor result in results['responseData']['results']:\n\t\tprint result['unescapedUrl']\n" }
{ "repo_name": "asomya/test", "ref": "refs/heads/quantum-integration", "path": "horizon/dashboards/nova/instances_and_volumes/instances/urls.py", "content": "# vim: tabstop=4 shiftwidth=4 softtabstop=4\n\n# Copyright 2012 United States Government as represented by the\n# Administrator of the National Aeronautics and Space Administration.\n# All Rights Reserved.\n#\n# Copyright 2012 Nebula, Inc.\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\nfrom django.conf.urls.defaults import patterns, url\n\nfrom .views import UpdateView, DetailView\n\n\nINSTANCES = r'^(?P<instance_id>[^/]+)/%s$'\n\n\nurlpatterns = patterns(\n    'horizon.dashboards.nova.instances_and_volumes.instances.views',\n    url(INSTANCES % 'detail', DetailView.as_view(), name='detail'),\n    url(INSTANCES % 'console', 'console', name='console'),\n    url(INSTANCES % 'vnc', 'vnc', name='vnc'),\n    url(INSTANCES % 'update', UpdateView.as_view(), name='update'),\n)\n" }
{ "repo_name": "steveandroulakis/mytardis", "ref": "refs/heads/3.0", "path": "tardis/tardis_portal/models/license.py", "content": "from django.db import models\n\nfrom itertools import chain\nimport logging\nlogger = logging.getLogger(__name__)\n\nclass License(models.Model):\n    '''\n    Represents a licence for experiment content.\n\n    Instances should provide enough detail for both researchers to select the\n    licence, and for the users of their data to divine correct usage of\n    experiment content.\n\n    (Non-US developers: We're using US spelling in the code.)\n    '''\n\n    class Meta:\n        app_label = 'tardis_portal'\n\n    name = models.CharField(max_length=400, unique=True, blank=False)\n    url  = models.URLField(\n        verify_exists=True,\n        max_length=2000,\n        blank=False,\n        unique=True,\n        help_text=\"Link to document outlining licensing details.\")\n    internal_description = models.TextField(blank=False)\n    image_url = models.URLField(verify_exists=True, max_length=2000, blank=True)\n    allows_distribution = models.BooleanField(\n        default=False,\n        help_text=\"Does this license provide distribution rights?\")\n    is_active = models.BooleanField(\n        default=True,\n        help_text=\"Can experiments continue to select this license?\")\n\n    def __unicode__(self):\n        return self.name\n\n    @classmethod\n    def get_suitable_licenses(cls, public_access_method = None):\n        def with_none(seq):\n            return chain([cls.get_none_option_license()], seq)\n        # If no method specify, return all\n        if public_access_method == None:\n            return with_none(cls.objects.filter(is_active=True))\n        # Otherwise, ask Experiment to put it in terms we understand\n        from .experiment import Experiment\n        if Experiment.public_access_implies_distribution(public_access_method):\n            # Only licences which allow distribution\n            return cls.objects.filter(is_active=True, allows_distribution=True)\n        else:\n            # Only licenses which don't allow distribution (including none)\n            return with_none(cls.objects.filter(is_active=True,\n                                                allows_distribution=False))\n\n    @classmethod\n    def get_none_option_license(cls):\n        url = 'http://en.wikipedia.org/wiki/Copyright#Exclusive_rights'\n        desc = '''\n        No license is explicitly specified. You implicitly retain all rights\n        under copyright.\n        '''\n        return License(id='',\n                       name='Unspecified License',\n                       internal_description=desc,\n                       url=url,\n                       allows_distribution=False)\n\n" }
{ "repo_name": "jeffreylu9/django-cms", "ref": "refs/heads/wlsite", "path": "cms/utils/helpers.py", "content": "# -*- coding: utf-8 -*-\nimport re\n\nfrom django.contrib.sites.models import SITE_CACHE, Site\nfrom .compat.dj import is_installed\n\nSITE_VAR = \"site__exact\"\n\n\n# modify reversions to match our needs if required...\ndef reversion_register(model_class, fields=None, follow=(), format=\"json\", exclude_fields=None):\n    \"\"\"CMS interface to reversion api - helper function. Registers model for\n    reversion only if reversion is available.\n\n    Auto excludes publisher fields.\n\n    \"\"\"\n\n    # reversion's merely recommended, not required\n    if not is_installed('reversion'):\n        return\n\n    if fields and exclude_fields:\n        raise ValueError(\"Just one of fields, exclude_fields arguments can be passed.\")\n\n    opts = model_class._meta\n    local_fields = opts.local_fields + opts.local_many_to_many\n    if fields is None:\n        fields = [field.name for field in local_fields]\n\n    exclude_fields = exclude_fields or []\n\n    fields = filter(lambda name: not name in exclude_fields, fields)\n\n    from cms.utils import reversion_hacks\n    reversion_hacks.register_draft_only(model_class, fields, follow, format)\n\n\ndef make_revision_with_plugins(obj, user=None, message=None):\n    from cms.models.pluginmodel import CMSPlugin\n    # we can safely import reversion - calls here always check for\n    # reversion in installed_applications first\n    import reversion\n    if hasattr(reversion.models, 'VERSION_CHANGE'):\n        from reversion.models import VERSION_CHANGE\n    \"\"\"\n    Only add to revision if it is a draft.\n    \"\"\"\n    revision_manager = reversion.revision\n    revision_context = reversion.revision_context_manager\n\n    cls = obj.__class__\n    if hasattr(revision_manager, '_registration_key_for_model'):\n        model_key = revision_manager._registration_key_for_model(cls)\n    else:\n        model_key = cls\n\n    if model_key in revision_manager._registered_models:\n\n        placeholder_relation = find_placeholder_relation(obj)\n\n        if revision_context.is_active():\n            if user:\n                revision_context.set_user(user)\n            if message:\n                revision_context.set_comment(message)\n            # add toplevel object to the revision\n            adapter = revision_manager.get_adapter(obj.__class__)\n            if hasattr(reversion.models, 'VERSION_CHANGE'):\n                revision_context.add_to_context(revision_manager, obj, adapter.get_version_data(obj, VERSION_CHANGE))\n            else:\n                revision_context.add_to_context(revision_manager, obj, adapter.get_version_data(obj))\n            # add placeholders to the revision\n            for ph in obj.get_placeholders():\n                phadapter = revision_manager.get_adapter(ph.__class__)\n                if hasattr(reversion.models, 'VERSION_CHANGE'):\n                    revision_context.add_to_context(revision_manager, ph, phadapter.get_version_data(ph, VERSION_CHANGE))\n                else:\n                    revision_context.add_to_context(revision_manager, ph, phadapter.get_version_data(ph))\n            # add plugins and subclasses to the revision\n            filters = {'placeholder__%s' % placeholder_relation: obj}\n            for plugin in CMSPlugin.objects.filter(**filters):\n                plugin_instance, admin = plugin.get_plugin_instance()\n                if plugin_instance:\n                    padapter = revision_manager.get_adapter(plugin_instance.__class__)\n                    if hasattr(reversion.models, 'VERSION_CHANGE'):\n                        revision_context.add_to_context(revision_manager, plugin_instance, padapter.get_version_data(plugin_instance, VERSION_CHANGE))\n                    else:\n                        revision_context.add_to_context(revision_manager, plugin_instance, padapter.get_version_data(plugin_instance))\n                bpadapter = revision_manager.get_adapter(plugin.__class__)\n                if hasattr(reversion.models, 'VERSION_CHANGE'):\n                    revision_context.add_to_context(revision_manager, plugin, bpadapter.get_version_data(plugin, VERSION_CHANGE))\n                else:\n                    revision_context.add_to_context(revision_manager, plugin, bpadapter.get_version_data(plugin))\n\n\ndef find_placeholder_relation(obj):\n    return 'page'\n\n\nclass classproperty(object):\n    \"\"\"Like @property, but for classes, not just instances.\n\n    Example usage:\n\n        >>> from cms.utils.helpers import classproperty\n        >>> class A(object):\n        ...     @classproperty\n        ...     def x(cls):\n        ...         return 'x'\n        ...     @property\n        ...     def y(self):\n        ...         return 'y'\n        ...\n        >>> A.x\n        'x'\n        >>> A().x\n        'x'\n        >>> A.y\n        <property object at 0x2939628>\n        >>> A().y\n        'y'\n\n    \"\"\"\n    def __init__(self, fget):\n        self.fget = fget\n\n    def __get__(self, owner_self, owner_cls):\n        return self.fget(owner_cls)\n\n\ndef current_site(request):\n    site_pk = request.GET.get(SITE_VAR, None) if request.GET.get(SITE_VAR, None) else request.POST.get(SITE_VAR, None)\n    if not site_pk:\n        site_pk = request.session.get('cms_admin_site', None)\n    if site_pk:\n        try:\n            site = SITE_CACHE.get(site_pk) or Site.objects.get(pk=site_pk)\n            SITE_CACHE[site_pk] = site\n            return site\n        except Site.DoesNotExist:\n            return None\n    else:\n        return Site.objects.get_current()\n\n\ndef normalize_name(name):\n    \"\"\"\n    Converts camel-case style names into underscore seperated words. Example::\n\n        >>> normalize_name('oneTwoThree')\n        'one_two_three'\n        >>> normalize_name('FourFiveSix')\n        'four_five_six'\n\n    taken from django.contrib.formtools\n    \"\"\"\n    new = re.sub('(((?<=[a-z])[A-Z])|([A-Z](?![A-Z]|$)))', '_\\\\1', name)\n    return new.lower().strip('_')" }
{ "repo_name": "libracore/erpnext", "ref": "refs/heads/v12", "path": "erpnext/non_profit/doctype/membership_type/test_membership_type.py", "content": "# -*- coding: utf-8 -*-\n# Copyright (c) 2017, Frappe Technologies Pvt. Ltd. and Contributors\n# See license.txt\nfrom __future__ import unicode_literals\n\nimport unittest\n\nclass TestMembershipType(unittest.TestCase):\n\tpass\n" }
{ "repo_name": "Pexego/alimentacion", "ref": "refs/heads/7.0", "path": "stock_location_templates/wizard/__init__.py", "content": "# -*- coding: utf-8 -*-\n##############################################################################\n#\n#    Copyright (C) 2004-2012 Pexego Sistemas Informáticos All Rights Reserved\n#    $Marta Vázquez Rodríguez$ <marta@pexego.es>\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU Affero General Public License as published\n#    by the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU Affero General Public License for more details.\n#\n#    You should have received a copy of the GNU Affero General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\nimport templates_product" }
{ "repo_name": "lokeshh/stem", "ref": "refs/heads/run_tests.py_fix", "path": "test/integ/descriptor/__init__.py", "content": "\"\"\"\nIntegration tests for stem.descriptor.* contents.\n\"\"\"\n\n__all__ = [\n  'extrainfo_descriptor',\n  'microdescriptor',\n  'server_descriptor',\n  'get_resource',\n  'open_desc',\n]\n" }
{ "repo_name": "Comunitea/alimentacion", "ref": "refs/heads/7.0", "path": "stock_location_templates/wizard/__init__.py", "content": "# -*- coding: utf-8 -*-\n##############################################################################\n#\n#    Copyright (C) 2004-2012 Pexego Sistemas Informáticos All Rights Reserved\n#    $Marta Vázquez Rodríguez$ <marta@pexego.es>\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU Affero General Public License as published\n#    by the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU Affero General Public License for more details.\n#\n#    You should have received a copy of the GNU Affero General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\nimport templates_product" }
{ "repo_name": "xingyepei/edx-platform", "ref": "refs/heads/release", "path": "openedx/core/djangoapps/programs/models.py", "content": "\"\"\"\nModels providing Programs support for the LMS and Studio.\n\"\"\"\n\nfrom urlparse import urljoin\n\nfrom django.db.models import BooleanField, IntegerField, URLField\nfrom django.utils.translation import ugettext_lazy as _\n\nfrom config_models.models import ConfigurationModel\n\n\nclass ProgramsApiConfig(ConfigurationModel):\n    \"\"\"\n    Manages configuration for connecting to the Programs service and using its\n    API.\n    \"\"\"\n\n    internal_service_url = URLField(verbose_name=_(\"Internal Service URL\"))\n    public_service_url = URLField(verbose_name=_(\"Public Service URL\"))\n    api_version_number = IntegerField(verbose_name=_(\"API Version\"))\n    enable_student_dashboard = BooleanField(verbose_name=_(\"Enable Student Dashboard Displays\"))\n\n    @property\n    def internal_api_url(self):\n        \"\"\"\n        Generate a URL based on internal service URL and api version number.\n        \"\"\"\n        return urljoin(self.internal_service_url, \"/api/v{}/\".format(self.api_version_number))\n\n    @property\n    def public_api_url(self):\n        \"\"\"\n        Generate a URL based on public service URL and api version number.\n        \"\"\"\n        return urljoin(self.public_service_url, \"/api/v{}/\".format(self.api_version_number))\n\n    @property\n    def is_student_dashboard_enabled(self):\n        \"\"\"\n        Indicate whether LMS dashboard functionality related to Programs should\n        be enabled or not.\n        \"\"\"\n        return self.enabled and self.enable_student_dashboard\n" }
{ "repo_name": "Foxboron/stem", "ref": "refs/heads/foxboron/python3/codebase", "path": "test/integ/descriptor/__init__.py", "content": "\"\"\"\nIntegration tests for stem.descriptor.* contents.\n\"\"\"\n\n__all__ = [\n  'extrainfo_descriptor',\n  'microdescriptor',\n  'server_descriptor',\n  'get_resource',\n  'open_desc',\n]\n" }
{ "repo_name": "yohn89/pythoner.net", "ref": "refs/heads/matt", "path": "pythoner/topic/migrations/0003_auto__add_field_topic_md_content.py", "content": "# -*- coding: utf-8 -*-\nimport datetime\nfrom south.db import db\nfrom south.v2 import SchemaMigration\nfrom django.db import models\n\n\nclass Migration(SchemaMigration):\n\n    def forwards(self, orm):\n        # Adding field 'Topic.md_content'\n        db.add_column('topic_topic', 'md_content',\n                      self.gf('django.db.models.fields.TextField')(default=''),\n                      keep_default=False)\n\n\n    def backwards(self, orm):\n        # Deleting field 'Topic.md_content'\n        db.delete_column('topic_topic', 'md_content')\n\n\n    models = {\n        'auth.group': {\n            'Meta': {'object_name': 'Group'}\n            'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),\n            'name': ('django.db.models.fields.CharField', [], {'unique': 'True', 'max_length': '80'}),\n            'permissions': ('django.db.models.fields.related.ManyToManyField', [], {'to': \"orm['auth.Permission']\", 'symmetrical': 'False', 'blank': 'True'})\n      }\n        'auth.permission': {\n            'Meta': {'ordering': \"('content_type__app_label', 'content_type__model', 'codename')\", 'unique_together': \"(('content_type', 'codename'),)\", 'object_name': 'Permission'}\n            'codename': ('django.db.models.fields.CharField', [], {'max_length': '100'}),\n            'content_type': ('django.db.models.fields.related.ForeignKey', [], {'to': \"orm['contenttypes.ContentType']\"}),\n            'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),\n            'name': ('django.db.models.fields.CharField', [], {'max_length': '50'})\n      }\n        'auth.user': {\n            'Meta': {'object_name': 'User'}\n            'date_joined': ('django.db.models.fields.DateTimeField', [], {'default': 'datetime.datetime.now'}),\n            'email': ('django.db.models.fields.EmailField', [], {'max_length': '75', 'blank': 'True'}),\n            'first_name': ('django.db.models.fields.CharField', [], {'max_length': '30', 'blank': 'True'}),\n            'groups': ('django.db.models.fields.related.ManyToManyField', [], {'to': \"orm['auth.Group']\", 'symmetrical': 'False', 'blank': 'True'}),\n            'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),\n            'is_active': ('django.db.models.fields.BooleanField', [], {'default': 'True'}),\n            'is_staff': ('django.db.models.fields.BooleanField', [], {'default': 'False'}),\n            'is_superuser': ('django.db.models.fields.BooleanField', [], {'default': 'False'}),\n            'last_login': ('django.db.models.fields.DateTimeField', [], {'default': 'datetime.datetime.now'}),\n            'last_name': ('django.db.models.fields.CharField', [], {'max_length': '30', 'blank': 'True'}),\n            'password': ('django.db.models.fields.CharField', [], {'max_length': '128'}),\n            'user_permissions': ('django.db.models.fields.related.ManyToManyField', [], {'to': \"orm['auth.Permission']\", 'symmetrical': 'False', 'blank': 'True'}),\n            'username': ('django.db.models.fields.CharField', [], {'unique': 'True', 'max_length': '30'})\n      }\n        'contenttypes.contenttype': {\n            'Meta': {'ordering': \"('name',)\", 'unique_together': \"(('app_label', 'model'),)\", 'object_name': 'ContentType', 'db_table': \"'django_content_type'\"}\n            'app_label': ('django.db.models.fields.CharField', [], {'max_length': '100'}),\n            'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),\n            'model': ('django.db.models.fields.CharField', [], {'max_length': '100'}),\n            'name': ('django.db.models.fields.CharField', [], {'max_length': '100'})\n      }\n        'topic.favorite': {\n            'Meta': {'object_name': 'Favorite'}\n            'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),\n            'topic': ('django.db.models.fields.related.ForeignKey', [], {'to': \"orm['topic.Topic']\"}),\n            'user': ('django.db.models.fields.related.ForeignKey', [], {'to': \"orm['auth.User']\"})\n      }\n        'topic.tag': {\n            'Meta': {'object_name': 'Tag'}\n            'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),\n            'name': ('django.db.models.fields.CharField', [], {'unique': 'True', 'max_length': '10'}),\n            'remark': ('django.db.models.fields.CharField', [], {'max_length': '300', 'null': 'True', 'blank': 'True'})\n      }\n        'topic.topic': {\n            'Meta': {'ordering': \"['deleted', '-top', '-latest_response', '-sub_time', 'author', '-click_times']\", 'object_name': 'Topic'}\n            'author': ('django.db.models.fields.related.ForeignKey', [], {'related_name': \"'author'\", 'to': \"orm['auth.User']\"}),\n            'click_times': ('django.db.models.fields.PositiveIntegerField', [], {'default': '0', 'max_length': '10'}),\n            'content': ('django.db.models.fields.TextField', [], {}),\n            'deleted': ('django.db.models.fields.BooleanField', [], {'default': 'False'}),\n            'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),\n            'ip': ('django.db.models.fields.IPAddressField', [], {'default': \"'127.0.0.1'\", 'max_length': '15'}),\n            'latest_response': ('django.db.models.fields.DateTimeField', [], {'null': 'True', 'blank': 'True'}),\n            'md_content': ('django.db.models.fields.TextField', [], {'default': \"''\"}),\n            'notice': ('django.db.models.fields.BooleanField', [], {'default': 'True'}),\n            'sub_time': ('django.db.models.fields.DateTimeField', [], {'auto_now_add': 'True', 'blank': 'True'}),\n            'tag': ('django.db.models.fields.related.ManyToManyField', [], {'symmetrical': 'False', 'to': \"orm['topic.Tag']\", 'null': 'True', 'blank': 'True'}),\n            'title': ('django.db.models.fields.CharField', [], {'max_length': '50'}),\n            'top': ('django.db.models.fields.BooleanField', [], {'default': 'False'})\n      }\n  }\n\n    complete_apps = ['topic']" }
{ "repo_name": "vmendez/DIRAC", "ref": "refs/heads/integration", "path": "Core/Utilities/TimeLeft/LSFTimeLeft.py", "content": "\"\"\" The LSF TimeLeft utility interrogates the LSF batch system for the\n    current CPU and Wallclock consumed, as well as their limits.\n\"\"\"\n__RCSID__ = \"$Id$\"\n\nimport os\nimport re\nimport time\n\nfrom DIRAC import gLogger, S_OK, S_ERROR\nfrom DIRAC.Core.Utilities.TimeLeft.TimeLeft import runCommand\n\nfrom DIRAC.Core.Utilities.Os import sourceEnv\n\n\nclass LSFTimeLeft( object ):\n\n  #############################################################################\n  def __init__( self ):\n    \"\"\" Standard constructor\n    \"\"\"\n    self.log = gLogger.getSubLogger( 'LSFTimeLeft' )\n    self.jobID = os.environ.get( 'LSB_JOBID' )\n    self.queue = os.environ.get( 'LSB_QUEUE' )\n    self.bin = os.environ.get( 'LSF_BINDIR' )\n    self.host = os.environ.get( 'LSB_HOSTS' )\n    self.year = time.strftime( '%Y', time.gmtime() )\n    self.log.verbose( 'LSB_JOBID=%s, LSB_QUEUE=%s, LSF_BINDIR=%s, LSB_HOSTS=%s' % ( self.jobID,\n                                                                                    self.queue,\n                                                                                    self.bin,\n                                                                                    self.host ) )\n\n    self.cpuLimit = None\n    self.cpuRef = None\n    self.normRef = None\n    self.wallClockLimit = None\n    self.hostNorm = None\n\n    cmd = '%s/bqueues -l %s' % ( self.bin, self.queue )\n    result = runCommand( cmd )\n    if not result['OK']:\n      return\n\n    lines = str( result['Value'] ).split( '\\n' )\n    self.log.debug( 'From %s' % cmd, '\\n'.join( [line if len( line ) <= 128 else line[:128] + ' [...]' for line in lines] ) )\n    for i in xrange( len( lines ) ):\n      if re.search( '.*CPULIMIT.*', lines[i] ):\n        info = lines[i + 1].split()\n        if len( info ) >= 4:\n          self.cpuLimit = float( info[0] ) * 60\n          self.cpuRef = info[3]\n        else:\n          self.log.warn( 'Problem parsing \"%s\" for CPU limit' % lines[i + 1] )\n          self.cpuLimit = -1\n      elif re.search( '.*RUNLIMIT.*', lines[i] ):\n        info = lines[i + 1].split()\n        if len( info ) >= 1:\n          self.wallClockLimit = float( info[0] ) * 60\n        else:\n          self.log.warn( 'Problem parsing \"%s\" for wall clock limit' % lines[i + 1] )\n          self.wallClockLimit = -1\n\n    modelMaxNorm = 0\n    if self.cpuRef:\n      # Now try to get the CPU_FACTOR for this reference CPU,\n      # it must be either a Model, a Host or the largest Model\n\n      cmd = '%s/lshosts -w %s' % ( self.bin, self.cpuRef )\n      result = runCommand( cmd )\n      if result['OK']:\n        # At CERN this command will return an error since there is no host defined\n        # with the name of the reference Host.\n        lines = str( result['Value'] ).split( '\\n' )\n        l1 = lines[0].split()\n        l2 = lines[1].split()\n        if len( l1 ) > len( l2 ):\n          self.log.error( \"Failed lshost command\", \"%s:\\n %s\\n %s\" % ( cmd, lines[0], lines[0] ) )\n        else:\n          for i in range( len( l1 ) ):\n            if l1[i] == 'cpuf':\n              try:\n                self.normRef = float( l2[i] )\n                self.log.info( 'Reference Normalization taken from Host', '%s: %s' % ( self.cpuRef, self.normRef ) )\n              except ValueError as e:\n                self.log.exception( 'Exception parsing lshosts output', '', e )\n\n      if not self.normRef:\n        # Try if there is a model define with the name of cpuRef\n        cmd = '%s/lsinfo -m' % ( self.bin )\n        result = runCommand( cmd )\n        if result['OK']:\n          lines = str( result['Value'] ).split( '\\n' )\n          for line in lines[1:]:\n            words = line.split()\n            if len( words ) > 1:\n              try:\n                norm = float( words[1] )\n                if norm > modelMaxNorm:\n                  modelMaxNorm = norm\n                if words[0].find( self.cpuRef ) > -1:\n                  self.normRef = norm\n                  self.log.info( 'Reference Normalization taken from Host Model',\n                                 '%s: %s' % ( self.cpuRef, self.normRef ) )\n              except ValueError as e:\n                self.log.exception( 'Exception parsing lsfinfo output', '', e )\n\n      if not self.normRef:\n        # Now parse LSF configuration files\n        if not os.path.isfile( './lsf.sh' ):\n          os.symlink( os.path.join( os.environ['LSF_ENVDIR'], 'lsf.conf' ) , './lsf.sh' )\n        # As the variables are not exported, we must force it\n        ret = sourceEnv( 10, ['./lsf', '&& export LSF_CONFDIR' ] )\n        if ret['OK']:\n          lsfEnv = ret['outputEnv']\n          shared = None\n          try:\n            egoShared = os.path.join( lsfEnv['LSF_CONFDIR'], 'ego.shared' )\n            lsfShared = os.path.join( lsfEnv['LSF_CONFDIR'], 'lsf.shared' )\n            if os.path.exists( egoShared ):\n              shared = egoShared\n            elif os.path.exists( lsfShared ):\n              shared = lsfShared\n          except KeyError as e:\n            self.log.exception( 'Exception getting LSF configuration', '', e )\n          if shared:\n            f = open( shared )\n            hostModelSection = False\n            for line in f.readlines():\n              if line.find( 'Begin HostModel' ) == 0:\n                hostModelSection = True\n                continue\n              if not hostModelSection:\n                continue\n              if line.find( 'End HostModel' ) == 0:\n                break\n              line = line.strip()\n              if line and line.split()[0] == self.cpuRef:\n                try:\n                  self.normRef = float( line.split()[1] )\n                  self.log.info( 'Reference Normalization taken from Configuration File',\n                                 '(%s) %s: %s' % ( shared, self.cpuRef, self.normRef ) )\n                except ValueError as e:\n                  self.log.exception( 'Exception reading LSF configuration', '', e )\n          else:\n            self.log.warn( 'Could not find LSF configuration' )\n        else:\n          self.log.error( 'Cannot source the LSF environment', ret['Message'] )\n    if not self.normRef:\n      # If nothing worked, take the maximum defined for a Model\n      if modelMaxNorm:\n        self.normRef = modelMaxNorm\n        self.log.info( 'Reference Normalization taken from Max Model:', self.normRef )\n\n    # Now get the Normalization for the current Host\n    if self.host:\n      cmd = '%s/lshosts -w %s' % ( self.bin, self.host )\n      result = runCommand( cmd )\n      if result['OK']:\n        lines = str( result['Value'] ).split( '\\n' )\n        l1 = lines[0].split()\n        l2 = lines[1].split()\n        if len( l1 ) > len( l2 ):\n          self.log.error( \"Failed lshost command\", \"%s:\\n %s\\n %s\" % ( cmd, lines[0], lines[0] ) )\n        else:\n          for i in range( len( l1 ) ):\n            if l1[i] == 'cpuf':\n              try:\n                self.hostNorm = float( l2[i] )\n                self.log.info( 'Host Normalization', '%s: %s' % ( self.host, self.hostNorm ) )\n              except ValueError as e:\n                self.log.exception( 'Exception parsing lshosts output', l1, e )\n              finally:\n                break\n\n      if self.hostNorm and self.normRef:\n        self.hostNorm /= self.normRef\n        self.log.info( 'CPU power w.r.t. batch unit', self.hostNorm )\n\n      if self.hostNorm:\n        # Set the limits in real seconds\n        self.cpuLimit /= self.hostNorm\n        self.wallClockLimit /= self.hostNorm\n\n  #############################################################################\n  def getResourceUsage( self ):\n    \"\"\"Returns a dictionary containing CPUConsumed, CPULimit, WallClockConsumed\n       and WallClockLimit for current slot.  All values returned in seconds.\n    \"\"\"\n    if not self.bin:\n      return S_ERROR( 'Could not determine bin directory for LSF' )\n    if not self.hostNorm:\n      return S_ERROR( 'Could not determine host Norm factor' )\n\n\n    cpu = None\n    wallClock = None\n\n    cmd = '%s/bjobs -W %s' % ( self.bin, self.jobID )\n    result = runCommand( cmd )\n    if not result['OK']:\n      return result\n    lines = str( result['Value'] ).split( '\\n' )\n    l1 = lines[0].split()\n    l2 = lines[1].split()\n    if len( l1 ) > len( l2 ):\n      self.log.error( \"Failed bjobs command\", \"%s:\\n %s\\n %s\" % ( cmd, lines[0], lines[0] ) )\n      return S_ERROR( 'Can not parse LSF output' )\n\n    sCPU = None\n    sStart = None\n    for i in range( len( l1 ) ):\n      if l1[i] == 'CPU_USED':\n        sCPU = l2[i]\n        lCPU = sCPU.split( ':' )\n        try:\n          cpu = float( lCPU[0] ) * 3600 + float( lCPU[1] ) * 60 + float( lCPU[2] )\n        except ( ValueError, IndexError ) as _e:\n          pass\n      elif l1[i] == 'START_TIME':\n        sStart = l2[i]\n        sStart = '%s %s' % ( sStart, self.year )\n        try:\n          timeTup = time.strptime( sStart, '%m/%d-%H:%M:%S %Y' )\n          wallClock = time.mktime( time.localtime() ) - time.mktime( timeTup )\n        except ValueError:\n          pass\n\n    if cpu is None or wallClock is None:\n      return S_ERROR( 'Failed to parse LSF output' )\n\n    consumed = {'CPU':cpu, 'CPULimit':self.cpuLimit, 'WallClock':wallClock, 'WallClockLimit':self.wallClockLimit}\n    self.log.debug( consumed )\n\n    if None not in consumed.values():\n      return S_OK( consumed )\n    else:\n      missed = [key for key, val in consumed.items() if val is None]\n      msg = 'Could not determine some parameters'\n      self.log.info( msg, ': %s\\nThis is the stdout from the batch system call\\n%s' % ( ','.join( missed ), result['Value'] ) )\n      return S_ERROR( msg )\n\n# EOF#EOF#EOF#EOF#EOF#EOF#EOF#EOF#EOF#EOF#EOF#EOF#EOF#EOF#EOF#EOF#EOF#EOF#EOF#\n" }
{ "repo_name": "dex4er/django", "ref": "refs/heads/1.6.x", "path": "django/views/generic/base.py", "content": "from __future__ import unicode_literals\n\nimport logging\nfrom functools import update_wrapper\n\nfrom django import http\nfrom django.core.exceptions import ImproperlyConfigured\nfrom django.core.urlresolvers import reverse, NoReverseMatch\nfrom django.template.response import TemplateResponse\nfrom django.utils.decorators import classonlymethod\nfrom django.utils import six\n\nlogger = logging.getLogger('django.request')\n\n\nclass ContextMixin(object):\n    \"\"\"\n    A default context mixin that passes the keyword arguments received by\n    get_context_data as the template context.\n    \"\"\"\n\n    def get_context_data(self, **kwargs):\n        if 'view' not in kwargs:\n            kwargs['view'] = self\n        return kwargs\n\n\nclass View(object):\n    \"\"\"\n    Intentionally simple parent class for all views. Only implements\n    dispatch-by-method and simple sanity checking.\n    \"\"\"\n\n    http_method_names = ['get', 'post', 'put', 'patch', 'delete', 'head', 'options', 'trace']\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Constructor. Called in the URLconf; can contain helpful extra\n        keyword arguments, and other things.\n        \"\"\"\n        # Go through keyword arguments, and either save their values to our\n        # instance, or raise an error.\n        for key, value in six.iteritems(kwargs):\n            setattr(self, key, value)\n\n    @classonlymethod\n    def as_view(cls, **initkwargs):\n        \"\"\"\n        Main entry point for a request-response process.\n        \"\"\"\n        # sanitize keyword arguments\n        for key in initkwargs:\n            if key in cls.http_method_names:\n                raise TypeError(\"You tried to pass in the %s method name as a \"\n                                \"keyword argument to %s(). Don't do that.\"\n                                % (key, cls.__name__))\n            if not hasattr(cls, key):\n                raise TypeError(\"%s() received an invalid keyword %r. as_view \"\n                                \"only accepts arguments that are already \"\n                                \"attributes of the class.\" % (cls.__name__, key))\n\n        def view(request, *args, **kwargs):\n            self = cls(**initkwargs)\n            if hasattr(self, 'get') and not hasattr(self, 'head'):\n                self.head = self.get\n            self.request = request\n            self.args = args\n            self.kwargs = kwargs\n            return self.dispatch(request, *args, **kwargs)\n\n        # take name and docstring from class\n        update_wrapper(view, cls, updated=())\n\n        # and possible attributes set by decorators\n        # like csrf_exempt from dispatch\n        update_wrapper(view, cls.dispatch, assigned=())\n        return view\n\n    def dispatch(self, request, *args, **kwargs):\n        # Try to dispatch to the right method; if a method doesn't exist,\n        # defer to the error handler. Also defer to the error handler if the\n        # request method isn't on the approved list.\n        if request.method.lower() in self.http_method_names:\n            handler = getattr(self, request.method.lower(), self.http_method_not_allowed)\n        else:\n            handler = self.http_method_not_allowed\n        return handler(request, *args, **kwargs)\n\n    def http_method_not_allowed(self, request, *args, **kwargs):\n        logger.warning('Method Not Allowed (%s): %s', request.method, request.path,\n            extra={\n                'status_code': 405,\n                'request': self.request\n          }\n        )\n        return http.HttpResponseNotAllowed(self._allowed_methods())\n\n    def options(self, request, *args, **kwargs):\n        \"\"\"\n        Handles responding to requests for the OPTIONS HTTP verb.\n        \"\"\"\n        response = http.HttpResponse()\n        response['Allow'] = ', '.join(self._allowed_methods())\n        response['Content-Length'] = '0'\n        return response\n\n    def _allowed_methods(self):\n        return [m.upper() for m in self.http_method_names if hasattr(self, m)]\n\n\nclass TemplateResponseMixin(object):\n    \"\"\"\n    A mixin that can be used to render a template.\n    \"\"\"\n    template_name = None\n    response_class = TemplateResponse\n    content_type = None\n\n    def render_to_response(self, context, **response_kwargs):\n        \"\"\"\n        Returns a response, using the `response_class` for this\n        view, with a template rendered with the given context.\n\n        If any keyword arguments are provided, they will be\n        passed to the constructor of the response class.\n        \"\"\"\n        response_kwargs.setdefault('content_type', self.content_type)\n        return self.response_class(\n            request = self.request,\n            template = self.get_template_names(),\n            context = context,\n            **response_kwargs\n        )\n\n    def get_template_names(self):\n        \"\"\"\n        Returns a list of template names to be used for the request. Must return\n        a list. May not be called if render_to_response is overridden.\n        \"\"\"\n        if self.template_name is None:\n            raise ImproperlyConfigured(\n                \"TemplateResponseMixin requires either a definition of \"\n                \"'template_name' or an implementation of 'get_template_names()'\")\n        else:\n            return [self.template_name]\n\n\nclass TemplateView(TemplateResponseMixin, ContextMixin, View):\n    \"\"\"\n    A view that renders a template.  This view will also pass into the context\n    any keyword arguments passed by the url conf.\n    \"\"\"\n    def get(self, request, *args, **kwargs):\n        context = self.get_context_data(**kwargs)\n        return self.render_to_response(context)\n\n\nclass RedirectView(View):\n    \"\"\"\n    A view that provides a redirect on any GET request.\n    \"\"\"\n    permanent = True\n    url = None\n    pattern_name = None\n    query_string = False\n\n    def get_redirect_url(self, *args, **kwargs):\n        \"\"\"\n        Return the URL redirect to. Keyword arguments from the\n        URL pattern match generating the redirect request\n        are provided as kwargs to this method.\n        \"\"\"\n        if self.url:\n            url = self.url % kwargs\n        elif self.pattern_name:\n            try:\n                url = reverse(self.pattern_name, args=args, kwargs=kwargs)\n            except NoReverseMatch:\n                return None\n        else:\n            return None\n\n        args = self.request.META.get('QUERY_STRING', '')\n        if args and self.query_string:\n            url = \"%s?%s\" % (url, args)\n        return url\n\n    def get(self, request, *args, **kwargs):\n        url = self.get_redirect_url(*args, **kwargs)\n        if url:\n            if self.permanent:\n                return http.HttpResponsePermanentRedirect(url)\n            else:\n                return http.HttpResponseRedirect(url)\n        else:\n            logger.warning('Gone: %s', self.request.path,\n                        extra={\n                            'status_code': 410,\n                            'request': self.request\n                      })\n            return http.HttpResponseGone()\n\n    def head(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def post(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def options(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def delete(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def put(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def patch(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n" }
{ "repo_name": "knowsis/django", "ref": "refs/heads/nonrel-1.6", "path": "django/views/generic/base.py", "content": "from __future__ import unicode_literals\n\nimport logging\nfrom functools import update_wrapper\n\nfrom django import http\nfrom django.core.exceptions import ImproperlyConfigured\nfrom django.core.urlresolvers import reverse, NoReverseMatch\nfrom django.template.response import TemplateResponse\nfrom django.utils.decorators import classonlymethod\nfrom django.utils import six\n\nlogger = logging.getLogger('django.request')\n\n\nclass ContextMixin(object):\n    \"\"\"\n    A default context mixin that passes the keyword arguments received by\n    get_context_data as the template context.\n    \"\"\"\n\n    def get_context_data(self, **kwargs):\n        if 'view' not in kwargs:\n            kwargs['view'] = self\n        return kwargs\n\n\nclass View(object):\n    \"\"\"\n    Intentionally simple parent class for all views. Only implements\n    dispatch-by-method and simple sanity checking.\n    \"\"\"\n\n    http_method_names = ['get', 'post', 'put', 'patch', 'delete', 'head', 'options', 'trace']\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Constructor. Called in the URLconf; can contain helpful extra\n        keyword arguments, and other things.\n        \"\"\"\n        # Go through keyword arguments, and either save their values to our\n        # instance, or raise an error.\n        for key, value in six.iteritems(kwargs):\n            setattr(self, key, value)\n\n    @classonlymethod\n    def as_view(cls, **initkwargs):\n        \"\"\"\n        Main entry point for a request-response process.\n        \"\"\"\n        # sanitize keyword arguments\n        for key in initkwargs:\n            if key in cls.http_method_names:\n                raise TypeError(\"You tried to pass in the %s method name as a \"\n                                \"keyword argument to %s(). Don't do that.\"\n                                % (key, cls.__name__))\n            if not hasattr(cls, key):\n                raise TypeError(\"%s() received an invalid keyword %r. as_view \"\n                                \"only accepts arguments that are already \"\n                                \"attributes of the class.\" % (cls.__name__, key))\n\n        def view(request, *args, **kwargs):\n            self = cls(**initkwargs)\n            if hasattr(self, 'get') and not hasattr(self, 'head'):\n                self.head = self.get\n            self.request = request\n            self.args = args\n            self.kwargs = kwargs\n            return self.dispatch(request, *args, **kwargs)\n\n        # take name and docstring from class\n        update_wrapper(view, cls, updated=())\n\n        # and possible attributes set by decorators\n        # like csrf_exempt from dispatch\n        update_wrapper(view, cls.dispatch, assigned=())\n        return view\n\n    def dispatch(self, request, *args, **kwargs):\n        # Try to dispatch to the right method; if a method doesn't exist,\n        # defer to the error handler. Also defer to the error handler if the\n        # request method isn't on the approved list.\n        if request.method.lower() in self.http_method_names:\n            handler = getattr(self, request.method.lower(), self.http_method_not_allowed)\n        else:\n            handler = self.http_method_not_allowed\n        return handler(request, *args, **kwargs)\n\n    def http_method_not_allowed(self, request, *args, **kwargs):\n        logger.warning('Method Not Allowed (%s): %s', request.method, request.path,\n            extra={\n                'status_code': 405,\n                'request': self.request\n          }\n        )\n        return http.HttpResponseNotAllowed(self._allowed_methods())\n\n    def options(self, request, *args, **kwargs):\n        \"\"\"\n        Handles responding to requests for the OPTIONS HTTP verb.\n        \"\"\"\n        response = http.HttpResponse()\n        response['Allow'] = ', '.join(self._allowed_methods())\n        response['Content-Length'] = '0'\n        return response\n\n    def _allowed_methods(self):\n        return [m.upper() for m in self.http_method_names if hasattr(self, m)]\n\n\nclass TemplateResponseMixin(object):\n    \"\"\"\n    A mixin that can be used to render a template.\n    \"\"\"\n    template_name = None\n    response_class = TemplateResponse\n    content_type = None\n\n    def render_to_response(self, context, **response_kwargs):\n        \"\"\"\n        Returns a response, using the `response_class` for this\n        view, with a template rendered with the given context.\n\n        If any keyword arguments are provided, they will be\n        passed to the constructor of the response class.\n        \"\"\"\n        response_kwargs.setdefault('content_type', self.content_type)\n        return self.response_class(\n            request = self.request,\n            template = self.get_template_names(),\n            context = context,\n            **response_kwargs\n        )\n\n    def get_template_names(self):\n        \"\"\"\n        Returns a list of template names to be used for the request. Must return\n        a list. May not be called if render_to_response is overridden.\n        \"\"\"\n        if self.template_name is None:\n            raise ImproperlyConfigured(\n                \"TemplateResponseMixin requires either a definition of \"\n                \"'template_name' or an implementation of 'get_template_names()'\")\n        else:\n            return [self.template_name]\n\n\nclass TemplateView(TemplateResponseMixin, ContextMixin, View):\n    \"\"\"\n    A view that renders a template.  This view will also pass into the context\n    any keyword arguments passed by the url conf.\n    \"\"\"\n    def get(self, request, *args, **kwargs):\n        context = self.get_context_data(**kwargs)\n        return self.render_to_response(context)\n\n\nclass RedirectView(View):\n    \"\"\"\n    A view that provides a redirect on any GET request.\n    \"\"\"\n    permanent = True\n    url = None\n    pattern_name = None\n    query_string = False\n\n    def get_redirect_url(self, *args, **kwargs):\n        \"\"\"\n        Return the URL redirect to. Keyword arguments from the\n        URL pattern match generating the redirect request\n        are provided as kwargs to this method.\n        \"\"\"\n        if self.url:\n            url = self.url % kwargs\n        elif self.pattern_name:\n            try:\n                url = reverse(self.pattern_name, args=args, kwargs=kwargs)\n            except NoReverseMatch:\n                return None\n        else:\n            return None\n\n        args = self.request.META.get('QUERY_STRING', '')\n        if args and self.query_string:\n            url = \"%s?%s\" % (url, args)\n        return url\n\n    def get(self, request, *args, **kwargs):\n        url = self.get_redirect_url(*args, **kwargs)\n        if url:\n            if self.permanent:\n                return http.HttpResponsePermanentRedirect(url)\n            else:\n                return http.HttpResponseRedirect(url)\n        else:\n            logger.warning('Gone: %s', self.request.path,\n                        extra={\n                            'status_code': 410,\n                            'request': self.request\n                      })\n            return http.HttpResponseGone()\n\n    def head(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def post(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def options(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def delete(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def put(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def patch(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n" }
{ "repo_name": "django-nonrel/django", "ref": "refs/heads/nonrel-1.6", "path": "django/views/generic/base.py", "content": "from __future__ import unicode_literals\n\nimport logging\nfrom functools import update_wrapper\n\nfrom django import http\nfrom django.core.exceptions import ImproperlyConfigured\nfrom django.core.urlresolvers import reverse, NoReverseMatch\nfrom django.template.response import TemplateResponse\nfrom django.utils.decorators import classonlymethod\nfrom django.utils import six\n\nlogger = logging.getLogger('django.request')\n\n\nclass ContextMixin(object):\n    \"\"\"\n    A default context mixin that passes the keyword arguments received by\n    get_context_data as the template context.\n    \"\"\"\n\n    def get_context_data(self, **kwargs):\n        if 'view' not in kwargs:\n            kwargs['view'] = self\n        return kwargs\n\n\nclass View(object):\n    \"\"\"\n    Intentionally simple parent class for all views. Only implements\n    dispatch-by-method and simple sanity checking.\n    \"\"\"\n\n    http_method_names = ['get', 'post', 'put', 'patch', 'delete', 'head', 'options', 'trace']\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Constructor. Called in the URLconf; can contain helpful extra\n        keyword arguments, and other things.\n        \"\"\"\n        # Go through keyword arguments, and either save their values to our\n        # instance, or raise an error.\n        for key, value in six.iteritems(kwargs):\n            setattr(self, key, value)\n\n    @classonlymethod\n    def as_view(cls, **initkwargs):\n        \"\"\"\n        Main entry point for a request-response process.\n        \"\"\"\n        # sanitize keyword arguments\n        for key in initkwargs:\n            if key in cls.http_method_names:\n                raise TypeError(\"You tried to pass in the %s method name as a \"\n                                \"keyword argument to %s(). Don't do that.\"\n                                % (key, cls.__name__))\n            if not hasattr(cls, key):\n                raise TypeError(\"%s() received an invalid keyword %r. as_view \"\n                                \"only accepts arguments that are already \"\n                                \"attributes of the class.\" % (cls.__name__, key))\n\n        def view(request, *args, **kwargs):\n            self = cls(**initkwargs)\n            if hasattr(self, 'get') and not hasattr(self, 'head'):\n                self.head = self.get\n            self.request = request\n            self.args = args\n            self.kwargs = kwargs\n            return self.dispatch(request, *args, **kwargs)\n\n        # take name and docstring from class\n        update_wrapper(view, cls, updated=())\n\n        # and possible attributes set by decorators\n        # like csrf_exempt from dispatch\n        update_wrapper(view, cls.dispatch, assigned=())\n        return view\n\n    def dispatch(self, request, *args, **kwargs):\n        # Try to dispatch to the right method; if a method doesn't exist,\n        # defer to the error handler. Also defer to the error handler if the\n        # request method isn't on the approved list.\n        if request.method.lower() in self.http_method_names:\n            handler = getattr(self, request.method.lower(), self.http_method_not_allowed)\n        else:\n            handler = self.http_method_not_allowed\n        return handler(request, *args, **kwargs)\n\n    def http_method_not_allowed(self, request, *args, **kwargs):\n        logger.warning('Method Not Allowed (%s): %s', request.method, request.path,\n            extra={\n                'status_code': 405,\n                'request': self.request\n          }\n        )\n        return http.HttpResponseNotAllowed(self._allowed_methods())\n\n    def options(self, request, *args, **kwargs):\n        \"\"\"\n        Handles responding to requests for the OPTIONS HTTP verb.\n        \"\"\"\n        response = http.HttpResponse()\n        response['Allow'] = ', '.join(self._allowed_methods())\n        response['Content-Length'] = '0'\n        return response\n\n    def _allowed_methods(self):\n        return [m.upper() for m in self.http_method_names if hasattr(self, m)]\n\n\nclass TemplateResponseMixin(object):\n    \"\"\"\n    A mixin that can be used to render a template.\n    \"\"\"\n    template_name = None\n    response_class = TemplateResponse\n    content_type = None\n\n    def render_to_response(self, context, **response_kwargs):\n        \"\"\"\n        Returns a response, using the `response_class` for this\n        view, with a template rendered with the given context.\n\n        If any keyword arguments are provided, they will be\n        passed to the constructor of the response class.\n        \"\"\"\n        response_kwargs.setdefault('content_type', self.content_type)\n        return self.response_class(\n            request = self.request,\n            template = self.get_template_names(),\n            context = context,\n            **response_kwargs\n        )\n\n    def get_template_names(self):\n        \"\"\"\n        Returns a list of template names to be used for the request. Must return\n        a list. May not be called if render_to_response is overridden.\n        \"\"\"\n        if self.template_name is None:\n            raise ImproperlyConfigured(\n                \"TemplateResponseMixin requires either a definition of \"\n                \"'template_name' or an implementation of 'get_template_names()'\")\n        else:\n            return [self.template_name]\n\n\nclass TemplateView(TemplateResponseMixin, ContextMixin, View):\n    \"\"\"\n    A view that renders a template.  This view will also pass into the context\n    any keyword arguments passed by the url conf.\n    \"\"\"\n    def get(self, request, *args, **kwargs):\n        context = self.get_context_data(**kwargs)\n        return self.render_to_response(context)\n\n\nclass RedirectView(View):\n    \"\"\"\n    A view that provides a redirect on any GET request.\n    \"\"\"\n    permanent = True\n    url = None\n    pattern_name = None\n    query_string = False\n\n    def get_redirect_url(self, *args, **kwargs):\n        \"\"\"\n        Return the URL redirect to. Keyword arguments from the\n        URL pattern match generating the redirect request\n        are provided as kwargs to this method.\n        \"\"\"\n        if self.url:\n            url = self.url % kwargs\n        elif self.pattern_name:\n            try:\n                url = reverse(self.pattern_name, args=args, kwargs=kwargs)\n            except NoReverseMatch:\n                return None\n        else:\n            return None\n\n        args = self.request.META.get('QUERY_STRING', '')\n        if args and self.query_string:\n            url = \"%s?%s\" % (url, args)\n        return url\n\n    def get(self, request, *args, **kwargs):\n        url = self.get_redirect_url(*args, **kwargs)\n        if url:\n            if self.permanent:\n                return http.HttpResponsePermanentRedirect(url)\n            else:\n                return http.HttpResponseRedirect(url)\n        else:\n            logger.warning('Gone: %s', self.request.path,\n                        extra={\n                            'status_code': 410,\n                            'request': self.request\n                      })\n            return http.HttpResponseGone()\n\n    def head(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def post(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def options(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def delete(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def put(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def patch(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n" }
{ "repo_name": "nemesiscodex/JukyOS-sugar", "ref": "refs/heads/juky", "path": "src/jarabe/frame/frame.py", "content": "# Copyright (C) 2006-2007 Red Hat, Inc.\n#\n# This program is free software; you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation; either version 2 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA\n\nimport logging\n\nimport gtk\nimport gobject\n\nfrom sugar.graphics import animator\nfrom sugar.graphics import style\nfrom sugar.graphics import palettegroup\nfrom sugar import profile\n\nfrom jarabe.frame.eventarea import EventArea\nfrom jarabe.frame.activitiestray import ActivitiesTray\nfrom jarabe.frame.zoomtoolbar import ZoomToolbar\nfrom jarabe.frame.friendstray import FriendsTray\nfrom jarabe.frame.devicestray import DevicesTray\nfrom jarabe.frame.framewindow import FrameWindow\nfrom jarabe.frame.clipboardpanelwindow import ClipboardPanelWindow\nfrom jarabe.frame.notification import NotificationIcon, NotificationWindow\nfrom jarabe.model import notifications\n\n\nTOP_RIGHT = 0\nTOP_LEFT = 1\nBOTTOM_RIGHT = 2\nBOTTOM_LEFT = 3\n\n_FRAME_HIDING_DELAY = 500\n_NOTIFICATION_DURATION = 5000\n\n\nclass _Animation(animator.Animation):\n    def __init__(self, frame, end):\n        start = frame.current_position\n        animator.Animation.__init__(self, start, end)\n        self._frame = frame\n\n    def next_frame(self, current):\n        self._frame.move(current)\n\n\nclass _MouseListener(object):\n    def __init__(self, frame):\n        self._frame = frame\n        self._hide_sid = 0\n\n    def mouse_enter(self):\n        self._show_frame()\n\n    def mouse_leave(self):\n        if self._frame.mode == Frame.MODE_MOUSE:\n            self._hide_frame()\n\n    def _show_frame(self):\n        if self._hide_sid != 0:\n            gobject.source_remove(self._hide_sid)\n        self._frame.show(Frame.MODE_MOUSE)\n\n    def _hide_frame_timeout_cb(self):\n        self._frame.hide()\n        return False\n\n    def _hide_frame(self):\n        if self._hide_sid != 0:\n            gobject.source_remove(self._hide_sid)\n        self._hide_sid = gobject.timeout_add(\n                  _FRAME_HIDING_DELAY, self._hide_frame_timeout_cb)\n\n\nclass _KeyListener(object):\n    def __init__(self, frame):\n        self._frame = frame\n\n    def key_press(self):\n        if self._frame.visible:\n            if self._frame.mode == Frame.MODE_KEYBOARD:\n                self._frame.hide()\n        else:\n            self._frame.show(Frame.MODE_KEYBOARD)\n\n\nclass Frame(object):\n    MODE_MOUSE = 0\n    MODE_KEYBOARD = 1\n    MODE_NON_INTERACTIVE = 2\n\n    def __init__(self):\n        logging.debug('STARTUP: Loading the frame')\n        self.mode = None\n\n        self._palette_group = palettegroup.get_group('frame')\n        self._palette_group.connect('popdown', self._palette_group_popdown_cb)\n\n        self._left_panel = None\n        self._right_panel = None\n        self._top_panel = None\n        self._bottom_panel = None\n\n        self.current_position = 0.0\n        self._animator = None\n\n        self._event_area = EventArea()\n        self._event_area.connect('enter', self._enter_corner_cb)\n        self._event_area.show()\n\n        self._top_panel = self._create_top_panel()\n        self._bottom_panel = self._create_bottom_panel()\n        self._left_panel = self._create_left_panel()\n        self._right_panel = self._create_right_panel()\n\n        screen = gtk.gdk.screen_get_default()\n        screen.connect('size-changed', self._size_changed_cb)\n\n        self._key_listener = _KeyListener(self)\n        self._mouse_listener = _MouseListener(self)\n\n        self._notif_by_icon = {}\n\n        notification_service = notifications.get_service()\n        notification_service.notification_received.connect(\n                self.__notification_received_cb)\n        notification_service.notification_cancelled.connect(\n                self.__notification_cancelled_cb)\n\n    def is_visible(self):\n        return self.current_position != 0.0\n\n    visible = property(is_visible, None)\n\n    def hide(self):\n        if self._animator:\n            self._animator.stop()\n\n        self._animator = animator.Animator(0.5)\n        self._animator.add(_Animation(self, 0.0))\n        self._animator.start()\n\n        self.mode = None\n\n    def show(self, mode):\n        if self.visible:\n            return\n        if self._animator:\n            self._animator.stop()\n\n        self.mode = mode\n\n        self._animator = animator.Animator(0.5)\n        self._animator.add(_Animation(self, 1.0))\n        self._animator.start()\n\n    def move(self, pos):\n        self.current_position = pos\n        self._update_position()\n\n    def _is_hover(self):\n        return (self._top_panel.hover or \\\n                self._bottom_panel.hover or \\\n                self._left_panel.hover or \\\n                self._right_panel.hover)\n\n    def _create_top_panel(self):\n        panel = self._create_panel(gtk.POS_TOP)\n\n        zoom_toolbar = ZoomToolbar()\n        panel.append(zoom_toolbar, expand=False)\n        zoom_toolbar.show()\n\n        activities_tray = ActivitiesTray()\n        panel.append(activities_tray)\n        activities_tray.show()\n\n        return panel\n\n    def _create_bottom_panel(self):\n        panel = self._create_panel(gtk.POS_BOTTOM)\n\n        devices_tray = DevicesTray()\n        panel.append(devices_tray)\n        devices_tray.show()\n\n        return panel\n\n    def _create_right_panel(self):\n        panel = self._create_panel(gtk.POS_RIGHT)\n\n        tray = FriendsTray()\n        panel.append(tray)\n        tray.show()\n\n        return panel\n\n    def _create_left_panel(self):\n        panel = ClipboardPanelWindow(self, gtk.POS_LEFT)\n\n        self._connect_to_panel(panel)\n        panel.connect('drag-motion', self._drag_motion_cb)\n        panel.connect('drag-leave', self._drag_leave_cb)\n\n        return panel\n\n    def _create_panel(self, orientation):\n        panel = FrameWindow(orientation)\n        self._connect_to_panel(panel)\n\n        return panel\n\n    def _move_panel(self, panel, pos, x1, y1, x2, y2):\n        x = (x2 - x1) * pos + x1\n        y = (y2 - y1) * pos + y1\n\n        panel.move(int(x), int(y))\n\n        # FIXME we should hide and show as necessary to free memory\n        if not panel.props.visible:\n            panel.show()\n\n    def _connect_to_panel(self, panel):\n        panel.connect('enter-notify-event', self._enter_notify_cb)\n        panel.connect('leave-notify-event', self._leave_notify_cb)\n\n    def _update_position(self):\n        screen_h = gtk.gdk.screen_height()\n        screen_w = gtk.gdk.screen_width()\n\n        self._move_panel(self._top_panel, self.current_position,\n                         0, - self._top_panel.size, 0, 0)\n\n        self._move_panel(self._bottom_panel, self.current_position,\n                         0, screen_h, 0, screen_h - self._bottom_panel.size)\n\n        self._move_panel(self._left_panel, self.current_position,\n                         - self._left_panel.size, 0, 0, 0)\n\n        self._move_panel(self._right_panel, self.current_position,\n                         screen_w, 0, screen_w - self._right_panel.size, 0)\n\n    def _size_changed_cb(self, screen):\n        self._update_position()\n\n    def _enter_notify_cb(self, window, event):\n        if event.detail != gtk.gdk.NOTIFY_INFERIOR:\n            self._mouse_listener.mouse_enter()\n\n    def _leave_notify_cb(self, window, event):\n        if event.detail == gtk.gdk.NOTIFY_INFERIOR:\n            return\n\n        if not self._is_hover() and not self._palette_group.is_up():\n            self._mouse_listener.mouse_leave()\n\n    def _palette_group_popdown_cb(self, group):\n        if not self._is_hover():\n            self._mouse_listener.mouse_leave()\n\n    def _drag_motion_cb(self, window, context, x, y, time):\n        self._mouse_listener.mouse_enter()\n\n    def _drag_leave_cb(self, window, drag_context, timestamp):\n        self._mouse_listener.mouse_leave()\n\n    def _enter_corner_cb(self, event_area):\n        self._mouse_listener.mouse_enter()\n\n    def notify_key_press(self):\n        self._key_listener.key_press()\n\n    def add_notification(self, icon, corner=gtk.CORNER_TOP_LEFT,\n                         duration=_NOTIFICATION_DURATION):\n\n        if not isinstance(icon, NotificationIcon):\n            raise TypeError('icon must be a NotificationIcon.')\n\n        window = NotificationWindow()\n\n        screen = gtk.gdk.screen_get_default()\n        if corner == gtk.CORNER_TOP_LEFT:\n            window.move(0, 0)\n        elif corner == gtk.CORNER_TOP_RIGHT:\n            window.move(screen.get_width() - style.GRID_CELL_SIZE, 0)\n        elif corner == gtk.CORNER_BOTTOM_LEFT:\n            window.move(0, screen.get_height() - style.GRID_CELL_SIZE)\n        elif corner == gtk.CORNER_BOTTOM_RIGHT:\n            window.move(screen.get_width() - style.GRID_CELL_SIZE,\n                        screen.get_height() - style.GRID_CELL_SIZE)\n        else:\n            raise ValueError('Inalid corner: %r' % corner)\n\n        window.add(icon)\n        icon.show()\n        window.show()\n\n        self._notif_by_icon[icon] = window\n\n        gobject.timeout_add(duration,\n                        lambda: self.remove_notification(icon))\n\n    def remove_notification(self, icon):\n        if icon not in self._notif_by_icon:\n            logging.debug('icon %r not in list of notifications.', icon)\n            return\n\n        window = self._notif_by_icon[icon]\n        window.destroy()\n        del self._notif_by_icon[icon]\n\n    def __notification_received_cb(self, **kwargs):\n        logging.debug('__notification_received_cb')\n        icon = NotificationIcon()\n\n        hints = kwargs['hints']\n\n        icon_file_name = hints.get('x-sugar-icon-file-name', '')\n        if icon_file_name:\n            icon.props.icon_filename = icon_file_name\n        else:\n            icon.props.icon_name = 'application-octet-stream'\n\n        icon_colors = hints.get('x-sugar-icon-colors', '')\n        if not icon_colors:\n            icon_colors = profile.get_color()\n        icon.props.xo_color = icon_colors\n\n        duration = kwargs.get('expire_timeout', -1)\n        if duration == -1:\n            duration = _NOTIFICATION_DURATION\n\n        self.add_notification(icon, gtk.CORNER_TOP_RIGHT, duration)\n\n    def __notification_cancelled_cb(self, **kwargs):\n        # Do nothing for now. Our notification UI is so simple, there's no\n        # point yet.\n        pass\n" }
{ "repo_name": "lumig242/Hue-Integration-with-CDAP", "ref": "refs/heads/pull3", "path": "desktop/core/ext-py/Django-1.6.10/django/views/generic/base.py", "content": "from __future__ import unicode_literals\n\nimport logging\nfrom functools import update_wrapper\n\nfrom django import http\nfrom django.core.exceptions import ImproperlyConfigured\nfrom django.core.urlresolvers import reverse, NoReverseMatch\nfrom django.template.response import TemplateResponse\nfrom django.utils.decorators import classonlymethod\nfrom django.utils import six\n\nlogger = logging.getLogger('django.request')\n\n\nclass ContextMixin(object):\n    \"\"\"\n    A default context mixin that passes the keyword arguments received by\n    get_context_data as the template context.\n    \"\"\"\n\n    def get_context_data(self, **kwargs):\n        if 'view' not in kwargs:\n            kwargs['view'] = self\n        return kwargs\n\n\nclass View(object):\n    \"\"\"\n    Intentionally simple parent class for all views. Only implements\n    dispatch-by-method and simple sanity checking.\n    \"\"\"\n\n    http_method_names = ['get', 'post', 'put', 'patch', 'delete', 'head', 'options', 'trace']\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Constructor. Called in the URLconf; can contain helpful extra\n        keyword arguments, and other things.\n        \"\"\"\n        # Go through keyword arguments, and either save their values to our\n        # instance, or raise an error.\n        for key, value in six.iteritems(kwargs):\n            setattr(self, key, value)\n\n    @classonlymethod\n    def as_view(cls, **initkwargs):\n        \"\"\"\n        Main entry point for a request-response process.\n        \"\"\"\n        # sanitize keyword arguments\n        for key in initkwargs:\n            if key in cls.http_method_names:\n                raise TypeError(\"You tried to pass in the %s method name as a \"\n                                \"keyword argument to %s(). Don't do that.\"\n                                % (key, cls.__name__))\n            if not hasattr(cls, key):\n                raise TypeError(\"%s() received an invalid keyword %r. as_view \"\n                                \"only accepts arguments that are already \"\n                                \"attributes of the class.\" % (cls.__name__, key))\n\n        def view(request, *args, **kwargs):\n            self = cls(**initkwargs)\n            if hasattr(self, 'get') and not hasattr(self, 'head'):\n                self.head = self.get\n            self.request = request\n            self.args = args\n            self.kwargs = kwargs\n            return self.dispatch(request, *args, **kwargs)\n\n        # take name and docstring from class\n        update_wrapper(view, cls, updated=())\n\n        # and possible attributes set by decorators\n        # like csrf_exempt from dispatch\n        update_wrapper(view, cls.dispatch, assigned=())\n        return view\n\n    def dispatch(self, request, *args, **kwargs):\n        # Try to dispatch to the right method; if a method doesn't exist,\n        # defer to the error handler. Also defer to the error handler if the\n        # request method isn't on the approved list.\n        if request.method.lower() in self.http_method_names:\n            handler = getattr(self, request.method.lower(), self.http_method_not_allowed)\n        else:\n            handler = self.http_method_not_allowed\n        return handler(request, *args, **kwargs)\n\n    def http_method_not_allowed(self, request, *args, **kwargs):\n        logger.warning('Method Not Allowed (%s): %s', request.method, request.path,\n            extra={\n                'status_code': 405,\n                'request': self.request\n          }\n        )\n        return http.HttpResponseNotAllowed(self._allowed_methods())\n\n    def options(self, request, *args, **kwargs):\n        \"\"\"\n        Handles responding to requests for the OPTIONS HTTP verb.\n        \"\"\"\n        response = http.HttpResponse()\n        response['Allow'] = ', '.join(self._allowed_methods())\n        response['Content-Length'] = '0'\n        return response\n\n    def _allowed_methods(self):\n        return [m.upper() for m in self.http_method_names if hasattr(self, m)]\n\n\nclass TemplateResponseMixin(object):\n    \"\"\"\n    A mixin that can be used to render a template.\n    \"\"\"\n    template_name = None\n    response_class = TemplateResponse\n    content_type = None\n\n    def render_to_response(self, context, **response_kwargs):\n        \"\"\"\n        Returns a response, using the `response_class` for this\n        view, with a template rendered with the given context.\n\n        If any keyword arguments are provided, they will be\n        passed to the constructor of the response class.\n        \"\"\"\n        response_kwargs.setdefault('content_type', self.content_type)\n        return self.response_class(\n            request = self.request,\n            template = self.get_template_names(),\n            context = context,\n            **response_kwargs\n        )\n\n    def get_template_names(self):\n        \"\"\"\n        Returns a list of template names to be used for the request. Must return\n        a list. May not be called if render_to_response is overridden.\n        \"\"\"\n        if self.template_name is None:\n            raise ImproperlyConfigured(\n                \"TemplateResponseMixin requires either a definition of \"\n                \"'template_name' or an implementation of 'get_template_names()'\")\n        else:\n            return [self.template_name]\n\n\nclass TemplateView(TemplateResponseMixin, ContextMixin, View):\n    \"\"\"\n    A view that renders a template.  This view will also pass into the context\n    any keyword arguments passed by the url conf.\n    \"\"\"\n    def get(self, request, *args, **kwargs):\n        context = self.get_context_data(**kwargs)\n        return self.render_to_response(context)\n\n\nclass RedirectView(View):\n    \"\"\"\n    A view that provides a redirect on any GET request.\n    \"\"\"\n    permanent = True\n    url = None\n    pattern_name = None\n    query_string = False\n\n    def get_redirect_url(self, *args, **kwargs):\n        \"\"\"\n        Return the URL redirect to. Keyword arguments from the\n        URL pattern match generating the redirect request\n        are provided as kwargs to this method.\n        \"\"\"\n        if self.url:\n            url = self.url % kwargs\n        elif self.pattern_name:\n            try:\n                url = reverse(self.pattern_name, args=args, kwargs=kwargs)\n            except NoReverseMatch:\n                return None\n        else:\n            return None\n\n        args = self.request.META.get('QUERY_STRING', '')\n        if args and self.query_string:\n            url = \"%s?%s\" % (url, args)\n        return url\n\n    def get(self, request, *args, **kwargs):\n        url = self.get_redirect_url(*args, **kwargs)\n        if url:\n            if self.permanent:\n                return http.HttpResponsePermanentRedirect(url)\n            else:\n                return http.HttpResponseRedirect(url)\n        else:\n            logger.warning('Gone: %s', self.request.path,\n                        extra={\n                            'status_code': 410,\n                            'request': self.request\n                      })\n            return http.HttpResponseGone()\n\n    def head(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def post(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def options(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def delete(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def put(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def patch(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n" }
{ "repo_name": "mapr/hue", "ref": "refs/heads/hue-3.9.0-mapr", "path": "desktop/core/ext-py/Django-1.6.10/django/views/generic/base.py", "content": "from __future__ import unicode_literals\n\nimport logging\nfrom functools import update_wrapper\n\nfrom django import http\nfrom django.core.exceptions import ImproperlyConfigured\nfrom django.core.urlresolvers import reverse, NoReverseMatch\nfrom django.template.response import TemplateResponse\nfrom django.utils.decorators import classonlymethod\nfrom django.utils import six\n\nlogger = logging.getLogger('django.request')\n\n\nclass ContextMixin(object):\n    \"\"\"\n    A default context mixin that passes the keyword arguments received by\n    get_context_data as the template context.\n    \"\"\"\n\n    def get_context_data(self, **kwargs):\n        if 'view' not in kwargs:\n            kwargs['view'] = self\n        return kwargs\n\n\nclass View(object):\n    \"\"\"\n    Intentionally simple parent class for all views. Only implements\n    dispatch-by-method and simple sanity checking.\n    \"\"\"\n\n    http_method_names = ['get', 'post', 'put', 'patch', 'delete', 'head', 'options', 'trace']\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Constructor. Called in the URLconf; can contain helpful extra\n        keyword arguments, and other things.\n        \"\"\"\n        # Go through keyword arguments, and either save their values to our\n        # instance, or raise an error.\n        for key, value in six.iteritems(kwargs):\n            setattr(self, key, value)\n\n    @classonlymethod\n    def as_view(cls, **initkwargs):\n        \"\"\"\n        Main entry point for a request-response process.\n        \"\"\"\n        # sanitize keyword arguments\n        for key in initkwargs:\n            if key in cls.http_method_names:\n                raise TypeError(\"You tried to pass in the %s method name as a \"\n                                \"keyword argument to %s(). Don't do that.\"\n                                % (key, cls.__name__))\n            if not hasattr(cls, key):\n                raise TypeError(\"%s() received an invalid keyword %r. as_view \"\n                                \"only accepts arguments that are already \"\n                                \"attributes of the class.\" % (cls.__name__, key))\n\n        def view(request, *args, **kwargs):\n            self = cls(**initkwargs)\n            if hasattr(self, 'get') and not hasattr(self, 'head'):\n                self.head = self.get\n            self.request = request\n            self.args = args\n            self.kwargs = kwargs\n            return self.dispatch(request, *args, **kwargs)\n\n        # take name and docstring from class\n        update_wrapper(view, cls, updated=())\n\n        # and possible attributes set by decorators\n        # like csrf_exempt from dispatch\n        update_wrapper(view, cls.dispatch, assigned=())\n        return view\n\n    def dispatch(self, request, *args, **kwargs):\n        # Try to dispatch to the right method; if a method doesn't exist,\n        # defer to the error handler. Also defer to the error handler if the\n        # request method isn't on the approved list.\n        if request.method.lower() in self.http_method_names:\n            handler = getattr(self, request.method.lower(), self.http_method_not_allowed)\n        else:\n            handler = self.http_method_not_allowed\n        return handler(request, *args, **kwargs)\n\n    def http_method_not_allowed(self, request, *args, **kwargs):\n        logger.warning('Method Not Allowed (%s): %s', request.method, request.path,\n            extra={\n                'status_code': 405,\n                'request': self.request\n          }\n        )\n        return http.HttpResponseNotAllowed(self._allowed_methods())\n\n    def options(self, request, *args, **kwargs):\n        \"\"\"\n        Handles responding to requests for the OPTIONS HTTP verb.\n        \"\"\"\n        response = http.HttpResponse()\n        response['Allow'] = ', '.join(self._allowed_methods())\n        response['Content-Length'] = '0'\n        return response\n\n    def _allowed_methods(self):\n        return [m.upper() for m in self.http_method_names if hasattr(self, m)]\n\n\nclass TemplateResponseMixin(object):\n    \"\"\"\n    A mixin that can be used to render a template.\n    \"\"\"\n    template_name = None\n    response_class = TemplateResponse\n    content_type = None\n\n    def render_to_response(self, context, **response_kwargs):\n        \"\"\"\n        Returns a response, using the `response_class` for this\n        view, with a template rendered with the given context.\n\n        If any keyword arguments are provided, they will be\n        passed to the constructor of the response class.\n        \"\"\"\n        response_kwargs.setdefault('content_type', self.content_type)\n        return self.response_class(\n            request = self.request,\n            template = self.get_template_names(),\n            context = context,\n            **response_kwargs\n        )\n\n    def get_template_names(self):\n        \"\"\"\n        Returns a list of template names to be used for the request. Must return\n        a list. May not be called if render_to_response is overridden.\n        \"\"\"\n        if self.template_name is None:\n            raise ImproperlyConfigured(\n                \"TemplateResponseMixin requires either a definition of \"\n                \"'template_name' or an implementation of 'get_template_names()'\")\n        else:\n            return [self.template_name]\n\n\nclass TemplateView(TemplateResponseMixin, ContextMixin, View):\n    \"\"\"\n    A view that renders a template.  This view will also pass into the context\n    any keyword arguments passed by the url conf.\n    \"\"\"\n    def get(self, request, *args, **kwargs):\n        context = self.get_context_data(**kwargs)\n        return self.render_to_response(context)\n\n\nclass RedirectView(View):\n    \"\"\"\n    A view that provides a redirect on any GET request.\n    \"\"\"\n    permanent = True\n    url = None\n    pattern_name = None\n    query_string = False\n\n    def get_redirect_url(self, *args, **kwargs):\n        \"\"\"\n        Return the URL redirect to. Keyword arguments from the\n        URL pattern match generating the redirect request\n        are provided as kwargs to this method.\n        \"\"\"\n        if self.url:\n            url = self.url % kwargs\n        elif self.pattern_name:\n            try:\n                url = reverse(self.pattern_name, args=args, kwargs=kwargs)\n            except NoReverseMatch:\n                return None\n        else:\n            return None\n\n        args = self.request.META.get('QUERY_STRING', '')\n        if args and self.query_string:\n            url = \"%s?%s\" % (url, args)\n        return url\n\n    def get(self, request, *args, **kwargs):\n        url = self.get_redirect_url(*args, **kwargs)\n        if url:\n            if self.permanent:\n                return http.HttpResponsePermanentRedirect(url)\n            else:\n                return http.HttpResponseRedirect(url)\n        else:\n            logger.warning('Gone: %s', self.request.path,\n                        extra={\n                            'status_code': 410,\n                            'request': self.request\n                      })\n            return http.HttpResponseGone()\n\n    def head(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def post(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def options(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def delete(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def put(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def patch(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n" }
{ "repo_name": "felixjimenez/django", "ref": "refs/heads/nonrel-1.6", "path": "django/views/generic/base.py", "content": "from __future__ import unicode_literals\n\nimport logging\nfrom functools import update_wrapper\n\nfrom django import http\nfrom django.core.exceptions import ImproperlyConfigured\nfrom django.core.urlresolvers import reverse, NoReverseMatch\nfrom django.template.response import TemplateResponse\nfrom django.utils.decorators import classonlymethod\nfrom django.utils import six\n\nlogger = logging.getLogger('django.request')\n\n\nclass ContextMixin(object):\n    \"\"\"\n    A default context mixin that passes the keyword arguments received by\n    get_context_data as the template context.\n    \"\"\"\n\n    def get_context_data(self, **kwargs):\n        if 'view' not in kwargs:\n            kwargs['view'] = self\n        return kwargs\n\n\nclass View(object):\n    \"\"\"\n    Intentionally simple parent class for all views. Only implements\n    dispatch-by-method and simple sanity checking.\n    \"\"\"\n\n    http_method_names = ['get', 'post', 'put', 'patch', 'delete', 'head', 'options', 'trace']\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Constructor. Called in the URLconf; can contain helpful extra\n        keyword arguments, and other things.\n        \"\"\"\n        # Go through keyword arguments, and either save their values to our\n        # instance, or raise an error.\n        for key, value in six.iteritems(kwargs):\n            setattr(self, key, value)\n\n    @classonlymethod\n    def as_view(cls, **initkwargs):\n        \"\"\"\n        Main entry point for a request-response process.\n        \"\"\"\n        # sanitize keyword arguments\n        for key in initkwargs:\n            if key in cls.http_method_names:\n                raise TypeError(\"You tried to pass in the %s method name as a \"\n                                \"keyword argument to %s(). Don't do that.\"\n                                % (key, cls.__name__))\n            if not hasattr(cls, key):\n                raise TypeError(\"%s() received an invalid keyword %r. as_view \"\n                                \"only accepts arguments that are already \"\n                                \"attributes of the class.\" % (cls.__name__, key))\n\n        def view(request, *args, **kwargs):\n            self = cls(**initkwargs)\n            if hasattr(self, 'get') and not hasattr(self, 'head'):\n                self.head = self.get\n            self.request = request\n            self.args = args\n            self.kwargs = kwargs\n            return self.dispatch(request, *args, **kwargs)\n\n        # take name and docstring from class\n        update_wrapper(view, cls, updated=())\n\n        # and possible attributes set by decorators\n        # like csrf_exempt from dispatch\n        update_wrapper(view, cls.dispatch, assigned=())\n        return view\n\n    def dispatch(self, request, *args, **kwargs):\n        # Try to dispatch to the right method; if a method doesn't exist,\n        # defer to the error handler. Also defer to the error handler if the\n        # request method isn't on the approved list.\n        if request.method.lower() in self.http_method_names:\n            handler = getattr(self, request.method.lower(), self.http_method_not_allowed)\n        else:\n            handler = self.http_method_not_allowed\n        return handler(request, *args, **kwargs)\n\n    def http_method_not_allowed(self, request, *args, **kwargs):\n        logger.warning('Method Not Allowed (%s): %s', request.method, request.path,\n            extra={\n                'status_code': 405,\n                'request': self.request\n          }\n        )\n        return http.HttpResponseNotAllowed(self._allowed_methods())\n\n    def options(self, request, *args, **kwargs):\n        \"\"\"\n        Handles responding to requests for the OPTIONS HTTP verb.\n        \"\"\"\n        response = http.HttpResponse()\n        response['Allow'] = ', '.join(self._allowed_methods())\n        response['Content-Length'] = '0'\n        return response\n\n    def _allowed_methods(self):\n        return [m.upper() for m in self.http_method_names if hasattr(self, m)]\n\n\nclass TemplateResponseMixin(object):\n    \"\"\"\n    A mixin that can be used to render a template.\n    \"\"\"\n    template_name = None\n    response_class = TemplateResponse\n    content_type = None\n\n    def render_to_response(self, context, **response_kwargs):\n        \"\"\"\n        Returns a response, using the `response_class` for this\n        view, with a template rendered with the given context.\n\n        If any keyword arguments are provided, they will be\n        passed to the constructor of the response class.\n        \"\"\"\n        response_kwargs.setdefault('content_type', self.content_type)\n        return self.response_class(\n            request = self.request,\n            template = self.get_template_names(),\n            context = context,\n            **response_kwargs\n        )\n\n    def get_template_names(self):\n        \"\"\"\n        Returns a list of template names to be used for the request. Must return\n        a list. May not be called if render_to_response is overridden.\n        \"\"\"\n        if self.template_name is None:\n            raise ImproperlyConfigured(\n                \"TemplateResponseMixin requires either a definition of \"\n                \"'template_name' or an implementation of 'get_template_names()'\")\n        else:\n            return [self.template_name]\n\n\nclass TemplateView(TemplateResponseMixin, ContextMixin, View):\n    \"\"\"\n    A view that renders a template.  This view will also pass into the context\n    any keyword arguments passed by the url conf.\n    \"\"\"\n    def get(self, request, *args, **kwargs):\n        context = self.get_context_data(**kwargs)\n        return self.render_to_response(context)\n\n\nclass RedirectView(View):\n    \"\"\"\n    A view that provides a redirect on any GET request.\n    \"\"\"\n    permanent = True\n    url = None\n    pattern_name = None\n    query_string = False\n\n    def get_redirect_url(self, *args, **kwargs):\n        \"\"\"\n        Return the URL redirect to. Keyword arguments from the\n        URL pattern match generating the redirect request\n        are provided as kwargs to this method.\n        \"\"\"\n        if self.url:\n            url = self.url % kwargs\n        elif self.pattern_name:\n            try:\n                url = reverse(self.pattern_name, args=args, kwargs=kwargs)\n            except NoReverseMatch:\n                return None\n        else:\n            return None\n\n        args = self.request.META.get('QUERY_STRING', '')\n        if args and self.query_string:\n            url = \"%s?%s\" % (url, args)\n        return url\n\n    def get(self, request, *args, **kwargs):\n        url = self.get_redirect_url(*args, **kwargs)\n        if url:\n            if self.permanent:\n                return http.HttpResponsePermanentRedirect(url)\n            else:\n                return http.HttpResponseRedirect(url)\n        else:\n            logger.warning('Gone: %s', self.request.path,\n                        extra={\n                            'status_code': 410,\n                            'request': self.request\n                      })\n            return http.HttpResponseGone()\n\n    def head(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def post(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def options(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def delete(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def put(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def patch(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n" }
{ "repo_name": "arviz-devs/arviz", "ref": "refs/heads/gh-pages", "path": "_downloads/f3778c5bef269387485b4113d05d6cd6/bokeh_plot_ppc.py", "content": "\"\"\"\nPosterior Predictive Check Plot\n===============================\n\n_thumb: .6, .5\n\"\"\"\nimport arviz as az\n\ndata = az.load_arviz_data(\"non_centered_eight\")\nax = az.plot_ppc(data, alpha=0.03, figsize=(12, 6), backend=\"bokeh\")\n" }
{ "repo_name": "cisco-openstack/neutron", "ref": "refs/heads/staging/libertyplus", "path": "neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/openflow/ovs_ofctl/test_br_phys.py", "content": "# Copyright (C) 2014,2015 VA Linux Systems Japan K.K.\n# Copyright (C) 2014,2015 YAMAMOTO Takashi <yamamoto at valinux co jp>\n# All Rights Reserved.\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\nimport mock\n\nimport neutron.plugins.ml2.drivers.openvswitch.agent.common.constants \\\n    as ovs_const\nfrom neutron.tests.unit.plugins.ml2.drivers.openvswitch.agent.\\\n    openflow.ovs_ofctl import ovs_bridge_test_base\n\n\ncall = mock.call  # short hand\n\n\nclass OVSPhysicalBridgeTest(ovs_bridge_test_base.OVSBridgeTestBase,\n                            ovs_bridge_test_base.OVSDVRProcessTestMixin):\n    dvr_process_table_id = ovs_const.DVR_PROCESS_VLAN\n    dvr_process_next_table_id = ovs_const.LOCAL_VLAN_TRANSLATION\n\n    def setUp(self):\n        super(OVSPhysicalBridgeTest, self).setUp()\n        self.setup_bridge_mock('br-phys', self.br_phys_cls)\n\n    def test_setup_default_table(self):\n        self.br.setup_default_table()\n        expected = [\n            call.delete_flows(),\n            call.add_flow(priority=0, table=0, actions='normal'),\n        ]\n        self.assertEqual(expected, self.mock.mock_calls)\n\n    def test_provision_local_vlan(self):\n        port = 999\n        lvid = 888\n        segmentation_id = 777\n        distributed = False\n        self.br.provision_local_vlan(port=port, lvid=lvid,\n                                     segmentation_id=segmentation_id,\n                                     distributed=distributed)\n        expected = [\n            call.add_flow(priority=4, table=0, dl_vlan=lvid, in_port=port,\n                          actions='mod_vlan_vid:%s,normal' % segmentation_id),\n        ]\n        self.assertEqual(expected, self.mock.mock_calls)\n\n    def test_provision_local_vlan_novlan(self):\n        port = 999\n        lvid = 888\n        segmentation_id = None\n        distributed = False\n        self.br.provision_local_vlan(port=port, lvid=lvid,\n                                     segmentation_id=segmentation_id,\n                                     distributed=distributed)\n        expected = [\n            call.add_flow(priority=4, table=0, dl_vlan=lvid, in_port=port,\n                          actions='strip_vlan,normal')\n        ]\n        self.assertEqual(expected, self.mock.mock_calls)\n\n    def test_reclaim_local_vlan(self):\n        port = 999\n        lvid = 888\n        self.br.reclaim_local_vlan(port=port, lvid=lvid)\n        expected = [\n            call.delete_flows(dl_vlan=lvid, in_port=port),\n        ]\n        self.assertEqual(expected, self.mock.mock_calls)\n\n    def test_add_dvr_mac_vlan(self):\n        mac = '00:02:b3:13:fe:3d'\n        port = 8888\n        self.br.add_dvr_mac_vlan(mac=mac, port=port)\n        expected = [\n            call.add_flow(priority=2, table=3, dl_src=mac,\n                          actions='output:%s' % port),\n        ]\n        self.assertEqual(expected, self.mock.mock_calls)\n\n    def test_remove_dvr_mac_vlan(self):\n        mac = '00:02:b3:13:fe:3d'\n        self.br.remove_dvr_mac_vlan(mac=mac)\n        expected = [\n            call.delete_flows(eth_src=mac, table_id=3),\n        ]\n        self.assertEqual(expected, self.mock.mock_calls)\n" }
{ "repo_name": "dahfool/navigator", "ref": "refs/heads/release", "path": "markets/tests/__init__.py", "content": "import os\nfrom markets.models import Market, Logo\nfrom geography.models import Country\nfrom products.models import Category\n\n\nCURRENT_DIRECTORY = os.path.dirname(os.path.abspath(__file__))\n\n\ndef create_market(**variable_data):\n\n    market_data = get_market_data(**variable_data)\n\n    if 'operating_countries' not in variable_data:\n        country = create_country('UK')\n        operating_countries = [country]\n    else:\n        operating_countries = market_data.pop('operating_countries')\n\n    if 'product_categories' not in variable_data:\n        category = create_category('Toys')\n        product_categories = [category]\n    else:\n        product_categories = market_data.pop('product_categories')\n\n    if 'name' not in variable_data:\n        variable_data['name'] = \"Amazon\"\n\n    if 'logo' not in variable_data:\n        logo = create_logo()\n    else:\n        logo = market_data.pop('logo')\n\n    market = Market(**market_data)\n    market.save()\n    market.operating_countries = operating_countries\n    market.product_categories = product_categories\n    market.logo = logo\n    market.save()\n    return market\n\n\ndef get_market_data(**variable_data):\n    \"\"\"\n    All basic fields that must be filled in to for a Market to be clean\n    \"\"\"\n\n    if 'name' not in variable_data:\n        variable_data['name'] = \"Amazon\"\n\n    if 'e_marketplace_description' not in variable_data:\n        variable_data['e_marketplace_description'] = \"Lorem Ipsum\"\n\n    if 'web_address' not in variable_data:\n        variable_data['web_address'] = \"example.com\"\n\n    if 'one_off_registration_fee' not in variable_data:\n        variable_data['one_off_registration_fee'] = 0\n\n    if 'membership_fees' not in variable_data:\n        variable_data['membership_fees'] = 0\n\n    if 'fee_per_listing' not in variable_data:\n        variable_data['fee_per_listing'] = True\n\n    if 'deposit' not in variable_data:\n        variable_data['deposit'] = 0\n\n    return variable_data\n\n\ndef create_logo(**variable_data):\n    if 'name' not in variable_data:\n        variable_data['name'] = 'logo'\n    if '_encoded_data' not in variable_data:\n        variable_data['_encoded_data'] = (\n            'data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HA'\n            'wCAAAAC0lEQVR4nGP6LwkAAiABG+faPgsAAAAASUVORK5CYII=')\n    logo = Logo(**variable_data)\n    logo.save()\n    return logo\n\n\ndef create_country(name):\n    country, created = Country.objects.get_or_create(name=name)\n    return country\n\n\ndef create_category(name):\n    category, created = Category.objects.get_or_create(name=name)\n    return category\n\n\ndef load_sample_png():\n    f = open(\"{}/png/sample.png\".format(CURRENT_DIRECTORY), \"rb\")\n    return f\n" }
{ "repo_name": "skosukhin/spack", "ref": "refs/heads/esiwace", "path": "var/spack/repos/builtin/packages/py-ont-fast5-api/package.py", "content": "##############################################################################\n# Copyright (c) 2013-2017, Lawrence Livermore National Security, LLC.\n# Produced at the Lawrence Livermore National Laboratory.\n#\n# This file is part of Spack.\n# Created by Todd Gamblin, tgamblin@llnl.gov, All rights reserved.\n# LLNL-CODE-647188\n#\n# For details, see https://github.com/spack/spack\n# Please also see the NOTICE and LICENSE files for our notice and the LGPL.\n#\n# This program is free software; you can redistribute it and/or modify\n# it under the terms of the GNU Lesser General Public License (as\n# published by the Free Software Foundation) version 2.1, February 1999.\n#\n# This program is distributed in the hope that it will be useful, but\n# WITHOUT ANY WARRANTY; without even the IMPLIED WARRANTY OF\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the terms and\n# conditions of the GNU Lesser General Public License for more details.\n#\n# You should have received a copy of the GNU Lesser General Public\n# License along with this program; if not, write to the Free Software\n# Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA\n##############################################################################\nfrom spack import *\n\n\nclass PyOntFast5Api(PythonPackage):\n    \"\"\"This project provides classes and utility functions for working with\n    read fast5 files. It provides an abstraction layer between the underlying\n    h5py library and the various concepts central to read fast5 files, such as\n    \"reads\", \"analyses\", \"analysis summaries\", and \"analysis datasets\".\n    Ideally all interaction with a read fast5 file should be possible via this\n    API, without having to directly invoke the h5py library.\"\"\"\n\n    homepage = \"https://github.com/nanoporetech/ont_fast5_api\"\n    url      = \"https://pypi.io/packages/source/o/ont-fast5-api/ont-fast5-api-0.3.2.tar.gz\"\n\n    version('0.3.2', '2ccfdbcd55239ffae712bb6e70ebfe8c')\n\n    depends_on('py-setuptools', type='build')\n    depends_on('py-h5py', type=('build', 'run'))\n    depends_on('py-numpy@1.8.1:', type=('build', 'run'))\n" }
{ "repo_name": "jumpojoy/neutron", "ref": "refs/heads/generic_switch", "path": "neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/openflow/ovs_ofctl/test_br_phys.py", "content": "# Copyright (C) 2014,2015 VA Linux Systems Japan K.K.\n# Copyright (C) 2014,2015 YAMAMOTO Takashi <yamamoto at valinux co jp>\n# All Rights Reserved.\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\nimport mock\n\nimport neutron.plugins.ml2.drivers.openvswitch.agent.common.constants \\\n    as ovs_const\nfrom neutron.tests.unit.plugins.ml2.drivers.openvswitch.agent.\\\n    openflow.ovs_ofctl import ovs_bridge_test_base\n\n\ncall = mock.call  # short hand\n\n\nclass OVSPhysicalBridgeTest(ovs_bridge_test_base.OVSBridgeTestBase,\n                            ovs_bridge_test_base.OVSDVRProcessTestMixin):\n    dvr_process_table_id = ovs_const.DVR_PROCESS_VLAN\n    dvr_process_next_table_id = ovs_const.LOCAL_VLAN_TRANSLATION\n\n    def setUp(self):\n        super(OVSPhysicalBridgeTest, self).setUp()\n        self.setup_bridge_mock('br-phys', self.br_phys_cls)\n\n    def test_setup_default_table(self):\n        self.br.setup_default_table()\n        expected = [\n            call.delete_flows(),\n            call.add_flow(priority=0, table=0, actions='normal'),\n        ]\n        self.assertEqual(expected, self.mock.mock_calls)\n\n    def test_provision_local_vlan(self):\n        port = 999\n        lvid = 888\n        segmentation_id = 777\n        distributed = False\n        self.br.provision_local_vlan(port=port, lvid=lvid,\n                                     segmentation_id=segmentation_id,\n                                     distributed=distributed)\n        expected = [\n            call.add_flow(priority=4, table=0, dl_vlan=lvid, in_port=port,\n                          actions='mod_vlan_vid:%s,normal' % segmentation_id),\n        ]\n        self.assertEqual(expected, self.mock.mock_calls)\n\n    def test_provision_local_vlan_novlan(self):\n        port = 999\n        lvid = 888\n        segmentation_id = None\n        distributed = False\n        self.br.provision_local_vlan(port=port, lvid=lvid,\n                                     segmentation_id=segmentation_id,\n                                     distributed=distributed)\n        expected = [\n            call.add_flow(priority=4, table=0, dl_vlan=lvid, in_port=port,\n                          actions='strip_vlan,normal')\n        ]\n        self.assertEqual(expected, self.mock.mock_calls)\n\n    def test_reclaim_local_vlan(self):\n        port = 999\n        lvid = 888\n        self.br.reclaim_local_vlan(port=port, lvid=lvid)\n        expected = [\n            call.delete_flows(dl_vlan=lvid, in_port=port),\n        ]\n        self.assertEqual(expected, self.mock.mock_calls)\n\n    def test_add_dvr_mac_vlan(self):\n        mac = '00:02:b3:13:fe:3d'\n        port = 8888\n        self.br.add_dvr_mac_vlan(mac=mac, port=port)\n        expected = [\n            call.add_flow(priority=2, table=3, dl_src=mac,\n                          actions='output:%s' % port),\n        ]\n        self.assertEqual(expected, self.mock.mock_calls)\n\n    def test_remove_dvr_mac_vlan(self):\n        mac = '00:02:b3:13:fe:3d'\n        self.br.remove_dvr_mac_vlan(mac=mac)\n        expected = [\n            call.delete_flows(eth_src=mac, table_id=3),\n        ]\n        self.assertEqual(expected, self.mock.mock_calls)\n" }
{ "repo_name": "kaplun/ops", "ref": "refs/heads/prod", "path": "modules/bibformat/lib/elements/bfe_authors.py", "content": "# -*- coding: utf-8 -*-\n##\n## This file is part of Invenio.\n## Copyright (C) 2006, 2007, 2008, 2009, 2010, 2011, 2013 CERN.\n##\n## Invenio is free software; you can redistribute it and/or\n## modify it under the terms of the GNU General Public License as\n## published by the Free Software Foundation; either version 2 of the\n## License, or (at your option) any later version.\n##\n## Invenio is distributed in the hope that it will be useful, but\n## WITHOUT ANY WARRANTY; without even the implied warranty of\n## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n## General Public License for more details.\n##\n## You should have received a copy of the GNU General Public License\n## along with Invenio; if not, write to the Free Software Foundation, Inc.,\n## 59 Temple Place, Suite 330, Boston, MA 02111-1307, USA.\n\"\"\"BibFormat element - Prints authors\n\"\"\"\n__revision__ = \"$Id$\"\n\nimport re\nfrom urllib import quote\nfrom cgi import escape\nfrom invenio.config import CFG_BASE_URL, CFG_SITE_RECORD\nfrom invenio.messages import gettext_set_language\nfrom invenio.bibauthority_config import \\\n    CFG_BIBAUTHORITY_AUTHORITY_COLLECTION_NAME, \\\n    CFG_BIBAUTHORITY_TYPE_NAMES, \\\n    CFG_BIBAUTHORITY_PREFIX_SEP\nfrom invenio.bibauthority_engine import \\\n    get_low_level_recIDs_from_control_no\n\ndef format_element(bfo, limit, separator=' ; ',\n           extension='[...]',\n           print_links=\"yes\",\n           print_affiliations='no',\n           affiliation_prefix=' (',\n           affiliation_suffix=')',\n           interactive=\"no\",\n           highlight=\"no\",\n           link_author_pages=\"no\",\n           link_mobile_pages=\"no\",\n           relator_code_pattern=None):\n    \"\"\"\n    Prints the list of authors of a record.\n\n    @param limit: the maximum number of authors to display\n    @param separator: the separator between authors.\n    @param extension: a text printed if more authors than 'limit' exist\n    @param print_links: if yes, prints the authors as HTML link to their publications\n    @param print_affiliations: if yes, make each author name followed by its affiliation\n    @param affiliation_prefix: prefix printed before each affiliation\n    @param affiliation_suffix: suffix printed after each affiliation\n    @param interactive: if yes, enable user to show/hide authors when there are too many (html + javascript)\n    @param highlight: highlights authors corresponding to search query if set to 'yes'\n    @param link_author_pages: should we link to author pages if print_links in on?\n    @param link_mobile_pages: should we link to mobile app pages if print_links in on?\n    @param relator_code_pattern: a regular expression to filter authors based on subfield $4 (relator code)\n    \"\"\"\n    _ = gettext_set_language(bfo.lang)    # load the right message language\n\n    authors = []\n    authors_1 = bfo.fields('100__', repeatable_subfields_p=True)\n    authors_2 = bfo.fields('700__', repeatable_subfields_p=True)\n\n    authors.extend(authors_1)\n    authors.extend(authors_2)\n\n    # make unique string per key\n    for author in authors:\n        if 'a' in author:\n            author['a'] = author['a'][0]\n        if 'u' in author:\n            author['u'] = author['u'][0]\n        pattern = '%s' + CFG_BIBAUTHORITY_PREFIX_SEP + \"(\"\n        for control_no in author.get('0', []):\n            if pattern % (CFG_BIBAUTHORITY_TYPE_NAMES[\"INSTITUTION\"]) in control_no:\n                author['u0'] = control_no # overwrite if multiples\n            elif pattern % (CFG_BIBAUTHORITY_TYPE_NAMES[\"AUTHOR\"]) in control_no:\n                author['a0'] = control_no # overwrite if multiples\n\n\n    if relator_code_pattern:\n        p = re.compile(relator_code_pattern)\n        authors = filter(lambda x: p.match(x.get('4', '')), authors)\n\n    nb_authors = len(authors)\n\n    bibrec_id = bfo.control_field(\"001\")\n\n    # Process authors to add link, highlight and format affiliation\n    for author in authors:\n\n        if author.has_key('a'):\n            if highlight == 'yes':\n                from invenio import bibformat_utils\n                author['a'] = bibformat_utils.highlight(author['a'],\n                                                        bfo.search_pattern)\n\n            if print_links.lower() == \"yes\":\n                if link_author_pages == \"yes\":\n                    author['a'] = '<a rel=\"author\" href=\"' + CFG_BASE_URL + \\\n                                  '/author/profile/' + quote(author['a']) + \\\n                                  '?recid=' +  bibrec_id + \\\n                                  '&ln=' + bfo.lang + \\\n                                  '\">' + escape(author['a']) + '</a>'\n                elif link_mobile_pages == 'yes':\n                    author['a'] = '<a rel=\"external\" href=\"#page=search' + \\\n                                  '&amp;f=author&amp;p=' + quote(author['a']) + \\\n                                  '\">' + escape(author['a']) + '</a>'\n                else:\n                    auth_coll_param = ''\n                    if 'a0' in author:\n                        recIDs = get_low_level_recIDs_from_control_no(author['a0'])\n                        if len(recIDs):\n                            auth_coll_param = '&amp;c=' + \\\n                                              CFG_BIBAUTHORITY_AUTHORITY_COLLECTION_NAME\n                    author['a'] = '<a href=\"' + CFG_BASE_URL + \\\n                                  '/search?f=author&amp;p=' + quote(author['a']) + \\\n                                   auth_coll_param + \\\n                                  '&amp;ln=' + bfo.lang + \\\n                                  '\">' + escape(author['a']) + '</a>'\n\n        if author.has_key('u'):\n            if print_affiliations == \"yes\":\n                if 'u0' in author:\n                    recIDs = get_low_level_recIDs_from_control_no(author['u0'])\n                    # if there is more than 1 recID, clicking on link and\n                    # thus displaying the authority record's page should\n                    # contain a warning that there are multiple authority\n                    # records with the same control number\n                    if len(recIDs):\n                        author['u'] = '<a href=\"' + CFG_BASE_URL + '/' + CFG_SITE_RECORD + '/' + \\\n                                      str(recIDs[0]) + \\\n                                      '?ln=' + bfo.lang + \\\n                                      '\">' + author['u'] + '</a>'\n                author['u'] = affiliation_prefix + author['u'] + \\\n                              affiliation_suffix\n\n    # Flatten author instances\n    if print_affiliations == 'yes':\n        authors = [author.get('a', '') + author.get('u', '')\n                   for author in authors]\n    else:\n        authors = [author.get('a', '')\n                   for author in authors]\n\n    if limit.isdigit() and  nb_authors > int(limit) and interactive != \"yes\":\n        return separator.join(authors[:int(limit)]) + extension\n\n    elif limit.isdigit() and nb_authors > int(limit) and interactive == \"yes\":\n        out = '<a name=\"show_hide\" />'\n        out += separator.join(authors[:int(limit)])\n        out += '<span id=\"more_%s\" style=\"\">' % bibrec_id + separator + \\\n               separator.join(authors[int(limit):]) + '</span>'\n        out += ' <span id=\"extension_%s\"></span>' % bibrec_id\n        out += ' <small><i><a id=\"link_%s\" href=\"#\" style=\"color:rgb(204,0,0);\"></a></i></small>' % bibrec_id\n        out += '''\n        <script type=\"text/javascript\">\n        $('#link_%(recid)s').click(function(event) {\n            event.preventDefault();\n            var more = document.getElementById('more_%(recid)s');\n            var link = document.getElementById('link_%(recid)s');\n            var extension = document.getElementById('extension_%(recid)s');\n            if (more.style.display=='none'){\n                more.style.display = '';\n                extension.style.display = 'none';\n                link.innerHTML = \"%(show_less)s\"\n          } else {\n                more.style.display = 'none';\n                extension.style.display = '';\n                link.innerHTML = \"%(show_more)s\"\n          }\n            link.style.color = \"rgb(204,0,0);\"\n      });\n\n        function set_up_%(recid)s(){\n            var extension = document.getElementById('extension_%(recid)s');\n            extension.innerHTML = \"%(extension)s\";\n            $('#link_%(recid)s').click();\n      }\n\n        </script>\n        ''' % {'show_less':_(\"Hide\"),\n             'show_more':_(\"Show all %i authors\") % nb_authors,\n             'extension':extension,\n             'recid': bibrec_id}\n        out += '<script type=\"text/javascript\">set_up_%s()</script>' % bibrec_id\n\n        return out\n    elif nb_authors > 0:\n        return separator.join(authors)\n\ndef escape_values(bfo):\n    \"\"\"\n    Called by BibFormat in order to check if output of this element\n    should be escaped.\n    \"\"\"\n    return 0\n" }
{ "repo_name": "oasiswork/RatticWeb", "ref": "refs/heads/prod", "path": "cred/api.py", "content": "from django.core.exceptions import ObjectDoesNotExist, MultipleObjectsReturned\nfrom django.core.files.base import File\nfrom django.http import HttpResponse\n\nfrom tastypie import fields, http\nfrom tastypie.authentication import SessionAuthentication, MultiAuthentication\nfrom tastypie.validation import FormValidation\nfrom tastypie.resources import ModelResource, ALL_WITH_RELATIONS\nfrom tastypie.authorization import Authorization\nfrom tastypie.exceptions import Unauthorized\n\nfrom account.authentication import MultiApiKeyAuthentication\nfrom cred.models import Cred, Tag, CredAudit\nfrom cred.forms import TagForm\nfrom cred.ssh_key import SSHKey\nfrom staff.api import GroupResource\n\nimport paramiko\n\n\nclass CredAuthorization(Authorization):\n    def read_list(self, object_list, bundle):\n        # List views remove the deletes and historical credentials\n        return object_list.filter(is_deleted=False, latest=None)\n\n    def read_detail(self, object_list, bundle):\n        # Check user has perms\n        if not bundle.obj.is_visible_by(bundle.request.user):\n            return False\n\n        # This audit should go somewhere else,\n        # is there a detail list function we can override?\n        CredAudit(\n            audittype=CredAudit.CREDPASSVIEW, cred=bundle.obj,\n            user=bundle.request.user).save()\n        return True\n\n    def create_list(self, object_list, bundle):\n        # Assuming their auto-assigned to ``user``.\n        raise Unauthorized(\"Not yet implemented.\")\n\n    def create_detail(self, object_list, bundle):\n        return bundle.request.user.groups.filter(\n            name=bundle.obj.group).exists()\n\n    def update_list(self, object_list, bundle):\n        raise Unauthorized(\"Not yet implemented.\")\n\n    def update_detail(self, object_list, bundle):\n        # Check user has perms\n        if not bundle.obj.is_owned_by(bundle.request.user):\n            return False\n\n        CredAudit(\n            audittype=CredAudit.CREDCHANGE, cred=bundle.obj,\n            user=bundle.request.user).save()\n        return True\n\n    def delete_list(self, object_list, bundle):\n        # Sorry user, no deletes for you!\n        raise Unauthorized(\"Not yet implemented.\")\n\n    def delete_detail(self, object_list, bundle):\n        # Check user has perms\n        if not bundle.obj.is_owned_by(bundle.request.user):\n            return False\n\n        CredAudit(\n            audittype=CredAudit.CREDDELETE, cred=bundle.obj,\n            user=bundle.request.user).save()\n        return True\n\n\nclass TagAuthorization(Authorization):\n    def read_list(self, object_list, bundle):\n        return object_list\n\n    def read_detail(self, object_list, bundle):\n        return True\n\n    def create_list(self, object_list, bundle):\n        # Assuming their auto-assigned to ``user``.\n        raise Unauthorized(\"Not yet implemented.\")\n\n    def create_detail(self, object_list, bundle):\n        return True\n\n    def update_list(self, object_list, bundle):\n        raise Unauthorized(\"Not yet implemented.\")\n\n    def update_detail(self, object_list, bundle):\n        raise Unauthorized(\"Not yet implemented.\")\n\n    def delete_list(self, object_list, bundle):\n        # Sorry user, no deletes for you!\n        raise Unauthorized(\"Not yet implemented.\")\n\n    def delete_detail(self, object_list, bundle):\n        raise Unauthorized(\"Not yet implemented.\")\n\n\nclass CredResource(ModelResource):\n\n    group = fields.ForeignKey(GroupResource, 'group', full=True)\n\n    def get_object_list(self, request):\n        # Only show latest, not deleted and accessible credentials\n        return Cred.objects.visible(\n            request.user, historical=True, deleted=True)\n\n    def dehydrate(self, bundle):\n        # Add a value indicating if something is on the change queue\n        bundle.data['on_changeq'] = bundle.obj.on_changeq()\n\n        # Only display group name, not full object\n        bundle.data['group'] = bundle.obj.group\n\n        # Unless you are viewing the details for a cred, hide the password\n        if self.get_resource_uri(bundle) != bundle.request.path:\n            del bundle.data['password']\n\n        # Expand the ssh key\n        if bundle.obj.ssh_key:\n            bundle.data['ssh_key'] = bundle.obj.ssh_key.read()\n        else:\n            del bundle.data['ssh_key']\n\n        return bundle\n\n    def obj_create(self, bundle, **kwargs):\n        bundle = super(CredResource, self).obj_create(bundle, **kwargs)\n\n        CredAudit(\n            audittype=CredAudit.CREDADD, cred=bundle.obj,\n            user=bundle.request.user).save()\n        return bundle\n\n    def post_detail(self, request, **kwargs):\n        if 'ssh_key' not in request.FILES:\n            res = HttpResponse(\"Please upload an ssh_key file\")\n            res.status_code = 500\n            return res\n\n        basic_bundle = self.build_bundle(request=request)\n\n        try:\n            obj = self.cached_obj_get(\n                bundle=basic_bundle, **self.remove_api_resource_names(kwargs))\n        except ObjectDoesNotExist:\n            return http.HttpNotFound()\n        except MultipleObjectsReturned:\n            return http.HttpMultipleChoices(\n                \"More than one resource is found at this URI.\")\n\n        ssh_key = request.FILES['ssh_key']\n        got = ssh_key.read()\n        ssh_key.seek(0)\n        try:\n            SSHKey(got, obj.password).key_obj\n        except paramiko.ssh_exception.SSHException as error:\n            res = HttpResponse(error)\n            res.status_code = 500\n            return res\n\n        obj.ssh_key = File(ssh_key)\n        obj.save()\n\n        if not self._meta.always_return_data:\n            return http.HttpAccepted()\n        else:\n            bundle = self.build_bundle(obj=obj, request=request)\n            bundle = self.full_dehydrate(bundle)\n            bundle = self.alter_detail_data_to_serialize(request, bundle)\n            return self.create_response(\n                request, bundle, response_class=http.HttpAccepted)\n\n    class Meta:\n        queryset = Cred.objects.filter(is_deleted=False, latest=None)\n        always_return_data = True\n        resource_name = 'cred'\n        excludes = ['is_deleted', 'attachment']\n        authentication = MultiAuthentication(\n            SessionAuthentication(), MultiApiKeyAuthentication())\n        authorization = CredAuthorization()\n        filtering = {\n            'title': ('exact', 'contains', 'icontains'),\n            'slug': ('exact', 'contains', 'icontains', 'startswith'),\n            'url': ('exact', 'startswith', ),\n            'group': ALL_WITH_RELATIONS,\n      }\n\n\nclass TagResource(ModelResource):\n    # When showing a tag, show all the creds under it,\n    # that we are allowed to see\n    creds = fields.ToManyField(\n        CredResource,\n        attribute=lambda bundle: Cred.objects.visible(\n            bundle.request.user).filter(tags=bundle.obj),\n        null=True,\n    )\n\n    class Meta:\n        queryset = Tag.objects.all()\n        always_return_data = True\n        filtering = {\n            'name': (\n                'exact', 'contains', 'icontains',\n                'startswith', 'istartswith'),\n      }\n        resource_name = 'tag'\n        authentication = MultiAuthentication(\n            SessionAuthentication(), MultiApiKeyAuthentication())\n        authorization = TagAuthorization()\n        validation = FormValidation(form_class=TagForm)\n" }
{ "repo_name": "GRArmstrong/invenio-inspire-ops", "ref": "refs/heads/prod", "path": "modules/bibformat/lib/elements/bfe_authors.py", "content": "# -*- coding: utf-8 -*-\n##\n## This file is part of Invenio.\n## Copyright (C) 2006, 2007, 2008, 2009, 2010, 2011, 2013 CERN.\n##\n## Invenio is free software; you can redistribute it and/or\n## modify it under the terms of the GNU General Public License as\n## published by the Free Software Foundation; either version 2 of the\n## License, or (at your option) any later version.\n##\n## Invenio is distributed in the hope that it will be useful, but\n## WITHOUT ANY WARRANTY; without even the implied warranty of\n## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n## General Public License for more details.\n##\n## You should have received a copy of the GNU General Public License\n## along with Invenio; if not, write to the Free Software Foundation, Inc.,\n## 59 Temple Place, Suite 330, Boston, MA 02111-1307, USA.\n\"\"\"BibFormat element - Prints authors\n\"\"\"\n__revision__ = \"$Id$\"\n\nimport re\nfrom urllib import quote\nfrom cgi import escape\nfrom invenio.config import CFG_BASE_URL, CFG_SITE_RECORD\nfrom invenio.messages import gettext_set_language\nfrom invenio.bibauthority_config import \\\n    CFG_BIBAUTHORITY_AUTHORITY_COLLECTION_NAME, \\\n    CFG_BIBAUTHORITY_TYPE_NAMES, \\\n    CFG_BIBAUTHORITY_PREFIX_SEP\nfrom invenio.bibauthority_engine import \\\n    get_low_level_recIDs_from_control_no\n\ndef format_element(bfo, limit, separator=' ; ',\n           extension='[...]',\n           print_links=\"yes\",\n           print_affiliations='no',\n           affiliation_prefix=' (',\n           affiliation_suffix=')',\n           interactive=\"no\",\n           highlight=\"no\",\n           link_author_pages=\"no\",\n           link_mobile_pages=\"no\",\n           relator_code_pattern=None):\n    \"\"\"\n    Prints the list of authors of a record.\n\n    @param limit: the maximum number of authors to display\n    @param separator: the separator between authors.\n    @param extension: a text printed if more authors than 'limit' exist\n    @param print_links: if yes, prints the authors as HTML link to their publications\n    @param print_affiliations: if yes, make each author name followed by its affiliation\n    @param affiliation_prefix: prefix printed before each affiliation\n    @param affiliation_suffix: suffix printed after each affiliation\n    @param interactive: if yes, enable user to show/hide authors when there are too many (html + javascript)\n    @param highlight: highlights authors corresponding to search query if set to 'yes'\n    @param link_author_pages: should we link to author pages if print_links in on?\n    @param link_mobile_pages: should we link to mobile app pages if print_links in on?\n    @param relator_code_pattern: a regular expression to filter authors based on subfield $4 (relator code)\n    \"\"\"\n    _ = gettext_set_language(bfo.lang)    # load the right message language\n\n    authors = []\n    authors_1 = bfo.fields('100__', repeatable_subfields_p=True)\n    authors_2 = bfo.fields('700__', repeatable_subfields_p=True)\n\n    authors.extend(authors_1)\n    authors.extend(authors_2)\n\n    # make unique string per key\n    for author in authors:\n        if 'a' in author:\n            author['a'] = author['a'][0]\n        if 'u' in author:\n            author['u'] = author['u'][0]\n        pattern = '%s' + CFG_BIBAUTHORITY_PREFIX_SEP + \"(\"\n        for control_no in author.get('0', []):\n            if pattern % (CFG_BIBAUTHORITY_TYPE_NAMES[\"INSTITUTION\"]) in control_no:\n                author['u0'] = control_no # overwrite if multiples\n            elif pattern % (CFG_BIBAUTHORITY_TYPE_NAMES[\"AUTHOR\"]) in control_no:\n                author['a0'] = control_no # overwrite if multiples\n\n\n    if relator_code_pattern:\n        p = re.compile(relator_code_pattern)\n        authors = filter(lambda x: p.match(x.get('4', '')), authors)\n\n    nb_authors = len(authors)\n\n    bibrec_id = bfo.control_field(\"001\")\n\n    # Process authors to add link, highlight and format affiliation\n    for author in authors:\n\n        if author.has_key('a'):\n            if highlight == 'yes':\n                from invenio import bibformat_utils\n                author['a'] = bibformat_utils.highlight(author['a'],\n                                                        bfo.search_pattern)\n\n            if print_links.lower() == \"yes\":\n                if link_author_pages == \"yes\":\n                    author['a'] = '<a rel=\"author\" href=\"' + CFG_BASE_URL + \\\n                                  '/author/profile/' + quote(author['a']) + \\\n                                  '?recid=' +  bibrec_id + \\\n                                  '&ln=' + bfo.lang + \\\n                                  '\">' + escape(author['a']) + '</a>'\n                elif link_mobile_pages == 'yes':\n                    author['a'] = '<a rel=\"external\" href=\"#page=search' + \\\n                                  '&amp;f=author&amp;p=' + quote(author['a']) + \\\n                                  '\">' + escape(author['a']) + '</a>'\n                else:\n                    auth_coll_param = ''\n                    if 'a0' in author:\n                        recIDs = get_low_level_recIDs_from_control_no(author['a0'])\n                        if len(recIDs):\n                            auth_coll_param = '&amp;c=' + \\\n                                              CFG_BIBAUTHORITY_AUTHORITY_COLLECTION_NAME\n                    author['a'] = '<a href=\"' + CFG_BASE_URL + \\\n                                  '/search?f=author&amp;p=' + quote(author['a']) + \\\n                                   auth_coll_param + \\\n                                  '&amp;ln=' + bfo.lang + \\\n                                  '\">' + escape(author['a']) + '</a>'\n\n        if author.has_key('u'):\n            if print_affiliations == \"yes\":\n                if 'u0' in author:\n                    recIDs = get_low_level_recIDs_from_control_no(author['u0'])\n                    # if there is more than 1 recID, clicking on link and\n                    # thus displaying the authority record's page should\n                    # contain a warning that there are multiple authority\n                    # records with the same control number\n                    if len(recIDs):\n                        author['u'] = '<a href=\"' + CFG_BASE_URL + '/' + CFG_SITE_RECORD + '/' + \\\n                                      str(recIDs[0]) + \\\n                                      '?ln=' + bfo.lang + \\\n                                      '\">' + author['u'] + '</a>'\n                author['u'] = affiliation_prefix + author['u'] + \\\n                              affiliation_suffix\n\n    # Flatten author instances\n    if print_affiliations == 'yes':\n        authors = [author.get('a', '') + author.get('u', '')\n                   for author in authors]\n    else:\n        authors = [author.get('a', '')\n                   for author in authors]\n\n    if limit.isdigit() and  nb_authors > int(limit) and interactive != \"yes\":\n        return separator.join(authors[:int(limit)]) + extension\n\n    elif limit.isdigit() and nb_authors > int(limit) and interactive == \"yes\":\n        out = '<a name=\"show_hide\" />'\n        out += separator.join(authors[:int(limit)])\n        out += '<span id=\"more_%s\" style=\"\">' % bibrec_id + separator + \\\n               separator.join(authors[int(limit):]) + '</span>'\n        out += ' <span id=\"extension_%s\"></span>' % bibrec_id\n        out += ' <small><i><a id=\"link_%s\" href=\"#\" style=\"color:rgb(204,0,0);\"></a></i></small>' % bibrec_id\n        out += '''\n        <script type=\"text/javascript\">\n        $('#link_%(recid)s').click(function(event) {\n            event.preventDefault();\n            var more = document.getElementById('more_%(recid)s');\n            var link = document.getElementById('link_%(recid)s');\n            var extension = document.getElementById('extension_%(recid)s');\n            if (more.style.display=='none'){\n                more.style.display = '';\n                extension.style.display = 'none';\n                link.innerHTML = \"%(show_less)s\"\n          } else {\n                more.style.display = 'none';\n                extension.style.display = '';\n                link.innerHTML = \"%(show_more)s\"\n          }\n            link.style.color = \"rgb(204,0,0);\"\n      });\n\n        function set_up_%(recid)s(){\n            var extension = document.getElementById('extension_%(recid)s');\n            extension.innerHTML = \"%(extension)s\";\n            $('#link_%(recid)s').click();\n      }\n\n        </script>\n        ''' % {'show_less':_(\"Hide\"),\n             'show_more':_(\"Show all %i authors\") % nb_authors,\n             'extension':extension,\n             'recid': bibrec_id}\n        out += '<script type=\"text/javascript\">set_up_%s()</script>' % bibrec_id\n\n        return out\n    elif nb_authors > 0:\n        return separator.join(authors)\n\ndef escape_values(bfo):\n    \"\"\"\n    Called by BibFormat in order to check if output of this element\n    should be escaped.\n    \"\"\"\n    return 0\n" }
{ "repo_name": "Inspq/ansible", "ref": "refs/heads/inspq", "path": "lib/ansible/modules/cloud/ovirt/ovirt_snapshots.py", "content": "#!/usr/bin/python\n# -*- coding: utf-8 -*-\n#\n# Copyright (c) 2016 Red Hat, Inc.\n#\n# This file is part of Ansible\n#\n# Ansible is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# Ansible is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.\n#\n\nANSIBLE_METADATA = {'metadata_version': '1.0',\n                    'status': ['preview'],\n                    'supported_by': 'community'}\n\n\nDOCUMENTATION = '''\n---\nmodule: ovirt_snapshots\nshort_description: \"Module to manage Virtual Machine Snapshots in oVirt\"\nversion_added: \"2.3\"\nauthor: \"Ondra Machacek (@machacekondra)\"\ndescription:\n    - \"Module to manage Virtual Machine Snapshots in oVirt\"\noptions:\n    snapshot_id:\n        description:\n            - \"ID of the snapshot to manage.\"\n    vm_name:\n        description:\n            - \"Name of the Virtual Machine to manage.\"\n        required: true\n    state:\n        description:\n            - \"Should the Virtual Machine snapshot be restore/present/absent.\"\n        choices: ['restore', 'present', 'absent']\n        default: present\n    description:\n        description:\n            - \"Description of the snapshot.\"\n    use_memory:\n        description:\n            - \"If I(true) and C(state) is I(present) save memory of the Virtual\n               Machine if it's running.\"\n            - \"If I(true) and C(state) is I(restore) restore memory of the\n               Virtual Machine.\"\n            - \"Note that Virtual Machine will be paused while saving the memory.\"\nnotes:\n    - \"Note that without a guest agent the data on the created snapshot may be\n       inconsistent.\"\n    - \"Deleting a snapshot does not remove any information from the virtual\n       machine - it simply removes a return-point. However, restoring a virtual\n       machine from a snapshot deletes any content that was written to the\n       virtual machine after the time the snapshot was taken.\"\nextends_documentation_fragment: ovirt\n'''\n\n\nEXAMPLES = '''\n# Examples don't contain auth parameter for simplicity,\n# look at ovirt_auth module to see how to reuse authentication:\n\n# Create snapshot:\n- ovirt_snapshots:\n    vm_name: rhel7\n    description: MySnapshot\n  register: snapshot\n\n# Create snapshot and save memory:\n- ovirt_snapshots:\n    vm_name: rhel7\n    description: SnapWithMem\n    use_memory: true\n  register: snapshot\n\n# Restore snapshot:\n- ovirt_snapshots:\n    state: restore\n    vm_name: rhel7\n    snapshot_id: \"{{ snapshot.id }}\"\n\n# Remove snapshot:\n- ovirt_snapshots:\n    state: absent\n    vm_name: rhel7\n    snapshot_id: \"{{ snapshot.id }}\"\n'''\n\n\nRETURN = '''\nid:\n    description: ID of the snapshot which is managed\n    returned: On success if snapshot is found.\n    type: str\n    sample: 7de90f31-222c-436c-a1ca-7e655bd5b60c\nsnapshot:\n    description: \"Dictionary of all the snapshot attributes. Snapshot attributes can be found on your oVirt instance\n                  at following url: https://ovirt.example.com/ovirt-engine/api/model#types/snapshot.\"\n    returned: On success if snapshot is found.\n'''\n\n\nimport traceback\n\ntry:\n    import ovirtsdk4.types as otypes\nexcept ImportError:\n    pass\n\nfrom ansible.module_utils.basic import AnsibleModule\nfrom ansible.module_utils.ovirt import (\n    check_sdk,\n    create_connection,\n    get_dict_of_struct,\n    get_entity,\n    ovirt_full_argument_spec,\n    search_by_name,\n    wait,\n)\n\n\ndef create_snapshot(module, vm_service, snapshots_service):\n    changed = False\n    snapshot = get_entity(\n        snapshots_service.snapshot_service(module.params['snapshot_id'])\n    )\n    if snapshot is None:\n        if not module.check_mode:\n            snapshot = snapshots_service.add(\n                otypes.Snapshot(\n                    description=module.params.get('description'),\n                    persist_memorystate=module.params.get('use_memory'),\n                )\n            )\n        changed = True\n        wait(\n            service=snapshots_service.snapshot_service(snapshot.id),\n            condition=lambda snap: snap.snapshot_status == otypes.SnapshotStatus.OK,\n            wait=module.params['wait'],\n            timeout=module.params['timeout'],\n        )\n    return {\n        'changed': changed,\n        'id': snapshot.id,\n        'snapshot': get_dict_of_struct(snapshot),\n  }\n\n\ndef remove_snapshot(module, vm_service, snapshots_service):\n    changed = False\n    snapshot = get_entity(\n        snapshots_service.snapshot_service(module.params['snapshot_id'])\n    )\n\n    if snapshot:\n        snapshot_service = snapshots_service.snapshot_service(snapshot.id)\n        if not module.check_mode:\n            snapshot_service.remove()\n        changed = True\n        wait(\n            service=snapshot_service,\n            condition=lambda snapshot: snapshot is None,\n            wait=module.params['wait'],\n            timeout=module.params['timeout'],\n        )\n\n    return {\n        'changed': changed,\n        'id': snapshot.id if snapshot else None,\n        'snapshot': get_dict_of_struct(snapshot),\n  }\n\n\ndef restore_snapshot(module, vm_service, snapshots_service):\n    changed = False\n    snapshot_service = snapshots_service.snapshot_service(\n        module.params['snapshot_id']\n    )\n    snapshot = get_entity(snapshot_service)\n    if snapshot is None:\n        raise Exception(\n            \"Snapshot with id '%s' doesn't exist\" % module.params['snapshot_id']\n        )\n\n    if snapshot.snapshot_status != otypes.SnapshotStatus.IN_PREVIEW:\n        if not module.check_mode:\n            snapshot_service.restore(\n                restore_memory=module.params.get('use_memory'),\n            )\n        changed = True\n    else:\n        if not module.check_mode:\n            vm_service.commit_snapshot()\n        changed = True\n\n    if changed:\n        wait(\n            service=snapshot_service,\n            condition=lambda snap: snap.snapshot_status == otypes.SnapshotStatus.OK,\n            wait=module.params['wait'],\n            timeout=module.params['timeout'],\n        )\n    return {\n        'changed': changed,\n        'id': snapshot.id if snapshot else None,\n        'snapshot': get_dict_of_struct(snapshot),\n  }\n\n\ndef main():\n    argument_spec = ovirt_full_argument_spec(\n        state=dict(\n            choices=['restore', 'present', 'absent'],\n            default='present',\n        ),\n        vm_name=dict(required=True),\n        snapshot_id=dict(default=None),\n        description=dict(default=None),\n        use_memory=dict(\n            default=None,\n            type='bool',\n            aliases=['restore_memory', 'save_memory'],\n        ),\n    )\n    module = AnsibleModule(\n        argument_spec=argument_spec,\n        supports_check_mode=True,\n        required_if=[\n            ('state', 'absent', ['snapshot_id']),\n            ('state', 'restore', ['snapshot_id']),\n        ]\n    )\n    check_sdk(module)\n\n    vm_name = module.params.get('vm_name')\n    auth = module.params.pop('auth')\n    connection = create_connection(auth)\n    vms_service = connection.system_service().vms_service()\n    vm = search_by_name(vms_service, vm_name)\n    if not vm:\n        module.fail_json(\n            msg=\"Vm '{name}' doesn't exist.\".format(name=vm_name),\n        )\n\n    vm_service = vms_service.vm_service(vm.id)\n    snapshots_service = vms_service.vm_service(vm.id).snapshots_service()\n    try:\n        state = module.params['state']\n        if state == 'present':\n            ret = create_snapshot(module, vm_service, snapshots_service)\n        elif state == 'restore':\n            ret = restore_snapshot(module, vm_service, snapshots_service)\n        elif state == 'absent':\n            ret = remove_snapshot(module, vm_service, snapshots_service)\n        module.exit_json(**ret)\n    except Exception as e:\n        module.fail_json(msg=str(e), exception=traceback.format_exc())\n    finally:\n        connection.close(logout=auth.get('token') is None)\n\n\nif __name__ == \"__main__\":\n    main()\n" }
{ "repo_name": "redhat-openstack/django", "ref": "refs/heads/epel7-patches", "path": "django/views/generic/base.py", "content": "from __future__ import unicode_literals\n\nimport logging\nfrom functools import update_wrapper\n\nfrom django import http\nfrom django.core.exceptions import ImproperlyConfigured\nfrom django.core.urlresolvers import reverse, NoReverseMatch\nfrom django.template.response import TemplateResponse\nfrom django.utils.decorators import classonlymethod\nfrom django.utils import six\n\nlogger = logging.getLogger('django.request')\n\n\nclass ContextMixin(object):\n    \"\"\"\n    A default context mixin that passes the keyword arguments received by\n    get_context_data as the template context.\n    \"\"\"\n\n    def get_context_data(self, **kwargs):\n        if 'view' not in kwargs:\n            kwargs['view'] = self\n        return kwargs\n\n\nclass View(object):\n    \"\"\"\n    Intentionally simple parent class for all views. Only implements\n    dispatch-by-method and simple sanity checking.\n    \"\"\"\n\n    http_method_names = ['get', 'post', 'put', 'patch', 'delete', 'head', 'options', 'trace']\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Constructor. Called in the URLconf; can contain helpful extra\n        keyword arguments, and other things.\n        \"\"\"\n        # Go through keyword arguments, and either save their values to our\n        # instance, or raise an error.\n        for key, value in six.iteritems(kwargs):\n            setattr(self, key, value)\n\n    @classonlymethod\n    def as_view(cls, **initkwargs):\n        \"\"\"\n        Main entry point for a request-response process.\n        \"\"\"\n        # sanitize keyword arguments\n        for key in initkwargs:\n            if key in cls.http_method_names:\n                raise TypeError(\"You tried to pass in the %s method name as a \"\n                                \"keyword argument to %s(). Don't do that.\"\n                                % (key, cls.__name__))\n            if not hasattr(cls, key):\n                raise TypeError(\"%s() received an invalid keyword %r. as_view \"\n                                \"only accepts arguments that are already \"\n                                \"attributes of the class.\" % (cls.__name__, key))\n\n        def view(request, *args, **kwargs):\n            self = cls(**initkwargs)\n            if hasattr(self, 'get') and not hasattr(self, 'head'):\n                self.head = self.get\n            self.request = request\n            self.args = args\n            self.kwargs = kwargs\n            return self.dispatch(request, *args, **kwargs)\n\n        # take name and docstring from class\n        update_wrapper(view, cls, updated=())\n\n        # and possible attributes set by decorators\n        # like csrf_exempt from dispatch\n        update_wrapper(view, cls.dispatch, assigned=())\n        return view\n\n    def dispatch(self, request, *args, **kwargs):\n        # Try to dispatch to the right method; if a method doesn't exist,\n        # defer to the error handler. Also defer to the error handler if the\n        # request method isn't on the approved list.\n        if request.method.lower() in self.http_method_names:\n            handler = getattr(self, request.method.lower(), self.http_method_not_allowed)\n        else:\n            handler = self.http_method_not_allowed\n        return handler(request, *args, **kwargs)\n\n    def http_method_not_allowed(self, request, *args, **kwargs):\n        logger.warning('Method Not Allowed (%s): %s', request.method, request.path,\n            extra={\n                'status_code': 405,\n                'request': self.request\n          }\n        )\n        return http.HttpResponseNotAllowed(self._allowed_methods())\n\n    def options(self, request, *args, **kwargs):\n        \"\"\"\n        Handles responding to requests for the OPTIONS HTTP verb.\n        \"\"\"\n        response = http.HttpResponse()\n        response['Allow'] = ', '.join(self._allowed_methods())\n        response['Content-Length'] = '0'\n        return response\n\n    def _allowed_methods(self):\n        return [m.upper() for m in self.http_method_names if hasattr(self, m)]\n\n\nclass TemplateResponseMixin(object):\n    \"\"\"\n    A mixin that can be used to render a template.\n    \"\"\"\n    template_name = None\n    response_class = TemplateResponse\n    content_type = None\n\n    def render_to_response(self, context, **response_kwargs):\n        \"\"\"\n        Returns a response, using the `response_class` for this\n        view, with a template rendered with the given context.\n\n        If any keyword arguments are provided, they will be\n        passed to the constructor of the response class.\n        \"\"\"\n        response_kwargs.setdefault('content_type', self.content_type)\n        return self.response_class(\n            request = self.request,\n            template = self.get_template_names(),\n            context = context,\n            **response_kwargs\n        )\n\n    def get_template_names(self):\n        \"\"\"\n        Returns a list of template names to be used for the request. Must return\n        a list. May not be called if render_to_response is overridden.\n        \"\"\"\n        if self.template_name is None:\n            raise ImproperlyConfigured(\n                \"TemplateResponseMixin requires either a definition of \"\n                \"'template_name' or an implementation of 'get_template_names()'\")\n        else:\n            return [self.template_name]\n\n\nclass TemplateView(TemplateResponseMixin, ContextMixin, View):\n    \"\"\"\n    A view that renders a template.  This view will also pass into the context\n    any keyword arguments passed by the url conf.\n    \"\"\"\n    def get(self, request, *args, **kwargs):\n        context = self.get_context_data(**kwargs)\n        return self.render_to_response(context)\n\n\nclass RedirectView(View):\n    \"\"\"\n    A view that provides a redirect on any GET request.\n    \"\"\"\n    permanent = True\n    url = None\n    pattern_name = None\n    query_string = False\n\n    def get_redirect_url(self, *args, **kwargs):\n        \"\"\"\n        Return the URL redirect to. Keyword arguments from the\n        URL pattern match generating the redirect request\n        are provided as kwargs to this method.\n        \"\"\"\n        if self.url:\n            url = self.url % kwargs\n        elif self.pattern_name:\n            try:\n                url = reverse(self.pattern_name, args=args, kwargs=kwargs)\n            except NoReverseMatch:\n                return None\n        else:\n            return None\n\n        args = self.request.META.get('QUERY_STRING', '')\n        if args and self.query_string:\n            url = \"%s?%s\" % (url, args)\n        return url\n\n    def get(self, request, *args, **kwargs):\n        url = self.get_redirect_url(*args, **kwargs)\n        if url:\n            if self.permanent:\n                return http.HttpResponsePermanentRedirect(url)\n            else:\n                return http.HttpResponseRedirect(url)\n        else:\n            logger.warning('Gone: %s', self.request.path,\n                        extra={\n                            'status_code': 410,\n                            'request': self.request\n                      })\n            return http.HttpResponseGone()\n\n    def head(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def post(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def options(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def delete(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def put(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n\n    def patch(self, request, *args, **kwargs):\n        return self.get(request, *args, **kwargs)\n" }
{ "repo_name": "wbond/subversion", "ref": "refs/heads/1.7.x", "path": "tools/hook-scripts/mailer/tests/mailer-tweak.py", "content": "#!/usr/bin/env python\n#\n#\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n#\n#\n#\n# mailer-tweak.py: tweak the svn:date and svn:author properties\n#                  on all revisions\n#\n# We need constant dates and authors for the revisions so that we can\n# consistently compare an output against a known quantity.\n#\n# USAGE: ./mailer-tweak.py REPOS\n#\n\n\nimport sys\nimport os\nimport getopt\n\nfrom svn import fs, core\n\nDATE_BASE = 1000000000\nDATE_INCR = 10000\n\n\ndef tweak_dates(pool, home='.'):\n  db_path = os.path.join(home, 'db')\n  if not os.path.exists(db_path):\n    db_path = home\n\n  fsob = fs.new(None, pool)\n  fs.open_berkeley(fsob, db_path)\n\n  for i in range(fs.youngest_rev(fsob, pool)):\n    # convert secs into microseconds, then a string\n    date = core.svn_time_to_cstring((DATE_BASE+i*DATE_INCR) * 1000000L, pool)\n    #print date\n    fs.change_rev_prop(fsob, i+1, core.SVN_PROP_REVISION_DATE, date, pool)\n    fs.change_rev_prop(fsob, i+1, core.SVN_PROP_REVISION_AUTHOR, 'mailer test', pool)\n\ndef main():\n  if len(sys.argv) != 2:\n    print('USAGE: %s REPOS' % sys.argv[0])\n    sys.exit(1)\n\n  core.run_app(tweak_dates, sys.argv[1])\n\nif __name__ == '__main__':\n  main()\n" }
{ "repo_name": "pbs/cmsplugin-filer", "ref": "refs/heads/master_pbs", "path": "cmsplugin_filer_image/south_migrations/0010_auto__add_field_filerimage_target_blank.py", "content": "# -*- coding: utf-8 -*-\nimport datetime\nfrom south.db import db\nfrom south.v2 import SchemaMigration\nfrom django.db import models\n\n\nclass Migration(SchemaMigration):\n\n    def forwards(self, orm):\n        # Adding field 'FilerImage.target_blank'\n        db.add_column('cmsplugin_filerimage', 'target_blank',\n                      self.gf('django.db.models.fields.BooleanField')(default=False),\n                      keep_default=False)\n\n\n    def backwards(self, orm):\n        # Deleting field 'FilerImage.target_blank'\n        db.delete_column('cmsplugin_filerimage', 'target_blank')\n\n\n    models = {\n        'auth.group': {\n            'Meta': {'object_name': 'Group'}\n            'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),\n            'name': ('django.db.models.fields.CharField', [], {'unique': 'True', 'max_length': '80'}),\n            'permissions': ('django.db.models.fields.related.ManyToManyField', [], {'to': \"orm['auth.Permission']\", 'symmetrical': 'False', 'blank': 'True'})\n      }\n        'auth.permission': {\n            'Meta': {'ordering': \"('content_type__app_label', 'content_type__model', 'codename')\", 'unique_together': \"(('content_type', 'codename'),)\", 'object_name': 'Permission'}\n            'codename': ('django.db.models.fields.CharField', [], {'max_length': '100'}),\n            'content_type': ('django.db.models.fields.related.ForeignKey', [], {'to': \"orm['contenttypes.ContentType']\"}),\n            'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),\n            'name': ('django.db.models.fields.CharField', [], {'max_length': '50'})\n      }\n        'auth.user': {\n            'Meta': {'object_name': 'User'}\n            'date_joined': ('django.db.models.fields.DateTimeField', [], {'default': 'datetime.datetime.now'}),\n            'email': ('django.db.models.fields.EmailField', [], {'max_length': '75', 'blank': 'True'}),\n            'first_name': ('django.db.models.fields.CharField', [], {'max_length': '30', 'blank': 'True'}),\n            'groups': ('django.db.models.fields.related.ManyToManyField', [], {'to': \"orm['auth.Group']\", 'symmetrical': 'False', 'blank': 'True'}),\n            'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),\n            'is_active': ('django.db.models.fields.BooleanField', [], {'default': 'True'}),\n            'is_staff': ('django.db.models.fields.BooleanField', [], {'default': 'False'}),\n            'is_superuser': ('django.db.models.fields.BooleanField', [], {'default': 'False'}),\n            'last_login': ('django.db.models.fields.DateTimeField', [], {'default': 'datetime.datetime.now'}),\n            'last_name': ('django.db.models.fields.CharField', [], {'max_length': '30', 'blank': 'True'}),\n            'password': ('django.db.models.fields.CharField', [], {'max_length': '128'}),\n            'user_permissions': ('django.db.models.fields.related.ManyToManyField', [], {'to': \"orm['auth.Permission']\", 'symmetrical': 'False', 'blank': 'True'}),\n            'username': ('django.db.models.fields.CharField', [], {'unique': 'True', 'max_length': '30'})\n      }\n        'cms.cmsplugin': {\n            'Meta': {'object_name': 'CMSPlugin'}\n            'changed_date': ('django.db.models.fields.DateTimeField', [], {'auto_now': 'True', 'blank': 'True'}),\n            'creation_date': ('django.db.models.fields.DateTimeField', [], {'default': 'datetime.datetime(2012, 11, 29, 0, 0)'}),\n            'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),\n            'language': ('django.db.models.fields.CharField', [], {'max_length': '15', 'db_index': 'True'}),\n            'level': ('django.db.models.fields.PositiveIntegerField', [], {'db_index': 'True'}),\n            'lft': ('django.db.models.fields.PositiveIntegerField', [], {'db_index': 'True'}),\n            'parent': ('django.db.models.fields.related.ForeignKey', [], {'to': \"orm['cms.CMSPlugin']\", 'null': 'True', 'blank': 'True'}),\n            'placeholder': ('django.db.models.fields.related.ForeignKey', [], {'to': \"orm['cms.Placeholder']\", 'null': 'True'}),\n            'plugin_type': ('django.db.models.fields.CharField', [], {'max_length': '50', 'db_index': 'True'}),\n            'position': ('django.db.models.fields.PositiveSmallIntegerField', [], {'null': 'True', 'blank': 'True'}),\n            'rght': ('django.db.models.fields.PositiveIntegerField', [], {'db_index': 'True'}),\n            'tree_id': ('django.db.models.fields.PositiveIntegerField', [], {'db_index': 'True'})\n      }\n        'cms.page': {\n            'Meta': {'ordering': \"('site', 'tree_id', 'lft')\", 'object_name': 'Page'}\n            'changed_by': ('django.db.models.fields.CharField', [], {'max_length': '70'}),\n            'changed_date': ('django.db.models.fields.DateTimeField', [], {'auto_now': 'True', 'blank': 'True'}),\n            'created_by': ('django.db.models.fields.CharField', [], {'max_length': '70'}),\n            'creation_date': ('django.db.models.fields.DateTimeField', [], {'auto_now_add': 'True', 'blank': 'True'}),\n            'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),\n            'in_navigation': ('django.db.models.fields.BooleanField', [], {'default': 'True', 'db_index': 'True'}),\n            'level': ('django.db.models.fields.PositiveIntegerField', [], {'db_index': 'True'}),\n            'lft': ('django.db.models.fields.PositiveIntegerField', [], {'db_index': 'True'}),\n            'limit_visibility_in_menu': ('django.db.models.fields.SmallIntegerField', [], {'default': 'None', 'null': 'True', 'db_index': 'True', 'blank': 'True'}),\n            'login_required': ('django.db.models.fields.BooleanField', [], {'default': 'False'}),\n            'moderator_state': ('django.db.models.fields.SmallIntegerField', [], {'default': '1', 'blank': 'True'}),\n            'navigation_extenders': ('django.db.models.fields.CharField', [], {'db_index': 'True', 'max_length': '80', 'null': 'True', 'blank': 'True'}),\n            'parent': ('django.db.models.fields.related.ForeignKey', [], {'blank': 'True', 'related_name': \"'children'\", 'null': 'True', 'to': \"orm['cms.Page']\"}),\n            'placeholders': ('django.db.models.fields.related.ManyToManyField', [], {'to': \"orm['cms.Placeholder']\", 'symmetrical': 'False'}),\n            'publication_date': ('django.db.models.fields.DateTimeField', [], {'db_index': 'True', 'null': 'True', 'blank': 'True'}),\n            'publication_end_date': ('django.db.models.fields.DateTimeField', [], {'db_index': 'True', 'null': 'True', 'blank': 'True'}),\n            'published': ('django.db.models.fields.BooleanField', [], {'default': 'False'}),\n            'publisher_is_draft': ('django.db.models.fields.BooleanField', [], {'default': 'True', 'db_index': 'True'}),\n            'publisher_public': ('django.db.models.fields.related.OneToOneField', [], {'related_name': \"'publisher_draft'\", 'unique': 'True', 'null': 'True', 'to': \"orm['cms.Page']\"}),\n            'publisher_state': ('django.db.models.fields.SmallIntegerField', [], {'default': '0', 'db_index': 'True'}),\n            'reverse_id': ('django.db.models.fields.CharField', [], {'db_index': 'True', 'max_length': '40', 'null': 'True', 'blank': 'True'}),\n            'rght': ('django.db.models.fields.PositiveIntegerField', [], {'db_index': 'True'}),\n            'site': ('django.db.models.fields.related.ForeignKey', [], {'to': \"orm['sites.Site']\"}),\n            'soft_root': ('django.db.models.fields.BooleanField', [], {'default': 'False', 'db_index': 'True'}),\n            'template': ('django.db.models.fields.CharField', [], {'max_length': '100'}),\n            'tree_id': ('django.db.models.fields.PositiveIntegerField', [], {'db_index': 'True'})\n      }\n        'cms.placeholder': {\n            'Meta': {'object_name': 'Placeholder'}\n            'default_width': ('django.db.models.fields.PositiveSmallIntegerField', [], {'null': 'True'}),\n            'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),\n            'slot': ('django.db.models.fields.CharField', [], {'max_length': '50', 'db_index': 'True'})\n      }\n        'cmsplugin_filer_image.filerimage': {\n            'Meta': {'object_name': 'FilerImage', 'db_table': \"'cmsplugin_filerimage'\", '_ormbases': ['cms.CMSPlugin']}\n            'alignment': ('django.db.models.fields.CharField', [], {'max_length': '10', 'null': 'True', 'blank': 'True'}),\n            'alt_text': ('django.db.models.fields.CharField', [], {'max_length': '255', 'null': 'True', 'blank': 'True'}),\n            'caption_text': ('django.db.models.fields.CharField', [], {'max_length': '255', 'null': 'True', 'blank': 'True'}),\n            'cmsplugin_ptr': ('django.db.models.fields.related.OneToOneField', [], {'to': \"orm['cms.CMSPlugin']\", 'unique': 'True', 'primary_key': 'True'}),\n            'crop': ('django.db.models.fields.BooleanField', [], {'default': 'True'}),\n            'description': ('django.db.models.fields.TextField', [], {'null': 'True', 'blank': 'True'}),\n            'file_link': ('django.db.models.fields.related.ForeignKey', [], {'default': 'None', 'related_name': \"'+'\", 'null': 'True', 'blank': 'True', 'to': \"orm['filer.File']\"}),\n            'free_link': ('django.db.models.fields.CharField', [], {'max_length': '255', 'null': 'True', 'blank': 'True'}),\n            'height': ('django.db.models.fields.PositiveIntegerField', [], {'null': 'True', 'blank': 'True'}),\n            'image': ('django.db.models.fields.related.ForeignKey', [], {'default': 'None', 'to': \"orm['filer.Image']\", 'null': 'True', 'blank': 'True'}),\n            'image_url': ('django.db.models.fields.URLField', [], {'default': 'None', 'max_length': '200', 'null': 'True', 'blank': 'True'}),\n            'original_link': ('django.db.models.fields.BooleanField', [], {'default': 'False'}),\n            'page_link': ('django.db.models.fields.related.ForeignKey', [], {'to': \"orm['cms.Page']\", 'null': 'True', 'blank': 'True'}),\n            'target_blank': ('django.db.models.fields.BooleanField', [], {'default': 'False'}),\n            'thumbnail_option': ('django.db.models.fields.related.ForeignKey', [], {'to': \"orm['cmsplugin_filer_image.ThumbnailOption']\", 'null': 'True', 'blank': 'True'}),\n            'upscale': ('django.db.models.fields.BooleanField', [], {'default': 'True'}),\n            'use_autoscale': ('django.db.models.fields.BooleanField', [], {'default': 'False'}),\n            'use_original_image': ('django.db.models.fields.BooleanField', [], {'default': 'False'}),\n            'width': ('django.db.models.fields.PositiveIntegerField', [], {'null': 'True', 'blank': 'True'})\n      }\n        'cmsplugin_filer_image.thumbnailoption': {\n            'Meta': {'ordering': \"('width', 'height')\", 'object_name': 'ThumbnailOption'}\n            'crop': ('django.db.models.fields.BooleanField', [], {'default': 'True'}),\n            'height': ('django.db.models.fields.IntegerField', [], {}),\n            'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),\n            'name': ('django.db.models.fields.CharField', [], {'max_length': '100'}),\n            'upscale': ('django.db.models.fields.BooleanField', [], {'default': 'True'}),\n            'width': ('django.db.models.fields.IntegerField', [], {})\n      }\n        'contenttypes.contenttype': {\n            'Meta': {'ordering': \"('name',)\", 'unique_together': \"(('app_label', 'model'),)\", 'object_name': 'ContentType', 'db_table': \"'django_content_type'\"}\n            'app_label': ('django.db.models.fields.CharField', [], {'max_length': '100'}),\n            'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),\n            'model': ('django.db.models.fields.CharField', [], {'max_length': '100'}),\n            'name': ('django.db.models.fields.CharField', [], {'max_length': '100'})\n      }\n        'filer.file': {\n            'Meta': {'object_name': 'File'}\n            '_file_size': ('django.db.models.fields.IntegerField', [], {'null': 'True', 'blank': 'True'}),\n            'description': ('django.db.models.fields.TextField', [], {'null': 'True', 'blank': 'True'}),\n            'file': ('django.db.models.fields.files.FileField', [], {'max_length': '255', 'null': 'True', 'blank': 'True'}),\n            'folder': ('django.db.models.fields.related.ForeignKey', [], {'blank': 'True', 'related_name': \"'all_files'\", 'null': 'True', 'to': \"orm['filer.Folder']\"}),\n            'has_all_mandatory_data': ('django.db.models.fields.BooleanField', [], {'default': 'False'}),\n            'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),\n            'is_public': ('django.db.models.fields.BooleanField', [], {'default': 'True'}),\n            'modified_at': ('django.db.models.fields.DateTimeField', [], {'auto_now': 'True', 'blank': 'True'}),\n            'name': ('django.db.models.fields.CharField', [], {'default': \"''\", 'max_length': '255', 'blank': 'True'}),\n            'original_filename': ('django.db.models.fields.CharField', [], {'max_length': '255', 'null': 'True', 'blank': 'True'}),\n            'owner': ('django.db.models.fields.related.ForeignKey', [], {'blank': 'True', 'related_name': \"'owned_files'\", 'null': 'True', 'to': \"orm['auth.User']\"}),\n            'polymorphic_ctype': ('django.db.models.fields.related.ForeignKey', [], {'related_name': \"'polymorphic_filer.file_set'\", 'null': 'True', 'to': \"orm['contenttypes.ContentType']\"}),\n            'sha1': ('django.db.models.fields.CharField', [], {'default': \"''\", 'max_length': '40', 'blank': 'True'}),\n            'uploaded_at': ('django.db.models.fields.DateTimeField', [], {'auto_now_add': 'True', 'blank': 'True'})\n      }\n        'filer.folder': {\n            'Meta': {'ordering': \"('name',)\", 'unique_together': \"(('parent', 'name'),)\", 'object_name': 'Folder'}\n            'created_at': ('django.db.models.fields.DateTimeField', [], {'auto_now_add': 'True', 'blank': 'True'}),\n            'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),\n            'level': ('django.db.models.fields.PositiveIntegerField', [], {'db_index': 'True'}),\n            'lft': ('django.db.models.fields.PositiveIntegerField', [], {'db_index': 'True'}),\n            'modified_at': ('django.db.models.fields.DateTimeField', [], {'auto_now': 'True', 'blank': 'True'}),\n            'name': ('django.db.models.fields.CharField', [], {'max_length': '255'}),\n            'owner': ('django.db.models.fields.related.ForeignKey', [], {'blank': 'True', 'related_name': \"'filer_owned_folders'\", 'null': 'True', 'to': \"orm['auth.User']\"}),\n            'parent': ('django.db.models.fields.related.ForeignKey', [], {'blank': 'True', 'related_name': \"'children'\", 'null': 'True', 'to': \"orm['filer.Folder']\"}),\n            'rght': ('django.db.models.fields.PositiveIntegerField', [], {'db_index': 'True'}),\n            'tree_id': ('django.db.models.fields.PositiveIntegerField', [], {'db_index': 'True'}),\n            'uploaded_at': ('django.db.models.fields.DateTimeField', [], {'auto_now_add': 'True', 'blank': 'True'})\n      }\n        'filer.image': {\n            'Meta': {'object_name': 'Image', '_ormbases': ['filer.File']}\n            '_height': ('django.db.models.fields.IntegerField', [], {'null': 'True', 'blank': 'True'}),\n            '_width': ('django.db.models.fields.IntegerField', [], {'null': 'True', 'blank': 'True'}),\n            'author': ('django.db.models.fields.CharField', [], {'max_length': '255', 'null': 'True', 'blank': 'True'}),\n            'date_taken': ('django.db.models.fields.DateTimeField', [], {'null': 'True', 'blank': 'True'}),\n            'default_alt_text': ('django.db.models.fields.CharField', [], {'max_length': '255', 'null': 'True', 'blank': 'True'}),\n            'default_caption': ('django.db.models.fields.CharField', [], {'max_length': '255', 'null': 'True', 'blank': 'True'}),\n            'file_ptr': ('django.db.models.fields.related.OneToOneField', [], {'to': \"orm['filer.File']\", 'unique': 'True', 'primary_key': 'True'}),\n            'must_always_publish_author_credit': ('django.db.models.fields.BooleanField', [], {'default': 'False'}),\n            'must_always_publish_copyright': ('django.db.models.fields.BooleanField', [], {'default': 'False'}),\n            'subject_location': ('django.db.models.fields.CharField', [], {'default': 'None', 'max_length': '64', 'null': 'True', 'blank': 'True'})\n      }\n        'sites.site': {\n            'Meta': {'ordering': \"('domain',)\", 'object_name': 'Site', 'db_table': \"'django_site'\"}\n            'domain': ('django.db.models.fields.CharField', [], {'max_length': '100'}),\n            'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),\n            'name': ('django.db.models.fields.CharField', [], {'max_length': '50'})\n      }\n  }\n\n    complete_apps = ['cmsplugin_filer_image']" }
{ "repo_name": "balister/GNU-Radio", "ref": "refs/heads/adap", "path": "gnuradio-runtime/python/gnuradio/gr/__init__.py", "content": "#\n# Copyright 2003-2012 Free Software Foundation, Inc.\n#\n# This file is part of GNU Radio\n#\n# GNU Radio is free software; you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation; either version 3, or (at your option)\n# any later version.\n#\n# GNU Radio is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with GNU Radio; see the file COPYING.  If not, write to\n# the Free Software Foundation, Inc., 51 Franklin Street,\n# Boston, MA 02110-1301, USA.\n#\n\n# The presence of this file turns this directory into a Python package\n\n\"\"\"\nCore contents.\n\"\"\"\n\n# This is the main GNU Radio python module.\n# We pull the swig output and the other modules into the gnuradio.gr namespace\n\n# If gnuradio is installed then the swig output will be in this directory.\n# Otherwise it will reside in ../../../swig.\n\nimport os\n\ntry:\n    from runtime_swig import *\nexcept ImportError:\n    dirname, filename = os.path.split(os.path.abspath(__file__))\n    __path__.append(os.path.join(dirname, \"..\", \"..\", \"..\", \"swig\"))\n    from runtime_swig import *\n\nfrom exceptions import *\nfrom top_block import *\nfrom hier_block2 import *\nfrom tag_utils import *\nfrom gateway import basic_block, sync_block, decim_block, interp_block\n\n# Force the preference database to be initialized\nprefs = prefs.singleton\n" }
{ "repo_name": "yiqingj/work", "ref": "refs/heads/tn-vector", "path": "utils/pgsql2sqlite/build.py", "content": "#\n# This file is part of Mapnik (c++ mapping toolkit)\n#\n# Copyright (C) 2009 Artem Pavlenko, Dane Springmeyer\n#\n# Mapnik is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n#\n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n#\n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA\n#\n# \n\nimport os\nfrom copy import copy\n\nImport ('env')\n\nprefix = env['PREFIX']\n\nprogram_env = env.Clone()\n\nsource = Split(\n    \"\"\"\n    main.cpp\n    sqlite.cpp\n    \"\"\"\n    )\n\nprogram_env['CXXFLAGS'] = copy(env['LIBMAPNIK_CXXFLAGS'])\nprogram_env.Append(CPPDEFINES = env['LIBMAPNIK_DEFINES'])\n\nif env['HAS_CAIRO']:\n    program_env.PrependUnique(CPPPATH=env['CAIRO_CPPPATHS'])\n    program_env.Append(CPPDEFINES = '-DHAVE_CAIRO')\n\nprogram_env.PrependUnique(CPPPATH=['#plugins/input/postgis'])\n\nlibraries = []\nboost_program_options = 'boost_program_options%s' % env['BOOST_APPEND']\nlibraries.extend([boost_program_options,'sqlite3','pq','mapnik','icuuc'])\n\nif env.get('BOOST_LIB_VERSION_FROM_HEADER'):\n    boost_version_from_header = int(env['BOOST_LIB_VERSION_FROM_HEADER'].split('_')[1])\n    if boost_version_from_header >= 50:\n        boost_system = 'boost_system%s' % env['BOOST_APPEND']\n        libraries.extend([boost_system])\n\nif env['SQLITE_LINKFLAGS']:\n    program_env.Append(LINKFLAGS=env['SQLITE_LINKFLAGS'])\n\nif env['RUNTIME_LINK'] == 'static':\n    if env['PLATFORM'] == 'Darwin':\n        libraries.extend(['ldap', 'pam', 'ssl', 'crypto', 'krb5'])\n    else:\n        # TODO - parse back into libraries variable\n        program_env.ParseConfig('pg_config --libs')\n        libraries.append('dl')\n\npgsql2sqlite = program_env.Program('pgsql2sqlite', source, LIBS=libraries)\nDepends(pgsql2sqlite, env.subst('../../src/%s' % env['MAPNIK_LIB_NAME']))\n\nif 'uninstall' not in COMMAND_LINE_TARGETS:\n    env.Install(os.path.join(env['INSTALL_PREFIX'],'bin'), pgsql2sqlite)\n    env.Alias('install', os.path.join(env['INSTALL_PREFIX'],'bin'))\n\nenv['create_uninstall_target'](env, os.path.join(env['INSTALL_PREFIX'],'bin','pgsql2sqlite'))\n" }
{ "repo_name": "cloudbase/nova-virtualbox", "ref": "refs/heads/virtualbox_driver", "path": "nova/db/sqlalchemy/migrate_repo/versions/274_update_instances_project_id_index.py", "content": "# Copyright 2014 Rackspace Hosting\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\n\nfrom sqlalchemy import MetaData, Table, Index\n\n\ndef upgrade(migrate_engine):\n    \"\"\"Change instances (project_id) index to cover (project_id, deleted).\"\"\"\n\n    meta = MetaData(bind=migrate_engine)\n\n    # Indexes can't be changed, we need to create the new one and delete\n    # the old one\n\n    instances = Table('instances', meta, autoload=True)\n\n    index = Index('instances_project_id_deleted_idx',\n                  instances.c.project_id, instances.c.deleted)\n    index.create()\n\n    for index in instances.indexes:\n        if [c.name for c in index.columns] == ['project_id']:\n            index.drop()\n\n\ndef downgrade(migrate_engine):\n    \"\"\"Change instances (project_id, deleted) index to cover (project_id).\"\"\"\n\n    meta = MetaData(bind=migrate_engine)\n\n    instances = Table('instances', meta, autoload=True)\n\n    index = Index('project_id', instances.c.project_id)\n    index.create()\n\n    for index in instances.indexes:\n        if [c.name for c in index.columns] == ['project_id', 'deleted']:\n            index.drop()\n" }
{ "repo_name": "jeffreylu9/django-cms", "ref": "refs/heads/wlsite", "path": "cms/admin/permissionadmin.py", "content": "# -*- coding: utf-8 -*-\nfrom copy import deepcopy\nfrom django.contrib import admin\nfrom django.contrib.admin import site\nfrom django.contrib.auth import get_user_model, get_permission_codename\nfrom django.contrib.auth.admin import UserAdmin\nfrom django.utils.translation import ugettext as _\n\nfrom cms.admin.forms import GlobalPagePermissionAdminForm, PagePermissionInlineAdminForm, ViewRestrictionInlineAdminForm\nfrom cms.exceptions import NoPermissionsException\nfrom cms.models import Page, PagePermission, GlobalPagePermission, PageUser\nfrom cms.utils.conf import get_cms_setting\nfrom cms.utils.helpers import classproperty\nfrom cms.utils.permissions import get_user_permission_level\n\nfrom cms.admin import cmsadmin\n\nPERMISSION_ADMIN_INLINES = []\n\nuser_model = get_user_model()\nadmin_class = UserAdmin\nfor model, admin_instance in site._registry.items():\n    if model == user_model:\n        admin_class = admin_instance.__class__\n\nclass TabularInline(admin.TabularInline):\n    pass\n\n\nclass PagePermissionInlineAdmin(TabularInline):\n    model = PagePermission\n    # use special form, so we can override of user and group field\n    form = PagePermissionInlineAdminForm\n    classes = ['collapse', 'collapsed']\n    exclude = ['can_view']\n    extra = 0  # edit page load time boost\n\n    @classproperty\n    def raw_id_fields(cls):\n        # Dynamically set raw_id_fields based on settings\n        threshold = get_cms_setting('RAW_ID_USERS')\n        if threshold and get_user_model().objects.count() > threshold:\n            return ['user']\n        return []\n\n    def get_queryset(self, request):\n        \"\"\"\n        Queryset change, so user with global change permissions can see\n        all permissions. Otherwise can user see only permissions for\n        peoples which are under him (he can't see his permissions, because\n        this will lead to violation, when he can add more power to itself)\n        \"\"\"\n        # can see only permissions for users which are under him in tree\n\n        # here an exception can be thrown\n        try:\n            qs = PagePermission.objects.subordinate_to_user(request.user)\n            return qs.filter(can_view=False)\n        except NoPermissionsException:\n            return self.objects.get_empty_query_set()\n\n    def get_formset(self, request, obj=None, **kwargs):\n        \"\"\"\n        Some fields may be excluded here. User can change only\n        permissions which are available for him. E.g. if user does not haves\n        can_publish flag, he can't change assign can_publish permissions.\n        \"\"\"\n        exclude = self.exclude or []\n        if obj:\n            if not obj.has_add_permission(request):\n                exclude.append('can_add')\n            if not obj.has_delete_permission(request):\n                exclude.append('can_delete')\n            if not obj.has_publish_permission(request):\n                exclude.append('can_publish')\n            if not obj.has_advanced_settings_permission(request):\n                exclude.append('can_change_advanced_settings')\n            if not obj.has_move_page_permission(request):\n                exclude.append('can_move_page')\n        formset_cls = super(PagePermissionInlineAdmin, self\n        ).get_formset(request, obj=None, exclude=exclude, **kwargs)\n        qs = self.get_queryset(request)\n        if obj is not None:\n            qs = qs.filter(page=obj)\n        formset_cls._queryset = qs\n        return formset_cls\n\n\nclass ViewRestrictionInlineAdmin(PagePermissionInlineAdmin):\n    extra = 0  # edit page load time boost\n    form = ViewRestrictionInlineAdminForm\n    verbose_name = _(\"View restriction\")\n    verbose_name_plural = _(\"View restrictions\")\n    exclude = [\n        'can_add', 'can_change', 'can_delete', 'can_view',\n        'can_publish', 'can_change_advanced_settings', 'can_move_page',\n        'can_change_permissions'\n    ]\n\n    def get_formset(self, request, obj=None, **kwargs):\n        \"\"\"\n        Some fields may be excluded here. User can change only permissions\n        which are available for him. E.g. if user does not haves can_publish\n        flag, he can't change assign can_publish permissions.\n        \"\"\"\n        formset_cls = super(PagePermissionInlineAdmin, self).get_formset(request, obj, **kwargs)\n        qs = self.get_queryset(request)\n        if obj is not None:\n            qs = qs.filter(page=obj)\n        formset_cls._queryset = qs\n        return formset_cls\n\n    def get_queryset(self, request):\n        \"\"\"\n        Returns a QuerySet of all model instances that can be edited by the\n        admin site. This is used by changelist_view.\n        \"\"\"\n        qs = PagePermission.objects.subordinate_to_user(request.user)\n        return qs.filter(can_view=True)\n\n\nclass GlobalPagePermissionAdmin(admin.ModelAdmin):\n    list_display = ['user', 'group', 'can_change', 'can_delete', 'can_publish', 'can_change_permissions']\n    list_filter = ['user', 'group', 'can_change', 'can_delete', 'can_publish', 'can_change_permissions']\n\n    form = GlobalPagePermissionAdminForm\n    search_fields = []\n    for field in admin_class.search_fields:\n        search_fields.append(\"user__%s\" % field)\n    search_fields.append('group__name')\n\n    exclude = []\n\n    list_display.append('can_change_advanced_settings')\n    list_filter.append('can_change_advanced_settings')\n\n\nclass GenericCmsPermissionAdmin(object):\n    \"\"\"\n    Custom mixin for permission-enabled admin interfaces.\n    \"\"\"\n\n    def update_permission_fieldsets(self, request, obj=None):\n        \"\"\"\n        Nobody can grant more than he haves, so check for user permissions\n        to Page and User model and render fieldset depending on them.\n        \"\"\"\n        fieldsets = deepcopy(self.fieldsets)\n        perm_models = (\n            (Page, _('Page permissions')),\n            (PageUser, _('User & Group permissions')),\n            (PagePermission, _('Page permissions management')),\n        )\n        for i, perm_model in enumerate(perm_models):\n            model, title = perm_model\n            opts, fields = model._meta, []\n            name = model.__name__.lower()\n            for key in ('add', 'change', 'delete'):\n                perm_code = '%s.%s' % (opts.app_label, get_permission_codename(key, opts))\n                if request.user.has_perm(perm_code):\n                    fields.append('can_%s_%s' % (key, name))\n            if fields:\n                fieldsets.insert(2 + i, (title, {'fields': (fields,)}))\n        return fieldsets\n\n    def _has_change_permissions_permission(self, request):\n        \"\"\"\n        User is able to add/change objects only if he haves can change\n        permission on some page.\n        \"\"\"\n        try:\n            get_user_permission_level(request.user)\n        except NoPermissionsException:\n            return False\n        return True\n\n    def has_add_permission(self, request):\n        return self._has_change_permissions_permission(request) and \\\n               super(self.__class__, self).has_add_permission(request)\n\n    def has_change_permission(self, request, obj=None):\n        return self._has_change_permissions_permission(request) and \\\n               super(self.__class__, self).has_change_permission(request, obj)\n\n\nif get_cms_setting('PERMISSION'):\n    admin.site.register(GlobalPagePermission, GlobalPagePermissionAdmin)\n    PERMISSION_ADMIN_INLINES.extend([\n        ViewRestrictionInlineAdmin,\n        PagePermissionInlineAdmin,\n    ])\n\n" }
{ "repo_name": "ppiotr/Bibedit-some-refactoring", "ref": "refs/heads/bibedit-hp-change-to-field-with-many-instances", "path": "modules/bibcheck/web/admin/bibcheckadmin.py", "content": "## This file is part of CDS Invenio.\n## Copyright (C) 2002, 2003, 2004, 2005, 2006, 2007, 2008 CERN.\n##\n## CDS Invenio is free software; you can redistribute it and/or\n## modify it under the terms of the GNU General Public License as\n## published by the Free Software Foundation; either version 2 of the\n## License, or (at your option) any later version.\n##\n## CDS Invenio is distributed in the hope that it will be useful, but\n## WITHOUT ANY WARRANTY; without even the implied warranty of\n## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n## General Public License for more details.\n##\n## You should have received a copy of the GNU General Public License\n## along with CDS Invenio; if not, write to the Free Software Foundation, Inc.,\n## 59 Temple Place, Suite 330, Boston, MA 02111-1307, USA.\n\n\"\"\"CDS Invenio BibCheck Administrator Interface.\"\"\"\n\nimport cgi\nimport os\nimport os.path\nimport MySQLdb\nfrom invenio.bibrankadminlib import check_user\nfrom invenio.webpage import page, create_error_box\nfrom invenio.webuser import getUid, page_not_authorized\nfrom invenio.messages import wash_language, gettext_set_language\n#from invenio.urlutils import wash_url_argument, redirect_to_url\nfrom invenio.config import CFG_SITE_LANG, CFG_SITE_URL, \\\n                           CFG_SITE_NAME, CFG_ETCDIR, CFG_BINDIR\n\n__lastupdated__ = \"\"\"$Date$\"\"\"\n\n\ndef is_admin(req):\n    \"\"\"checks if the user has the rights (etc)\"\"\"\n    # Check if user is authorized to administer\n    uid = 0\n    try:\n        uid = getUid(req)\n    except MySQLdb.Error:\n        return error_page(req)\n    (auth_code, auth_msg) = check_user(req, 'cfgbibformat')\n    if not auth_code:\n        return (True, uid)\n    else:\n        return (False, uid)\n\n\ndef index(req, search=\"\", ln=CFG_SITE_LANG):\n    \"\"\"\n    Main BibCheck administration page.\n    @param ln: language\n    \"\"\"\n    ln = wash_language(ln)\n    _ = gettext_set_language(ln)\n    navtrail = \"\"\"<a class=\"navtrail\" href=\"%s/help/admin\">%s</a>\"\"\" % \\\n               (CFG_SITE_URL, _(\"Admin Area\"))\n    (admin_ok, uid) = is_admin(req)\n    if admin_ok:\n        return page(title=_(\"BibCheck Admin\"),\n                body=_perform_request_index(ln, search),\n                language=ln,\n                uid=uid,\n                navtrail = navtrail,\n                lastupdated=__lastupdated__,\n                req=req,\n                warnings=[])\n    else:\n        #redirect to login\n        return page_not_authorized(req=req, text=_(\"Not authorized\"), navtrail=navtrail)\n\n\ndef _perform_request_index(ln, search=\"\"):\n    \"\"\" makes a listing of files that are found in etc/bibcheck.\n        Include a delete button for each. \"\"\"\n    ln = wash_language(ln)\n    _ = gettext_set_language(ln)\n    mydir = CFG_ETCDIR+\"/bibcheck\"\n    if not os.path.exists(mydir):\n        return _(\"ERROR\")+\" \"+mydir+\" \"+_(\"does not exist\")\n    if not os.path.isdir(mydir):\n        return  _(\"ERROR\")+\" \"+mydir+\" \"+_(\"is not a directory\")\n    if not os.access(mydir, os.W_OK):\n        return  _(\"ERROR\")+\" \"+mydir+\" \"+_(\"is not writable\")\n    myfiles = os.listdir(mydir)\n    if search:\n        #include only files that match\n        matching = []\n        for myfile in myfiles:\n            if (myfile.count(search) > 0):\n                matching.append(myfile)\n            else: #see if the string is in the file\n                mypath = CFG_ETCDIR+\"/bibcheck/\"+myfile\n                infile = file(mypath, 'r')\n                filelines = infile.readlines()\n                for line in filelines:\n                    if line.count(search) > 0:\n                        matching.append(myfile)\n                        break\n                infile.close()\n        myfiles = matching\n    lines = \"\"\n    #add a search box\n    lines += \"\"\"\n        <!--make a search box-->\n        <table class=\"admin_wvar\" cellspacing=\"0\">\n        <tr><td>\n        <form action=\"%(siteurl)s/admin/bibcheck/bibcheckadmin.py/index\">\n          %(searchforastr)s\n          <input type=\"text\" name=\"search\" value=\"%(search)s\" />\n          <input type=\"hidden\" name=\"ln\" value=\"%(ln)s\" />\n          <input type=\"submit\" class=\"adminbutton\" value=\"Search\">\n          </form>\n          </td></tr></table> \"\"\" % { 'siteurl': CFG_SITE_URL,\n                                     'search': search,\n                                     'ln': ln,\n                                      'searchforastr': _(\"Limit to knowledge bases containing string:\") }\n    if myfiles:\n        #create a table..\n        oddstripestyle = 'style=\"background-color: rgb(235, 247, 255);\"' #for every other line\n        lines += '<table class=\"admin_wvar\">\\n'\n        isodd = True\n        myfiles.sort()\n        for myfile in myfiles:\n            mystyle = \"\"\n            if isodd:\n                mystyle = oddstripestyle\n            isodd = not isodd\n            lines += \"<tr \"+mystyle+\">\"\n            line = '<td>' + cgi.escape(myfile) + '</td>'\n            line += '<td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>'\n            line += '<td><a href=\"%s/admin/bibcheck/bibcheckadmin.py/edit?fname=' % CFG_SITE_URL + \\\n                    myfile+'&ln='+ln+'\">Edit</a></td>'\n            line += '<td>&nbsp;&nbsp;&nbsp;</td>'\n            reallydelq = _(\"Really delete\")+\" \"+myfile+\"?\"\n            line += '<td><a href=\"%s/admin/bibcheck/bibcheckadmin.py/delete?fname=' % CFG_SITE_URL + \\\n                    myfile+'&ln='+ln+'\" onclick=\"return confirm(\\''+reallydelq+'\\');\">'+_(\"Delete\")+'</a></td>'\n            #verify syntax..\n            line += '<td>&nbsp;&nbsp;&nbsp;</td>'\n            line += '<td><a href=\"%s/admin/bibcheck/bibcheckadmin.py/verify?fname=' % CFG_SITE_URL + \\\n                    myfile+'&ln='+ln+'\">'+_(\"Verify syntax\")+'</a></td>'\n            lines += line+\"</tr>\\n\"\n        lines += \"</table>\\n\"\n    myout = lines\n    myout += \"<br/><br/><a href=\\\"%s/admin/bibcheck/bibcheckadmin.py/edit\\\">\" % CFG_SITE_URL + \\\n             _(\"Create new\")+\"</a>\"\n    return myout\n\ndef verify(req, fname, ln=CFG_SITE_LANG):\n    \"\"\"verify syntax by calling an external checking program\"\"\"\n    ln = wash_language(ln)\n    _ = gettext_set_language(ln)\n    (admin_ok, uid) = is_admin(req)\n\n    # sanity check for fname:\n    fname = os.path.basename(fname)\n\n    navtrail = \"\"\"<a class=\"navtrail\" href=\"%s/help/admin\">%s</a>\"\"\" % \\\n               (CFG_SITE_URL, _(\"Admin Area\"))\n    navtrail += \"\"\"&gt; <a class=\"navtrail\" href=\"%s/admin/bibcheck/bibcheckadmin.py/\">BibCheck Admin</a> \"\"\" % CFG_SITE_URL\n    errors = \"\"\n    outstr = \"\"\n    errstr = \"\"\n    path_to_bibcheck_cli = CFG_BINDIR + os.sep + 'bibcheck'\n    if not os.path.exists(path_to_bibcheck_cli):\n        errors = _(\"File %s does not exist.\") % path_to_bibcheck_cli\n    if not errors:\n        #first check where we have stderr now so that we can assign it back\n        try:\n            (handle, mystdout, mystderr) = os.popen3(path_to_bibcheck_cli + \" --verify\" + fname)\n            outstr = str(mystdout.readlines())\n            errstr = str(mystderr.readlines())\n        except:\n            #the call failed?\n            errors = _(\"Calling bibcheck -verify failed.\")\n    if not errors:\n        if not errstr:\n            return \"OK\"\n        else:\n            return errstr\n    else:\n        return page(title=_(\"Verify BibCheck config file\"),\n                body= _(\"Verify problem\")+\":<br/>\"+errors,\n                language= ln,\n                uid=uid,\n                navtrail = navtrail,\n                lastupdated=__lastupdated__,\n                req=req,\n                warnings=[])\n\ndef edit(req, ln=CFG_SITE_LANG, fname=\"\"):\n    \"\"\" creates an editor for the file. This is called also when the user wants to\n        create a new file. In the case fname is empty\"\"\"\n    ln = wash_language(ln)\n    _ = gettext_set_language(ln)\n\n    # sanity check for fname:\n    fname = os.path.basename(fname)\n\n    #check auth\n    (admin_ok, uid) = is_admin(req)\n    navtrail = \"\"\"<a class=\"navtrail\" href=\"%s/help/admin\">%s</a>\"\"\" % \\\n               (CFG_SITE_URL, _(\"Admin Area\"))\n    navtrail += \"\"\"&gt; <a class=\"navtrail\" href=\"%s/admin/bibcheck/bibcheckadmin.py/\">BibCheck Admin</a> \"\"\" % CFG_SITE_URL\n    myout = _(\"File\")+\" \" + cgi.escape(fname) + \"<br/>\"\n    if admin_ok:\n        #add a javascript checker so that the user cannot save a form with empty\n        #fname\n        myout += \"\"\"<script language=\"JavaScript\" type=\"text/javascript\">\n                    <!--\n                     function checkform ( form ) { if (form.fname.value == \"\") {\n                              alert( \"Missing filename.\" ); form.fname.focus(); return false ;\n                          }\n                            return true ;\n                    }\n                     -->\n                     </script>\"\"\"\n\n\n        #read the file if there is one\n        filelines = []\n        if fname:\n            myfile = CFG_ETCDIR+\"/bibcheck/\"+fname\n            infile = file(myfile, 'r')\n            filelines = infile.readlines()\n            infile.close()\n        myout += '<form method=\"post\" action=\"save\" onsubmit=\"return checkform(this);\">'\n        #create a filename dialog box if there is no fname, otherwise it's hidden\n        if fname:\n            myout += '<input type=\"hidden\" name=\"fname\" value=\"'+fname+'\">'\n        else:\n            myout += '<input name=\"fname\" value=\"'+fname+'\"><br/>'\n            myout += '<input type=\"hidden\" name=\"wasnew\" value=\"1\">'\n        myout += '<input type=\"hidden\" name=\"ln\" value=\"'+ln+'\">'\n        myout += '<textarea name=\"code\" id=\"code\" rows=\"25\" style=\"width:100%\">'\n        for line in filelines:\n            myout += line\n        #create a save button\n        myout += '</textarea><br/><input type=\"submit\" name=\"save\" value=\"'+_(\"Save Changes\")+'\"></form>'\n        #create page\n        return page(title=_(\"Edit BibCheck config file\"),\n                body= myout,\n                language= ln,\n                uid=uid,\n                navtrail = navtrail,\n                lastupdated=__lastupdated__,\n                req=req,\n                warnings=[])\n    else: #not admin\n        return page_not_authorized(req=req, text=_(\"Not authorized\"), navtrail=navtrail)\n\ndef save(req, ln, fname, code, wasnew=0):\n    \"\"\"saves code into file fname. wasnew is 1 if this is a new file\"\"\"\n    ln = wash_language(ln)\n    _ = gettext_set_language(ln)\n\n    # sanity check for fname:\n    fname = os.path.basename(fname)\n\n    #check auth\n    (admin_ok, uid) = is_admin(req)\n    navtrail = '''<a class=\"navtrail\" href=\"%s/help/admin\">%s</a>''' % \\\n               (CFG_SITE_URL, _(\"Admin Area\"))\n    navtrail += \"\"\"&gt; <a class=\"navtrail\" href=\"%s/admin/bibcheck/bibcheckadmin.py/\">BibCheck Admin</a> \"\"\" % CFG_SITE_URL\n    myout = _(\"File\")+\" \" + cgi.escape(fname) + \" \"\n    if admin_ok:\n        myfile = CFG_ETCDIR+\"/bibcheck/\"+fname\n        #check if the file exists if this was new\n        if wasnew and os.path.exists(myfile):\n            msg = myout+\" \"+_(\"already exists.\")\n        else:\n            #write code into file\n            msg = myout+_(\"written OK.\")\n            try:\n                outfile = file(myfile, 'w')\n                outfile.write(code)\n                outfile.close()\n            except IOError:\n                msg = myout+_(\"write failed.\")\n        #print message\n        return page(title=_(\"Save BibCheck config file\"),\n                body= msg,\n                language= ln,\n                uid=uid,\n                navtrail = navtrail,\n                lastupdated=__lastupdated__,\n                req=req,\n                warnings=[])\n    else:\n        return page_not_authorized(req=req, text=_(\"Not authorized\"), navtrail=navtrail)\n\ndef delete(req, ln, fname):\n    \"\"\"delete file fname\"\"\"\n    ln = wash_language(ln)\n    _ = gettext_set_language(ln)\n\n    # sanity check for fname:\n    fname = os.path.basename(fname)\n\n    #check auth\n    (admin_ok, uid) = is_admin(req)\n    navtrail = \"\"\"<a class=\"navtrail\" href=\"%s/help/admin\">%s</a>\"\"\" % \\\n               (CFG_SITE_URL, _(\"Admin Area\"))\n    navtrail += \"\"\"&gt; <a class=\"navtrail\" href=\"%s/admin/bibcheck/bibcheckadmin.py/\">BibCheck Admin</a> \"\"\" % CFG_SITE_URL\n    myout = _(\"File\")+\" \"+fname+\" \"\n    if admin_ok:\n        msg = \"\"\n        myfile = CFG_ETCDIR+\"/bibcheck/\"+fname\n        success = 1\n        try:\n            os.remove(myfile)\n        except:\n            success = 0\n        if success:\n            msg = myout+_(\"deleted\")+\".\"\n        else:\n            msg = myout+_(\"delete failed\")+\".\"\n        #print message\n        return page(title=_(\"Delete BibCheck config file\"),\n                body= msg,\n                language= ln,\n                uid=uid,\n                navtrail = navtrail,\n                lastupdated=__lastupdated__,\n                req=req,\n                warnings=[])\n    else:\n        return page_not_authorized(req=req, text=_(\"Not authorized\"), navtrail=navtrail)\n\ndef error_page(req, ln=CFG_SITE_LANG, verbose=1):\n    \"\"\"Generic error .. in case one cannot find anything more specific\"\"\"\n    _ = gettext_set_language(ln)\n    return page(title=_(\"Internal Error\"),\n                body = create_error_box(req, verbose=verbose, ln=ln),\n                description=\"%s - Internal Error\" % CFG_SITE_NAME,\n                keywords=\"%s, Internal Error\" % CFG_SITE_NAME,\n                language=ln,\n                req=req)\n\n\n" }
{ "repo_name": "Arakmar/Sick-Beard", "ref": "refs/heads/development", "path": "lib/requests/packages/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "sallaire/Sick-Beard", "ref": "refs/heads/development", "path": "lib/requests/packages/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "eptmp3/Sick-Beard", "ref": "refs/heads/development", "path": "lib/requests/packages/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "puzzlet/chardet", "ref": "refs/heads/MarkPilgrim", "path": "src-python2/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "brinbois/Sick-Beard", "ref": "refs/heads/development", "path": "lib/requests/packages/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "stonewell/learn-curve", "ref": "refs/heads/main", "path": "modules/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "murfz/Sick-Beard", "ref": "refs/heads/development", "path": "lib/requests/packages/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "fernandog/Sick-Beard", "ref": "refs/heads/ThePirateBay", "path": "lib/requests/packages/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "LittleLama/Sick-Beard-BoxCar2", "ref": "refs/heads/development", "path": "lib/requests/packages/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "cstan11/Sick-Beard", "ref": "refs/heads/torrent_1080_subtitles", "path": "lib/requests/packages/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "mano3m/CouchPotatoServer", "ref": "refs/heads/develop_mano3m", "path": "libs/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "bob123bob/Sick-Beard", "ref": "refs/heads/development", "path": "lib/requests/packages/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "tquizzle/Sick-Beard", "ref": "refs/heads/development", "path": "lib/requests/packages/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "flotre/Sick-Beard", "ref": "refs/heads/development", "path": "lib/requests/packages/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "alexpap/exareme", "ref": "refs/heads/mip", "path": "exareme-tools/madis/src/lib/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "rui-castro/Sick-Beard", "ref": "refs/heads/torrent_1080_subtitles", "path": "lib/requests/packages/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "Taranys/Sick-Beard", "ref": "refs/heads/development", "path": "lib/requests/packages/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "Fafou/Sick-Beard", "ref": "refs/heads/development", "path": "lib/requests/packages/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "jymannob/Sick-Beard", "ref": "refs/heads/development", "path": "lib/requests/packages/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "Pistachitos/Sick-Beard", "ref": "refs/heads/Pistachitos", "path": "lib/requests/packages/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "cyril51/Sick-Beard", "ref": "refs/heads/development", "path": "lib/requests/packages/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "icucinema/madcow", "ref": "refs/heads/icu-cinema-deployment", "path": "madcow/include/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "pepetreshere/odoo", "ref": "refs/heads/patch-2", "path": "addons/website_event_meet/models/__init__.py", "content": "# -*- coding: utf-8 -*-\n# Part of Odoo. See LICENSE file for full copyright and licensing details.\n\nfrom . import event_event\nfrom . import event_type\nfrom . import event_meeting_room\nfrom . import ir_autovacuum\nfrom . import website_event_menu\n" }
{ "repo_name": "navycrow/Sick-Beard", "ref": "refs/heads/development", "path": "lib/requests/packages/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "kobolabs/calibre", "ref": "refs/heads/kobo", "path": "src/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "mozvip/Sick-Beard", "ref": "refs/heads/development", "path": "lib/requests/packages/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "MadCat34/Sick-Beard", "ref": "refs/heads/development", "path": "lib/requests/packages/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "gtko/Sick-Beard", "ref": "refs/heads/development", "path": "lib/requests/packages/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "nadley/Sick-Beard", "ref": "refs/heads/development", "path": "lib/requests/packages/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "sss/calibre-at-bzr", "ref": "refs/heads/upstream/master", "path": "src/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "l0b0/cds-invenio-vengmark", "ref": "refs/heads/install-from-source", "path": "modules/bibcheck/web/admin/bibcheckadmin.py", "content": "## This file is part of CDS Invenio.\n## Copyright (C) 2002, 2003, 2004, 2005, 2006, 2007, 2008 CERN.\n##\n## CDS Invenio is free software; you can redistribute it and/or\n## modify it under the terms of the GNU General Public License as\n## published by the Free Software Foundation; either version 2 of the\n## License, or (at your option) any later version.\n##\n## CDS Invenio is distributed in the hope that it will be useful, but\n## WITHOUT ANY WARRANTY; without even the implied warranty of\n## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n## General Public License for more details.\n##\n## You should have received a copy of the GNU General Public License\n## along with CDS Invenio; if not, write to the Free Software Foundation, Inc.,\n## 59 Temple Place, Suite 330, Boston, MA 02111-1307, USA.\n\n\"\"\"CDS Invenio BibCheck Administrator Interface.\"\"\"\n\nimport cgi\nimport os\nimport os.path\nimport MySQLdb\nfrom invenio.bibrankadminlib import check_user\nfrom invenio.webpage import page, create_error_box\nfrom invenio.webuser import getUid, page_not_authorized\nfrom invenio.messages import wash_language, gettext_set_language\n#from invenio.urlutils import wash_url_argument, redirect_to_url\nfrom invenio.config import CFG_SITE_LANG, CFG_SITE_URL, \\\n                           CFG_SITE_NAME, CFG_ETCDIR, CFG_BINDIR\n\n__lastupdated__ = \"\"\"$Date$\"\"\"\n\n\ndef is_admin(req):\n    \"\"\"checks if the user has the rights (etc)\"\"\"\n    # Check if user is authorized to administer\n    uid = 0\n    try:\n        uid = getUid(req)\n    except MySQLdb.Error:\n        return error_page(req)\n    (auth_code, auth_msg) = check_user(req, 'cfgbibformat')\n    if not auth_code:\n        return (True, uid)\n    else:\n        return (False, uid)\n\n\ndef index(req, search=\"\", ln=CFG_SITE_LANG):\n    \"\"\"\n    Main BibCheck administration page.\n    @param ln: language\n    \"\"\"\n    ln = wash_language(ln)\n    _ = gettext_set_language(ln)\n    navtrail = \"\"\"<a class=\"navtrail\" href=\"%s/help/admin\">%s</a>\"\"\" % \\\n               (CFG_SITE_URL, _(\"Admin Area\"))\n    (admin_ok, uid) = is_admin(req)\n    if admin_ok:\n        return page(title=_(\"BibCheck Admin\"),\n                body=_perform_request_index(ln, search),\n                language=ln,\n                uid=uid,\n                navtrail = navtrail,\n                lastupdated=__lastupdated__,\n                req=req,\n                warnings=[])\n    else:\n        #redirect to login\n        return page_not_authorized(req=req, text=_(\"Not authorized\"), navtrail=navtrail)\n\n\ndef _perform_request_index(ln, search=\"\"):\n    \"\"\" makes a listing of files that are found in etc/bibcheck.\n        Include a delete button for each. \"\"\"\n    ln = wash_language(ln)\n    _ = gettext_set_language(ln)\n    mydir = CFG_ETCDIR+\"/bibcheck\"\n    if not os.path.exists(mydir):\n        return _(\"ERROR\")+\" \"+mydir+\" \"+_(\"does not exist\")\n    if not os.path.isdir(mydir):\n        return  _(\"ERROR\")+\" \"+mydir+\" \"+_(\"is not a directory\")\n    if not os.access(mydir, os.W_OK):\n        return  _(\"ERROR\")+\" \"+mydir+\" \"+_(\"is not writable\")\n    myfiles = os.listdir(mydir)\n    if search:\n        #include only files that match\n        matching = []\n        for myfile in myfiles:\n            if (myfile.count(search) > 0):\n                matching.append(myfile)\n            else: #see if the string is in the file\n                mypath = CFG_ETCDIR+\"/bibcheck/\"+myfile\n                infile = file(mypath, 'r')\n                filelines = infile.readlines()\n                for line in filelines:\n                    if line.count(search) > 0:\n                        matching.append(myfile)\n                        break\n                infile.close()\n        myfiles = matching\n    lines = \"\"\n    #add a search box\n    lines += \"\"\"\n        <!--make a search box-->\n        <table class=\"admin_wvar\" cellspacing=\"0\">\n        <tr><td>\n        <form action=\"%(siteurl)s/admin/bibcheck/bibcheckadmin.py/index\">\n          %(searchforastr)s\n          <input type=\"text\" name=\"search\" value=\"%(search)s\" />\n          <input type=\"hidden\" name=\"ln\" value=\"%(ln)s\" />\n          <input type=\"submit\" class=\"adminbutton\" value=\"Search\">\n          </form>\n          </td></tr></table> \"\"\" % { 'siteurl': CFG_SITE_URL,\n                                     'search': search,\n                                     'ln': ln,\n                                      'searchforastr': _(\"Limit to knowledge bases containing string:\") }\n    if myfiles:\n        #create a table..\n        oddstripestyle = 'style=\"background-color: rgb(235, 247, 255);\"' #for every other line\n        lines += '<table class=\"admin_wvar\">\\n'\n        isodd = True\n        myfiles.sort()\n        for myfile in myfiles:\n            mystyle = \"\"\n            if isodd:\n                mystyle = oddstripestyle\n            isodd = not isodd\n            lines += \"<tr \"+mystyle+\">\"\n            line = '<td>' + cgi.escape(myfile) + '</td>'\n            line += '<td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>'\n            line += '<td><a href=\"%s/admin/bibcheck/bibcheckadmin.py/edit?fname=' % CFG_SITE_URL + \\\n                    myfile+'&ln='+ln+'\">Edit</a></td>'\n            line += '<td>&nbsp;&nbsp;&nbsp;</td>'\n            reallydelq = _(\"Really delete\")+\" \"+myfile+\"?\"\n            line += '<td><a href=\"%s/admin/bibcheck/bibcheckadmin.py/delete?fname=' % CFG_SITE_URL + \\\n                    myfile+'&ln='+ln+'\" onclick=\"return confirm(\\''+reallydelq+'\\');\">'+_(\"Delete\")+'</a></td>'\n            #verify syntax..\n            line += '<td>&nbsp;&nbsp;&nbsp;</td>'\n            line += '<td><a href=\"%s/admin/bibcheck/bibcheckadmin.py/verify?fname=' % CFG_SITE_URL + \\\n                    myfile+'&ln='+ln+'\">'+_(\"Verify syntax\")+'</a></td>'\n            lines += line+\"</tr>\\n\"\n        lines += \"</table>\\n\"\n    myout = lines\n    myout += \"<br/><br/><a href=\\\"%s/admin/bibcheck/bibcheckadmin.py/edit\\\">\" % CFG_SITE_URL + \\\n             _(\"Create new\")+\"</a>\"\n    return myout\n\ndef verify(req, fname, ln=CFG_SITE_LANG):\n    \"\"\"verify syntax by calling an external checking program\"\"\"\n    ln = wash_language(ln)\n    _ = gettext_set_language(ln)\n    (admin_ok, uid) = is_admin(req)\n\n    # sanity check for fname:\n    fname = os.path.basename(fname)\n\n    navtrail = \"\"\"<a class=\"navtrail\" href=\"%s/help/admin\">%s</a>\"\"\" % \\\n               (CFG_SITE_URL, _(\"Admin Area\"))\n    navtrail += \"\"\"&gt; <a class=\"navtrail\" href=\"%s/admin/bibcheck/bibcheckadmin.py/\">BibCheck Admin</a> \"\"\" % CFG_SITE_URL\n    errors = \"\"\n    outstr = \"\"\n    errstr = \"\"\n    path_to_bibcheck_cli = CFG_BINDIR + os.sep + 'bibcheck'\n    if not os.path.exists(path_to_bibcheck_cli):\n        errors = _(\"File %s does not exist.\") % path_to_bibcheck_cli\n    if not errors:\n        #first check where we have stderr now so that we can assign it back\n        try:\n            (handle, mystdout, mystderr) = os.popen3(path_to_bibcheck_cli + \" --verify\" + fname)\n            outstr = str(mystdout.readlines())\n            errstr = str(mystderr.readlines())\n        except:\n            #the call failed?\n            errors = _(\"Calling bibcheck -verify failed.\")\n    if not errors:\n        if not errstr:\n            return \"OK\"\n        else:\n            return errstr\n    else:\n        return page(title=_(\"Verify BibCheck config file\"),\n                body= _(\"Verify problem\")+\":<br/>\"+errors,\n                language= ln,\n                uid=uid,\n                navtrail = navtrail,\n                lastupdated=__lastupdated__,\n                req=req,\n                warnings=[])\n\ndef edit(req, ln=CFG_SITE_LANG, fname=\"\"):\n    \"\"\" creates an editor for the file. This is called also when the user wants to\n        create a new file. In the case fname is empty\"\"\"\n    ln = wash_language(ln)\n    _ = gettext_set_language(ln)\n\n    # sanity check for fname:\n    fname = os.path.basename(fname)\n\n    #check auth\n    (admin_ok, uid) = is_admin(req)\n    navtrail = \"\"\"<a class=\"navtrail\" href=\"%s/help/admin\">%s</a>\"\"\" % \\\n               (CFG_SITE_URL, _(\"Admin Area\"))\n    navtrail += \"\"\"&gt; <a class=\"navtrail\" href=\"%s/admin/bibcheck/bibcheckadmin.py/\">BibCheck Admin</a> \"\"\" % CFG_SITE_URL\n    myout = _(\"File\")+\" \" + cgi.escape(fname) + \"<br/>\"\n    if admin_ok:\n        #add a javascript checker so that the user cannot save a form with empty\n        #fname\n        myout += \"\"\"<script language=\"JavaScript\" type=\"text/javascript\">\n                    <!--\n                     function checkform ( form ) { if (form.fname.value == \"\") {\n                              alert( \"Missing filename.\" ); form.fname.focus(); return false ;\n                          }\n                            return true ;\n                    }\n                     -->\n                     </script>\"\"\"\n\n\n        #read the file if there is one\n        filelines = []\n        if fname:\n            myfile = CFG_ETCDIR+\"/bibcheck/\"+fname\n            infile = file(myfile, 'r')\n            filelines = infile.readlines()\n            infile.close()\n        myout += '<form method=\"post\" action=\"save\" onsubmit=\"return checkform(this);\">'\n        #create a filename dialog box if there is no fname, otherwise it's hidden\n        if fname:\n            myout += '<input type=\"hidden\" name=\"fname\" value=\"'+fname+'\">'\n        else:\n            myout += '<input name=\"fname\" value=\"'+fname+'\"><br/>'\n            myout += '<input type=\"hidden\" name=\"wasnew\" value=\"1\">'\n        myout += '<input type=\"hidden\" name=\"ln\" value=\"'+ln+'\">'\n        myout += '<textarea name=\"code\" id=\"code\" rows=\"25\" style=\"width:100%\">'\n        for line in filelines:\n            myout += line\n        #create a save button\n        myout += '</textarea><br/><input type=\"submit\" name=\"save\" value=\"'+_(\"Save Changes\")+'\"></form>'\n        #create page\n        return page(title=_(\"Edit BibCheck config file\"),\n                body= myout,\n                language= ln,\n                uid=uid,\n                navtrail = navtrail,\n                lastupdated=__lastupdated__,\n                req=req,\n                warnings=[])\n    else: #not admin\n        return page_not_authorized(req=req, text=_(\"Not authorized\"), navtrail=navtrail)\n\ndef save(req, ln, fname, code, wasnew=0):\n    \"\"\"saves code into file fname. wasnew is 1 if this is a new file\"\"\"\n    ln = wash_language(ln)\n    _ = gettext_set_language(ln)\n\n    # sanity check for fname:\n    fname = os.path.basename(fname)\n\n    #check auth\n    (admin_ok, uid) = is_admin(req)\n    navtrail = '''<a class=\"navtrail\" href=\"%s/help/admin\">%s</a>''' % \\\n               (CFG_SITE_URL, _(\"Admin Area\"))\n    navtrail += \"\"\"&gt; <a class=\"navtrail\" href=\"%s/admin/bibcheck/bibcheckadmin.py/\">BibCheck Admin</a> \"\"\" % CFG_SITE_URL\n    myout = _(\"File\")+\" \" + cgi.escape(fname) + \" \"\n    if admin_ok:\n        myfile = CFG_ETCDIR+\"/bibcheck/\"+fname\n        #check if the file exists if this was new\n        if wasnew and os.path.exists(myfile):\n            msg = myout+\" \"+_(\"already exists.\")\n        else:\n            #write code into file\n            msg = myout+_(\"written OK.\")\n            try:\n                outfile = file(myfile, 'w')\n                outfile.write(code)\n                outfile.close()\n            except IOError:\n                msg = myout+_(\"write failed.\")\n        #print message\n        return page(title=_(\"Save BibCheck config file\"),\n                body= msg,\n                language= ln,\n                uid=uid,\n                navtrail = navtrail,\n                lastupdated=__lastupdated__,\n                req=req,\n                warnings=[])\n    else:\n        return page_not_authorized(req=req, text=_(\"Not authorized\"), navtrail=navtrail)\n\ndef delete(req, ln, fname):\n    \"\"\"delete file fname\"\"\"\n    ln = wash_language(ln)\n    _ = gettext_set_language(ln)\n\n    # sanity check for fname:\n    fname = os.path.basename(fname)\n\n    #check auth\n    (admin_ok, uid) = is_admin(req)\n    navtrail = \"\"\"<a class=\"navtrail\" href=\"%s/help/admin\">%s</a>\"\"\" % \\\n               (CFG_SITE_URL, _(\"Admin Area\"))\n    navtrail += \"\"\"&gt; <a class=\"navtrail\" href=\"%s/admin/bibcheck/bibcheckadmin.py/\">BibCheck Admin</a> \"\"\" % CFG_SITE_URL\n    myout = _(\"File\")+\" \"+fname+\" \"\n    if admin_ok:\n        msg = \"\"\n        myfile = CFG_ETCDIR+\"/bibcheck/\"+fname\n        success = 1\n        try:\n            os.remove(myfile)\n        except:\n            success = 0\n        if success:\n            msg = myout+_(\"deleted\")+\".\"\n        else:\n            msg = myout+_(\"delete failed\")+\".\"\n        #print message\n        return page(title=_(\"Delete BibCheck config file\"),\n                body= msg,\n                language= ln,\n                uid=uid,\n                navtrail = navtrail,\n                lastupdated=__lastupdated__,\n                req=req,\n                warnings=[])\n    else:\n        return page_not_authorized(req=req, text=_(\"Not authorized\"), navtrail=navtrail)\n\ndef error_page(req, ln=CFG_SITE_LANG, verbose=1):\n    \"\"\"Generic error .. in case one cannot find anything more specific\"\"\"\n    _ = gettext_set_language(ln)\n    return page(title=_(\"Internal Error\"),\n                body = create_error_box(req, verbose=verbose, ln=ln),\n                description=\"%s - Internal Error\" % CFG_SITE_NAME,\n                keywords=\"%s, Internal Error\" % CFG_SITE_NAME,\n                language=ln,\n                req=req)\n\n\n" }
{ "repo_name": "foufou55/Sick-Beard", "ref": "refs/heads/development", "path": "lib/requests/packages/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "gromez/Sick-Beard", "ref": "refs/heads/development", "path": "lib/requests/packages/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "Kiiv/Sick-Beard", "ref": "refs/heads/development", "path": "lib/requests/packages/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "sh4t/Sick-Beard", "ref": "refs/heads/development", "path": "lib/requests/packages/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "yannickcr/Sick-Beard", "ref": "refs/heads/development", "path": "lib/requests/packages/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "BaesFr/Sick-Beard", "ref": "refs/heads/development", "path": "lib/requests/packages/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "RAtechntukan/Sick-Beard", "ref": "refs/heads/development", "path": "lib/requests/packages/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "kinooo/Sick-Beard", "ref": "refs/heads/development", "path": "lib/requests/packages/chardet/codingstatemachine.py", "content": "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is mozilla.org code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n# \n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n# \n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom constants import eStart, eError, eItsMe\n\nclass CodingStateMachine:\n    def __init__(self, sm):\n        self._mModel = sm\n        self._mCurrentBytePos = 0\n        self._mCurrentCharLen = 0\n        self.reset()\n\n    def reset(self):\n        self._mCurrentState = eStart\n\n    def next_state(self, c):\n        # for each byte we get its class\n        # if it is first byte, we also get byte length\n        byteCls = self._mModel['classTable'][ord(c)]\n        if self._mCurrentState == eStart:\n            self._mCurrentBytePos = 0\n            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]\n        # from byte's class and stateTable, we get its next state\n        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]\n        self._mCurrentBytePos += 1\n        return self._mCurrentState\n\n    def get_current_charlen(self):\n        return self._mCurrentCharLen\n\n    def get_coding_state_machine(self):\n        return self._mModel['name']\n" }
{ "repo_name": "nubark/odoo", "ref": "refs/heads/9.0", "path": "addons/account/tests/test_manual_reconciliation.py", "content": "from openerp.addons.account.tests.account_test_classes import AccountingTestCase\n\nclass TestManualReconciliation(AccountingTestCase):\n\n    def test_reconciliation_proposition(self):\n        pass\n\n    def test_full_reconcile(self):\n        pass\n\n    def test_partial_reconcile(self):\n        pass\n\n    def test_reconcile_with_write_off(self):\n        pass\n" }
{ "repo_name": "allenp/odoo", "ref": "refs/heads/9.0", "path": "addons/account/tests/test_manual_reconciliation.py", "content": "from openerp.addons.account.tests.account_test_classes import AccountingTestCase\n\nclass TestManualReconciliation(AccountingTestCase):\n\n    def test_reconciliation_proposition(self):\n        pass\n\n    def test_full_reconcile(self):\n        pass\n\n    def test_partial_reconcile(self):\n        pass\n\n    def test_reconcile_with_write_off(self):\n        pass\n" }
{ "repo_name": "odoobgorg/odoo", "ref": "refs/heads/9.0", "path": "addons/account/tests/test_manual_reconciliation.py", "content": "from openerp.addons.account.tests.account_test_classes import AccountingTestCase\n\nclass TestManualReconciliation(AccountingTestCase):\n\n    def test_reconciliation_proposition(self):\n        pass\n\n    def test_full_reconcile(self):\n        pass\n\n    def test_partial_reconcile(self):\n        pass\n\n    def test_reconcile_with_write_off(self):\n        pass\n" }
{ "repo_name": "Elico-Corp/odoo_OCB", "ref": "refs/heads/9.0", "path": "addons/account/tests/test_manual_reconciliation.py", "content": "from openerp.addons.account.tests.account_test_classes import AccountingTestCase\n\nclass TestManualReconciliation(AccountingTestCase):\n\n    def test_reconciliation_proposition(self):\n        pass\n\n    def test_full_reconcile(self):\n        pass\n\n    def test_partial_reconcile(self):\n        pass\n\n    def test_reconcile_with_write_off(self):\n        pass\n" }
{ "repo_name": "Vauxoo/server-tools", "ref": "refs/heads/12.0", "path": "company_country/migrations/12.0.1.0.2/pre-migration.py", "content": "import logging\nfrom psycopg2.extensions import AsIs\n\nfrom odoo import tools\n\n\n_logger = logging.getLogger(__name__)\n\n\ndef migrate(cr, version):\n    drop_table_model_company_country(cr)\n\n\ndef drop_table_model_company_country(cr):\n    tablename = 'company_country_config_settings'\n    if tools.table_exists(cr, tablename):\n        _logger.info(\"Dropping table %s\", tablename)\n        cr.execute(\"DROP TABLE IF EXISTS %s;\", (AsIs(tablename),))\n" }
{ "repo_name": "stephen144/odoo", "ref": "refs/heads/9.0", "path": "addons/account/tests/test_manual_reconciliation.py", "content": "from openerp.addons.account.tests.account_test_classes import AccountingTestCase\n\nclass TestManualReconciliation(AccountingTestCase):\n\n    def test_reconciliation_proposition(self):\n        pass\n\n    def test_full_reconcile(self):\n        pass\n\n    def test_partial_reconcile(self):\n        pass\n\n    def test_reconcile_with_write_off(self):\n        pass\n" }
{ "repo_name": "blooparksystems/odoo", "ref": "refs/heads/9.0", "path": "addons/account/tests/test_manual_reconciliation.py", "content": "from openerp.addons.account.tests.account_test_classes import AccountingTestCase\n\nclass TestManualReconciliation(AccountingTestCase):\n\n    def test_reconciliation_proposition(self):\n        pass\n\n    def test_full_reconcile(self):\n        pass\n\n    def test_partial_reconcile(self):\n        pass\n\n    def test_reconcile_with_write_off(self):\n        pass\n" }
{ "repo_name": "microcom/odoo", "ref": "refs/heads/9.0", "path": "addons/account/tests/test_manual_reconciliation.py", "content": "from openerp.addons.account.tests.account_test_classes import AccountingTestCase\n\nclass TestManualReconciliation(AccountingTestCase):\n\n    def test_reconciliation_proposition(self):\n        pass\n\n    def test_full_reconcile(self):\n        pass\n\n    def test_partial_reconcile(self):\n        pass\n\n    def test_reconcile_with_write_off(self):\n        pass\n" }
{ "repo_name": "optima-ict/odoo", "ref": "refs/heads/9.0", "path": "addons/account/tests/test_manual_reconciliation.py", "content": "from openerp.addons.account.tests.account_test_classes import AccountingTestCase\n\nclass TestManualReconciliation(AccountingTestCase):\n\n    def test_reconciliation_proposition(self):\n        pass\n\n    def test_full_reconcile(self):\n        pass\n\n    def test_partial_reconcile(self):\n        pass\n\n    def test_reconcile_with_write_off(self):\n        pass\n" }
{ "repo_name": "ludwiktrammer/odoo", "ref": "refs/heads/9.0", "path": "addons/account/tests/test_manual_reconciliation.py", "content": "from openerp.addons.account.tests.account_test_classes import AccountingTestCase\n\nclass TestManualReconciliation(AccountingTestCase):\n\n    def test_reconciliation_proposition(self):\n        pass\n\n    def test_full_reconcile(self):\n        pass\n\n    def test_partial_reconcile(self):\n        pass\n\n    def test_reconcile_with_write_off(self):\n        pass\n" }
{ "repo_name": "bplancher/odoo", "ref": "refs/heads/9.0", "path": "addons/account/tests/test_manual_reconciliation.py", "content": "from openerp.addons.account.tests.account_test_classes import AccountingTestCase\n\nclass TestManualReconciliation(AccountingTestCase):\n\n    def test_reconciliation_proposition(self):\n        pass\n\n    def test_full_reconcile(self):\n        pass\n\n    def test_partial_reconcile(self):\n        pass\n\n    def test_reconcile_with_write_off(self):\n        pass\n" }
{ "repo_name": "storm-computers/odoo", "ref": "refs/heads/9.0", "path": "addons/account/tests/test_manual_reconciliation.py", "content": "from openerp.addons.account.tests.account_test_classes import AccountingTestCase\n\nclass TestManualReconciliation(AccountingTestCase):\n\n    def test_reconciliation_proposition(self):\n        pass\n\n    def test_full_reconcile(self):\n        pass\n\n    def test_partial_reconcile(self):\n        pass\n\n    def test_reconcile_with_write_off(self):\n        pass\n" }
{ "repo_name": "sysadminmatmoz/OCB", "ref": "refs/heads/9.0", "path": "addons/account/tests/test_manual_reconciliation.py", "content": "from openerp.addons.account.tests.account_test_classes import AccountingTestCase\n\nclass TestManualReconciliation(AccountingTestCase):\n\n    def test_reconciliation_proposition(self):\n        pass\n\n    def test_full_reconcile(self):\n        pass\n\n    def test_partial_reconcile(self):\n        pass\n\n    def test_reconcile_with_write_off(self):\n        pass\n" }
{ "repo_name": "angelapper/odoo", "ref": "refs/heads/9.0", "path": "addons/account/tests/test_manual_reconciliation.py", "content": "from openerp.addons.account.tests.account_test_classes import AccountingTestCase\n\nclass TestManualReconciliation(AccountingTestCase):\n\n    def test_reconciliation_proposition(self):\n        pass\n\n    def test_full_reconcile(self):\n        pass\n\n    def test_partial_reconcile(self):\n        pass\n\n    def test_reconcile_with_write_off(self):\n        pass\n" }
{ "repo_name": "AyoubZahid/odoo", "ref": "refs/heads/9.0", "path": "addons/account/tests/test_manual_reconciliation.py", "content": "from openerp.addons.account.tests.account_test_classes import AccountingTestCase\n\nclass TestManualReconciliation(AccountingTestCase):\n\n    def test_reconciliation_proposition(self):\n        pass\n\n    def test_full_reconcile(self):\n        pass\n\n    def test_partial_reconcile(self):\n        pass\n\n    def test_reconcile_with_write_off(self):\n        pass\n" }
{ "repo_name": "laslabs/odoo", "ref": "refs/heads/9.0", "path": "addons/account/tests/test_manual_reconciliation.py", "content": "from openerp.addons.account.tests.account_test_classes import AccountingTestCase\n\nclass TestManualReconciliation(AccountingTestCase):\n\n    def test_reconciliation_proposition(self):\n        pass\n\n    def test_full_reconcile(self):\n        pass\n\n    def test_partial_reconcile(self):\n        pass\n\n    def test_reconcile_with_write_off(self):\n        pass\n" }
{ "repo_name": "OCA/server-tools", "ref": "refs/heads/12.0", "path": "company_country/migrations/12.0.1.0.2/pre-migration.py", "content": "import logging\nfrom psycopg2.extensions import AsIs\n\nfrom odoo import tools\n\n\n_logger = logging.getLogger(__name__)\n\n\ndef migrate(cr, version):\n    drop_table_model_company_country(cr)\n\n\ndef drop_table_model_company_country(cr):\n    tablename = 'company_country_config_settings'\n    if tools.table_exists(cr, tablename):\n        _logger.info(\"Dropping table %s\", tablename)\n        cr.execute(\"DROP TABLE IF EXISTS %s;\", (AsIs(tablename),))\n" }
{ "repo_name": "Fl0rianFischer/sme_odoo", "ref": "refs/heads/9.0", "path": "addons/account/tests/test_manual_reconciliation.py", "content": "from openerp.addons.account.tests.account_test_classes import AccountingTestCase\n\nclass TestManualReconciliation(AccountingTestCase):\n\n    def test_reconciliation_proposition(self):\n        pass\n\n    def test_full_reconcile(self):\n        pass\n\n    def test_partial_reconcile(self):\n        pass\n\n    def test_reconcile_with_write_off(self):\n        pass\n" }
{ "repo_name": "be-cloud-be/horizon-addons", "ref": "refs/heads/9.0", "path": "server/addons/account/tests/test_manual_reconciliation.py", "content": "from openerp.addons.account.tests.account_test_classes import AccountingTestCase\n\nclass TestManualReconciliation(AccountingTestCase):\n\n    def test_reconciliation_proposition(self):\n        pass\n\n    def test_full_reconcile(self):\n        pass\n\n    def test_partial_reconcile(self):\n        pass\n\n    def test_reconcile_with_write_off(self):\n        pass\n" }
{ "repo_name": "kmee/PySPED", "ref": "refs/heads/odoo", "path": "pysped/nfe/leiaute/soap_200.py", "content": "# -*- coding: utf-8 -*-\n#\n# PySPED - Python libraries to deal with Brazil's SPED Project\n#\n# Copyright (C) 2010-2012\n# Copyright (C) Aristides Caldeira <aristides.caldeira at tauga.com.br>\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU Library General Public License as\n# published by the Free Software Foundation, either version 2.1 of the\n# License, or (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU Library General Public License for more details.\n#\n# You should have received a copy of the GNU Library General Public License\n# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n# PySPED - Bibliotecas Python para o\n#          SPED - Sistema Público de Escrituração Digital\n#\n# Copyright (C) 2010-2012\n# Copyright (C) Aristides Caldeira <aristides.caldeira arroba tauga.com.br>\n#\n# Este programa é um software livre: você pode redistribuir e/ou modificar\n# este programa sob os termos da licença GNU Library General Public License,\n# publicada pela Free Software Foundation, em sua versão 2.1 ou, de acordo\n# com sua opção, qualquer versão posterior.\n#\n# Este programa é distribuido na esperança de que venha a ser útil,\n# porém SEM QUAISQUER GARANTIAS, nem mesmo a garantia implícita de\n# COMERCIABILIDADE ou ADEQUAÇÃO A UMA FINALIDADE ESPECÍFICA. Veja a\n# GNU Library General Public License para mais detalhes.\n#\n# Você deve ter recebido uma cópia da GNU Library General Public License\n# juntamente com este programa. Caso esse não seja o caso, acesse:\n# <http://www.gnu.org/licenses/>\n#\n\nfrom __future__ import division, print_function, unicode_literals\n\nfrom pysped.xml_sped import (ABERTURA, TagDecimal, TagInteiro, XMLNFe,\n                             tira_abertura)\nimport os\n\nDIRNAME = os.path.dirname(__file__)\n\n\nclass NFeCabecMsg(XMLNFe):\n    def __init__(self):\n        super(NFeCabecMsg, self).__init__()\n        self.webservice = ''\n        self.cUF         = TagInteiro(nome='cUF'        , codigo='', raiz='//cabecMsg', tamanho=[2, 2], valor=35)\n        self.versaoDados = TagDecimal(nome='versaoDados', codigo='', raiz='//cabecMsg', tamanho=[1, 4], valor='2.00')\n\n    def get_xml(self):\n        xml = XMLNFe.get_xml(self)\n        xml += '<nfeCabecMsg xmlns=\"http://www.portalfiscal.inf.br/nfe/wsdl/' + self.webservice + '\">'\n        xml += self.cUF.xml\n        xml += self.versaoDados.xml\n        xml += '</nfeCabecMsg>'\n        return xml\n\n    def set_xml(self, arquivo):\n        if self._le_xml(arquivo):\n            self.cUF.xml         = arquivo\n            self.versaoDados.xml = arquivo\n\n        return self.xml\n\n    xml = property(get_xml, set_xml)\n\n\nclass NFeDadosMsg(XMLNFe):\n    def __init__(self):\n        super(NFeDadosMsg, self).__init__()\n        self.webservice = ''\n        self.dados = None\n\n    def get_xml(self):\n        xml = XMLNFe.get_xml(self)\n        xml += '<nfeDadosMsg xmlns=\"http://www.portalfiscal.inf.br/nfe/wsdl/' + self.webservice + '\">'\n        xml += tira_abertura(self.dados.xml)\n        xml += '</nfeDadosMsg>'\n        return xml\n\n    def set_xml(self, arquivo):\n        pass\n\n    xml = property(get_xml, set_xml)\n\n\nclass SOAPEnvio(XMLNFe):\n    def __init__(self):\n        super(SOAPEnvio, self).__init__()\n        self.webservice = ''\n        self.metodo = ''\n        self.cUF    = None\n        self.envio  = None\n        self.nfeCabecMsg = NFeCabecMsg()\n        self.nfeDadosMsg = NFeDadosMsg()\n        self._header = {b'content-type': b'application/soap+xml; charset=utf-8'}\n        self.soap_action_webservice_e_metodo = False\n\n    def get_xml(self):\n        self.nfeCabecMsg.webservice = self.webservice\n        self.nfeCabecMsg.cUF.valor = self.cUF\n        self.nfeCabecMsg.versaoDados.valor = self.envio.versao.valor\n\n        self.nfeDadosMsg.webservice = self.webservice\n        self.nfeDadosMsg.dados = self.envio\n\n        if self.soap_action_webservice_e_metodo:\n            self._header[b'content-type'] = b'application/soap+xml; charset=utf-8; action=\"http://www.portalfiscal.inf.br/nfe/wsdl/' + self.webservice.encode('utf-8') + b'/' + self.metodo.encode('utf-8') + b'\"'\n        else:\n            self._header[b'content-type'] = b'application/soap+xml; charset=utf-8; action=\"http://www.portalfiscal.inf.br/nfe/wsdl/' + self.webservice.encode('utf-8') + b'\"'\n\n        xml = XMLNFe.get_xml(self)\n        xml += ABERTURA\n        xml += '<soap:Envelope xmlns:soap=\"http://www.w3.org/2003/05/soap-envelope\">'\n        xml +=     '<soap:Header>'\n        xml +=             self.nfeCabecMsg.xml\n        xml +=     '</soap:Header>'\n        xml +=     '<soap:Body>'\n        xml +=             self.nfeDadosMsg.xml\n        xml +=     '</soap:Body>'\n        xml += '</soap:Envelope>'\n        return xml\n\n    def set_xml(self):\n        pass\n\n    xml = property(get_xml, set_xml)\n\n    def get_header(self):\n        header = self._header\n        return header\n\n    header = property(get_header)\n\n\nclass SOAPRetorno(XMLNFe):\n    def __init__(self):\n        super(SOAPRetorno, self).__init__()\n        self.webservice = ''\n        self.metodo = ''\n        self.nfeCabecMsg = NFeCabecMsg()\n        self.resposta = None\n\n    def get_xml(self):\n        xml = XMLNFe.get_xml(self)\n        xml += ABERTURA\n        xml += '<soap:Envelope xmlns:soap=\"http://www.w3.org/2003/05/soap-envelope\">'\n        xml +=     '<soap:Header>'\n        xml +=         '<nfeCabecMsg xmlns=\"http://www.portalfiscal.inf.br/nfe/wsdl/' + self.webservice + '\">'\n        xml +=             self.nfeCabecMsg.xml\n        xml +=         '</nfeCabecMsg>'\n        xml +=     '</soap:Header>'\n        xml +=     '<soap:Body>'\n        xml +=         '<' + self.metodo + 'Result xmlns=\"http://www.portalfiscal.inf.br/nfe/wsdl/' + self.webservice + '\">'\n        xml +=             self.resposta.xml\n        xml +=         '</' + self.metodo + 'Result>'\n        xml +=     '</soap:Body>'\n        xml += '</soap:Envelope>'\n        return xml\n\n    def set_xml(self, arquivo):\n        if self._le_xml(arquivo):\n            self.nfeCabecMsg.xml = arquivo\n            self.resposta.xml = arquivo\n\n    xml = property(get_xml, set_xml)\n" }
{ "repo_name": "syci/OCB", "ref": "refs/heads/9.0", "path": "addons/account/tests/test_manual_reconciliation.py", "content": "from openerp.addons.account.tests.account_test_classes import AccountingTestCase\n\nclass TestManualReconciliation(AccountingTestCase):\n\n    def test_reconciliation_proposition(self):\n        pass\n\n    def test_full_reconcile(self):\n        pass\n\n    def test_partial_reconcile(self):\n        pass\n\n    def test_reconcile_with_write_off(self):\n        pass\n" }
{ "repo_name": "sourcefabric/airtime", "ref": "refs/heads/2.5.x", "path": "python_apps/media-monitor/mm2/tests/test_eventcontractor.py", "content": "import unittest\nfrom media.monitor.eventcontractor import EventContractor\n#from media.monitor.exceptions import BadSongFile\nfrom media.monitor.events import FakePyinotify, NewFile, MoveFile, \\\nDeleteFile\n\nclass TestMMP(unittest.TestCase):\n    def test_event_registered(self):\n        ev = EventContractor()\n        e1 = NewFile( FakePyinotify('bull.mp3') ).proxify()\n        e2 = MoveFile( FakePyinotify('bull.mp3') ).proxify()\n        ev.register(e1)\n        self.assertTrue( ev.event_registered(e2) )\n\n    def test_get_old_event(self):\n        ev = EventContractor()\n        e1 = NewFile( FakePyinotify('bull.mp3') ).proxify()\n        e2 = MoveFile( FakePyinotify('bull.mp3') ).proxify()\n        ev.register(e1)\n        self.assertEqual( ev.get_old_event(e2), e1 )\n\n    def test_register(self):\n        ev = EventContractor()\n        e1 = NewFile( FakePyinotify('bull.mp3') ).proxify()\n        e2 = DeleteFile( FakePyinotify('bull.mp3') ).proxify()\n        self.assertTrue( ev.register(e1) )\n\n        self.assertFalse( ev.register(e2) )\n\n        self.assertEqual( len(ev.store.keys()), 1 )\n\n        delete_ev = e1.safe_pack()[0]\n        self.assertEqual( delete_ev['mode'], u'delete')\n        self.assertEqual( len(ev.store.keys()), 0 )\n\n        e3 = DeleteFile( FakePyinotify('horse.mp3') ).proxify()\n        self.assertTrue( ev.register(e3) )\n        self.assertTrue( ev.register(e2) )\n\n\n    def test_register2(self):\n        ev = EventContractor()\n        p = 'bull.mp3'\n        events = [\n                NewFile( FakePyinotify(p) ),\n                NewFile( FakePyinotify(p) ),\n                DeleteFile( FakePyinotify(p) ),\n                NewFile( FakePyinotify(p) ),\n                NewFile( FakePyinotify(p) ), ]\n        events = map(lambda x: x.proxify(), events)\n        actual_events = []\n        for e in events:\n            if ev.register(e):\n                actual_events.append(e)\n        self.assertEqual( len(ev.store.keys()), 1 )\n        #packed = [ x.safe_pack() for x in actual_events ]\n\nif __name__ == '__main__': unittest.main()\n" }
{ "repo_name": "radiorabe/airtime", "ref": "refs/heads/rabe", "path": "python_apps/media-monitor/mm2/tests/test_eventcontractor.py", "content": "import unittest\nfrom media.monitor.eventcontractor import EventContractor\n#from media.monitor.exceptions import BadSongFile\nfrom media.monitor.events import FakePyinotify, NewFile, MoveFile, \\\nDeleteFile\n\nclass TestMMP(unittest.TestCase):\n    def test_event_registered(self):\n        ev = EventContractor()\n        e1 = NewFile( FakePyinotify('bull.mp3') ).proxify()\n        e2 = MoveFile( FakePyinotify('bull.mp3') ).proxify()\n        ev.register(e1)\n        self.assertTrue( ev.event_registered(e2) )\n\n    def test_get_old_event(self):\n        ev = EventContractor()\n        e1 = NewFile( FakePyinotify('bull.mp3') ).proxify()\n        e2 = MoveFile( FakePyinotify('bull.mp3') ).proxify()\n        ev.register(e1)\n        self.assertEqual( ev.get_old_event(e2), e1 )\n\n    def test_register(self):\n        ev = EventContractor()\n        e1 = NewFile( FakePyinotify('bull.mp3') ).proxify()\n        e2 = DeleteFile( FakePyinotify('bull.mp3') ).proxify()\n        self.assertTrue( ev.register(e1) )\n\n        self.assertFalse( ev.register(e2) )\n\n        self.assertEqual( len(ev.store.keys()), 1 )\n\n        delete_ev = e1.safe_pack()[0]\n        self.assertEqual( delete_ev['mode'], u'delete')\n        self.assertEqual( len(ev.store.keys()), 0 )\n\n        e3 = DeleteFile( FakePyinotify('horse.mp3') ).proxify()\n        self.assertTrue( ev.register(e3) )\n        self.assertTrue( ev.register(e2) )\n\n\n    def test_register2(self):\n        ev = EventContractor()\n        p = 'bull.mp3'\n        events = [\n                NewFile( FakePyinotify(p) ),\n                NewFile( FakePyinotify(p) ),\n                DeleteFile( FakePyinotify(p) ),\n                NewFile( FakePyinotify(p) ),\n                NewFile( FakePyinotify(p) ), ]\n        events = map(lambda x: x.proxify(), events)\n        actual_events = []\n        for e in events:\n            if ev.register(e):\n                actual_events.append(e)\n        self.assertEqual( len(ev.store.keys()), 1 )\n        #packed = [ x.safe_pack() for x in actual_events ]\n\nif __name__ == '__main__': unittest.main()\n" }
{ "repo_name": "vdeluca/tfi", "ref": "refs/heads/tfi", "path": "geonode/tasks/tests.py", "content": "from django.test import TestCase\n\n\nclass TasksTests(TestCase):\n    pass\n" }
{ "repo_name": "slabanja/ase", "ref": "refs/heads/lammps", "path": "doc/tutorials/spacegroup/spacegroup-sg2.py", "content": "print sg\n" }
{ "repo_name": "sourcefabric/Airtime", "ref": "refs/heads/2.5.x", "path": "python_apps/media-monitor/mm2/tests/test_eventcontractor.py", "content": "import unittest\nfrom media.monitor.eventcontractor import EventContractor\n#from media.monitor.exceptions import BadSongFile\nfrom media.monitor.events import FakePyinotify, NewFile, MoveFile, \\\nDeleteFile\n\nclass TestMMP(unittest.TestCase):\n    def test_event_registered(self):\n        ev = EventContractor()\n        e1 = NewFile( FakePyinotify('bull.mp3') ).proxify()\n        e2 = MoveFile( FakePyinotify('bull.mp3') ).proxify()\n        ev.register(e1)\n        self.assertTrue( ev.event_registered(e2) )\n\n    def test_get_old_event(self):\n        ev = EventContractor()\n        e1 = NewFile( FakePyinotify('bull.mp3') ).proxify()\n        e2 = MoveFile( FakePyinotify('bull.mp3') ).proxify()\n        ev.register(e1)\n        self.assertEqual( ev.get_old_event(e2), e1 )\n\n    def test_register(self):\n        ev = EventContractor()\n        e1 = NewFile( FakePyinotify('bull.mp3') ).proxify()\n        e2 = DeleteFile( FakePyinotify('bull.mp3') ).proxify()\n        self.assertTrue( ev.register(e1) )\n\n        self.assertFalse( ev.register(e2) )\n\n        self.assertEqual( len(ev.store.keys()), 1 )\n\n        delete_ev = e1.safe_pack()[0]\n        self.assertEqual( delete_ev['mode'], u'delete')\n        self.assertEqual( len(ev.store.keys()), 0 )\n\n        e3 = DeleteFile( FakePyinotify('horse.mp3') ).proxify()\n        self.assertTrue( ev.register(e3) )\n        self.assertTrue( ev.register(e2) )\n\n\n    def test_register2(self):\n        ev = EventContractor()\n        p = 'bull.mp3'\n        events = [\n                NewFile( FakePyinotify(p) ),\n                NewFile( FakePyinotify(p) ),\n                DeleteFile( FakePyinotify(p) ),\n                NewFile( FakePyinotify(p) ),\n                NewFile( FakePyinotify(p) ), ]\n        events = map(lambda x: x.proxify(), events)\n        actual_events = []\n        for e in events:\n            if ev.register(e):\n                actual_events.append(e)\n        self.assertEqual( len(ev.store.keys()), 1 )\n        #packed = [ x.safe_pack() for x in actual_events ]\n\nif __name__ == '__main__': unittest.main()\n" }
{ "repo_name": "Ryex/airtime", "ref": "refs/heads/ktek-2.6.x", "path": "python_apps/media-monitor/mm2/tests/test_eventcontractor.py", "content": "import unittest\nfrom media.monitor.eventcontractor import EventContractor\n#from media.monitor.exceptions import BadSongFile\nfrom media.monitor.events import FakePyinotify, NewFile, MoveFile, \\\nDeleteFile\n\nclass TestMMP(unittest.TestCase):\n    def test_event_registered(self):\n        ev = EventContractor()\n        e1 = NewFile( FakePyinotify('bull.mp3') ).proxify()\n        e2 = MoveFile( FakePyinotify('bull.mp3') ).proxify()\n        ev.register(e1)\n        self.assertTrue( ev.event_registered(e2) )\n\n    def test_get_old_event(self):\n        ev = EventContractor()\n        e1 = NewFile( FakePyinotify('bull.mp3') ).proxify()\n        e2 = MoveFile( FakePyinotify('bull.mp3') ).proxify()\n        ev.register(e1)\n        self.assertEqual( ev.get_old_event(e2), e1 )\n\n    def test_register(self):\n        ev = EventContractor()\n        e1 = NewFile( FakePyinotify('bull.mp3') ).proxify()\n        e2 = DeleteFile( FakePyinotify('bull.mp3') ).proxify()\n        self.assertTrue( ev.register(e1) )\n\n        self.assertFalse( ev.register(e2) )\n\n        self.assertEqual( len(ev.store.keys()), 1 )\n\n        delete_ev = e1.safe_pack()[0]\n        self.assertEqual( delete_ev['mode'], u'delete')\n        self.assertEqual( len(ev.store.keys()), 0 )\n\n        e3 = DeleteFile( FakePyinotify('horse.mp3') ).proxify()\n        self.assertTrue( ev.register(e3) )\n        self.assertTrue( ev.register(e2) )\n\n\n    def test_register2(self):\n        ev = EventContractor()\n        p = 'bull.mp3'\n        events = [\n                NewFile( FakePyinotify(p) ),\n                NewFile( FakePyinotify(p) ),\n                DeleteFile( FakePyinotify(p) ),\n                NewFile( FakePyinotify(p) ),\n                NewFile( FakePyinotify(p) ), ]\n        events = map(lambda x: x.proxify(), events)\n        actual_events = []\n        for e in events:\n            if ev.register(e):\n                actual_events.append(e)\n        self.assertEqual( len(ev.store.keys()), 1 )\n        #packed = [ x.safe_pack() for x in actual_events ]\n\nif __name__ == '__main__': unittest.main()\n" }
{ "repo_name": "habeanf/Open-Knesset", "ref": "refs/heads/upmaster", "path": "okhelptexts/migrations/0002_auto__add_field_helptext_moreinfo.py", "content": "# encoding: utf-8\nimport datetime\nfrom south.db import db\nfrom south.v2 import SchemaMigration\nfrom django.db import models\n\nclass Migration(SchemaMigration):\n\n    def forwards(self, orm):\n        \n        # Adding field 'Helptext.moreinfo'\n        db.add_column('okhelptexts_helptext', 'moreinfo', self.gf('django.db.models.fields.CharField')(default='', max_length=200, blank=True), keep_default=False)\n\n\n    def backwards(self, orm):\n        \n        # Deleting field 'Helptext.moreinfo'\n        db.delete_column('okhelptexts_helptext', 'moreinfo')\n\n\n    models = {\n        'okhelptexts.helptext': {\n            'Meta': {'object_name': 'Helptext'}\n            'fulltext': ('django.db.models.fields.TextField', [], {}),\n            'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),\n            'moreinfo': ('django.db.models.fields.CharField', [], {'default': \"''\", 'max_length': '200', 'blank': 'True'})\n      }\n        'okhelptexts.keyword': {\n            'Meta': {'object_name': 'Keyword'}\n            'helptext': ('django.db.models.fields.related.ForeignKey', [], {'to': \"orm['okhelptexts.Helptext']\"}),\n            'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),\n            'kw_text': ('django.db.models.fields.CharField', [], {'max_length': '200'})\n      }\n  }\n\n    complete_apps = ['okhelptexts']\n" }
{ "repo_name": "justvanbloom/airtime", "ref": "refs/heads/2.5.x", "path": "python_apps/media-monitor/mm2/tests/test_eventcontractor.py", "content": "import unittest\nfrom media.monitor.eventcontractor import EventContractor\n#from media.monitor.exceptions import BadSongFile\nfrom media.monitor.events import FakePyinotify, NewFile, MoveFile, \\\nDeleteFile\n\nclass TestMMP(unittest.TestCase):\n    def test_event_registered(self):\n        ev = EventContractor()\n        e1 = NewFile( FakePyinotify('bull.mp3') ).proxify()\n        e2 = MoveFile( FakePyinotify('bull.mp3') ).proxify()\n        ev.register(e1)\n        self.assertTrue( ev.event_registered(e2) )\n\n    def test_get_old_event(self):\n        ev = EventContractor()\n        e1 = NewFile( FakePyinotify('bull.mp3') ).proxify()\n        e2 = MoveFile( FakePyinotify('bull.mp3') ).proxify()\n        ev.register(e1)\n        self.assertEqual( ev.get_old_event(e2), e1 )\n\n    def test_register(self):\n        ev = EventContractor()\n        e1 = NewFile( FakePyinotify('bull.mp3') ).proxify()\n        e2 = DeleteFile( FakePyinotify('bull.mp3') ).proxify()\n        self.assertTrue( ev.register(e1) )\n\n        self.assertFalse( ev.register(e2) )\n\n        self.assertEqual( len(ev.store.keys()), 1 )\n\n        delete_ev = e1.safe_pack()[0]\n        self.assertEqual( delete_ev['mode'], u'delete')\n        self.assertEqual( len(ev.store.keys()), 0 )\n\n        e3 = DeleteFile( FakePyinotify('horse.mp3') ).proxify()\n        self.assertTrue( ev.register(e3) )\n        self.assertTrue( ev.register(e2) )\n\n\n    def test_register2(self):\n        ev = EventContractor()\n        p = 'bull.mp3'\n        events = [\n                NewFile( FakePyinotify(p) ),\n                NewFile( FakePyinotify(p) ),\n                DeleteFile( FakePyinotify(p) ),\n                NewFile( FakePyinotify(p) ),\n                NewFile( FakePyinotify(p) ), ]\n        events = map(lambda x: x.proxify(), events)\n        actual_events = []\n        for e in events:\n            if ev.register(e):\n                actual_events.append(e)\n        self.assertEqual( len(ev.store.keys()), 1 )\n        #packed = [ x.safe_pack() for x in actual_events ]\n\nif __name__ == '__main__': unittest.main()\n" }
{ "repo_name": "ReganDryke/airtime", "ref": "refs/heads/2.5.x", "path": "python_apps/media-monitor/mm2/tests/test_eventcontractor.py", "content": "import unittest\nfrom media.monitor.eventcontractor import EventContractor\n#from media.monitor.exceptions import BadSongFile\nfrom media.monitor.events import FakePyinotify, NewFile, MoveFile, \\\nDeleteFile\n\nclass TestMMP(unittest.TestCase):\n    def test_event_registered(self):\n        ev = EventContractor()\n        e1 = NewFile( FakePyinotify('bull.mp3') ).proxify()\n        e2 = MoveFile( FakePyinotify('bull.mp3') ).proxify()\n        ev.register(e1)\n        self.assertTrue( ev.event_registered(e2) )\n\n    def test_get_old_event(self):\n        ev = EventContractor()\n        e1 = NewFile( FakePyinotify('bull.mp3') ).proxify()\n        e2 = MoveFile( FakePyinotify('bull.mp3') ).proxify()\n        ev.register(e1)\n        self.assertEqual( ev.get_old_event(e2), e1 )\n\n    def test_register(self):\n        ev = EventContractor()\n        e1 = NewFile( FakePyinotify('bull.mp3') ).proxify()\n        e2 = DeleteFile( FakePyinotify('bull.mp3') ).proxify()\n        self.assertTrue( ev.register(e1) )\n\n        self.assertFalse( ev.register(e2) )\n\n        self.assertEqual( len(ev.store.keys()), 1 )\n\n        delete_ev = e1.safe_pack()[0]\n        self.assertEqual( delete_ev['mode'], u'delete')\n        self.assertEqual( len(ev.store.keys()), 0 )\n\n        e3 = DeleteFile( FakePyinotify('horse.mp3') ).proxify()\n        self.assertTrue( ev.register(e3) )\n        self.assertTrue( ev.register(e2) )\n\n\n    def test_register2(self):\n        ev = EventContractor()\n        p = 'bull.mp3'\n        events = [\n                NewFile( FakePyinotify(p) ),\n                NewFile( FakePyinotify(p) ),\n                DeleteFile( FakePyinotify(p) ),\n                NewFile( FakePyinotify(p) ),\n                NewFile( FakePyinotify(p) ), ]\n        events = map(lambda x: x.proxify(), events)\n        actual_events = []\n        for e in events:\n            if ev.register(e):\n                actual_events.append(e)\n        self.assertEqual( len(ev.store.keys()), 1 )\n        #packed = [ x.safe_pack() for x in actual_events ]\n\nif __name__ == '__main__': unittest.main()\n" }
{ "repo_name": "XKNX/xknx", "ref": "refs/heads/main", "path": "xknx/io/const.py", "content": "\"\"\"KNX Constants used within io.\"\"\"\n\nDEFAULT_MCAST_GRP = \"224.0.23.12\"\nDEFAULT_MCAST_PORT = 3671\n\nCONNECTION_ALIVE_TIME = 120\nCONNECTIONSTATE_REQUEST_TIMEOUT = 10\nHEARTBEAT_RATE = CONNECTION_ALIVE_TIME - (CONNECTIONSTATE_REQUEST_TIMEOUT * 5)\n" }
{ "repo_name": "mkotsbak/ModemManager", "ref": "refs/heads/Samsung_LTE_support", "path": "test/disable.py", "content": "#!/usr/bin/python\n# -*- Mode: python; tab-width: 4; indent-tabs-mode: nil; c-basic-offset: 4 -*-\n#\n# This program is free software; you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation; either version 2 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details:\n#\n# Copyright (C) 2009 - 2010 Red Hat, Inc.\n#\n\nimport sys, dbus\n\nMM_DBUS_SERVICE='org.freedesktop.ModemManager'\nMM_DBUS_PATH='/org/freedesktop/ModemManager'\nMM_DBUS_INTERFACE_MODEM='org.freedesktop.ModemManager.Modem'\n\nbus = dbus.SystemBus()\nproxy = bus.get_object(MM_DBUS_SERVICE, sys.argv[1])\nmodem = dbus.Interface(proxy, dbus_interface=MM_DBUS_INTERFACE_MODEM)\nmodem.Enable (False)\n\n" }
{ "repo_name": "thnkloud9/Airtime", "ref": "refs/heads/2.5.x", "path": "python_apps/media-monitor/mm2/tests/test_eventcontractor.py", "content": "import unittest\nfrom media.monitor.eventcontractor import EventContractor\n#from media.monitor.exceptions import BadSongFile\nfrom media.monitor.events import FakePyinotify, NewFile, MoveFile, \\\nDeleteFile\n\nclass TestMMP(unittest.TestCase):\n    def test_event_registered(self):\n        ev = EventContractor()\n        e1 = NewFile( FakePyinotify('bull.mp3') ).proxify()\n        e2 = MoveFile( FakePyinotify('bull.mp3') ).proxify()\n        ev.register(e1)\n        self.assertTrue( ev.event_registered(e2) )\n\n    def test_get_old_event(self):\n        ev = EventContractor()\n        e1 = NewFile( FakePyinotify('bull.mp3') ).proxify()\n        e2 = MoveFile( FakePyinotify('bull.mp3') ).proxify()\n        ev.register(e1)\n        self.assertEqual( ev.get_old_event(e2), e1 )\n\n    def test_register(self):\n        ev = EventContractor()\n        e1 = NewFile( FakePyinotify('bull.mp3') ).proxify()\n        e2 = DeleteFile( FakePyinotify('bull.mp3') ).proxify()\n        self.assertTrue( ev.register(e1) )\n\n        self.assertFalse( ev.register(e2) )\n\n        self.assertEqual( len(ev.store.keys()), 1 )\n\n        delete_ev = e1.safe_pack()[0]\n        self.assertEqual( delete_ev['mode'], u'delete')\n        self.assertEqual( len(ev.store.keys()), 0 )\n\n        e3 = DeleteFile( FakePyinotify('horse.mp3') ).proxify()\n        self.assertTrue( ev.register(e3) )\n        self.assertTrue( ev.register(e2) )\n\n\n    def test_register2(self):\n        ev = EventContractor()\n        p = 'bull.mp3'\n        events = [\n                NewFile( FakePyinotify(p) ),\n                NewFile( FakePyinotify(p) ),\n                DeleteFile( FakePyinotify(p) ),\n                NewFile( FakePyinotify(p) ),\n                NewFile( FakePyinotify(p) ), ]\n        events = map(lambda x: x.proxify(), events)\n        actual_events = []\n        for e in events:\n            if ev.register(e):\n                actual_events.append(e)\n        self.assertEqual( len(ev.store.keys()), 1 )\n        #packed = [ x.safe_pack() for x in actual_events ]\n\nif __name__ == '__main__': unittest.main()\n" }
{ "repo_name": "comiconomenclaturist/Airtime", "ref": "refs/heads/2.5.x", "path": "python_apps/media-monitor/mm2/tests/test_eventcontractor.py", "content": "import unittest\nfrom media.monitor.eventcontractor import EventContractor\n#from media.monitor.exceptions import BadSongFile\nfrom media.monitor.events import FakePyinotify, NewFile, MoveFile, \\\nDeleteFile\n\nclass TestMMP(unittest.TestCase):\n    def test_event_registered(self):\n        ev = EventContractor()\n        e1 = NewFile( FakePyinotify('bull.mp3') ).proxify()\n        e2 = MoveFile( FakePyinotify('bull.mp3') ).proxify()\n        ev.register(e1)\n        self.assertTrue( ev.event_registered(e2) )\n\n    def test_get_old_event(self):\n        ev = EventContractor()\n        e1 = NewFile( FakePyinotify('bull.mp3') ).proxify()\n        e2 = MoveFile( FakePyinotify('bull.mp3') ).proxify()\n        ev.register(e1)\n        self.assertEqual( ev.get_old_event(e2), e1 )\n\n    def test_register(self):\n        ev = EventContractor()\n        e1 = NewFile( FakePyinotify('bull.mp3') ).proxify()\n        e2 = DeleteFile( FakePyinotify('bull.mp3') ).proxify()\n        self.assertTrue( ev.register(e1) )\n\n        self.assertFalse( ev.register(e2) )\n\n        self.assertEqual( len(ev.store.keys()), 1 )\n\n        delete_ev = e1.safe_pack()[0]\n        self.assertEqual( delete_ev['mode'], u'delete')\n        self.assertEqual( len(ev.store.keys()), 0 )\n\n        e3 = DeleteFile( FakePyinotify('horse.mp3') ).proxify()\n        self.assertTrue( ev.register(e3) )\n        self.assertTrue( ev.register(e2) )\n\n\n    def test_register2(self):\n        ev = EventContractor()\n        p = 'bull.mp3'\n        events = [\n                NewFile( FakePyinotify(p) ),\n                NewFile( FakePyinotify(p) ),\n                DeleteFile( FakePyinotify(p) ),\n                NewFile( FakePyinotify(p) ),\n                NewFile( FakePyinotify(p) ), ]\n        events = map(lambda x: x.proxify(), events)\n        actual_events = []\n        for e in events:\n            if ev.register(e):\n                actual_events.append(e)\n        self.assertEqual( len(ev.store.keys()), 1 )\n        #packed = [ x.safe_pack() for x in actual_events ]\n\nif __name__ == '__main__': unittest.main()\n" }
{ "repo_name": "named-data-ndnSIM/ns-3-dev", "ref": "refs/heads/ndnSIM-ns-3.29", "path": "src/lte/bindings/modulegen__gcc_ILP32.py", "content": null }
{ "repo_name": "allenp/odoo", "ref": "refs/heads/9.0", "path": "addons/hw_proxy/controllers/main.py", "content": "# -*- coding: utf-8 -*-\nimport logging\nimport commands\nimport json\nimport os\nimport os.path\nimport openerp\nimport time\nimport random\nimport subprocess\nimport json\nimport werkzeug\nimport werkzeug.wrappers\n_logger = logging.getLogger(__name__)\n\n\nfrom openerp import http\nfrom openerp.http import request\n\n# Those are the builtin raspberry pi USB modules, they should\n# not appear in the list of connected devices.\nBANNED_DEVICES = set([\n\t\"0424:9514\",\t# Standard Microsystem Corp. Builtin Ethernet module\n\t\"1d6b:0002\",\t# Linux Foundation 2.0 root hub\n\t\"0424:ec00\",\t# Standard Microsystem Corp. Other Builtin Ethernet module\n])\n\n\n# drivers modules must add to drivers an object with a get_status() method \n# so that 'status' can return the status of all active drivers\ndrivers = {}\n\nclass Proxy(http.Controller):\n\n    def get_status(self):\n        statuses = {}\n        for driver in drivers:\n            statuses[driver] = drivers[driver].get_status()\n        return statuses\n\n    @http.route('/hw_proxy/hello', type='http', auth='none', cors='*')\n    def hello(self):\n        return \"ping\"\n\n    @http.route('/hw_proxy/handshake', type='json', auth='none', cors='*')\n    def handshake(self):\n        return True\n\n    @http.route('/hw_proxy/status', type='http', auth='none', cors='*')\n    def status_http(self):\n        resp = \"\"\"\n<!DOCTYPE HTML>\n<html>\n    <head>\n        <title>Odoo's PosBox</title>\n        <style>\n        body {\n            width: 480px;\n            margin: 60px auto;\n            font-family: sans-serif;\n            text-align: justify;\n            color: #6B6B6B;\n      }\n        .device {\n            border-bottom: solid 1px rgb(216,216,216);\n            padding: 9px;\n      }\n        .device:nth-child(2n) {\n            background:rgb(240,240,240);\n      }\n        </style>\n    </head>\n    <body>\n        <h1>Hardware Status</h1>\n        <p>The list of enabled drivers and their status</p>\n\"\"\"\n        statuses = self.get_status()\n        for driver in statuses:\n\n            status = statuses[driver]\n\n            if status['status'] == 'connecting':\n                color = 'black'\n            elif status['status'] == 'connected':\n                color = 'green'\n            else:\n                color = 'red'\n\n            resp += \"<h3 style='color:\"+color+\";'>\"+driver+' : '+status['status']+\"</h3>\\n\"\n            resp += \"<ul>\\n\"\n            for msg in status['messages']:\n                resp += '<li>'+msg+'</li>\\n'\n            resp += \"</ul>\\n\"\n        resp += \"\"\"\n            <h2>Connected Devices</h2>\n            <p>The list of connected USB devices as seen by the posbox</p>\n        \"\"\"\n        devices = commands.getoutput(\"lsusb\").split('\\n')\n        count   = 0\n        resp += \"<div class='devices'>\\n\"\n        for device in devices:\n            device_name = device[device.find('ID')+2:]\n            device_id   = device_name.split()[0]\n            if not (device_id in BANNED_DEVICES):\n            \tresp+= \"<div class='device' data-device='\"+device+\"'>\"+device_name+\"</div>\\n\"\n                count += 1\n        \n        if count == 0:\n            resp += \"<div class='device'>No USB Device Found</div>\"\n\n        resp += \"</div>\\n</body>\\n</html>\\n\\n\"\n\n        return request.make_response(resp,{\n            'Cache-Control': 'no-cache', \n            'Content-Type': 'text/html; charset=utf-8',\n            'Access-Control-Allow-Origin':  '*',\n            'Access-Control-Allow-Methods': 'GET',\n          })\n\n    @http.route('/hw_proxy/status_json', type='json', auth='none', cors='*')\n    def status_json(self):\n        return self.get_status()\n\n    @http.route('/hw_proxy/scan_item_success', type='json', auth='none', cors='*')\n    def scan_item_success(self, ean):\n        \"\"\"\n        A product has been scanned with success\n        \"\"\"\n        print 'scan_item_success: ' + str(ean)\n\n    @http.route('/hw_proxy/scan_item_error_unrecognized', type='json', auth='none', cors='*')\n    def scan_item_error_unrecognized(self, ean):\n        \"\"\"\n        A product has been scanned without success\n        \"\"\"\n        print 'scan_item_error_unrecognized: ' + str(ean)\n\n    @http.route('/hw_proxy/help_needed', type='json', auth='none', cors='*')\n    def help_needed(self):\n        \"\"\"\n        The user wants an help (ex: light is on)\n        \"\"\"\n        print \"help_needed\"\n\n    @http.route('/hw_proxy/help_canceled', type='json', auth='none', cors='*')\n    def help_canceled(self):\n        \"\"\"\n        The user stops the help request\n        \"\"\"\n        print \"help_canceled\"\n\n    @http.route('/hw_proxy/payment_request', type='json', auth='none', cors='*')\n    def payment_request(self, price):\n        \"\"\"\n        The PoS will activate the method payment \n        \"\"\"\n        print \"payment_request: price:\"+str(price)\n        return 'ok'\n\n    @http.route('/hw_proxy/payment_status', type='json', auth='none', cors='*')\n    def payment_status(self):\n        print \"payment_status\"\n        return { 'status':'waiting' } \n\n    @http.route('/hw_proxy/payment_cancel', type='json', auth='none', cors='*')\n    def payment_cancel(self):\n        print \"payment_cancel\"\n\n    @http.route('/hw_proxy/transaction_start', type='json', auth='none', cors='*')\n    def transaction_start(self):\n        print 'transaction_start'\n\n    @http.route('/hw_proxy/transaction_end', type='json', auth='none', cors='*')\n    def transaction_end(self):\n        print 'transaction_end'\n\n    @http.route('/hw_proxy/cashier_mode_activated', type='json', auth='none', cors='*')\n    def cashier_mode_activated(self):\n        print 'cashier_mode_activated'\n\n    @http.route('/hw_proxy/cashier_mode_deactivated', type='json', auth='none', cors='*')\n    def cashier_mode_deactivated(self):\n        print 'cashier_mode_deactivated'\n\n    @http.route('/hw_proxy/open_cashbox', type='json', auth='none', cors='*')\n    def open_cashbox(self):\n        print 'open_cashbox'\n\n    @http.route('/hw_proxy/print_receipt', type='json', auth='none', cors='*')\n    def print_receipt(self, receipt):\n        print 'print_receipt' + str(receipt)\n\n    @http.route('/hw_proxy/is_scanner_connected', type='json', auth='none', cors='*')\n    def is_scanner_connected(self, receipt):\n        print 'is_scanner_connected?' \n        return False\n\n    @http.route('/hw_proxy/scanner', type='json', auth='none', cors='*')\n    def scanner(self, receipt):\n        print 'scanner' \n        time.sleep(10)\n        return ''\n\n    @http.route('/hw_proxy/log', type='json', auth='none', cors='*')\n    def log(self, arguments):\n        _logger.info(' '.join(str(v) for v in arguments))\n\n    @http.route('/hw_proxy/print_pdf_invoice', type='json', auth='none', cors='*')\n    def print_pdf_invoice(self, pdfinvoice):\n        print 'print_pdf_invoice' + str(pdfinvoice)\n" }
{ "repo_name": "odoobgorg/odoo", "ref": "refs/heads/9.0", "path": "addons/hw_proxy/controllers/main.py", "content": "# -*- coding: utf-8 -*-\nimport logging\nimport commands\nimport json\nimport os\nimport os.path\nimport openerp\nimport time\nimport random\nimport subprocess\nimport json\nimport werkzeug\nimport werkzeug.wrappers\n_logger = logging.getLogger(__name__)\n\n\nfrom openerp import http\nfrom openerp.http import request\n\n# Those are the builtin raspberry pi USB modules, they should\n# not appear in the list of connected devices.\nBANNED_DEVICES = set([\n\t\"0424:9514\",\t# Standard Microsystem Corp. Builtin Ethernet module\n\t\"1d6b:0002\",\t# Linux Foundation 2.0 root hub\n\t\"0424:ec00\",\t# Standard Microsystem Corp. Other Builtin Ethernet module\n])\n\n\n# drivers modules must add to drivers an object with a get_status() method \n# so that 'status' can return the status of all active drivers\ndrivers = {}\n\nclass Proxy(http.Controller):\n\n    def get_status(self):\n        statuses = {}\n        for driver in drivers:\n            statuses[driver] = drivers[driver].get_status()\n        return statuses\n\n    @http.route('/hw_proxy/hello', type='http', auth='none', cors='*')\n    def hello(self):\n        return \"ping\"\n\n    @http.route('/hw_proxy/handshake', type='json', auth='none', cors='*')\n    def handshake(self):\n        return True\n\n    @http.route('/hw_proxy/status', type='http', auth='none', cors='*')\n    def status_http(self):\n        resp = \"\"\"\n<!DOCTYPE HTML>\n<html>\n    <head>\n        <title>Odoo's PosBox</title>\n        <style>\n        body {\n            width: 480px;\n            margin: 60px auto;\n            font-family: sans-serif;\n            text-align: justify;\n            color: #6B6B6B;\n      }\n        .device {\n            border-bottom: solid 1px rgb(216,216,216);\n            padding: 9px;\n      }\n        .device:nth-child(2n) {\n            background:rgb(240,240,240);\n      }\n        </style>\n    </head>\n    <body>\n        <h1>Hardware Status</h1>\n        <p>The list of enabled drivers and their status</p>\n\"\"\"\n        statuses = self.get_status()\n        for driver in statuses:\n\n            status = statuses[driver]\n\n            if status['status'] == 'connecting':\n                color = 'black'\n            elif status['status'] == 'connected':\n                color = 'green'\n            else:\n                color = 'red'\n\n            resp += \"<h3 style='color:\"+color+\";'>\"+driver+' : '+status['status']+\"</h3>\\n\"\n            resp += \"<ul>\\n\"\n            for msg in status['messages']:\n                resp += '<li>'+msg+'</li>\\n'\n            resp += \"</ul>\\n\"\n        resp += \"\"\"\n            <h2>Connected Devices</h2>\n            <p>The list of connected USB devices as seen by the posbox</p>\n        \"\"\"\n        devices = commands.getoutput(\"lsusb\").split('\\n')\n        count   = 0\n        resp += \"<div class='devices'>\\n\"\n        for device in devices:\n            device_name = device[device.find('ID')+2:]\n            device_id   = device_name.split()[0]\n            if not (device_id in BANNED_DEVICES):\n            \tresp+= \"<div class='device' data-device='\"+device+\"'>\"+device_name+\"</div>\\n\"\n                count += 1\n        \n        if count == 0:\n            resp += \"<div class='device'>No USB Device Found</div>\"\n\n        resp += \"</div>\\n</body>\\n</html>\\n\\n\"\n\n        return request.make_response(resp,{\n            'Cache-Control': 'no-cache', \n            'Content-Type': 'text/html; charset=utf-8',\n            'Access-Control-Allow-Origin':  '*',\n            'Access-Control-Allow-Methods': 'GET',\n          })\n\n    @http.route('/hw_proxy/status_json', type='json', auth='none', cors='*')\n    def status_json(self):\n        return self.get_status()\n\n    @http.route('/hw_proxy/scan_item_success', type='json', auth='none', cors='*')\n    def scan_item_success(self, ean):\n        \"\"\"\n        A product has been scanned with success\n        \"\"\"\n        print 'scan_item_success: ' + str(ean)\n\n    @http.route('/hw_proxy/scan_item_error_unrecognized', type='json', auth='none', cors='*')\n    def scan_item_error_unrecognized(self, ean):\n        \"\"\"\n        A product has been scanned without success\n        \"\"\"\n        print 'scan_item_error_unrecognized: ' + str(ean)\n\n    @http.route('/hw_proxy/help_needed', type='json', auth='none', cors='*')\n    def help_needed(self):\n        \"\"\"\n        The user wants an help (ex: light is on)\n        \"\"\"\n        print \"help_needed\"\n\n    @http.route('/hw_proxy/help_canceled', type='json', auth='none', cors='*')\n    def help_canceled(self):\n        \"\"\"\n        The user stops the help request\n        \"\"\"\n        print \"help_canceled\"\n\n    @http.route('/hw_proxy/payment_request', type='json', auth='none', cors='*')\n    def payment_request(self, price):\n        \"\"\"\n        The PoS will activate the method payment \n        \"\"\"\n        print \"payment_request: price:\"+str(price)\n        return 'ok'\n\n    @http.route('/hw_proxy/payment_status', type='json', auth='none', cors='*')\n    def payment_status(self):\n        print \"payment_status\"\n        return { 'status':'waiting' } \n\n    @http.route('/hw_proxy/payment_cancel', type='json', auth='none', cors='*')\n    def payment_cancel(self):\n        print \"payment_cancel\"\n\n    @http.route('/hw_proxy/transaction_start', type='json', auth='none', cors='*')\n    def transaction_start(self):\n        print 'transaction_start'\n\n    @http.route('/hw_proxy/transaction_end', type='json', auth='none', cors='*')\n    def transaction_end(self):\n        print 'transaction_end'\n\n    @http.route('/hw_proxy/cashier_mode_activated', type='json', auth='none', cors='*')\n    def cashier_mode_activated(self):\n        print 'cashier_mode_activated'\n\n    @http.route('/hw_proxy/cashier_mode_deactivated', type='json', auth='none', cors='*')\n    def cashier_mode_deactivated(self):\n        print 'cashier_mode_deactivated'\n\n    @http.route('/hw_proxy/open_cashbox', type='json', auth='none', cors='*')\n    def open_cashbox(self):\n        print 'open_cashbox'\n\n    @http.route('/hw_proxy/print_receipt', type='json', auth='none', cors='*')\n    def print_receipt(self, receipt):\n        print 'print_receipt' + str(receipt)\n\n    @http.route('/hw_proxy/is_scanner_connected', type='json', auth='none', cors='*')\n    def is_scanner_connected(self, receipt):\n        print 'is_scanner_connected?' \n        return False\n\n    @http.route('/hw_proxy/scanner', type='json', auth='none', cors='*')\n    def scanner(self, receipt):\n        print 'scanner' \n        time.sleep(10)\n        return ''\n\n    @http.route('/hw_proxy/log', type='json', auth='none', cors='*')\n    def log(self, arguments):\n        _logger.info(' '.join(str(v) for v in arguments))\n\n    @http.route('/hw_proxy/print_pdf_invoice', type='json', auth='none', cors='*')\n    def print_pdf_invoice(self, pdfinvoice):\n        print 'print_pdf_invoice' + str(pdfinvoice)\n" }
{ "repo_name": "stephen144/odoo", "ref": "refs/heads/9.0", "path": "addons/hw_proxy/controllers/main.py", "content": "# -*- coding: utf-8 -*-\nimport logging\nimport commands\nimport json\nimport os\nimport os.path\nimport openerp\nimport time\nimport random\nimport subprocess\nimport json\nimport werkzeug\nimport werkzeug.wrappers\n_logger = logging.getLogger(__name__)\n\n\nfrom openerp import http\nfrom openerp.http import request\n\n# Those are the builtin raspberry pi USB modules, they should\n# not appear in the list of connected devices.\nBANNED_DEVICES = set([\n\t\"0424:9514\",\t# Standard Microsystem Corp. Builtin Ethernet module\n\t\"1d6b:0002\",\t# Linux Foundation 2.0 root hub\n\t\"0424:ec00\",\t# Standard Microsystem Corp. Other Builtin Ethernet module\n])\n\n\n# drivers modules must add to drivers an object with a get_status() method \n# so that 'status' can return the status of all active drivers\ndrivers = {}\n\nclass Proxy(http.Controller):\n\n    def get_status(self):\n        statuses = {}\n        for driver in drivers:\n            statuses[driver] = drivers[driver].get_status()\n        return statuses\n\n    @http.route('/hw_proxy/hello', type='http', auth='none', cors='*')\n    def hello(self):\n        return \"ping\"\n\n    @http.route('/hw_proxy/handshake', type='json', auth='none', cors='*')\n    def handshake(self):\n        return True\n\n    @http.route('/hw_proxy/status', type='http', auth='none', cors='*')\n    def status_http(self):\n        resp = \"\"\"\n<!DOCTYPE HTML>\n<html>\n    <head>\n        <title>Odoo's PosBox</title>\n        <style>\n        body {\n            width: 480px;\n            margin: 60px auto;\n            font-family: sans-serif;\n            text-align: justify;\n            color: #6B6B6B;\n      }\n        .device {\n            border-bottom: solid 1px rgb(216,216,216);\n            padding: 9px;\n      }\n        .device:nth-child(2n) {\n            background:rgb(240,240,240);\n      }\n        </style>\n    </head>\n    <body>\n        <h1>Hardware Status</h1>\n        <p>The list of enabled drivers and their status</p>\n\"\"\"\n        statuses = self.get_status()\n        for driver in statuses:\n\n            status = statuses[driver]\n\n            if status['status'] == 'connecting':\n                color = 'black'\n            elif status['status'] == 'connected':\n                color = 'green'\n            else:\n                color = 'red'\n\n            resp += \"<h3 style='color:\"+color+\";'>\"+driver+' : '+status['status']+\"</h3>\\n\"\n            resp += \"<ul>\\n\"\n            for msg in status['messages']:\n                resp += '<li>'+msg+'</li>\\n'\n            resp += \"</ul>\\n\"\n        resp += \"\"\"\n            <h2>Connected Devices</h2>\n            <p>The list of connected USB devices as seen by the posbox</p>\n        \"\"\"\n        devices = commands.getoutput(\"lsusb\").split('\\n')\n        count   = 0\n        resp += \"<div class='devices'>\\n\"\n        for device in devices:\n            device_name = device[device.find('ID')+2:]\n            device_id   = device_name.split()[0]\n            if not (device_id in BANNED_DEVICES):\n            \tresp+= \"<div class='device' data-device='\"+device+\"'>\"+device_name+\"</div>\\n\"\n                count += 1\n        \n        if count == 0:\n            resp += \"<div class='device'>No USB Device Found</div>\"\n\n        resp += \"</div>\\n</body>\\n</html>\\n\\n\"\n\n        return request.make_response(resp,{\n            'Cache-Control': 'no-cache', \n            'Content-Type': 'text/html; charset=utf-8',\n            'Access-Control-Allow-Origin':  '*',\n            'Access-Control-Allow-Methods': 'GET',\n          })\n\n    @http.route('/hw_proxy/status_json', type='json', auth='none', cors='*')\n    def status_json(self):\n        return self.get_status()\n\n    @http.route('/hw_proxy/scan_item_success', type='json', auth='none', cors='*')\n    def scan_item_success(self, ean):\n        \"\"\"\n        A product has been scanned with success\n        \"\"\"\n        print 'scan_item_success: ' + str(ean)\n\n    @http.route('/hw_proxy/scan_item_error_unrecognized', type='json', auth='none', cors='*')\n    def scan_item_error_unrecognized(self, ean):\n        \"\"\"\n        A product has been scanned without success\n        \"\"\"\n        print 'scan_item_error_unrecognized: ' + str(ean)\n\n    @http.route('/hw_proxy/help_needed', type='json', auth='none', cors='*')\n    def help_needed(self):\n        \"\"\"\n        The user wants an help (ex: light is on)\n        \"\"\"\n        print \"help_needed\"\n\n    @http.route('/hw_proxy/help_canceled', type='json', auth='none', cors='*')\n    def help_canceled(self):\n        \"\"\"\n        The user stops the help request\n        \"\"\"\n        print \"help_canceled\"\n\n    @http.route('/hw_proxy/payment_request', type='json', auth='none', cors='*')\n    def payment_request(self, price):\n        \"\"\"\n        The PoS will activate the method payment \n        \"\"\"\n        print \"payment_request: price:\"+str(price)\n        return 'ok'\n\n    @http.route('/hw_proxy/payment_status', type='json', auth='none', cors='*')\n    def payment_status(self):\n        print \"payment_status\"\n        return { 'status':'waiting' } \n\n    @http.route('/hw_proxy/payment_cancel', type='json', auth='none', cors='*')\n    def payment_cancel(self):\n        print \"payment_cancel\"\n\n    @http.route('/hw_proxy/transaction_start', type='json', auth='none', cors='*')\n    def transaction_start(self):\n        print 'transaction_start'\n\n    @http.route('/hw_proxy/transaction_end', type='json', auth='none', cors='*')\n    def transaction_end(self):\n        print 'transaction_end'\n\n    @http.route('/hw_proxy/cashier_mode_activated', type='json', auth='none', cors='*')\n    def cashier_mode_activated(self):\n        print 'cashier_mode_activated'\n\n    @http.route('/hw_proxy/cashier_mode_deactivated', type='json', auth='none', cors='*')\n    def cashier_mode_deactivated(self):\n        print 'cashier_mode_deactivated'\n\n    @http.route('/hw_proxy/open_cashbox', type='json', auth='none', cors='*')\n    def open_cashbox(self):\n        print 'open_cashbox'\n\n    @http.route('/hw_proxy/print_receipt', type='json', auth='none', cors='*')\n    def print_receipt(self, receipt):\n        print 'print_receipt' + str(receipt)\n\n    @http.route('/hw_proxy/is_scanner_connected', type='json', auth='none', cors='*')\n    def is_scanner_connected(self, receipt):\n        print 'is_scanner_connected?' \n        return False\n\n    @http.route('/hw_proxy/scanner', type='json', auth='none', cors='*')\n    def scanner(self, receipt):\n        print 'scanner' \n        time.sleep(10)\n        return ''\n\n    @http.route('/hw_proxy/log', type='json', auth='none', cors='*')\n    def log(self, arguments):\n        _logger.info(' '.join(str(v) for v in arguments))\n\n    @http.route('/hw_proxy/print_pdf_invoice', type='json', auth='none', cors='*')\n    def print_pdf_invoice(self, pdfinvoice):\n        print 'print_pdf_invoice' + str(pdfinvoice)\n" }
{ "repo_name": "wbond/subversion", "ref": "refs/heads/1.7.x", "path": "contrib/client-side/svn_apply_autoprops.py", "content": "#!/usr/bin/env python\n\n# To do:\n# 1) Switch to using the Subversion Python bindings.\n#\n# $HeadURL$\n# $LastChangedRevision$\n# $LastChangedDate$\n# $LastChangedBy$\n#\n# Copyright (C) 2005,2006 Blair Zajac <blair@orcaware.com>\n#\n# This script is free software; you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation; either version 2 of the License, or\n# (at your option) any later version.\n#\n# This script is distributed in the hope that it will be useful, but\n# WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# General Public License for more details.\n#\n# A copy of the GNU General Public License can be obtained by writing\n# to the Free Software Foundation, Inc., 59 Temple Place, Suite 330,\n# Boston, MA 02111-1307 USA.\n\nimport getopt\nimport fnmatch\nimport os\nimport re\nimport sys\n\n# The default path to the Subversion configuration file.\nSVN_CONFIG_FILENAME = os.path.expandvars('$HOME/.subversion/config')\n\n# The name of Subversion's private directory in working copies.\nSVN_WC_ADM_DIR_NAME = '.svn'\n\n# The name this script was invoked as.\nPROGNAME = os.path.basename(sys.argv[0])\n\ndef usage():\n  print(\"\"\"This script reads the auto-properties defined in the file\n'%s'\nand applies them recursively to all the files and directories in the\ncurrent working copy.  It may behave differently than the Subversion\ncommand line; where the subversion command line may only apply a single\nmatching auto-property to a single pathname, this script will apply all\nmatching lines to a single pathname.\n\nUsage:\n  %s [options] [WC_PATH]\nwhere WC_PATH is the path to a working copy.\nIf WC_PATH is not specified, '.' is assumed.\n\nValid options are:\n  --help, -h         : Print this help text.\n  --config ARG       : Read the Subversion config file at path ARG\n                       instead of '%s'.\n\"\"\" % (SVN_CONFIG_FILENAME, PROGNAME, SVN_CONFIG_FILENAME))\n\ndef get_autoprop_lines(fd):\n  lines = []\n  reading_autoprops = 0\n\n  re_start_autoprops = re.compile('^\\s*\\[auto-props\\]\\s*')\n  re_end_autoprops = re.compile('^\\s*\\[\\w+\\]\\s*')\n\n  for line in fd.xreadlines():\n    if reading_autoprops:\n      if re_end_autoprops.match(line):\n        reading_autoprops = 0\n        continue\n    else:\n      if re_start_autoprops.match(line):\n        reading_autoprops = 1\n        continue\n\n    if reading_autoprops:\n      lines += [line]\n\n  return lines\n\ndef process_autoprop_lines(lines):\n  result = []\n\n  for line in lines:\n    # Split the line on the = separating the fnmatch string from the\n    # properties.\n    try:\n      (fnmatch, props) = line.split('=', 1)\n    except ValueError:\n      continue\n\n    # Remove leading and trailing whitespace from the fnmatch and\n    # properties.\n    fnmatch = fnmatch.strip()\n    props = props.strip()\n\n    # Create a list of property name and property values.  Remove all\n    # leading and trailing whitespce from the propery names and\n    # values.\n    props_list = []\n    for prop in props.split(';'):\n      prop = prop.strip()\n      if not len(prop):\n        continue\n      try:\n        (prop_name, prop_value) = prop.split('=', 1)\n        prop_name = prop_name.strip()\n        prop_value = prop_value.strip()\n      except ValueError:\n        prop_name = prop\n        prop_value = '*'\n      if len(prop_name):\n        props_list += [(prop_name, prop_value)]\n\n    result += [(fnmatch, props_list)]\n\n  return result\n\ndef filter_walk(autoprop_lines, dirname, filenames):\n  # Do not descend into a .svn directory.\n  try:\n    filenames.remove(SVN_WC_ADM_DIR_NAME)\n  except ValueError:\n    pass\n\n  filenames.sort()\n\n  # Find those filenames that match each fnmatch.\n  for autoprops_line in autoprop_lines:\n    fnmatch_str = autoprops_line[0]\n    prop_list = autoprops_line[1]\n\n    matching_filenames = fnmatch.filter(filenames, fnmatch_str)\n    matching_filenames = [f for f in matching_filenames \\\n      if not os.path.islink(os.path.join(dirname, f))]\n    if not matching_filenames:\n      continue\n\n    for prop in prop_list:\n      command = ['svn', 'propset', prop[0], prop[1]]\n      for f in matching_filenames:\n        command += [\"%s/%s\" % (dirname, f)]\n\n      status = os.spawnvp(os.P_WAIT, 'svn', command)\n      if status:\n        print('Command %s failed with exit status %s' \\\n              % (command, status))\n\ndef main():\n  try:\n    opts, args = getopt.getopt(sys.argv[1:], 'h', ['help', 'config='])\n  except getopt.GetoptError, e:\n    usage()\n    return 1\n\n  config_filename = None\n  for (o, a) in opts:\n    if o == '-h' or o == '--help':\n      usage()\n      return 0\n    elif o == '--config':\n      config_filename = os.path.abspath(a)\n\n  if not config_filename:\n    config_filename = SVN_CONFIG_FILENAME\n\n  if len(args) == 0:\n    wc_path = '.'\n  elif len(args) == 1:\n    wc_path = args[0]\n  else:\n    usage()\n    print(\"Too many arguments: %s\" % ' '.join(args))\n    return 1\n\n  try:\n    fd = file(config_filename)\n  except IOError:\n    print(\"Cannot open svn configuration file '%s' for reading: %s\" \\\n          % (config_filename, sys.exc_value.strerror))\n    return 1\n\n  autoprop_lines = get_autoprop_lines(fd)\n\n  fd.close()\n\n  autoprop_lines = process_autoprop_lines(autoprop_lines)\n\n  os.path.walk(wc_path, filter_walk, autoprop_lines)\n\nif __name__ == '__main__':\n  sys.exit(main())\n" }
{ "repo_name": "microcom/odoo", "ref": "refs/heads/9.0", "path": "addons/hw_proxy/controllers/main.py", "content": "# -*- coding: utf-8 -*-\nimport logging\nimport commands\nimport json\nimport os\nimport os.path\nimport openerp\nimport time\nimport random\nimport subprocess\nimport json\nimport werkzeug\nimport werkzeug.wrappers\n_logger = logging.getLogger(__name__)\n\n\nfrom openerp import http\nfrom openerp.http import request\n\n# Those are the builtin raspberry pi USB modules, they should\n# not appear in the list of connected devices.\nBANNED_DEVICES = set([\n\t\"0424:9514\",\t# Standard Microsystem Corp. Builtin Ethernet module\n\t\"1d6b:0002\",\t# Linux Foundation 2.0 root hub\n\t\"0424:ec00\",\t# Standard Microsystem Corp. Other Builtin Ethernet module\n])\n\n\n# drivers modules must add to drivers an object with a get_status() method \n# so that 'status' can return the status of all active drivers\ndrivers = {}\n\nclass Proxy(http.Controller):\n\n    def get_status(self):\n        statuses = {}\n        for driver in drivers:\n            statuses[driver] = drivers[driver].get_status()\n        return statuses\n\n    @http.route('/hw_proxy/hello', type='http', auth='none', cors='*')\n    def hello(self):\n        return \"ping\"\n\n    @http.route('/hw_proxy/handshake', type='json', auth='none', cors='*')\n    def handshake(self):\n        return True\n\n    @http.route('/hw_proxy/status', type='http', auth='none', cors='*')\n    def status_http(self):\n        resp = \"\"\"\n<!DOCTYPE HTML>\n<html>\n    <head>\n        <title>Odoo's PosBox</title>\n        <style>\n        body {\n            width: 480px;\n            margin: 60px auto;\n            font-family: sans-serif;\n            text-align: justify;\n            color: #6B6B6B;\n      }\n        .device {\n            border-bottom: solid 1px rgb(216,216,216);\n            padding: 9px;\n      }\n        .device:nth-child(2n) {\n            background:rgb(240,240,240);\n      }\n        </style>\n    </head>\n    <body>\n        <h1>Hardware Status</h1>\n        <p>The list of enabled drivers and their status</p>\n\"\"\"\n        statuses = self.get_status()\n        for driver in statuses:\n\n            status = statuses[driver]\n\n            if status['status'] == 'connecting':\n                color = 'black'\n            elif status['status'] == 'connected':\n                color = 'green'\n            else:\n                color = 'red'\n\n            resp += \"<h3 style='color:\"+color+\";'>\"+driver+' : '+status['status']+\"</h3>\\n\"\n            resp += \"<ul>\\n\"\n            for msg in status['messages']:\n                resp += '<li>'+msg+'</li>\\n'\n            resp += \"</ul>\\n\"\n        resp += \"\"\"\n            <h2>Connected Devices</h2>\n            <p>The list of connected USB devices as seen by the posbox</p>\n        \"\"\"\n        devices = commands.getoutput(\"lsusb\").split('\\n')\n        count   = 0\n        resp += \"<div class='devices'>\\n\"\n        for device in devices:\n            device_name = device[device.find('ID')+2:]\n            device_id   = device_name.split()[0]\n            if not (device_id in BANNED_DEVICES):\n            \tresp+= \"<div class='device' data-device='\"+device+\"'>\"+device_name+\"</div>\\n\"\n                count += 1\n        \n        if count == 0:\n            resp += \"<div class='device'>No USB Device Found</div>\"\n\n        resp += \"</div>\\n</body>\\n</html>\\n\\n\"\n\n        return request.make_response(resp,{\n            'Cache-Control': 'no-cache', \n            'Content-Type': 'text/html; charset=utf-8',\n            'Access-Control-Allow-Origin':  '*',\n            'Access-Control-Allow-Methods': 'GET',\n          })\n\n    @http.route('/hw_proxy/status_json', type='json', auth='none', cors='*')\n    def status_json(self):\n        return self.get_status()\n\n    @http.route('/hw_proxy/scan_item_success', type='json', auth='none', cors='*')\n    def scan_item_success(self, ean):\n        \"\"\"\n        A product has been scanned with success\n        \"\"\"\n        print 'scan_item_success: ' + str(ean)\n\n    @http.route('/hw_proxy/scan_item_error_unrecognized', type='json', auth='none', cors='*')\n    def scan_item_error_unrecognized(self, ean):\n        \"\"\"\n        A product has been scanned without success\n        \"\"\"\n        print 'scan_item_error_unrecognized: ' + str(ean)\n\n    @http.route('/hw_proxy/help_needed', type='json', auth='none', cors='*')\n    def help_needed(self):\n        \"\"\"\n        The user wants an help (ex: light is on)\n        \"\"\"\n        print \"help_needed\"\n\n    @http.route('/hw_proxy/help_canceled', type='json', auth='none', cors='*')\n    def help_canceled(self):\n        \"\"\"\n        The user stops the help request\n        \"\"\"\n        print \"help_canceled\"\n\n    @http.route('/hw_proxy/payment_request', type='json', auth='none', cors='*')\n    def payment_request(self, price):\n        \"\"\"\n        The PoS will activate the method payment \n        \"\"\"\n        print \"payment_request: price:\"+str(price)\n        return 'ok'\n\n    @http.route('/hw_proxy/payment_status', type='json', auth='none', cors='*')\n    def payment_status(self):\n        print \"payment_status\"\n        return { 'status':'waiting' } \n\n    @http.route('/hw_proxy/payment_cancel', type='json', auth='none', cors='*')\n    def payment_cancel(self):\n        print \"payment_cancel\"\n\n    @http.route('/hw_proxy/transaction_start', type='json', auth='none', cors='*')\n    def transaction_start(self):\n        print 'transaction_start'\n\n    @http.route('/hw_proxy/transaction_end', type='json', auth='none', cors='*')\n    def transaction_end(self):\n        print 'transaction_end'\n\n    @http.route('/hw_proxy/cashier_mode_activated', type='json', auth='none', cors='*')\n    def cashier_mode_activated(self):\n        print 'cashier_mode_activated'\n\n    @http.route('/hw_proxy/cashier_mode_deactivated', type='json', auth='none', cors='*')\n    def cashier_mode_deactivated(self):\n        print 'cashier_mode_deactivated'\n\n    @http.route('/hw_proxy/open_cashbox', type='json', auth='none', cors='*')\n    def open_cashbox(self):\n        print 'open_cashbox'\n\n    @http.route('/hw_proxy/print_receipt', type='json', auth='none', cors='*')\n    def print_receipt(self, receipt):\n        print 'print_receipt' + str(receipt)\n\n    @http.route('/hw_proxy/is_scanner_connected', type='json', auth='none', cors='*')\n    def is_scanner_connected(self, receipt):\n        print 'is_scanner_connected?' \n        return False\n\n    @http.route('/hw_proxy/scanner', type='json', auth='none', cors='*')\n    def scanner(self, receipt):\n        print 'scanner' \n        time.sleep(10)\n        return ''\n\n    @http.route('/hw_proxy/log', type='json', auth='none', cors='*')\n    def log(self, arguments):\n        _logger.info(' '.join(str(v) for v in arguments))\n\n    @http.route('/hw_proxy/print_pdf_invoice', type='json', auth='none', cors='*')\n    def print_pdf_invoice(self, pdfinvoice):\n        print 'print_pdf_invoice' + str(pdfinvoice)\n" }
{ "repo_name": "optima-ict/odoo", "ref": "refs/heads/9.0", "path": "addons/hw_proxy/controllers/main.py", "content": "# -*- coding: utf-8 -*-\nimport logging\nimport commands\nimport json\nimport os\nimport os.path\nimport openerp\nimport time\nimport random\nimport subprocess\nimport json\nimport werkzeug\nimport werkzeug.wrappers\n_logger = logging.getLogger(__name__)\n\n\nfrom openerp import http\nfrom openerp.http import request\n\n# Those are the builtin raspberry pi USB modules, they should\n# not appear in the list of connected devices.\nBANNED_DEVICES = set([\n\t\"0424:9514\",\t# Standard Microsystem Corp. Builtin Ethernet module\n\t\"1d6b:0002\",\t# Linux Foundation 2.0 root hub\n\t\"0424:ec00\",\t# Standard Microsystem Corp. Other Builtin Ethernet module\n])\n\n\n# drivers modules must add to drivers an object with a get_status() method \n# so that 'status' can return the status of all active drivers\ndrivers = {}\n\nclass Proxy(http.Controller):\n\n    def get_status(self):\n        statuses = {}\n        for driver in drivers:\n            statuses[driver] = drivers[driver].get_status()\n        return statuses\n\n    @http.route('/hw_proxy/hello', type='http', auth='none', cors='*')\n    def hello(self):\n        return \"ping\"\n\n    @http.route('/hw_proxy/handshake', type='json', auth='none', cors='*')\n    def handshake(self):\n        return True\n\n    @http.route('/hw_proxy/status', type='http', auth='none', cors='*')\n    def status_http(self):\n        resp = \"\"\"\n<!DOCTYPE HTML>\n<html>\n    <head>\n        <title>Odoo's PosBox</title>\n        <style>\n        body {\n            width: 480px;\n            margin: 60px auto;\n            font-family: sans-serif;\n            text-align: justify;\n            color: #6B6B6B;\n      }\n        .device {\n            border-bottom: solid 1px rgb(216,216,216);\n            padding: 9px;\n      }\n        .device:nth-child(2n) {\n            background:rgb(240,240,240);\n      }\n        </style>\n    </head>\n    <body>\n        <h1>Hardware Status</h1>\n        <p>The list of enabled drivers and their status</p>\n\"\"\"\n        statuses = self.get_status()\n        for driver in statuses:\n\n            status = statuses[driver]\n\n            if status['status'] == 'connecting':\n                color = 'black'\n            elif status['status'] == 'connected':\n                color = 'green'\n            else:\n                color = 'red'\n\n            resp += \"<h3 style='color:\"+color+\";'>\"+driver+' : '+status['status']+\"</h3>\\n\"\n            resp += \"<ul>\\n\"\n            for msg in status['messages']:\n                resp += '<li>'+msg+'</li>\\n'\n            resp += \"</ul>\\n\"\n        resp += \"\"\"\n            <h2>Connected Devices</h2>\n            <p>The list of connected USB devices as seen by the posbox</p>\n        \"\"\"\n        devices = commands.getoutput(\"lsusb\").split('\\n')\n        count   = 0\n        resp += \"<div class='devices'>\\n\"\n        for device in devices:\n            device_name = device[device.find('ID')+2:]\n            device_id   = device_name.split()[0]\n            if not (device_id in BANNED_DEVICES):\n            \tresp+= \"<div class='device' data-device='\"+device+\"'>\"+device_name+\"</div>\\n\"\n                count += 1\n        \n        if count == 0:\n            resp += \"<div class='device'>No USB Device Found</div>\"\n\n        resp += \"</div>\\n</body>\\n</html>\\n\\n\"\n\n        return request.make_response(resp,{\n            'Cache-Control': 'no-cache', \n            'Content-Type': 'text/html; charset=utf-8',\n            'Access-Control-Allow-Origin':  '*',\n            'Access-Control-Allow-Methods': 'GET',\n          })\n\n    @http.route('/hw_proxy/status_json', type='json', auth='none', cors='*')\n    def status_json(self):\n        return self.get_status()\n\n    @http.route('/hw_proxy/scan_item_success', type='json', auth='none', cors='*')\n    def scan_item_success(self, ean):\n        \"\"\"\n        A product has been scanned with success\n        \"\"\"\n        print 'scan_item_success: ' + str(ean)\n\n    @http.route('/hw_proxy/scan_item_error_unrecognized', type='json', auth='none', cors='*')\n    def scan_item_error_unrecognized(self, ean):\n        \"\"\"\n        A product has been scanned without success\n        \"\"\"\n        print 'scan_item_error_unrecognized: ' + str(ean)\n\n    @http.route('/hw_proxy/help_needed', type='json', auth='none', cors='*')\n    def help_needed(self):\n        \"\"\"\n        The user wants an help (ex: light is on)\n        \"\"\"\n        print \"help_needed\"\n\n    @http.route('/hw_proxy/help_canceled', type='json', auth='none', cors='*')\n    def help_canceled(self):\n        \"\"\"\n        The user stops the help request\n        \"\"\"\n        print \"help_canceled\"\n\n    @http.route('/hw_proxy/payment_request', type='json', auth='none', cors='*')\n    def payment_request(self, price):\n        \"\"\"\n        The PoS will activate the method payment \n        \"\"\"\n        print \"payment_request: price:\"+str(price)\n        return 'ok'\n\n    @http.route('/hw_proxy/payment_status', type='json', auth='none', cors='*')\n    def payment_status(self):\n        print \"payment_status\"\n        return { 'status':'waiting' } \n\n    @http.route('/hw_proxy/payment_cancel', type='json', auth='none', cors='*')\n    def payment_cancel(self):\n        print \"payment_cancel\"\n\n    @http.route('/hw_proxy/transaction_start', type='json', auth='none', cors='*')\n    def transaction_start(self):\n        print 'transaction_start'\n\n    @http.route('/hw_proxy/transaction_end', type='json', auth='none', cors='*')\n    def transaction_end(self):\n        print 'transaction_end'\n\n    @http.route('/hw_proxy/cashier_mode_activated', type='json', auth='none', cors='*')\n    def cashier_mode_activated(self):\n        print 'cashier_mode_activated'\n\n    @http.route('/hw_proxy/cashier_mode_deactivated', type='json', auth='none', cors='*')\n    def cashier_mode_deactivated(self):\n        print 'cashier_mode_deactivated'\n\n    @http.route('/hw_proxy/open_cashbox', type='json', auth='none', cors='*')\n    def open_cashbox(self):\n        print 'open_cashbox'\n\n    @http.route('/hw_proxy/print_receipt', type='json', auth='none', cors='*')\n    def print_receipt(self, receipt):\n        print 'print_receipt' + str(receipt)\n\n    @http.route('/hw_proxy/is_scanner_connected', type='json', auth='none', cors='*')\n    def is_scanner_connected(self, receipt):\n        print 'is_scanner_connected?' \n        return False\n\n    @http.route('/hw_proxy/scanner', type='json', auth='none', cors='*')\n    def scanner(self, receipt):\n        print 'scanner' \n        time.sleep(10)\n        return ''\n\n    @http.route('/hw_proxy/log', type='json', auth='none', cors='*')\n    def log(self, arguments):\n        _logger.info(' '.join(str(v) for v in arguments))\n\n    @http.route('/hw_proxy/print_pdf_invoice', type='json', auth='none', cors='*')\n    def print_pdf_invoice(self, pdfinvoice):\n        print 'print_pdf_invoice' + str(pdfinvoice)\n" }
{ "repo_name": "ludwiktrammer/odoo", "ref": "refs/heads/9.0", "path": "addons/hw_proxy/controllers/main.py", "content": "# -*- coding: utf-8 -*-\nimport logging\nimport commands\nimport json\nimport os\nimport os.path\nimport openerp\nimport time\nimport random\nimport subprocess\nimport json\nimport werkzeug\nimport werkzeug.wrappers\n_logger = logging.getLogger(__name__)\n\n\nfrom openerp import http\nfrom openerp.http import request\n\n# Those are the builtin raspberry pi USB modules, they should\n# not appear in the list of connected devices.\nBANNED_DEVICES = set([\n\t\"0424:9514\",\t# Standard Microsystem Corp. Builtin Ethernet module\n\t\"1d6b:0002\",\t# Linux Foundation 2.0 root hub\n\t\"0424:ec00\",\t# Standard Microsystem Corp. Other Builtin Ethernet module\n])\n\n\n# drivers modules must add to drivers an object with a get_status() method \n# so that 'status' can return the status of all active drivers\ndrivers = {}\n\nclass Proxy(http.Controller):\n\n    def get_status(self):\n        statuses = {}\n        for driver in drivers:\n            statuses[driver] = drivers[driver].get_status()\n        return statuses\n\n    @http.route('/hw_proxy/hello', type='http', auth='none', cors='*')\n    def hello(self):\n        return \"ping\"\n\n    @http.route('/hw_proxy/handshake', type='json', auth='none', cors='*')\n    def handshake(self):\n        return True\n\n    @http.route('/hw_proxy/status', type='http', auth='none', cors='*')\n    def status_http(self):\n        resp = \"\"\"\n<!DOCTYPE HTML>\n<html>\n    <head>\n        <title>Odoo's PosBox</title>\n        <style>\n        body {\n            width: 480px;\n            margin: 60px auto;\n            font-family: sans-serif;\n            text-align: justify;\n            color: #6B6B6B;\n      }\n        .device {\n            border-bottom: solid 1px rgb(216,216,216);\n            padding: 9px;\n      }\n        .device:nth-child(2n) {\n            background:rgb(240,240,240);\n      }\n        </style>\n    </head>\n    <body>\n        <h1>Hardware Status</h1>\n        <p>The list of enabled drivers and their status</p>\n\"\"\"\n        statuses = self.get_status()\n        for driver in statuses:\n\n            status = statuses[driver]\n\n            if status['status'] == 'connecting':\n                color = 'black'\n            elif status['status'] == 'connected':\n                color = 'green'\n            else:\n                color = 'red'\n\n            resp += \"<h3 style='color:\"+color+\";'>\"+driver+' : '+status['status']+\"</h3>\\n\"\n            resp += \"<ul>\\n\"\n            for msg in status['messages']:\n                resp += '<li>'+msg+'</li>\\n'\n            resp += \"</ul>\\n\"\n        resp += \"\"\"\n            <h2>Connected Devices</h2>\n            <p>The list of connected USB devices as seen by the posbox</p>\n        \"\"\"\n        devices = commands.getoutput(\"lsusb\").split('\\n')\n        count   = 0\n        resp += \"<div class='devices'>\\n\"\n        for device in devices:\n            device_name = device[device.find('ID')+2:]\n            device_id   = device_name.split()[0]\n            if not (device_id in BANNED_DEVICES):\n            \tresp+= \"<div class='device' data-device='\"+device+\"'>\"+device_name+\"</div>\\n\"\n                count += 1\n        \n        if count == 0:\n            resp += \"<div class='device'>No USB Device Found</div>\"\n\n        resp += \"</div>\\n</body>\\n</html>\\n\\n\"\n\n        return request.make_response(resp,{\n            'Cache-Control': 'no-cache', \n            'Content-Type': 'text/html; charset=utf-8',\n            'Access-Control-Allow-Origin':  '*',\n            'Access-Control-Allow-Methods': 'GET',\n          })\n\n    @http.route('/hw_proxy/status_json', type='json', auth='none', cors='*')\n    def status_json(self):\n        return self.get_status()\n\n    @http.route('/hw_proxy/scan_item_success', type='json', auth='none', cors='*')\n    def scan_item_success(self, ean):\n        \"\"\"\n        A product has been scanned with success\n        \"\"\"\n        print 'scan_item_success: ' + str(ean)\n\n    @http.route('/hw_proxy/scan_item_error_unrecognized', type='json', auth='none', cors='*')\n    def scan_item_error_unrecognized(self, ean):\n        \"\"\"\n        A product has been scanned without success\n        \"\"\"\n        print 'scan_item_error_unrecognized: ' + str(ean)\n\n    @http.route('/hw_proxy/help_needed', type='json', auth='none', cors='*')\n    def help_needed(self):\n        \"\"\"\n        The user wants an help (ex: light is on)\n        \"\"\"\n        print \"help_needed\"\n\n    @http.route('/hw_proxy/help_canceled', type='json', auth='none', cors='*')\n    def help_canceled(self):\n        \"\"\"\n        The user stops the help request\n        \"\"\"\n        print \"help_canceled\"\n\n    @http.route('/hw_proxy/payment_request', type='json', auth='none', cors='*')\n    def payment_request(self, price):\n        \"\"\"\n        The PoS will activate the method payment \n        \"\"\"\n        print \"payment_request: price:\"+str(price)\n        return 'ok'\n\n    @http.route('/hw_proxy/payment_status', type='json', auth='none', cors='*')\n    def payment_status(self):\n        print \"payment_status\"\n        return { 'status':'waiting' } \n\n    @http.route('/hw_proxy/payment_cancel', type='json', auth='none', cors='*')\n    def payment_cancel(self):\n        print \"payment_cancel\"\n\n    @http.route('/hw_proxy/transaction_start', type='json', auth='none', cors='*')\n    def transaction_start(self):\n        print 'transaction_start'\n\n    @http.route('/hw_proxy/transaction_end', type='json', auth='none', cors='*')\n    def transaction_end(self):\n        print 'transaction_end'\n\n    @http.route('/hw_proxy/cashier_mode_activated', type='json', auth='none', cors='*')\n    def cashier_mode_activated(self):\n        print 'cashier_mode_activated'\n\n    @http.route('/hw_proxy/cashier_mode_deactivated', type='json', auth='none', cors='*')\n    def cashier_mode_deactivated(self):\n        print 'cashier_mode_deactivated'\n\n    @http.route('/hw_proxy/open_cashbox', type='json', auth='none', cors='*')\n    def open_cashbox(self):\n        print 'open_cashbox'\n\n    @http.route('/hw_proxy/print_receipt', type='json', auth='none', cors='*')\n    def print_receipt(self, receipt):\n        print 'print_receipt' + str(receipt)\n\n    @http.route('/hw_proxy/is_scanner_connected', type='json', auth='none', cors='*')\n    def is_scanner_connected(self, receipt):\n        print 'is_scanner_connected?' \n        return False\n\n    @http.route('/hw_proxy/scanner', type='json', auth='none', cors='*')\n    def scanner(self, receipt):\n        print 'scanner' \n        time.sleep(10)\n        return ''\n\n    @http.route('/hw_proxy/log', type='json', auth='none', cors='*')\n    def log(self, arguments):\n        _logger.info(' '.join(str(v) for v in arguments))\n\n    @http.route('/hw_proxy/print_pdf_invoice', type='json', auth='none', cors='*')\n    def print_pdf_invoice(self, pdfinvoice):\n        print 'print_pdf_invoice' + str(pdfinvoice)\n" }
{ "repo_name": "angelapper/odoo", "ref": "refs/heads/9.0", "path": "addons/hw_proxy/controllers/main.py", "content": "# -*- coding: utf-8 -*-\nimport logging\nimport commands\nimport json\nimport os\nimport os.path\nimport openerp\nimport time\nimport random\nimport subprocess\nimport json\nimport werkzeug\nimport werkzeug.wrappers\n_logger = logging.getLogger(__name__)\n\n\nfrom openerp import http\nfrom openerp.http import request\n\n# Those are the builtin raspberry pi USB modules, they should\n# not appear in the list of connected devices.\nBANNED_DEVICES = set([\n\t\"0424:9514\",\t# Standard Microsystem Corp. Builtin Ethernet module\n\t\"1d6b:0002\",\t# Linux Foundation 2.0 root hub\n\t\"0424:ec00\",\t# Standard Microsystem Corp. Other Builtin Ethernet module\n])\n\n\n# drivers modules must add to drivers an object with a get_status() method \n# so that 'status' can return the status of all active drivers\ndrivers = {}\n\nclass Proxy(http.Controller):\n\n    def get_status(self):\n        statuses = {}\n        for driver in drivers:\n            statuses[driver] = drivers[driver].get_status()\n        return statuses\n\n    @http.route('/hw_proxy/hello', type='http', auth='none', cors='*')\n    def hello(self):\n        return \"ping\"\n\n    @http.route('/hw_proxy/handshake', type='json', auth='none', cors='*')\n    def handshake(self):\n        return True\n\n    @http.route('/hw_proxy/status', type='http', auth='none', cors='*')\n    def status_http(self):\n        resp = \"\"\"\n<!DOCTYPE HTML>\n<html>\n    <head>\n        <title>Odoo's PosBox</title>\n        <style>\n        body {\n            width: 480px;\n            margin: 60px auto;\n            font-family: sans-serif;\n            text-align: justify;\n            color: #6B6B6B;\n      }\n        .device {\n            border-bottom: solid 1px rgb(216,216,216);\n            padding: 9px;\n      }\n        .device:nth-child(2n) {\n            background:rgb(240,240,240);\n      }\n        </style>\n    </head>\n    <body>\n        <h1>Hardware Status</h1>\n        <p>The list of enabled drivers and their status</p>\n\"\"\"\n        statuses = self.get_status()\n        for driver in statuses:\n\n            status = statuses[driver]\n\n            if status['status'] == 'connecting':\n                color = 'black'\n            elif status['status'] == 'connected':\n                color = 'green'\n            else:\n                color = 'red'\n\n            resp += \"<h3 style='color:\"+color+\";'>\"+driver+' : '+status['status']+\"</h3>\\n\"\n            resp += \"<ul>\\n\"\n            for msg in status['messages']:\n                resp += '<li>'+msg+'</li>\\n'\n            resp += \"</ul>\\n\"\n        resp += \"\"\"\n            <h2>Connected Devices</h2>\n            <p>The list of connected USB devices as seen by the posbox</p>\n        \"\"\"\n        devices = commands.getoutput(\"lsusb\").split('\\n')\n        count   = 0\n        resp += \"<div class='devices'>\\n\"\n        for device in devices:\n            device_name = device[device.find('ID')+2:]\n            device_id   = device_name.split()[0]\n            if not (device_id in BANNED_DEVICES):\n            \tresp+= \"<div class='device' data-device='\"+device+\"'>\"+device_name+\"</div>\\n\"\n                count += 1\n        \n        if count == 0:\n            resp += \"<div class='device'>No USB Device Found</div>\"\n\n        resp += \"</div>\\n</body>\\n</html>\\n\\n\"\n\n        return request.make_response(resp,{\n            'Cache-Control': 'no-cache', \n            'Content-Type': 'text/html; charset=utf-8',\n            'Access-Control-Allow-Origin':  '*',\n            'Access-Control-Allow-Methods': 'GET',\n          })\n\n    @http.route('/hw_proxy/status_json', type='json', auth='none', cors='*')\n    def status_json(self):\n        return self.get_status()\n\n    @http.route('/hw_proxy/scan_item_success', type='json', auth='none', cors='*')\n    def scan_item_success(self, ean):\n        \"\"\"\n        A product has been scanned with success\n        \"\"\"\n        print 'scan_item_success: ' + str(ean)\n\n    @http.route('/hw_proxy/scan_item_error_unrecognized', type='json', auth='none', cors='*')\n    def scan_item_error_unrecognized(self, ean):\n        \"\"\"\n        A product has been scanned without success\n        \"\"\"\n        print 'scan_item_error_unrecognized: ' + str(ean)\n\n    @http.route('/hw_proxy/help_needed', type='json', auth='none', cors='*')\n    def help_needed(self):\n        \"\"\"\n        The user wants an help (ex: light is on)\n        \"\"\"\n        print \"help_needed\"\n\n    @http.route('/hw_proxy/help_canceled', type='json', auth='none', cors='*')\n    def help_canceled(self):\n        \"\"\"\n        The user stops the help request\n        \"\"\"\n        print \"help_canceled\"\n\n    @http.route('/hw_proxy/payment_request', type='json', auth='none', cors='*')\n    def payment_request(self, price):\n        \"\"\"\n        The PoS will activate the method payment \n        \"\"\"\n        print \"payment_request: price:\"+str(price)\n        return 'ok'\n\n    @http.route('/hw_proxy/payment_status', type='json', auth='none', cors='*')\n    def payment_status(self):\n        print \"payment_status\"\n        return { 'status':'waiting' } \n\n    @http.route('/hw_proxy/payment_cancel', type='json', auth='none', cors='*')\n    def payment_cancel(self):\n        print \"payment_cancel\"\n\n    @http.route('/hw_proxy/transaction_start', type='json', auth='none', cors='*')\n    def transaction_start(self):\n        print 'transaction_start'\n\n    @http.route('/hw_proxy/transaction_end', type='json', auth='none', cors='*')\n    def transaction_end(self):\n        print 'transaction_end'\n\n    @http.route('/hw_proxy/cashier_mode_activated', type='json', auth='none', cors='*')\n    def cashier_mode_activated(self):\n        print 'cashier_mode_activated'\n\n    @http.route('/hw_proxy/cashier_mode_deactivated', type='json', auth='none', cors='*')\n    def cashier_mode_deactivated(self):\n        print 'cashier_mode_deactivated'\n\n    @http.route('/hw_proxy/open_cashbox', type='json', auth='none', cors='*')\n    def open_cashbox(self):\n        print 'open_cashbox'\n\n    @http.route('/hw_proxy/print_receipt', type='json', auth='none', cors='*')\n    def print_receipt(self, receipt):\n        print 'print_receipt' + str(receipt)\n\n    @http.route('/hw_proxy/is_scanner_connected', type='json', auth='none', cors='*')\n    def is_scanner_connected(self, receipt):\n        print 'is_scanner_connected?' \n        return False\n\n    @http.route('/hw_proxy/scanner', type='json', auth='none', cors='*')\n    def scanner(self, receipt):\n        print 'scanner' \n        time.sleep(10)\n        return ''\n\n    @http.route('/hw_proxy/log', type='json', auth='none', cors='*')\n    def log(self, arguments):\n        _logger.info(' '.join(str(v) for v in arguments))\n\n    @http.route('/hw_proxy/print_pdf_invoice', type='json', auth='none', cors='*')\n    def print_pdf_invoice(self, pdfinvoice):\n        print 'print_pdf_invoice' + str(pdfinvoice)\n" }
{ "repo_name": "swvist/Debexpo", "ref": "refs/heads/gsoc", "path": "debexpo/tests/functional/test_ppa.py", "content": "from debexpo.tests import *\n\nclass TestPpaController(TestController):\n\n    def test_index(self):\n        response = self.app.get(url(controller='ppa', action='index'))\n        # Test response...\n" }
{ "repo_name": "OCA/account-financial-tools", "ref": "refs/heads/13.0", "path": "account_journal_lock_date/wizards/__init__.py", "content": "# License AGPL-3.0 or later (https://www.gnu.org/licenses/agpl).\n\nfrom . import update_journal_lock_dates\n" }
{ "repo_name": "andrewcbennett/iris", "ref": "refs/heads/placeholder", "path": "lib/iris/tests/integration/test_regridding.py", "content": "# (C) British Crown Copyright 2013 - 2015, Met Office\n#\n# This file is part of Iris.\n#\n# Iris is free software: you can redistribute it and/or modify it under\n# the terms of the GNU Lesser General Public License as published by the\n# Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# Iris is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU Lesser General Public License for more details.\n#\n# You should have received a copy of the GNU Lesser General Public License\n# along with Iris.  If not, see <http://www.gnu.org/licenses/>.\n\"\"\"Integration tests for regridding.\"\"\"\n\nfrom __future__ import (absolute_import, division, print_function)\nfrom six.moves import (filter, input, map, range, zip)  # noqa\n\n# Import iris.tests first so that some things can be initialised before\n# importing anything else.\nimport iris.tests as tests\n\nimport numpy as np\n\nimport iris\nfrom iris.analysis._regrid import RectilinearRegridder as Regridder\nfrom iris.coord_systems import GeogCS\nfrom iris.coords import DimCoord\nfrom iris.cube import Cube\nfrom iris.tests.stock import global_pp\n\n# Run tests in no graphics mode if matplotlib is not available.\nif tests.MPL_AVAILABLE:\n    import iris.quickplot as qplt\n\n\n@tests.skip_data\n@tests.skip_plot\nclass TestOSGBToLatLon(tests.GraphicsTest):\n    def setUp(self):\n        path = tests.get_data_path(\n            ('NIMROD', 'uk2km', 'WO0000000003452',\n             '201007020900_u1096_ng_ey00_visibility0180_screen_2km'))\n        self.src = iris.load_cube(path)[0]\n        self.src.data = self.src.data.astype(np.float32)\n        self.grid = Cube(np.empty((73, 96)))\n        cs = GeogCS(6370000)\n        lat = DimCoord(np.linspace(46, 65, 73), 'latitude', units='degrees',\n                       coord_system=cs)\n        lon = DimCoord(np.linspace(-14, 8, 96), 'longitude', units='degrees',\n                       coord_system=cs)\n        self.grid.add_dim_coord(lat, 0)\n        self.grid.add_dim_coord(lon, 1)\n\n    def _regrid(self, method):\n        regridder = Regridder(self.src, self.grid, method, 'mask')\n        result = regridder(self.src)\n        qplt.pcolor(result, antialiased=False)\n        qplt.plt.gca().coastlines()\n\n    def test_linear(self):\n        self._regrid('linear')\n        self.check_graphic()\n\n    def test_nearest(self):\n        self._regrid('nearest')\n        self.check_graphic()\n\n\n@tests.skip_data\n@tests.skip_plot\nclass TestGlobalSubsample(tests.GraphicsTest):\n    def setUp(self):\n        self.src = global_pp()\n        # Subsample and shift the target grid so that we can see a visual\n        # difference between regridding scheme methods.\n        grid = self.src[1::2, 1::3]\n        grid.coord('latitude').points = grid.coord('latitude').points + 1\n        grid.coord('longitude').points = grid.coord('longitude').points + 1\n        self.grid = grid\n\n    def _regrid(self, method):\n        regridder = Regridder(self.src, self.grid, method, 'mask')\n        result = regridder(self.src)\n        qplt.pcolormesh(result)\n        qplt.plt.gca().coastlines()\n\n    def test_linear(self):\n        self._regrid('linear')\n        self.check_graphic()\n\n    def test_nearest(self):\n        self._regrid('nearest')\n        self.check_graphic()\n\n\nif __name__ == \"__main__\":\n    tests.main()\n" }
{ "repo_name": "jkettleb/iris", "ref": "refs/heads/placeholder", "path": "lib/iris/tests/integration/test_regridding.py", "content": "# (C) British Crown Copyright 2013 - 2015, Met Office\n#\n# This file is part of Iris.\n#\n# Iris is free software: you can redistribute it and/or modify it under\n# the terms of the GNU Lesser General Public License as published by the\n# Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# Iris is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU Lesser General Public License for more details.\n#\n# You should have received a copy of the GNU Lesser General Public License\n# along with Iris.  If not, see <http://www.gnu.org/licenses/>.\n\"\"\"Integration tests for regridding.\"\"\"\n\nfrom __future__ import (absolute_import, division, print_function)\nfrom six.moves import (filter, input, map, range, zip)  # noqa\n\n# Import iris.tests first so that some things can be initialised before\n# importing anything else.\nimport iris.tests as tests\n\nimport numpy as np\n\nimport iris\nfrom iris.analysis._regrid import RectilinearRegridder as Regridder\nfrom iris.coord_systems import GeogCS\nfrom iris.coords import DimCoord\nfrom iris.cube import Cube\nfrom iris.tests.stock import global_pp\n\n# Run tests in no graphics mode if matplotlib is not available.\nif tests.MPL_AVAILABLE:\n    import iris.quickplot as qplt\n\n\n@tests.skip_data\n@tests.skip_plot\nclass TestOSGBToLatLon(tests.GraphicsTest):\n    def setUp(self):\n        path = tests.get_data_path(\n            ('NIMROD', 'uk2km', 'WO0000000003452',\n             '201007020900_u1096_ng_ey00_visibility0180_screen_2km'))\n        self.src = iris.load_cube(path)[0]\n        self.src.data = self.src.data.astype(np.float32)\n        self.grid = Cube(np.empty((73, 96)))\n        cs = GeogCS(6370000)\n        lat = DimCoord(np.linspace(46, 65, 73), 'latitude', units='degrees',\n                       coord_system=cs)\n        lon = DimCoord(np.linspace(-14, 8, 96), 'longitude', units='degrees',\n                       coord_system=cs)\n        self.grid.add_dim_coord(lat, 0)\n        self.grid.add_dim_coord(lon, 1)\n\n    def _regrid(self, method):\n        regridder = Regridder(self.src, self.grid, method, 'mask')\n        result = regridder(self.src)\n        qplt.pcolor(result, antialiased=False)\n        qplt.plt.gca().coastlines()\n\n    def test_linear(self):\n        self._regrid('linear')\n        self.check_graphic()\n\n    def test_nearest(self):\n        self._regrid('nearest')\n        self.check_graphic()\n\n\n@tests.skip_data\n@tests.skip_plot\nclass TestGlobalSubsample(tests.GraphicsTest):\n    def setUp(self):\n        self.src = global_pp()\n        # Subsample and shift the target grid so that we can see a visual\n        # difference between regridding scheme methods.\n        grid = self.src[1::2, 1::3]\n        grid.coord('latitude').points = grid.coord('latitude').points + 1\n        grid.coord('longitude').points = grid.coord('longitude').points + 1\n        self.grid = grid\n\n    def _regrid(self, method):\n        regridder = Regridder(self.src, self.grid, method, 'mask')\n        result = regridder(self.src)\n        qplt.pcolormesh(result)\n        qplt.plt.gca().coastlines()\n\n    def test_linear(self):\n        self._regrid('linear')\n        self.check_graphic()\n\n    def test_nearest(self):\n        self._regrid('nearest')\n        self.check_graphic()\n\n\nif __name__ == \"__main__\":\n    tests.main()\n" }
{ "repo_name": "sysadminmatmoz/OCB", "ref": "refs/heads/9.0", "path": "addons/hw_proxy/controllers/main.py", "content": "# -*- coding: utf-8 -*-\nimport logging\nimport commands\nimport json\nimport os\nimport os.path\nimport openerp\nimport time\nimport random\nimport subprocess\nimport json\nimport werkzeug\nimport werkzeug.wrappers\n_logger = logging.getLogger(__name__)\n\n\nfrom openerp import http\nfrom openerp.http import request\n\n# Those are the builtin raspberry pi USB modules, they should\n# not appear in the list of connected devices.\nBANNED_DEVICES = set([\n\t\"0424:9514\",\t# Standard Microsystem Corp. Builtin Ethernet module\n\t\"1d6b:0002\",\t# Linux Foundation 2.0 root hub\n\t\"0424:ec00\",\t# Standard Microsystem Corp. Other Builtin Ethernet module\n])\n\n\n# drivers modules must add to drivers an object with a get_status() method \n# so that 'status' can return the status of all active drivers\ndrivers = {}\n\nclass Proxy(http.Controller):\n\n    def get_status(self):\n        statuses = {}\n        for driver in drivers:\n            statuses[driver] = drivers[driver].get_status()\n        return statuses\n\n    @http.route('/hw_proxy/hello', type='http', auth='none', cors='*')\n    def hello(self):\n        return \"ping\"\n\n    @http.route('/hw_proxy/handshake', type='json', auth='none', cors='*')\n    def handshake(self):\n        return True\n\n    @http.route('/hw_proxy/status', type='http', auth='none', cors='*')\n    def status_http(self):\n        resp = \"\"\"\n<!DOCTYPE HTML>\n<html>\n    <head>\n        <title>Odoo's PosBox</title>\n        <style>\n        body {\n            width: 480px;\n            margin: 60px auto;\n            font-family: sans-serif;\n            text-align: justify;\n            color: #6B6B6B;\n      }\n        .device {\n            border-bottom: solid 1px rgb(216,216,216);\n            padding: 9px;\n      }\n        .device:nth-child(2n) {\n            background:rgb(240,240,240);\n      }\n        </style>\n    </head>\n    <body>\n        <h1>Hardware Status</h1>\n        <p>The list of enabled drivers and their status</p>\n\"\"\"\n        statuses = self.get_status()\n        for driver in statuses:\n\n            status = statuses[driver]\n\n            if status['status'] == 'connecting':\n                color = 'black'\n            elif status['status'] == 'connected':\n                color = 'green'\n            else:\n                color = 'red'\n\n            resp += \"<h3 style='color:\"+color+\";'>\"+driver+' : '+status['status']+\"</h3>\\n\"\n            resp += \"<ul>\\n\"\n            for msg in status['messages']:\n                resp += '<li>'+msg+'</li>\\n'\n            resp += \"</ul>\\n\"\n        resp += \"\"\"\n            <h2>Connected Devices</h2>\n            <p>The list of connected USB devices as seen by the posbox</p>\n        \"\"\"\n        devices = commands.getoutput(\"lsusb\").split('\\n')\n        count   = 0\n        resp += \"<div class='devices'>\\n\"\n        for device in devices:\n            device_name = device[device.find('ID')+2:]\n            device_id   = device_name.split()[0]\n            if not (device_id in BANNED_DEVICES):\n            \tresp+= \"<div class='device' data-device='\"+device+\"'>\"+device_name+\"</div>\\n\"\n                count += 1\n        \n        if count == 0:\n            resp += \"<div class='device'>No USB Device Found</div>\"\n\n        resp += \"</div>\\n</body>\\n</html>\\n\\n\"\n\n        return request.make_response(resp,{\n            'Cache-Control': 'no-cache', \n            'Content-Type': 'text/html; charset=utf-8',\n            'Access-Control-Allow-Origin':  '*',\n            'Access-Control-Allow-Methods': 'GET',\n          })\n\n    @http.route('/hw_proxy/status_json', type='json', auth='none', cors='*')\n    def status_json(self):\n        return self.get_status()\n\n    @http.route('/hw_proxy/scan_item_success', type='json', auth='none', cors='*')\n    def scan_item_success(self, ean):\n        \"\"\"\n        A product has been scanned with success\n        \"\"\"\n        print 'scan_item_success: ' + str(ean)\n\n    @http.route('/hw_proxy/scan_item_error_unrecognized', type='json', auth='none', cors='*')\n    def scan_item_error_unrecognized(self, ean):\n        \"\"\"\n        A product has been scanned without success\n        \"\"\"\n        print 'scan_item_error_unrecognized: ' + str(ean)\n\n    @http.route('/hw_proxy/help_needed', type='json', auth='none', cors='*')\n    def help_needed(self):\n        \"\"\"\n        The user wants an help (ex: light is on)\n        \"\"\"\n        print \"help_needed\"\n\n    @http.route('/hw_proxy/help_canceled', type='json', auth='none', cors='*')\n    def help_canceled(self):\n        \"\"\"\n        The user stops the help request\n        \"\"\"\n        print \"help_canceled\"\n\n    @http.route('/hw_proxy/payment_request', type='json', auth='none', cors='*')\n    def payment_request(self, price):\n        \"\"\"\n        The PoS will activate the method payment \n        \"\"\"\n        print \"payment_request: price:\"+str(price)\n        return 'ok'\n\n    @http.route('/hw_proxy/payment_status', type='json', auth='none', cors='*')\n    def payment_status(self):\n        print \"payment_status\"\n        return { 'status':'waiting' } \n\n    @http.route('/hw_proxy/payment_cancel', type='json', auth='none', cors='*')\n    def payment_cancel(self):\n        print \"payment_cancel\"\n\n    @http.route('/hw_proxy/transaction_start', type='json', auth='none', cors='*')\n    def transaction_start(self):\n        print 'transaction_start'\n\n    @http.route('/hw_proxy/transaction_end', type='json', auth='none', cors='*')\n    def transaction_end(self):\n        print 'transaction_end'\n\n    @http.route('/hw_proxy/cashier_mode_activated', type='json', auth='none', cors='*')\n    def cashier_mode_activated(self):\n        print 'cashier_mode_activated'\n\n    @http.route('/hw_proxy/cashier_mode_deactivated', type='json', auth='none', cors='*')\n    def cashier_mode_deactivated(self):\n        print 'cashier_mode_deactivated'\n\n    @http.route('/hw_proxy/open_cashbox', type='json', auth='none', cors='*')\n    def open_cashbox(self):\n        print 'open_cashbox'\n\n    @http.route('/hw_proxy/print_receipt', type='json', auth='none', cors='*')\n    def print_receipt(self, receipt):\n        print 'print_receipt' + str(receipt)\n\n    @http.route('/hw_proxy/is_scanner_connected', type='json', auth='none', cors='*')\n    def is_scanner_connected(self, receipt):\n        print 'is_scanner_connected?' \n        return False\n\n    @http.route('/hw_proxy/scanner', type='json', auth='none', cors='*')\n    def scanner(self, receipt):\n        print 'scanner' \n        time.sleep(10)\n        return ''\n\n    @http.route('/hw_proxy/log', type='json', auth='none', cors='*')\n    def log(self, arguments):\n        _logger.info(' '.join(str(v) for v in arguments))\n\n    @http.route('/hw_proxy/print_pdf_invoice', type='json', auth='none', cors='*')\n    def print_pdf_invoice(self, pdfinvoice):\n        print 'print_pdf_invoice' + str(pdfinvoice)\n" }
{ "repo_name": "AyoubZahid/odoo", "ref": "refs/heads/9.0", "path": "addons/hw_proxy/controllers/main.py", "content": "# -*- coding: utf-8 -*-\nimport logging\nimport commands\nimport json\nimport os\nimport os.path\nimport openerp\nimport time\nimport random\nimport subprocess\nimport json\nimport werkzeug\nimport werkzeug.wrappers\n_logger = logging.getLogger(__name__)\n\n\nfrom openerp import http\nfrom openerp.http import request\n\n# Those are the builtin raspberry pi USB modules, they should\n# not appear in the list of connected devices.\nBANNED_DEVICES = set([\n\t\"0424:9514\",\t# Standard Microsystem Corp. Builtin Ethernet module\n\t\"1d6b:0002\",\t# Linux Foundation 2.0 root hub\n\t\"0424:ec00\",\t# Standard Microsystem Corp. Other Builtin Ethernet module\n])\n\n\n# drivers modules must add to drivers an object with a get_status() method \n# so that 'status' can return the status of all active drivers\ndrivers = {}\n\nclass Proxy(http.Controller):\n\n    def get_status(self):\n        statuses = {}\n        for driver in drivers:\n            statuses[driver] = drivers[driver].get_status()\n        return statuses\n\n    @http.route('/hw_proxy/hello', type='http', auth='none', cors='*')\n    def hello(self):\n        return \"ping\"\n\n    @http.route('/hw_proxy/handshake', type='json', auth='none', cors='*')\n    def handshake(self):\n        return True\n\n    @http.route('/hw_proxy/status', type='http', auth='none', cors='*')\n    def status_http(self):\n        resp = \"\"\"\n<!DOCTYPE HTML>\n<html>\n    <head>\n        <title>Odoo's PosBox</title>\n        <style>\n        body {\n            width: 480px;\n            margin: 60px auto;\n            font-family: sans-serif;\n            text-align: justify;\n            color: #6B6B6B;\n      }\n        .device {\n            border-bottom: solid 1px rgb(216,216,216);\n            padding: 9px;\n      }\n        .device:nth-child(2n) {\n            background:rgb(240,240,240);\n      }\n        </style>\n    </head>\n    <body>\n        <h1>Hardware Status</h1>\n        <p>The list of enabled drivers and their status</p>\n\"\"\"\n        statuses = self.get_status()\n        for driver in statuses:\n\n            status = statuses[driver]\n\n            if status['status'] == 'connecting':\n                color = 'black'\n            elif status['status'] == 'connected':\n                color = 'green'\n            else:\n                color = 'red'\n\n            resp += \"<h3 style='color:\"+color+\";'>\"+driver+' : '+status['status']+\"</h3>\\n\"\n            resp += \"<ul>\\n\"\n            for msg in status['messages']:\n                resp += '<li>'+msg+'</li>\\n'\n            resp += \"</ul>\\n\"\n        resp += \"\"\"\n            <h2>Connected Devices</h2>\n            <p>The list of connected USB devices as seen by the posbox</p>\n        \"\"\"\n        devices = commands.getoutput(\"lsusb\").split('\\n')\n        count   = 0\n        resp += \"<div class='devices'>\\n\"\n        for device in devices:\n            device_name = device[device.find('ID')+2:]\n            device_id   = device_name.split()[0]\n            if not (device_id in BANNED_DEVICES):\n            \tresp+= \"<div class='device' data-device='\"+device+\"'>\"+device_name+\"</div>\\n\"\n                count += 1\n        \n        if count == 0:\n            resp += \"<div class='device'>No USB Device Found</div>\"\n\n        resp += \"</div>\\n</body>\\n</html>\\n\\n\"\n\n        return request.make_response(resp,{\n            'Cache-Control': 'no-cache', \n            'Content-Type': 'text/html; charset=utf-8',\n            'Access-Control-Allow-Origin':  '*',\n            'Access-Control-Allow-Methods': 'GET',\n          })\n\n    @http.route('/hw_proxy/status_json', type='json', auth='none', cors='*')\n    def status_json(self):\n        return self.get_status()\n\n    @http.route('/hw_proxy/scan_item_success', type='json', auth='none', cors='*')\n    def scan_item_success(self, ean):\n        \"\"\"\n        A product has been scanned with success\n        \"\"\"\n        print 'scan_item_success: ' + str(ean)\n\n    @http.route('/hw_proxy/scan_item_error_unrecognized', type='json', auth='none', cors='*')\n    def scan_item_error_unrecognized(self, ean):\n        \"\"\"\n        A product has been scanned without success\n        \"\"\"\n        print 'scan_item_error_unrecognized: ' + str(ean)\n\n    @http.route('/hw_proxy/help_needed', type='json', auth='none', cors='*')\n    def help_needed(self):\n        \"\"\"\n        The user wants an help (ex: light is on)\n        \"\"\"\n        print \"help_needed\"\n\n    @http.route('/hw_proxy/help_canceled', type='json', auth='none', cors='*')\n    def help_canceled(self):\n        \"\"\"\n        The user stops the help request\n        \"\"\"\n        print \"help_canceled\"\n\n    @http.route('/hw_proxy/payment_request', type='json', auth='none', cors='*')\n    def payment_request(self, price):\n        \"\"\"\n        The PoS will activate the method payment \n        \"\"\"\n        print \"payment_request: price:\"+str(price)\n        return 'ok'\n\n    @http.route('/hw_proxy/payment_status', type='json', auth='none', cors='*')\n    def payment_status(self):\n        print \"payment_status\"\n        return { 'status':'waiting' } \n\n    @http.route('/hw_proxy/payment_cancel', type='json', auth='none', cors='*')\n    def payment_cancel(self):\n        print \"payment_cancel\"\n\n    @http.route('/hw_proxy/transaction_start', type='json', auth='none', cors='*')\n    def transaction_start(self):\n        print 'transaction_start'\n\n    @http.route('/hw_proxy/transaction_end', type='json', auth='none', cors='*')\n    def transaction_end(self):\n        print 'transaction_end'\n\n    @http.route('/hw_proxy/cashier_mode_activated', type='json', auth='none', cors='*')\n    def cashier_mode_activated(self):\n        print 'cashier_mode_activated'\n\n    @http.route('/hw_proxy/cashier_mode_deactivated', type='json', auth='none', cors='*')\n    def cashier_mode_deactivated(self):\n        print 'cashier_mode_deactivated'\n\n    @http.route('/hw_proxy/open_cashbox', type='json', auth='none', cors='*')\n    def open_cashbox(self):\n        print 'open_cashbox'\n\n    @http.route('/hw_proxy/print_receipt', type='json', auth='none', cors='*')\n    def print_receipt(self, receipt):\n        print 'print_receipt' + str(receipt)\n\n    @http.route('/hw_proxy/is_scanner_connected', type='json', auth='none', cors='*')\n    def is_scanner_connected(self, receipt):\n        print 'is_scanner_connected?' \n        return False\n\n    @http.route('/hw_proxy/scanner', type='json', auth='none', cors='*')\n    def scanner(self, receipt):\n        print 'scanner' \n        time.sleep(10)\n        return ''\n\n    @http.route('/hw_proxy/log', type='json', auth='none', cors='*')\n    def log(self, arguments):\n        _logger.info(' '.join(str(v) for v in arguments))\n\n    @http.route('/hw_proxy/print_pdf_invoice', type='json', auth='none', cors='*')\n    def print_pdf_invoice(self, pdfinvoice):\n        print 'print_pdf_invoice' + str(pdfinvoice)\n" }
{ "repo_name": "Fl0rianFischer/sme_odoo", "ref": "refs/heads/9.0", "path": "addons/hw_proxy/controllers/main.py", "content": "# -*- coding: utf-8 -*-\nimport logging\nimport commands\nimport json\nimport os\nimport os.path\nimport openerp\nimport time\nimport random\nimport subprocess\nimport json\nimport werkzeug\nimport werkzeug.wrappers\n_logger = logging.getLogger(__name__)\n\n\nfrom openerp import http\nfrom openerp.http import request\n\n# Those are the builtin raspberry pi USB modules, they should\n# not appear in the list of connected devices.\nBANNED_DEVICES = set([\n\t\"0424:9514\",\t# Standard Microsystem Corp. Builtin Ethernet module\n\t\"1d6b:0002\",\t# Linux Foundation 2.0 root hub\n\t\"0424:ec00\",\t# Standard Microsystem Corp. Other Builtin Ethernet module\n])\n\n\n# drivers modules must add to drivers an object with a get_status() method \n# so that 'status' can return the status of all active drivers\ndrivers = {}\n\nclass Proxy(http.Controller):\n\n    def get_status(self):\n        statuses = {}\n        for driver in drivers:\n            statuses[driver] = drivers[driver].get_status()\n        return statuses\n\n    @http.route('/hw_proxy/hello', type='http', auth='none', cors='*')\n    def hello(self):\n        return \"ping\"\n\n    @http.route('/hw_proxy/handshake', type='json', auth='none', cors='*')\n    def handshake(self):\n        return True\n\n    @http.route('/hw_proxy/status', type='http', auth='none', cors='*')\n    def status_http(self):\n        resp = \"\"\"\n<!DOCTYPE HTML>\n<html>\n    <head>\n        <title>Odoo's PosBox</title>\n        <style>\n        body {\n            width: 480px;\n            margin: 60px auto;\n            font-family: sans-serif;\n            text-align: justify;\n            color: #6B6B6B;\n      }\n        .device {\n            border-bottom: solid 1px rgb(216,216,216);\n            padding: 9px;\n      }\n        .device:nth-child(2n) {\n            background:rgb(240,240,240);\n      }\n        </style>\n    </head>\n    <body>\n        <h1>Hardware Status</h1>\n        <p>The list of enabled drivers and their status</p>\n\"\"\"\n        statuses = self.get_status()\n        for driver in statuses:\n\n            status = statuses[driver]\n\n            if status['status'] == 'connecting':\n                color = 'black'\n            elif status['status'] == 'connected':\n                color = 'green'\n            else:\n                color = 'red'\n\n            resp += \"<h3 style='color:\"+color+\";'>\"+driver+' : '+status['status']+\"</h3>\\n\"\n            resp += \"<ul>\\n\"\n            for msg in status['messages']:\n                resp += '<li>'+msg+'</li>\\n'\n            resp += \"</ul>\\n\"\n        resp += \"\"\"\n            <h2>Connected Devices</h2>\n            <p>The list of connected USB devices as seen by the posbox</p>\n        \"\"\"\n        devices = commands.getoutput(\"lsusb\").split('\\n')\n        count   = 0\n        resp += \"<div class='devices'>\\n\"\n        for device in devices:\n            device_name = device[device.find('ID')+2:]\n            device_id   = device_name.split()[0]\n            if not (device_id in BANNED_DEVICES):\n            \tresp+= \"<div class='device' data-device='\"+device+\"'>\"+device_name+\"</div>\\n\"\n                count += 1\n        \n        if count == 0:\n            resp += \"<div class='device'>No USB Device Found</div>\"\n\n        resp += \"</div>\\n</body>\\n</html>\\n\\n\"\n\n        return request.make_response(resp,{\n            'Cache-Control': 'no-cache', \n            'Content-Type': 'text/html; charset=utf-8',\n            'Access-Control-Allow-Origin':  '*',\n            'Access-Control-Allow-Methods': 'GET',\n          })\n\n    @http.route('/hw_proxy/status_json', type='json', auth='none', cors='*')\n    def status_json(self):\n        return self.get_status()\n\n    @http.route('/hw_proxy/scan_item_success', type='json', auth='none', cors='*')\n    def scan_item_success(self, ean):\n        \"\"\"\n        A product has been scanned with success\n        \"\"\"\n        print 'scan_item_success: ' + str(ean)\n\n    @http.route('/hw_proxy/scan_item_error_unrecognized', type='json', auth='none', cors='*')\n    def scan_item_error_unrecognized(self, ean):\n        \"\"\"\n        A product has been scanned without success\n        \"\"\"\n        print 'scan_item_error_unrecognized: ' + str(ean)\n\n    @http.route('/hw_proxy/help_needed', type='json', auth='none', cors='*')\n    def help_needed(self):\n        \"\"\"\n        The user wants an help (ex: light is on)\n        \"\"\"\n        print \"help_needed\"\n\n    @http.route('/hw_proxy/help_canceled', type='json', auth='none', cors='*')\n    def help_canceled(self):\n        \"\"\"\n        The user stops the help request\n        \"\"\"\n        print \"help_canceled\"\n\n    @http.route('/hw_proxy/payment_request', type='json', auth='none', cors='*')\n    def payment_request(self, price):\n        \"\"\"\n        The PoS will activate the method payment \n        \"\"\"\n        print \"payment_request: price:\"+str(price)\n        return 'ok'\n\n    @http.route('/hw_proxy/payment_status', type='json', auth='none', cors='*')\n    def payment_status(self):\n        print \"payment_status\"\n        return { 'status':'waiting' } \n\n    @http.route('/hw_proxy/payment_cancel', type='json', auth='none', cors='*')\n    def payment_cancel(self):\n        print \"payment_cancel\"\n\n    @http.route('/hw_proxy/transaction_start', type='json', auth='none', cors='*')\n    def transaction_start(self):\n        print 'transaction_start'\n\n    @http.route('/hw_proxy/transaction_end', type='json', auth='none', cors='*')\n    def transaction_end(self):\n        print 'transaction_end'\n\n    @http.route('/hw_proxy/cashier_mode_activated', type='json', auth='none', cors='*')\n    def cashier_mode_activated(self):\n        print 'cashier_mode_activated'\n\n    @http.route('/hw_proxy/cashier_mode_deactivated', type='json', auth='none', cors='*')\n    def cashier_mode_deactivated(self):\n        print 'cashier_mode_deactivated'\n\n    @http.route('/hw_proxy/open_cashbox', type='json', auth='none', cors='*')\n    def open_cashbox(self):\n        print 'open_cashbox'\n\n    @http.route('/hw_proxy/print_receipt', type='json', auth='none', cors='*')\n    def print_receipt(self, receipt):\n        print 'print_receipt' + str(receipt)\n\n    @http.route('/hw_proxy/is_scanner_connected', type='json', auth='none', cors='*')\n    def is_scanner_connected(self, receipt):\n        print 'is_scanner_connected?' \n        return False\n\n    @http.route('/hw_proxy/scanner', type='json', auth='none', cors='*')\n    def scanner(self, receipt):\n        print 'scanner' \n        time.sleep(10)\n        return ''\n\n    @http.route('/hw_proxy/log', type='json', auth='none', cors='*')\n    def log(self, arguments):\n        _logger.info(' '.join(str(v) for v in arguments))\n\n    @http.route('/hw_proxy/print_pdf_invoice', type='json', auth='none', cors='*')\n    def print_pdf_invoice(self, pdfinvoice):\n        print 'print_pdf_invoice' + str(pdfinvoice)\n" }
{ "repo_name": "rcomer/iris", "ref": "refs/heads/placeholder", "path": "lib/iris/tests/integration/test_regridding.py", "content": "# (C) British Crown Copyright 2013 - 2015, Met Office\n#\n# This file is part of Iris.\n#\n# Iris is free software: you can redistribute it and/or modify it under\n# the terms of the GNU Lesser General Public License as published by the\n# Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# Iris is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU Lesser General Public License for more details.\n#\n# You should have received a copy of the GNU Lesser General Public License\n# along with Iris.  If not, see <http://www.gnu.org/licenses/>.\n\"\"\"Integration tests for regridding.\"\"\"\n\nfrom __future__ import (absolute_import, division, print_function)\nfrom six.moves import (filter, input, map, range, zip)  # noqa\n\n# Import iris.tests first so that some things can be initialised before\n# importing anything else.\nimport iris.tests as tests\n\nimport numpy as np\n\nimport iris\nfrom iris.analysis._regrid import RectilinearRegridder as Regridder\nfrom iris.coord_systems import GeogCS\nfrom iris.coords import DimCoord\nfrom iris.cube import Cube\nfrom iris.tests.stock import global_pp\n\n# Run tests in no graphics mode if matplotlib is not available.\nif tests.MPL_AVAILABLE:\n    import iris.quickplot as qplt\n\n\n@tests.skip_data\n@tests.skip_plot\nclass TestOSGBToLatLon(tests.GraphicsTest):\n    def setUp(self):\n        path = tests.get_data_path(\n            ('NIMROD', 'uk2km', 'WO0000000003452',\n             '201007020900_u1096_ng_ey00_visibility0180_screen_2km'))\n        self.src = iris.load_cube(path)[0]\n        self.src.data = self.src.data.astype(np.float32)\n        self.grid = Cube(np.empty((73, 96)))\n        cs = GeogCS(6370000)\n        lat = DimCoord(np.linspace(46, 65, 73), 'latitude', units='degrees',\n                       coord_system=cs)\n        lon = DimCoord(np.linspace(-14, 8, 96), 'longitude', units='degrees',\n                       coord_system=cs)\n        self.grid.add_dim_coord(lat, 0)\n        self.grid.add_dim_coord(lon, 1)\n\n    def _regrid(self, method):\n        regridder = Regridder(self.src, self.grid, method, 'mask')\n        result = regridder(self.src)\n        qplt.pcolor(result, antialiased=False)\n        qplt.plt.gca().coastlines()\n\n    def test_linear(self):\n        self._regrid('linear')\n        self.check_graphic()\n\n    def test_nearest(self):\n        self._regrid('nearest')\n        self.check_graphic()\n\n\n@tests.skip_data\n@tests.skip_plot\nclass TestGlobalSubsample(tests.GraphicsTest):\n    def setUp(self):\n        self.src = global_pp()\n        # Subsample and shift the target grid so that we can see a visual\n        # difference between regridding scheme methods.\n        grid = self.src[1::2, 1::3]\n        grid.coord('latitude').points = grid.coord('latitude').points + 1\n        grid.coord('longitude').points = grid.coord('longitude').points + 1\n        self.grid = grid\n\n    def _regrid(self, method):\n        regridder = Regridder(self.src, self.grid, method, 'mask')\n        result = regridder(self.src)\n        qplt.pcolormesh(result)\n        qplt.plt.gca().coastlines()\n\n    def test_linear(self):\n        self._regrid('linear')\n        self.check_graphic()\n\n    def test_nearest(self):\n        self._regrid('nearest')\n        self.check_graphic()\n\n\nif __name__ == \"__main__\":\n    tests.main()\n" }
{ "repo_name": "libracore/erpnext", "ref": "refs/heads/v12", "path": "erpnext/healthcare/doctype/healthcare_settings/healthcare_settings.py", "content": "# -*- coding: utf-8 -*-\n# Copyright (c) 2017, Frappe Technologies Pvt. Ltd. and contributors\n# For license information, please see license.txt\n\nfrom __future__ import unicode_literals\nimport frappe\nfrom frappe import _\nfrom frappe.model.document import Document\nfrom frappe.core.doctype.sms_settings.sms_settings import send_sms\nimport json\n\nclass HealthcareSettings(Document):\n\tdef validate(self):\n\t\tfor key in [\"collect_registration_fee\",\"manage_customer\",\"patient_master_name\",\n\t\t\"require_test_result_approval\",\"require_sample_collection\", \"default_medical_code_standard\"]:\n\t\t\tfrappe.db.set_default(key, self.get(key, \"\"))\n\t\tif(self.collect_registration_fee):\n\t\t\tif self.registration_fee <= 0 :\n\t\t\t\tfrappe.throw(_(\"Registration fee can not be Zero\"))\n\t\tif self.inpatient_visit_charge_item:\n\t\t\tvalidate_service_item(self.inpatient_visit_charge_item, \"Configure a service Item for Inpatient Visit Charge Item\")\n\t\tif self.op_consulting_charge_item:\n\t\t\tvalidate_service_item(self.op_consulting_charge_item, \"Configure a service Item for Out Patient Consulting Charge Item\")\n\t\tif self.clinical_procedure_consumable_item:\n\t\t\tvalidate_service_item(self.clinical_procedure_consumable_item, \"Configure a service Item for Clinical Procedure Consumable Item\")\n\n@frappe.whitelist()\ndef get_sms_text(doc):\n    sms_text = {}\n    doc = frappe.get_doc(\"Lab Test\",doc)\n    #doc = json.loads(doc)\n    context = {\"doc\": doc, \"alert\": doc, \"comments\": None}\n    emailed = frappe.db.get_value(\"Healthcare Settings\", None, \"sms_emailed\")\n    sms_text['emailed'] = frappe.render_template(emailed, context)\n    printed = frappe.db.get_value(\"Healthcare Settings\", None, \"sms_printed\")\n    sms_text['printed'] = frappe.render_template(printed, context)\n    return sms_text\n\ndef send_registration_sms(doc):\n    if (frappe.db.get_value(\"Healthcare Settings\", None, \"reg_sms\")=='1'):\n        if doc.mobile:\n            context = {\"doc\": doc, \"alert\": doc, \"comments\": None}\n            if doc.get(\"_comments\"):\n                context[\"comments\"] = json.loads(doc.get(\"_comments\"))\n            messages = frappe.db.get_value(\"Healthcare Settings\", None, \"reg_msg\")\n            messages = frappe.render_template(messages, context)\n            number = [doc.mobile]\n            send_sms(number,messages)\n        else:\n            frappe.msgprint(doc.name + \" Has no mobile number to send registration SMS\", alert=True)\n\n\ndef get_receivable_account(company):\n    receivable_account = get_account(None, \"receivable_account\", \"Healthcare Settings\", company)\n    if receivable_account:\n        return receivable_account\n    return frappe.get_cached_value('Company',  company,  \"default_receivable_account\")\n\ndef get_income_account(practitioner, company):\n    if(practitioner):\n        income_account = get_account(\"Healthcare Practitioner\", None, practitioner, company)\n        if income_account:\n            return income_account\n    income_account = get_account(None, \"income_account\", \"Healthcare Settings\", company)\n    if income_account:\n        return income_account\n    return frappe.get_cached_value('Company',  company,  \"default_income_account\")\n\ndef get_account(parent_type, parent_field, parent, company):\n    if(parent_type):\n        return frappe.db.get_value(\"Party Account\",\n          {\"parenttype\": parent_type, \"parent\": parent, \"company\": company} \"account\")\n    if(parent_field):\n        return frappe.db.get_value(\"Party Account\",\n          {\"parentfield\": parent_field, \"parent\": parent, \"company\": company} \"account\")\n\ndef validate_service_item(item, msg):\n\tif frappe.db.get_value(\"Item\", item, \"is_stock_item\") == 1:\n\t\tfrappe.throw(_(msg))\n" }
{ "repo_name": "syci/OCB", "ref": "refs/heads/9.0", "path": "addons/hw_proxy/controllers/main.py", "content": "# -*- coding: utf-8 -*-\nimport logging\nimport commands\nimport json\nimport os\nimport os.path\nimport openerp\nimport time\nimport random\nimport subprocess\nimport json\nimport werkzeug\nimport werkzeug.wrappers\n_logger = logging.getLogger(__name__)\n\n\nfrom openerp import http\nfrom openerp.http import request\n\n# Those are the builtin raspberry pi USB modules, they should\n# not appear in the list of connected devices.\nBANNED_DEVICES = set([\n\t\"0424:9514\",\t# Standard Microsystem Corp. Builtin Ethernet module\n\t\"1d6b:0002\",\t# Linux Foundation 2.0 root hub\n\t\"0424:ec00\",\t# Standard Microsystem Corp. Other Builtin Ethernet module\n])\n\n\n# drivers modules must add to drivers an object with a get_status() method \n# so that 'status' can return the status of all active drivers\ndrivers = {}\n\nclass Proxy(http.Controller):\n\n    def get_status(self):\n        statuses = {}\n        for driver in drivers:\n            statuses[driver] = drivers[driver].get_status()\n        return statuses\n\n    @http.route('/hw_proxy/hello', type='http', auth='none', cors='*')\n    def hello(self):\n        return \"ping\"\n\n    @http.route('/hw_proxy/handshake', type='json', auth='none', cors='*')\n    def handshake(self):\n        return True\n\n    @http.route('/hw_proxy/status', type='http', auth='none', cors='*')\n    def status_http(self):\n        resp = \"\"\"\n<!DOCTYPE HTML>\n<html>\n    <head>\n        <title>Odoo's PosBox</title>\n        <style>\n        body {\n            width: 480px;\n            margin: 60px auto;\n            font-family: sans-serif;\n            text-align: justify;\n            color: #6B6B6B;\n      }\n        .device {\n            border-bottom: solid 1px rgb(216,216,216);\n            padding: 9px;\n      }\n        .device:nth-child(2n) {\n            background:rgb(240,240,240);\n      }\n        </style>\n    </head>\n    <body>\n        <h1>Hardware Status</h1>\n        <p>The list of enabled drivers and their status</p>\n\"\"\"\n        statuses = self.get_status()\n        for driver in statuses:\n\n            status = statuses[driver]\n\n            if status['status'] == 'connecting':\n                color = 'black'\n            elif status['status'] == 'connected':\n                color = 'green'\n            else:\n                color = 'red'\n\n            resp += \"<h3 style='color:\"+color+\";'>\"+driver+' : '+status['status']+\"</h3>\\n\"\n            resp += \"<ul>\\n\"\n            for msg in status['messages']:\n                resp += '<li>'+msg+'</li>\\n'\n            resp += \"</ul>\\n\"\n        resp += \"\"\"\n            <h2>Connected Devices</h2>\n            <p>The list of connected USB devices as seen by the posbox</p>\n        \"\"\"\n        devices = commands.getoutput(\"lsusb\").split('\\n')\n        count   = 0\n        resp += \"<div class='devices'>\\n\"\n        for device in devices:\n            device_name = device[device.find('ID')+2:]\n            device_id   = device_name.split()[0]\n            if not (device_id in BANNED_DEVICES):\n            \tresp+= \"<div class='device' data-device='\"+device+\"'>\"+device_name+\"</div>\\n\"\n                count += 1\n        \n        if count == 0:\n            resp += \"<div class='device'>No USB Device Found</div>\"\n\n        resp += \"</div>\\n</body>\\n</html>\\n\\n\"\n\n        return request.make_response(resp,{\n            'Cache-Control': 'no-cache', \n            'Content-Type': 'text/html; charset=utf-8',\n            'Access-Control-Allow-Origin':  '*',\n            'Access-Control-Allow-Methods': 'GET',\n          })\n\n    @http.route('/hw_proxy/status_json', type='json', auth='none', cors='*')\n    def status_json(self):\n        return self.get_status()\n\n    @http.route('/hw_proxy/scan_item_success', type='json', auth='none', cors='*')\n    def scan_item_success(self, ean):\n        \"\"\"\n        A product has been scanned with success\n        \"\"\"\n        print 'scan_item_success: ' + str(ean)\n\n    @http.route('/hw_proxy/scan_item_error_unrecognized', type='json', auth='none', cors='*')\n    def scan_item_error_unrecognized(self, ean):\n        \"\"\"\n        A product has been scanned without success\n        \"\"\"\n        print 'scan_item_error_unrecognized: ' + str(ean)\n\n    @http.route('/hw_proxy/help_needed', type='json', auth='none', cors='*')\n    def help_needed(self):\n        \"\"\"\n        The user wants an help (ex: light is on)\n        \"\"\"\n        print \"help_needed\"\n\n    @http.route('/hw_proxy/help_canceled', type='json', auth='none', cors='*')\n    def help_canceled(self):\n        \"\"\"\n        The user stops the help request\n        \"\"\"\n        print \"help_canceled\"\n\n    @http.route('/hw_proxy/payment_request', type='json', auth='none', cors='*')\n    def payment_request(self, price):\n        \"\"\"\n        The PoS will activate the method payment \n        \"\"\"\n        print \"payment_request: price:\"+str(price)\n        return 'ok'\n\n    @http.route('/hw_proxy/payment_status', type='json', auth='none', cors='*')\n    def payment_status(self):\n        print \"payment_status\"\n        return { 'status':'waiting' } \n\n    @http.route('/hw_proxy/payment_cancel', type='json', auth='none', cors='*')\n    def payment_cancel(self):\n        print \"payment_cancel\"\n\n    @http.route('/hw_proxy/transaction_start', type='json', auth='none', cors='*')\n    def transaction_start(self):\n        print 'transaction_start'\n\n    @http.route('/hw_proxy/transaction_end', type='json', auth='none', cors='*')\n    def transaction_end(self):\n        print 'transaction_end'\n\n    @http.route('/hw_proxy/cashier_mode_activated', type='json', auth='none', cors='*')\n    def cashier_mode_activated(self):\n        print 'cashier_mode_activated'\n\n    @http.route('/hw_proxy/cashier_mode_deactivated', type='json', auth='none', cors='*')\n    def cashier_mode_deactivated(self):\n        print 'cashier_mode_deactivated'\n\n    @http.route('/hw_proxy/open_cashbox', type='json', auth='none', cors='*')\n    def open_cashbox(self):\n        print 'open_cashbox'\n\n    @http.route('/hw_proxy/print_receipt', type='json', auth='none', cors='*')\n    def print_receipt(self, receipt):\n        print 'print_receipt' + str(receipt)\n\n    @http.route('/hw_proxy/is_scanner_connected', type='json', auth='none', cors='*')\n    def is_scanner_connected(self, receipt):\n        print 'is_scanner_connected?' \n        return False\n\n    @http.route('/hw_proxy/scanner', type='json', auth='none', cors='*')\n    def scanner(self, receipt):\n        print 'scanner' \n        time.sleep(10)\n        return ''\n\n    @http.route('/hw_proxy/log', type='json', auth='none', cors='*')\n    def log(self, arguments):\n        _logger.info(' '.join(str(v) for v in arguments))\n\n    @http.route('/hw_proxy/print_pdf_invoice', type='json', auth='none', cors='*')\n    def print_pdf_invoice(self, pdfinvoice):\n        print 'print_pdf_invoice' + str(pdfinvoice)\n" }
{ "repo_name": "ClearCorp/odoo-costa-rica", "ref": "refs/heads/9.0", "path": "TODO-7.0/l10n_cr_account_financial_report_webkit/__init__.py", "content": "# -*- coding: utf-8 -*-\n##############################################################################\n#\n#    OpenERP, Open Source Management Solution\n#    Addons modules by CLEARCORP S.A.\n#    Copyright (C) 2009-TODAY CLEARCORP S.A. (<http://clearcorp.co.cr>).\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU Affero General Public License as\n#    published by the Free Software Foundation, either version 3 of the\n#    License, or (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU Affero General Public License for more details.\n#\n#    You should have received a copy of the GNU Affero General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\n\nimport account\nfrom . import wizard\nfrom . import report\nfrom . import account_account\n" }
{ "repo_name": "vaisaghvt/django-bot-server-tutorial", "ref": "refs/heads/websockets", "path": "chatbot_tutorial/urls.py", "content": "\"\"\"chatbot_tutorial URL Configuration\n\nThe `urlpatterns` list routes URLs to views. For more information please see:\n    https://docs.djangoproject.com/en/1.10/topics/http/urls/\nExamples:\nFunction views\n    1. Add an import:  from my_app import views\n    2. Add a URL to urlpatterns:  url(r'^$', views.home, name='home')\nClass-based views\n    1. Add an import:  from other_app.views import Home\n    2. Add a URL to urlpatterns:  url(r'^$', Home.as_view(), name='home')\nIncluding another URLconf\n    1. Import the include() function: from django.conf.urls import url, include\n    2. Add a URL to urlpatterns:  url(r'^blog/', include('blog.urls'))\n\"\"\"\nfrom django.conf.urls import url\nfrom django.contrib import admin\nfrom .views import chat\n\nurlpatterns = [\n\turl(r'^chat/$', chat, name='chat'),\n    url(r'^admin/', admin.site.urls)\n]\n" }
{ "repo_name": "michael-dev2rights/ansible", "ref": "refs/heads/ansible-d2r", "path": "lib/ansible/modules/cloud/vmware/vca_fw.py", "content": "#!/usr/bin/python\n\n# Copyright (c) 2015 VMware, Inc. All Rights Reserved.\n# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)\n\nfrom __future__ import absolute_import, division, print_function\n__metaclass__ = type\n\n\nANSIBLE_METADATA = {'metadata_version': '1.1',\n                    'status': ['preview'],\n                    'supported_by': 'community'}\n\n\nDOCUMENTATION = '''\n---\nmodule: vca_fw\nshort_description: add remove firewall rules in a gateway  in a vca\ndescription:\n  - Adds or removes firewall rules from a gateway in a vca environment\nversion_added: \"2.0\"\nauthor: Peter Sprygada (@privateip)\noptions:\n    fw_rules:\n      description:\n        - A list of firewall rules to be added to the gateway, Please see examples on valid entries\n      required: True\n      default: false\nextends_documentation_fragment: vca.documentation\n'''\n\nEXAMPLES = '''\n\n#Add a set of firewall rules\n\n- hosts: localhost\n  connection: local\n  tasks:\n   - vca_fw:\n       instance_id: 'b15ff1e5-1024-4f55-889f-ea0209726282'\n       vdc_name: 'benz_ansible'\n       state: 'absent'\n       fw_rules:\n         - description: \"ben testing\"\n           source_ip: \"Any\"\n           dest_ip: 192.0.2.23\n         - description: \"ben testing 2\"\n           source_ip: 192.0.2.50\n           source_port: \"Any\"\n           dest_port: \"22\"\n           dest_ip: 192.0.2.101\n           is_enable: \"true\"\n           enable_logging: \"false\"\n           protocol: \"Tcp\"\n           policy: \"allow\"\n\n'''\n\ntry:\n    from pyvcloud.schema.vcd.v1_5.schemas.vcloud.networkType import FirewallRuleType\n    from pyvcloud.schema.vcd.v1_5.schemas.vcloud.networkType import ProtocolsType\nexcept ImportError:\n    # normally set a flag here but it will be caught when testing for\n    # the existence of pyvcloud (see module_utils/vca.py).  This just\n    # protects against generating an exception at runtime\n    pass\n\nfrom ansible.module_utils.basic import AnsibleModule\nfrom ansible.module_utils.vca import VcaError, vca_argument_spec, vca_login\n\n\nVALID_PROTO = ['Tcp', 'Udp', 'Icmp', 'Other', 'Any']\nVALID_RULE_KEYS = ['policy', 'is_enable', 'enable_logging', 'description',\n                   'dest_ip', 'dest_port', 'source_ip', 'source_port',\n                   'protocol']\n\n\ndef protocol_to_tuple(protocol):\n    return (protocol.get_Tcp(),\n            protocol.get_Udp(),\n            protocol.get_Icmp(),\n            protocol.get_Other(),\n            protocol.get_Any())\n\ndef protocol_to_string(protocol):\n    protocol = protocol_to_tuple(protocol)\n    if protocol[0] is True:\n        return 'Tcp'\n    elif protocol[1] is True:\n        return 'Udp'\n    elif protocol[2] is True:\n        return 'Icmp'\n    elif protocol[3] is True:\n        return 'Other'\n    elif protocol[4] is True:\n        return 'Any'\n\ndef protocol_to_type(protocol):\n    try:\n        protocols = ProtocolsType()\n        setattr(protocols, protocol, True)\n        return protocols\n    except AttributeError:\n        raise VcaError(\"The value in protocol is not valid\")\n\ndef validate_fw_rules(fw_rules):\n    for rule in fw_rules:\n        for k in rule.keys():\n            if k not in VALID_RULE_KEYS:\n                raise VcaError(\"%s is not a valid key in fw rules, please \"\n                               \"check above..\" % k, valid_keys=VALID_RULE_KEYS)\n\n        rule['dest_port'] = str(rule.get('dest_port', 'Any')).lower()\n        rule['dest_ip'] = rule.get('dest_ip', 'Any').lower()\n        rule['source_port'] = str(rule.get('source_port', 'Any')).lower()\n        rule['source_ip'] = rule.get('source_ip', 'Any').lower()\n        rule['protocol'] = rule.get('protocol', 'Any').lower()\n        rule['policy'] = rule.get('policy', 'allow').lower()\n        rule['is_enable'] = rule.get('is_enable', True)\n        rule['enable_logging'] = rule.get('enable_logging', False)\n        rule['description'] = rule.get('description', 'rule added by Ansible')\n\n    return fw_rules\n\ndef fw_rules_to_dict(rules):\n    fw_rules = list()\n    for rule in rules:\n        fw_rules.append(\n            dict(\n                dest_port=rule.get_DestinationPortRange().lower(),\n                dest_ip=rule.get_DestinationIp().lower().lower(),\n                source_port=rule.get_SourcePortRange().lower(),\n                source_ip=rule.get_SourceIp().lower(),\n                protocol=protocol_to_string(rule.get_Protocols()).lower(),\n                policy=rule.get_Policy().lower(),\n                is_enable=rule.get_IsEnabled(),\n                enable_logging=rule.get_EnableLogging(),\n                description=rule.get_Description()\n            )\n        )\n    return fw_rules\n\ndef create_fw_rule(is_enable, description, policy, protocol, dest_port,\n                   dest_ip, source_port, source_ip, enable_logging):\n\n    return FirewallRuleType(IsEnabled=is_enable,\n                            Description=description,\n                            Policy=policy,\n                            Protocols=protocol_to_type(protocol),\n                            DestinationPortRange=dest_port,\n                            DestinationIp=dest_ip,\n                            SourcePortRange=source_port,\n                            SourceIp=source_ip,\n                            EnableLogging=enable_logging)\n\ndef main():\n    argument_spec = vca_argument_spec()\n    argument_spec.update(\n        dict(\n            fw_rules = dict(required=True, type='list'),\n            gateway_name = dict(default='gateway'),\n            state = dict(default='present', choices=['present', 'absent'])\n        )\n    )\n\n    module = AnsibleModule(argument_spec, supports_check_mode=True)\n\n    fw_rules = module.params.get('fw_rules')\n    gateway_name = module.params.get('gateway_name')\n    vdc_name = module.params['vdc_name']\n\n    vca = vca_login(module)\n\n    gateway = vca.get_gateway(vdc_name, gateway_name)\n    if not gateway:\n        module.fail_json(msg=\"Not able to find the gateway %s, please check \"\n                             \"the gateway_name param\" % gateway_name)\n\n    fwservice = gateway._getFirewallService()\n\n    rules = gateway.get_fw_rules()\n    current_rules = fw_rules_to_dict(rules)\n\n    try:\n        desired_rules = validate_fw_rules(fw_rules)\n    except VcaError as e:\n        module.fail_json(msg=e.message)\n\n    result = dict(changed=False)\n    result['current_rules'] = current_rules\n    result['desired_rules'] = desired_rules\n\n    updates = list()\n    additions = list()\n    deletions = list()\n\n    for (index, rule) in enumerate(desired_rules):\n        try:\n            if rule != current_rules[index]:\n                updates.append((index, rule))\n        except IndexError:\n            additions.append(rule)\n\n    eol = len(current_rules) - len(desired_rules)\n    if eol > 0:\n        for rule in current_rules[eol:]:\n            deletions.append(rule)\n\n    for rule in additions:\n        if not module.check_mode:\n            rule['protocol'] = rule['protocol'].capitalize()\n            gateway.add_fw_rule(**rule)\n        result['changed'] = True\n\n    for index, rule in updates:\n        if not module.check_mode:\n            rule = create_fw_rule(**rule)\n            fwservice.replace_FirewallRule_at(index, rule)\n        result['changed'] = True\n\n    keys = ['protocol', 'dest_port', 'dest_ip', 'source_port', 'source_ip']\n    for rule in deletions:\n        if not module.check_mode:\n            kwargs = dict([(k, v) for k, v in rule.items() if k in keys])\n            kwargs['protocol'] = protocol_to_string(kwargs['protocol'])\n            gateway.delete_fw_rule(**kwargs)\n        result['changed'] = True\n\n    if not module.check_mode and result['changed'] is True:\n        task = gateway.save_services_configuration()\n        if task:\n            vca.block_until_completed(task)\n\n    result['rules_updated'] = len(updates)\n    result['rules_added'] = len(additions)\n    result['rules_deleted'] = len(deletions)\n\n    return module.exit_json(**result)\n\n\nif __name__ == '__main__':\n    main()\n" }
{ "repo_name": "esikachev/scenario", "ref": "refs/heads/test_cases", "path": "sahara/plugins/mapr/services/hbase/hbase.py", "content": "# Copyright (c) 2015, MapR Technologies\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n# not use this file except in compliance with the License. You may obtain\n# a copy of the License at\n#\n#       http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n\n\nimport six\n\nimport sahara.plugins.mapr.domain.configuration_file as bcf\nimport sahara.plugins.mapr.domain.node_process as np\nimport sahara.plugins.mapr.domain.service as s\nimport sahara.plugins.mapr.util.validation_utils as vu\n\n\nHBASE_MASTER = np.NodeProcess(\n    name='hbmaster',\n    ui_name='HBase-Master',\n    package='mapr-hbase-master',\n    open_ports=[60000, 60010]\n)\nHBASE_REGION_SERVER = np.NodeProcess(\n    name='hbregionserver',\n    ui_name='HBase-RegionServer',\n    package='mapr-hbase-regionserver',\n    open_ports=[60020]\n)\nHBASE_THRIFT = np.NodeProcess(\n    name='hbasethrift',\n    ui_name='HBase-Thrift',\n    package='mapr-hbasethrift',\n    open_ports=[9090]\n)\n\n\nclass HBase(s.Service):\n    def __init__(self):\n        super(HBase, self).__init__()\n        self._name = 'hbase'\n        self._ui_name = 'HBase'\n        self._node_processes = [\n            HBASE_MASTER,\n            HBASE_REGION_SERVER,\n            HBASE_THRIFT,\n        ]\n        self._cluster_defaults = ['hbase-default.json']\n        self._validation_rules = [\n            vu.at_least(1, HBASE_MASTER),\n            vu.at_least(1, HBASE_REGION_SERVER),\n        ]\n\n    def get_config_files(self, cluster_context, configs, instance=None):\n        hbase_site = bcf.HadoopXML(\"hbase-site.xml\")\n        hbase_site.remote_path = self.conf_dir(cluster_context)\n        if instance:\n            hbase_site.fetch(instance)\n        hbase_site.load_properties(configs)\n        return [hbase_site]\n\n\n@six.add_metaclass(s.Single)\nclass HBaseV094(HBase):\n    def __init__(self):\n        super(HBaseV094, self).__init__()\n        self._version = '0.94.24'\n        self._dependencies = [('mapr-hbase', self.version)]\n\n\n@six.add_metaclass(s.Single)\nclass HBaseV098(HBase):\n    def __init__(self):\n        super(HBaseV098, self).__init__()\n        self._version = '0.98.7'\n        self._dependencies = [('mapr-hbase', self.version)]\n" }
{ "repo_name": "lovelysystems/pyjamas", "ref": "refs/heads/ls-production", "path": "examples/showcase/src/demos_widgets/fileUpload.py", "content": "\"\"\"\nThe ``ui.FileUpload`` class implements a file uploader widget.\n\nThe FileUpload widget must be inside a ``ui.FormPanel`` which is used to submit\nthe HTML form to the server.  Note that you must set the form encoding and\nmethod like this:\n\n        self.form.setEncoding(FormPanel.ENCODING_MULTIPART)\n        self.form.setMethod(FormPanel.METHOD_POST)\n\nThis will ensure that the form is submitted in a way that allows files to be\nuploaded.\n\nThe example below doesn't really work, as there is no suitable server at\n``nonexistent.com``.  However, it does show how a file upload widget could be\nused within a FormPanel.\n\"\"\"\nfrom pyjamas.ui.SimplePanel import SimplePanel\nfrom pyjamas.ui.FormPanel import FormPanel\nfrom pyjamas.ui.VerticalPanel import VerticalPanel\nfrom pyjamas.ui.HorizontalPanel import HorizontalPanel\nfrom pyjamas.ui.FileUpload import FileUpload\nfrom pyjamas.ui.Label import Label\nfrom pyjamas.ui.Button import Button\n\nclass FileUploadDemo(SimplePanel):\n    def __init__(self):\n        SimplePanel.__init__(self)\n\n        self.form = FormPanel()\n        self.form.setEncoding(FormPanel.ENCODING_MULTIPART)\n        self.form.setMethod(FormPanel.METHOD_POST)\n        self.form.setAction(\"http://nonexistent.com\")\n        self.form.setTarget(\"results\")\n\n        vPanel = VerticalPanel()\n\n        hPanel = HorizontalPanel()\n        hPanel.setSpacing(5)\n        hPanel.add(Label(\"Upload file:\"))\n\n        self.field = FileUpload()\n        self.field.setName(\"file\")\n        hPanel.add(self.field)\n\n        hPanel.add(Button(\"Submit\", getattr(self, \"onBtnClick\")))\n\n        vPanel.add(hPanel)\n\n        results = NamedFrame(\"results\")\n        vPanel.add(results)\n\n        self.form.add(vPanel)\n        self.add(self.form)\n\n\n    def onBtnClick(self, event):\n        self.form.submit()\n\n" }
{ "repo_name": "redhat-openstack/sahara", "ref": "refs/heads/master-patches", "path": "sahara/plugins/mapr/services/hbase/hbase.py", "content": "# Copyright (c) 2015, MapR Technologies\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n# not use this file except in compliance with the License. You may obtain\n# a copy of the License at\n#\n#       http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n\n\nimport six\n\nimport sahara.plugins.mapr.domain.configuration_file as bcf\nimport sahara.plugins.mapr.domain.node_process as np\nimport sahara.plugins.mapr.domain.service as s\nimport sahara.plugins.mapr.util.validation_utils as vu\n\n\nHBASE_MASTER = np.NodeProcess(\n    name='hbmaster',\n    ui_name='HBase-Master',\n    package='mapr-hbase-master',\n    open_ports=[60000, 60010]\n)\nHBASE_REGION_SERVER = np.NodeProcess(\n    name='hbregionserver',\n    ui_name='HBase-RegionServer',\n    package='mapr-hbase-regionserver',\n    open_ports=[60020]\n)\nHBASE_THRIFT = np.NodeProcess(\n    name='hbasethrift',\n    ui_name='HBase-Thrift',\n    package='mapr-hbasethrift',\n    open_ports=[9090]\n)\n\n\nclass HBase(s.Service):\n    def __init__(self):\n        super(HBase, self).__init__()\n        self._name = 'hbase'\n        self._ui_name = 'HBase'\n        self._node_processes = [\n            HBASE_MASTER,\n            HBASE_REGION_SERVER,\n            HBASE_THRIFT,\n        ]\n        self._cluster_defaults = ['hbase-default.json']\n        self._validation_rules = [\n            vu.at_least(1, HBASE_MASTER),\n            vu.at_least(1, HBASE_REGION_SERVER),\n        ]\n\n    def get_config_files(self, cluster_context, configs, instance=None):\n        hbase_site = bcf.HadoopXML(\"hbase-site.xml\")\n        hbase_site.remote_path = self.conf_dir(cluster_context)\n        if instance:\n            hbase_site.fetch(instance)\n        hbase_site.load_properties(configs)\n        return [hbase_site]\n\n\n@six.add_metaclass(s.Single)\nclass HBaseV094(HBase):\n    def __init__(self):\n        super(HBaseV094, self).__init__()\n        self._version = '0.94.24'\n        self._dependencies = [('mapr-hbase', self.version)]\n\n\n@six.add_metaclass(s.Single)\nclass HBaseV098(HBase):\n    def __init__(self):\n        super(HBaseV098, self).__init__()\n        self._version = '0.98.7'\n        self._dependencies = [('mapr-hbase', self.version)]\n" }
{ "repo_name": "Smile-SA/odoo_addons", "ref": "refs/heads/12.0", "path": "smile_anonymization/models/res_partner_title.py", "content": "# -*- coding: utf-8 -*-\n# (C) 2019 Smile (<http://www.smile.fr>)\n# License AGPL-3.0 or later (https://www.gnu.org/licenses/agpl).\n\nfrom odoo import fields, models\n\n\nclass ResPartnerTitle(models.Model):\n    _inherit = 'res.partner.title'\n\n    name = fields.Char(data_mask=\"'title_' || id::text\")\n    shortcut = fields.Char(data_mask=\"NULL\")\n" }
{ "repo_name": "bigfootproject/sahara", "ref": "refs/heads/spark-plugin", "path": "sahara/plugins/mapr/services/hbase/hbase.py", "content": "# Copyright (c) 2015, MapR Technologies\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n# not use this file except in compliance with the License. You may obtain\n# a copy of the License at\n#\n#       http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n\n\nimport six\n\nimport sahara.plugins.mapr.domain.configuration_file as bcf\nimport sahara.plugins.mapr.domain.node_process as np\nimport sahara.plugins.mapr.domain.service as s\nimport sahara.plugins.mapr.util.validation_utils as vu\n\n\nHBASE_MASTER = np.NodeProcess(\n    name='hbmaster',\n    ui_name='HBase-Master',\n    package='mapr-hbase-master',\n    open_ports=[60000, 60010]\n)\nHBASE_REGION_SERVER = np.NodeProcess(\n    name='hbregionserver',\n    ui_name='HBase-RegionServer',\n    package='mapr-hbase-regionserver',\n    open_ports=[60020]\n)\nHBASE_THRIFT = np.NodeProcess(\n    name='hbasethrift',\n    ui_name='HBase-Thrift',\n    package='mapr-hbasethrift',\n    open_ports=[9090]\n)\n\n\nclass HBase(s.Service):\n    def __init__(self):\n        super(HBase, self).__init__()\n        self._name = 'hbase'\n        self._ui_name = 'HBase'\n        self._node_processes = [\n            HBASE_MASTER,\n            HBASE_REGION_SERVER,\n            HBASE_THRIFT,\n        ]\n        self._cluster_defaults = ['hbase-default.json']\n        self._validation_rules = [\n            vu.at_least(1, HBASE_MASTER),\n            vu.at_least(1, HBASE_REGION_SERVER),\n        ]\n\n    def get_config_files(self, cluster_context, configs, instance=None):\n        hbase_site = bcf.HadoopXML(\"hbase-site.xml\")\n        hbase_site.remote_path = self.conf_dir(cluster_context)\n        if instance:\n            hbase_site.fetch(instance)\n        hbase_site.load_properties(configs)\n        return [hbase_site]\n\n\n@six.add_metaclass(s.Single)\nclass HBaseV094(HBase):\n    def __init__(self):\n        super(HBaseV094, self).__init__()\n        self._version = '0.94.24'\n        self._dependencies = [('mapr-hbase', self.version)]\n\n\n@six.add_metaclass(s.Single)\nclass HBaseV098(HBase):\n    def __init__(self):\n        super(HBaseV098, self).__init__()\n        self._version = '0.98.7'\n        self._dependencies = [('mapr-hbase', self.version)]\n" }
{ "repo_name": "nubark/odoo", "ref": "refs/heads/9.0", "path": "openerp/addons/test_limits/__openerp__.py", "content": "# -*- coding: utf-8 -*-\n{\n    'name': 'test-limits',\n    'version': '0.1',\n    'category': 'Tests',\n    'description': \"\"\"A module with dummy methods.\"\"\",\n    'depends': ['base'],\n    'data': ['ir.model.access.csv'],\n    'installable': True,\n    'auto_install': False,\n}\n" }
{ "repo_name": "odoobgorg/odoo", "ref": "refs/heads/9.0", "path": "openerp/addons/test_limits/__openerp__.py", "content": "# -*- coding: utf-8 -*-\n{\n    'name': 'test-limits',\n    'version': '0.1',\n    'category': 'Tests',\n    'description': \"\"\"A module with dummy methods.\"\"\",\n    'depends': ['base'],\n    'data': ['ir.model.access.csv'],\n    'installable': True,\n    'auto_install': False,\n}\n" }
{ "repo_name": "Elico-Corp/odoo_OCB", "ref": "refs/heads/9.0", "path": "openerp/addons/test_limits/__openerp__.py", "content": "# -*- coding: utf-8 -*-\n{\n    'name': 'test-limits',\n    'version': '0.1',\n    'category': 'Tests',\n    'description': \"\"\"A module with dummy methods.\"\"\",\n    'depends': ['base'],\n    'data': ['ir.model.access.csv'],\n    'installable': True,\n    'auto_install': False,\n}\n" }
{ "repo_name": "kvar/ansible", "ref": "refs/heads/seas_master_2.9.5", "path": "test/units/modules/storage/netapp/test_na_ontap_vserver_cifs_security.py", "content": "# (c) 2019, NetApp, Inc\n# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)\n\n''' unit test template for ONTAP Ansible module '''\n\nfrom __future__ import (absolute_import, division, print_function)\n__metaclass__ = type\nimport json\nimport pytest\n\nfrom units.compat import unittest\nfrom units.compat.mock import patch, Mock\nfrom ansible.module_utils import basic\nfrom ansible.module_utils._text import to_bytes\nimport ansible.module_utils.netapp as netapp_utils\n\nfrom ansible.modules.storage.netapp.na_ontap_vserver_cifs_security \\\n    import NetAppONTAPCifsSecurity as cifs_security_module  # module under test\n\nif not netapp_utils.has_netapp_lib():\n    pytestmark = pytest.mark.skip('skipping as missing required netapp_lib')\n\n\ndef set_module_args(args):\n    \"\"\"prepare arguments so that they will be picked up during module creation\"\"\"\n    args = json.dumps({'ANSIBLE_MODULE_ARGS': args})\n    basic._ANSIBLE_ARGS = to_bytes(args)  # pylint: disable=protected-access\n\n\nclass AnsibleExitJson(Exception):\n    \"\"\"Exception class to be raised by module.exit_json and caught by the test case\"\"\"\n    pass\n\n\nclass AnsibleFailJson(Exception):\n    \"\"\"Exception class to be raised by module.fail_json and caught by the test case\"\"\"\n    pass\n\n\ndef exit_json(*args, **kwargs):  # pylint: disable=unused-argument\n    \"\"\"function to patch over exit_json; package return data into an exception\"\"\"\n    if 'changed' not in kwargs:\n        kwargs['changed'] = False\n    raise AnsibleExitJson(kwargs)\n\n\ndef fail_json(*args, **kwargs):  # pylint: disable=unused-argument\n    \"\"\"function to patch over fail_json; package return data into an exception\"\"\"\n    kwargs['failed'] = True\n    raise AnsibleFailJson(kwargs)\n\n\nclass MockONTAPConnection(object):\n    ''' mock server connection to ONTAP host '''\n\n    def __init__(self, kind=None, data=None):\n        ''' save arguments '''\n        self.type = kind\n        self.data = data\n        self.xml_in = None\n        self.xml_out = None\n\n    def invoke_successfully(self, xml, enable_tunneling):  # pylint: disable=unused-argument\n        ''' mock invoke_successfully returning xml data '''\n        self.xml_in = xml\n        if self.type == 'cifs_security':\n            xml = self.build_port_info(self.data)\n        if self.type == 'error':\n            error = netapp_utils.zapi.NaApiError('test', 'error')\n            raise error\n        self.xml_out = xml\n        return xml\n\n    @staticmethod\n    def build_port_info(cifs_security_details):\n        ''' build xml data for cifs-security '''\n        xml = netapp_utils.zapi.NaElement('xml')\n        attributes = {\n            'num-records': 1,\n            'attributes-list': {\n                'cifs-security': {\n                    'is_aes_encryption_enabled': cifs_security_details['is_aes_encryption_enabled'],\n                    'lm_compatibility_level': cifs_security_details['lm_compatibility_level']\n              }\n          }\n      }\n        xml.translate_struct(attributes)\n        return xml\n\n\nclass TestMyModule(unittest.TestCase):\n    ''' a group of related Unit Tests '''\n\n    def setUp(self):\n        self.mock_module_helper = patch.multiple(basic.AnsibleModule,\n                                                 exit_json=exit_json,\n                                                 fail_json=fail_json)\n        self.mock_module_helper.start()\n        self.addCleanup(self.mock_module_helper.stop)\n        self.mock_cifs_security = {\n            'is_aes_encryption_enabled': 'true',\n            'lm_compatibility_level': 'krb'\n      }\n\n    def mock_args(self):\n        return {\n            'is_aes_encryption_enabled': self.mock_cifs_security['is_aes_encryption_enabled'],\n            'lm_compatibility_level': self.mock_cifs_security['lm_compatibility_level'],\n            'vserver': 'ansible',\n            'hostname': 'test',\n            'username': 'test_user',\n            'password': 'test_pass!',\n            'https': 'False'\n      }\n\n    def get_cifs_security_mock_object(self, kind=None):\n        \"\"\"\n        Helper method to return an na_ontap_vserver_cifs_security object\n        :param kind: passes this param to MockONTAPConnection()\n        :return: na_ontap_vserver_cifs_security object\n        \"\"\"\n        obj = cifs_security_module()\n        obj.asup_log_for_cserver = Mock(return_value=None)\n        obj.server = Mock()\n        obj.server.invoke_successfully = Mock()\n        if kind is None:\n            obj.server = MockONTAPConnection()\n        else:\n            obj.server = MockONTAPConnection(kind=kind, data=self.mock_cifs_security)\n        return obj\n\n    @patch('ansible.modules.storage.netapp.na_ontap_vserver_cifs_security.NetAppONTAPCifsSecurity.cifs_security_get_iter')\n    def test_successful_modify(self, get_cifs_security):\n        ''' Test successful modify max throughput '''\n        data = self.mock_args()\n        set_module_args(data)\n        current = {\n            'is_aes_encryption_enabled': False,\n            'lm_compatibility_level': 'lm_ntlm_ntlmv2_krb'\n      }\n        get_cifs_security.side_effect = [\n            current\n        ]\n        with pytest.raises(AnsibleExitJson) as exc:\n            self.get_cifs_security_mock_object('cifs_security').apply()\n        assert exc.value.args[0]['changed']\n\n    @patch('ansible.modules.storage.netapp.na_ontap_vserver_cifs_security.NetAppONTAPCifsSecurity.cifs_security_get_iter')\n    def test_modify_error(self, get_cifs_security):\n        ''' Test create idempotency '''\n        data = self.mock_args()\n        set_module_args(data)\n        current = {\n            'is_aes_encryption_enabled': False\n      }\n        get_cifs_security.side_effect = [\n            current\n        ]\n        with pytest.raises(AnsibleFailJson) as exc:\n            self.get_cifs_security_mock_object('error').apply()\n        assert exc.value.args[0]['msg'] == 'Error modifying cifs security on ansible: NetApp API failed. Reason - test:error'\n" } 
{ "repo_name": "microcom/odoo", "ref": "refs/heads/9.0", "path": "openerp/addons/test_limits/__openerp__.py", "content": "# -*- coding: utf-8 -*-\n{\n    'name': 'test-limits',\n    'version': '0.1',\n    'category': 'Tests',\n    'description': \"\"\"A module with dummy methods.\"\"\",\n    'depends': ['base'],\n    'data': ['ir.model.access.csv'],\n    'installable': True,\n    'auto_install': False,\n}\n" }
{ "repo_name": "bplancher/odoo", "ref": "refs/heads/9.0", "path": "openerp/addons/test_limits/__openerp__.py", "content": "# -*- coding: utf-8 -*-\n{\n    'name': 'test-limits',\n    'version': '0.1',\n    'category': 'Tests',\n    'description': \"\"\"A module with dummy methods.\"\"\",\n    'depends': ['base'],\n    'data': ['ir.model.access.csv'],\n    'installable': True,\n    'auto_install': False,\n}\n" }
{ "repo_name": "storm-computers/odoo", "ref": "refs/heads/9.0", "path": "openerp/addons/test_limits/__openerp__.py", "content": "# -*- coding: utf-8 -*-\n{\n    'name': 'test-limits',\n    'version': '0.1',\n    'category': 'Tests',\n    'description': \"\"\"A module with dummy methods.\"\"\",\n    'depends': ['base'],\n    'data': ['ir.model.access.csv'],\n    'installable': True,\n    'auto_install': False,\n}\n" }
{ "repo_name": "AyoubZahid/odoo", "ref": "refs/heads/9.0", "path": "openerp/addons/test_limits/__openerp__.py", "content": "# -*- coding: utf-8 -*-\n{\n    'name': 'test-limits',\n    'version': '0.1',\n    'category': 'Tests',\n    'description': \"\"\"A module with dummy methods.\"\"\",\n    'depends': ['base'],\n    'data': ['ir.model.access.csv'],\n    'installable': True,\n    'auto_install': False,\n}\n" }
{ "repo_name": "b12io/orchestra", "ref": "refs/heads/main", "path": "orchestra/utils/json_schema.py", "content": "\"\"\"\nValidation function for json schemas\n\"\"\"\nfrom jsonschema import Draft4Validator\nfrom jsonschema import validators\n\n\ndef extend_with_default(validator_class):\n    \"\"\"\n    Extends json schema validator so that it fills in default values.\n\n    NOTE(aditya): Copied code from\n    https://github.com/b12io/crowdsurfing/blob/master/product/common/json_schema.py\n    \"\"\"\n    validate_properties = validator_class.VALIDATORS['properties']\n\n    def set_defaults(validator, properties, instance, schema):\n        for property, subschema in properties.items():\n            if 'default' in subschema:\n                instance.setdefault(property, subschema['default'])\n\n        for error in validate_properties(\n                validator, properties, instance, schema):\n            yield error\n\n    return validators.extend(validator_class, {'properties': set_defaults})\n\n\nDefaultValidatingDraft4Validator = extend_with_default(Draft4Validator)\n" }
{ "repo_name": "thaim/ansible", "ref": "refs/heads/fix-broken-link", "path": "test/units/modules/storage/netapp/test_na_ontap_vserver_cifs_security.py", "content": "# (c) 2019, NetApp, Inc\n# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)\n\n''' unit test template for ONTAP Ansible module '''\n\nfrom __future__ import (absolute_import, division, print_function)\n__metaclass__ = type\nimport json\nimport pytest\n\nfrom units.compat import unittest\nfrom units.compat.mock import patch, Mock\nfrom ansible.module_utils import basic\nfrom ansible.module_utils._text import to_bytes\nimport ansible.module_utils.netapp as netapp_utils\n\nfrom ansible.modules.storage.netapp.na_ontap_vserver_cifs_security \\\n    import NetAppONTAPCifsSecurity as cifs_security_module  # module under test\n\nif not netapp_utils.has_netapp_lib():\n    pytestmark = pytest.mark.skip('skipping as missing required netapp_lib')\n\n\ndef set_module_args(args):\n    \"\"\"prepare arguments so that they will be picked up during module creation\"\"\"\n    args = json.dumps({'ANSIBLE_MODULE_ARGS': args})\n    basic._ANSIBLE_ARGS = to_bytes(args)  # pylint: disable=protected-access\n\n\nclass AnsibleExitJson(Exception):\n    \"\"\"Exception class to be raised by module.exit_json and caught by the test case\"\"\"\n    pass\n\n\nclass AnsibleFailJson(Exception):\n    \"\"\"Exception class to be raised by module.fail_json and caught by the test case\"\"\"\n    pass\n\n\ndef exit_json(*args, **kwargs):  # pylint: disable=unused-argument\n    \"\"\"function to patch over exit_json; package return data into an exception\"\"\"\n    if 'changed' not in kwargs:\n        kwargs['changed'] = False\n    raise AnsibleExitJson(kwargs)\n\n\ndef fail_json(*args, **kwargs):  # pylint: disable=unused-argument\n    \"\"\"function to patch over fail_json; package return data into an exception\"\"\"\n    kwargs['failed'] = True\n    raise AnsibleFailJson(kwargs)\n\n\nclass MockONTAPConnection(object):\n    ''' mock server connection to ONTAP host '''\n\n    def __init__(self, kind=None, data=None):\n        ''' save arguments '''\n        self.type = kind\n        self.data = data\n        self.xml_in = None\n        self.xml_out = None\n\n    def invoke_successfully(self, xml, enable_tunneling):  # pylint: disable=unused-argument\n        ''' mock invoke_successfully returning xml data '''\n        self.xml_in = xml\n        if self.type == 'cifs_security':\n            xml = self.build_port_info(self.data)\n        if self.type == 'error':\n            error = netapp_utils.zapi.NaApiError('test', 'error')\n            raise error\n        self.xml_out = xml\n        return xml\n\n    @staticmethod\n    def build_port_info(cifs_security_details):\n        ''' build xml data for cifs-security '''\n        xml = netapp_utils.zapi.NaElement('xml')\n        attributes = {\n            'num-records': 1,\n            'attributes-list': {\n                'cifs-security': {\n                    'is_aes_encryption_enabled': cifs_security_details['is_aes_encryption_enabled'],\n                    'lm_compatibility_level': cifs_security_details['lm_compatibility_level']\n              }\n          }\n      }\n        xml.translate_struct(attributes)\n        return xml\n\n\nclass TestMyModule(unittest.TestCase):\n    ''' a group of related Unit Tests '''\n\n    def setUp(self):\n        self.mock_module_helper = patch.multiple(basic.AnsibleModule,\n                                                 exit_json=exit_json,\n                                                 fail_json=fail_json)\n        self.mock_module_helper.start()\n        self.addCleanup(self.mock_module_helper.stop)\n        self.mock_cifs_security = {\n            'is_aes_encryption_enabled': 'true',\n            'lm_compatibility_level': 'krb'\n      }\n\n    def mock_args(self):\n        return {\n            'is_aes_encryption_enabled': self.mock_cifs_security['is_aes_encryption_enabled'],\n            'lm_compatibility_level': self.mock_cifs_security['lm_compatibility_level'],\n            'vserver': 'ansible',\n            'hostname': 'test',\n            'username': 'test_user',\n            'password': 'test_pass!',\n            'https': 'False'\n      }\n\n    def get_cifs_security_mock_object(self, kind=None):\n        \"\"\"\n        Helper method to return an na_ontap_vserver_cifs_security object\n        :param kind: passes this param to MockONTAPConnection()\n        :return: na_ontap_vserver_cifs_security object\n        \"\"\"\n        obj = cifs_security_module()\n        obj.asup_log_for_cserver = Mock(return_value=None)\n        obj.server = Mock()\n        obj.server.invoke_successfully = Mock()\n        if kind is None:\n            obj.server = MockONTAPConnection()\n        else:\n            obj.server = MockONTAPConnection(kind=kind, data=self.mock_cifs_security)\n        return obj\n\n    @patch('ansible.modules.storage.netapp.na_ontap_vserver_cifs_security.NetAppONTAPCifsSecurity.cifs_security_get_iter')\n    def test_successful_modify(self, get_cifs_security):\n        ''' Test successful modify max throughput '''\n        data = self.mock_args()\n        set_module_args(data)\n        current = {\n            'is_aes_encryption_enabled': False,\n            'lm_compatibility_level': 'lm_ntlm_ntlmv2_krb'\n      }\n        get_cifs_security.side_effect = [\n            current\n        ]\n        with pytest.raises(AnsibleExitJson) as exc:\n            self.get_cifs_security_mock_object('cifs_security').apply()\n        assert exc.value.args[0]['changed']\n\n    @patch('ansible.modules.storage.netapp.na_ontap_vserver_cifs_security.NetAppONTAPCifsSecurity.cifs_security_get_iter')\n    def test_modify_error(self, get_cifs_security):\n        ''' Test create idempotency '''\n        data = self.mock_args()\n        set_module_args(data)\n        current = {\n            'is_aes_encryption_enabled': False\n      }\n        get_cifs_security.side_effect = [\n            current\n        ]\n        with pytest.raises(AnsibleFailJson) as exc:\n            self.get_cifs_security_mock_object('error').apply()\n        assert exc.value.args[0]['msg'] == 'Error modifying cifs security on ansible: NetApp API failed. Reason - test:error'\n" }
{ "repo_name": "roscopecoltran/scraper", "ref": "refs/heads/sniperkit", "path": ".staging/meta-engines/xlinkBook/update/update_stanford_cs.py", "content": "#!/usr/bin/env python\n    \n#author: wowdd1\n#mail: developergf@gmail.com\n#data: 2014.12.07\n    \nfrom spider import *\nfrom update_stanford import StanfordSpider\nfrom update_stanford_online import StanfordOnlineSpider\nsys.path.append(\"..\")\nfrom record import CourseRecord\n\nclass StanfordCSSpider(Spider):\n    course_num_list = []\n\n    def __init__(self):\n        Spider.__init__(self)\n        self.school = \"stanford\"\n        self.subject = \"eecs\"\n        stanfordSpider = StanfordSpider()\n        stanfordOnlineSpider = StanfordOnlineSpider()\n\n        self.description_dict = stanfordSpider.getDescriptionDict('Computer Science')\n        self.course_name_dict = stanfordOnlineSpider.getCourseNameDict()\n    \n    def isInCourseNumList(self, course_num):\n        for item in self.course_num_list:\n            if item == course_num:\n                return True\n        self.course_num_list.append(course_num)\n        return False\n   \n    def formatCourseTitle(self, title):\n        if title.find('(') != -1:\n            title = title[0 : title.find('(')]\n        return title.strip()\n \n    def processStanfordDate(self, f, url, course_dict):\n        print 'processing ' + url\n        r = requests.get(url)\n        soup = BeautifulSoup(r.text)\n        th_set = soup.find_all(\"th\")\n        td_set_all = soup.find_all(\"td\")\n        td_set = []\n        td_set_2 = []\n        del th_set[0:5]\n        i = 0\n        for td in td_set_all:\n            i = i + 1\n            if i == 1:\n                td_set.append(td.string)\n            if i == 2:\n                td_set_2.append(td.string)\n            if i == 4:\n                i = 0\n    \n        for index in range(0,len(th_set)):\n            link = th_set[index].prettify()\n            link = link[link.find(\"http\"):link.find(\"EDU\") + 3]\n            if self.isInCourseNumList(th_set[index].string):\n                continue\n            course_id = th_set[index].string.upper()\n            description = ''\n            description += 'instructors:' + td_set_2[index] + ' '\n            if self.course_name_dict.get(self.formatCourseTitle(td_set[index]), '') != '':\n                if self.course_name_dict.get(self.formatCourseTitle(td_set[index]), '') != '':\n                    description += 'videourl:' + self.course_name_dict[self.formatCourseTitle(td_set[index])] + ' '\n\n            if self.description_dict.get(course_id, '') != '':\n                description += 'description:' + self.description_dict[course_id] + ' '\n            course_dict[th_set[index].string.upper()] = CourseRecord(self.get_storage_format(th_set[index].string.upper(), td_set[index], link, description))\n\n   \n    def getCsCourseLinks(self):\n        links = []\n        r = requests.get('http://cs.stanford.edu/academics/courses')\n        soup = BeautifulSoup(r.text)\n        for a in soup.find_all('a'):\n            if a.attrs.has_key('href') and a['href'].find('http://cs.stanford.edu/courses/schedules/') != -1:\n                links.append(a['href'])\n\n        return links\n\n    def doWork(self):\n        #stanford\n        #\"\"\"\n        print \"downloading stanford course info\"\n\n        file_name = self.get_file_name(\"eecs/\" + \"cs\", self.school)\n        file_lines = self.countFileLineNum(file_name)\n        f = self.open_db(file_name + \".tmp\")\n        self.count = 0\n \n        print \"processing html and write data to file...\"\n        course_dict = {}\n        for url in self.getCsCourseLinks():\n            self.processStanfordDate(f, url, course_dict)\n\n        for k, record in [(k,course_dict[k]) for k in sorted(course_dict.keys())]:\n            self.count += 1\n            self.write_db(f, k, record.get_title().strip(), record.get_url().strip(), record.get_describe().strip()) \n    \n        self.close_db(f)\n        if file_lines != self.count and self.count > 0:\n            self.do_upgrade_db(file_name)\n            print \"before lines: \" + str(file_lines) + \" after update: \" + str(self.count) + \" \\n\\n\"\n        else:\n            self.cancel_upgrade(file_name)\n            print \"no need upgrade\\n\"\n        #\"\"\"\n    \ndef main(argv):\n    start = StanfordCSSpider()\n    start.doWork()\n\nif __name__ == '__main__':\n    main(sys.argv)\n\n" }
{ "repo_name": "unlimitedlabs/orchestra", "ref": "refs/heads/dependabot-npm_and_yarn-lodash-4.17.21", "path": "orchestra/utils/json_schema.py", "content": "\"\"\"\nValidation function for json schemas\n\"\"\"\nfrom jsonschema import Draft4Validator\nfrom jsonschema import validators\n\n\ndef extend_with_default(validator_class):\n    \"\"\"\n    Extends json schema validator so that it fills in default values.\n\n    NOTE(aditya): Copied code from\n    https://github.com/b12io/crowdsurfing/blob/master/product/common/json_schema.py\n    \"\"\"\n    validate_properties = validator_class.VALIDATORS['properties']\n\n    def set_defaults(validator, properties, instance, schema):\n        for property, subschema in properties.items():\n            if 'default' in subschema:\n                instance.setdefault(property, subschema['default'])\n\n        for error in validate_properties(\n                validator, properties, instance, schema):\n            yield error\n\n    return validators.extend(validator_class, {'properties': set_defaults})\n\n\nDefaultValidatingDraft4Validator = extend_with_default(Draft4Validator)\n" }
{ "repo_name": "laslabs/odoo", "ref": "refs/heads/9.0", "path": "openerp/addons/test_limits/__openerp__.py", "content": "# -*- coding: utf-8 -*-\n{\n    'name': 'test-limits',\n    'version': '0.1',\n    'category': 'Tests',\n    'description': \"\"\"A module with dummy methods.\"\"\",\n    'depends': ['base'],\n    'data': ['ir.model.access.csv'],\n    'installable': True,\n    'auto_install': False,\n}\n" }
{ "repo_name": "pfalcon/micropython", "ref": "refs/heads/pfalcon", "path": "tests/basics/python36.py", "content": "# tests for things that only Python 3.6 supports\n\n# underscores in numeric literals\nprint(100_000)\nprint(0b1010_0101)\nprint(0xff_ff)\n\n# underscore supported by int constructor\nprint(int('1_2_3'))\nprint(int('0o1_2_3', 8))\n" }
{ "repo_name": "be-cloud-be/horizon-addons", "ref": "refs/heads/9.0", "path": "server/openerp/addons/test_limits/__openerp__.py", "content": "# -*- coding: utf-8 -*-\n{\n    'name': 'test-limits',\n    'version': '0.1',\n    'category': 'Tests',\n    'description': \"\"\"A module with dummy methods.\"\"\",\n    'depends': ['base'],\n    'data': ['ir.model.access.csv'],\n    'installable': True,\n    'auto_install': False,\n}\n" }
{ "repo_name": "pozetroninc/micropython", "ref": "refs/heads/stable", "path": "tests/basics/python36.py", "content": "# tests for things that only Python 3.6 supports\n\n# underscores in numeric literals\nprint(100_000)\nprint(0b1010_0101)\nprint(0xff_ff)\n\n# underscore supported by int constructor\nprint(int('1_2_3'))\nprint(int('0o1_2_3', 8))\n" }
{ "repo_name": "ngageoint/voxel-globe", "ref": "refs/heads/nga_p2_release", "path": "voxel_globe/ingest/serializers.py", "content": "from rest_framework import serializers\n\nimport voxel_globe.ingest.models\n\nclass UploadSessionSerializer(serializers.ModelSerializer):\n  #directory = serializers.RelatedField(many=True, read_only=True)\n  class Meta(object):\n    model = voxel_globe.ingest.models.UploadSession\n    fields = ('file',)\n    read_only_fields = ('file',)\n#Add all the fields\nfn = map(lambda x:x.name, voxel_globe.ingest.models.UploadSession._meta.fields)\n#Except owner\nfn.remove('owner')\n#Add them to the existing list\nUploadSessionSerializer.Meta.fields = UploadSessionSerializer.Meta.fields + \\\n                                      tuple(fn)\ndel fn #clean up\n\n# class DirectorySerializer(serializers.ModelSerializer):\n#   class Meta(object):\n#     model = voxel_globe.ingest.models.Directory\n#     fields = ('id', 'name', 'file', 'session')\n#     read_only_fields = ('file',)\n\nclass FileSerializer(serializers.ModelSerializer):\n  class Meta:\n    model = voxel_globe.ingest.models.File\n    fields = ('id', 'name', 'session', 'completed')\n\n#Huge Security. Exposes Owner which exposes the password hash\n#def NestFactory(serializer):\n#  return type('Nested', (serializer,), \n#            {'Meta': type('Nested_Meta', (serializer.Meta,), {'depth':1})})" }
{ "repo_name": "trezor/micropython", "ref": "refs/heads/trezor-v1.12", "path": "tests/basics/python36.py", "content": "# tests for things that only Python 3.6 supports\n\n# underscores in numeric literals\nprint(100_000)\nprint(0b1010_0101)\nprint(0xff_ff)\n\n# underscore supported by int constructor\nprint(int('1_2_3'))\nprint(int('0o1_2_3', 8))\n" }
{ "repo_name": "Southpaw-TACTIC/TACTIC", "ref": "refs/heads/4.7", "path": "src/context/client/tactic-api-python-4.0.api04/Lib/genericpath.py", "content": "\"\"\"\r\nPath operations common to more than one OS\r\nDo not use directly.  The OS specific modules import the appropriate\r\nfunctions from this module themselves.\r\n\"\"\"\r\nimport os\r\nimport stat\r\n\r\n__all__ = ['commonprefix', 'exists', 'getatime', 'getctime', 'getmtime',\r\n           'getsize', 'isdir', 'isfile']\r\n\r\n\r\n# Does a path exist?\r\n# This is false for dangling symbolic links on systems that support them.\r\ndef exists(path):\r\n    \"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\r\n    try:\r\n        st = os.stat(path)\r\n    except os.error:\r\n        return False\r\n    return True\r\n\r\n\r\n# This follows symbolic links, so both islink() and isdir() can be true\r\n# for the same path ono systems that support symlinks\r\ndef isfile(path):\r\n    \"\"\"Test whether a path is a regular file\"\"\"\r\n    try:\r\n        st = os.stat(path)\r\n    except os.error:\r\n        return False\r\n    return stat.S_ISREG(st.st_mode)\r\n\r\n\r\n# Is a path a directory?\r\n# This follows symbolic links, so both islink() and isdir()\r\n# can be true for the same path on systems that support symlinks\r\ndef isdir(s):\r\n    \"\"\"Return true if the pathname refers to an existing directory.\"\"\"\r\n    try:\r\n        st = os.stat(s)\r\n    except os.error:\r\n        return False\r\n    return stat.S_ISDIR(st.st_mode)\r\n\r\n\r\ndef getsize(filename):\r\n    \"\"\"Return the size of a file, reported by os.stat().\"\"\"\r\n    return os.stat(filename).st_size\r\n\r\n\r\ndef getmtime(filename):\r\n    \"\"\"Return the last modification time of a file, reported by os.stat().\"\"\"\r\n    return os.stat(filename).st_mtime\r\n\r\n\r\ndef getatime(filename):\r\n    \"\"\"Return the last access time of a file, reported by os.stat().\"\"\"\r\n    return os.stat(filename).st_atime\r\n\r\n\r\ndef getctime(filename):\r\n    \"\"\"Return the metadata change time of a file, reported by os.stat().\"\"\"\r\n    return os.stat(filename).st_ctime\r\n\r\n\r\n# Return the longest prefix of all list elements.\r\ndef commonprefix(m):\r\n    \"Given a list of pathnames, returns the longest common leading component\"\r\n    if not m: return ''\r\n    s1 = min(m)\r\n    s2 = max(m)\r\n    for i, c in enumerate(s1):\r\n        if c != s2[i]:\r\n            return s1[:i]\r\n    return s1\r\n\r\n# Split a path in root and extension.\r\n# The extension is everything starting at the last dot in the last\r\n# pathname component; the root is everything before that.\r\n# It is always true that root + ext == p.\r\n\r\n# Generic implementation of splitext, to be parametrized with\r\n# the separators\r\ndef _splitext(p, sep, altsep, extsep):\r\n    \"\"\"Split the extension from a pathname.\r\n\r\n    Extension is everything from the last dot to the end, ignoring\r\n    leading dots.  Returns \"(root, ext)\"; ext may be empty.\"\"\"\r\n\r\n    sepIndex = p.rfind(sep)\r\n    if altsep:\r\n        altsepIndex = p.rfind(altsep)\r\n        sepIndex = max(sepIndex, altsepIndex)\r\n\r\n    dotIndex = p.rfind(extsep)\r\n    if dotIndex > sepIndex:\r\n        # skip all leading dots\r\n        filenameIndex = sepIndex + 1\r\n        while filenameIndex < dotIndex:\r\n            if p[filenameIndex] != extsep:\r\n                return p[:dotIndex], p[dotIndex:]\r\n            filenameIndex += 1\r\n\r\n    return p, ''\r\n" }
{ "repo_name": "dwavesystems/dimod", "ref": "refs/heads/main", "path": "dimod/higherorder/__init__.py", "content": "# Copyright 2019 D-Wave Systems Inc.\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\");\n#    you may not use this file except in compliance with the License.\n#    You may obtain a copy of the License at\n#\n#        http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS,\n#    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#    See the License for the specific language governing permissions and\n#    limitations under the License.\n#\n# ============================================================================\n\nfrom dimod.higherorder.polynomial import BinaryPolynomial\nfrom dimod.higherorder.utils import make_quadratic, poly_energy, poly_energies\n" }
{ "repo_name": "sajuptpm/neutron-ipam", "ref": "refs/heads/stable/icehouse", "path": "neutron/plugins/metaplugin/meta_neutron_plugin.py", "content": "# vim: tabstop=4 shiftwidth=4 softtabstop=4\n\n# Copyright 2012, Nachi Ueno, NTT MCL, Inc.\n# All Rights Reserved.\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\nfrom oslo.config import cfg\n\nfrom neutron.common import exceptions as exc\nfrom neutron.common import topics\nfrom neutron import context as neutron_context\nfrom neutron.db import api as db\nfrom neutron.db import db_base_plugin_v2\nfrom neutron.db import external_net_db\nfrom neutron.db import extraroute_db\nfrom neutron.db import l3_db\nfrom neutron.db import models_v2\nfrom neutron.extensions.flavor import (FLAVOR_NETWORK, FLAVOR_ROUTER)\nfrom neutron.openstack.common import importutils\nfrom neutron.openstack.common import log as logging\nfrom neutron.plugins.metaplugin.common import config  # noqa\nfrom neutron.plugins.metaplugin import meta_db_v2\nfrom neutron.plugins.metaplugin.meta_models_v2 import (NetworkFlavor,\n                                                       RouterFlavor)\n\n\nLOG = logging.getLogger(__name__)\n\n\n# Hooks used to select records which belong a target plugin.\ndef _meta_network_model_hook(context, original_model, query):\n    return query.outerjoin(NetworkFlavor,\n                           NetworkFlavor.network_id == models_v2.Network.id)\n\n\ndef _meta_port_model_hook(context, original_model, query):\n    return query.join(NetworkFlavor,\n                      NetworkFlavor.network_id == models_v2.Port.network_id)\n\n\ndef _meta_flavor_filter_hook(query, filters):\n    if FLAVOR_NETWORK in filters:\n        return query.filter(NetworkFlavor.flavor ==\n                            filters[FLAVOR_NETWORK][0])\n    return query\n\n\n# Metaplugin  Exceptions\nclass FlavorNotFound(exc.NotFound):\n    message = _(\"Flavor %(flavor)s could not be found\")\n\n\nclass FaildToAddFlavorBinding(exc.NeutronException):\n    message = _(\"Failed to add flavor binding\")\n\n\nclass MetaPluginV2(db_base_plugin_v2.NeutronDbPluginV2,\n                   external_net_db.External_net_db_mixin,\n                   extraroute_db.ExtraRoute_db_mixin):\n\n    def __init__(self, configfile=None):\n        super(MetaPluginV2, self).__init__()\n        LOG.debug(_(\"Start initializing metaplugin\"))\n        self.supported_extension_aliases = ['flavor', 'external-net']\n        if cfg.CONF.META.supported_extension_aliases:\n            cfg_aliases = cfg.CONF.META.supported_extension_aliases.split(',')\n            self.supported_extension_aliases += cfg_aliases\n\n        # Ignore config option overapping\n        def _is_opt_registered(opts, opt):\n            if opt.dest in opts:\n                return True\n            else:\n                return False\n\n        cfg._is_opt_registered = _is_opt_registered\n\n        # Keep existing tables if multiple plugin use same table name.\n        db.model_base.NeutronBase.__table_args__ = {'keep_existing': True}\n\n        self.plugins = {}\n\n        plugin_list = [plugin_set.split(':')\n                       for plugin_set\n                       in cfg.CONF.META.plugin_list.split(',')]\n        self.rpc_flavor = cfg.CONF.META.rpc_flavor\n        topic_save = topics.PLUGIN\n        topic_fake = topic_save + '-metaplugin'\n        for flavor, plugin_provider in plugin_list:\n            # Rename topic used by a plugin other than rpc_flavor during\n            # loading the plugin instance if rpc_flavor is specified.\n            # This enforces the plugin specified by rpc_flavor is only\n            # consumer of 'q-plugin'. It is a bit tricky but there is no\n            # bad effect.\n            if self.rpc_flavor and self.rpc_flavor != flavor:\n                topics.PLUGIN = topic_fake\n            self.plugins[flavor] = self._load_plugin(plugin_provider)\n            topics.PLUGIN = topic_save\n\n        self.l3_plugins = {}\n        if cfg.CONF.META.l3_plugin_list:\n            l3_plugin_list = [plugin_set.split(':')\n                              for plugin_set\n                              in cfg.CONF.META.l3_plugin_list.split(',')]\n            for flavor, plugin_provider in l3_plugin_list:\n                if flavor in self.plugins:\n                    self.l3_plugins[flavor] = self.plugins[flavor]\n                else:\n                    # For l3 only plugin\n                    self.l3_plugins[flavor] = self._load_plugin(\n                        plugin_provider)\n\n        self.default_flavor = cfg.CONF.META.default_flavor\n        if self.default_flavor not in self.plugins:\n            raise exc.Invalid(_('default_flavor %s is not plugin list') %\n                              self.default_flavor)\n\n        if self.l3_plugins:\n            self.default_l3_flavor = cfg.CONF.META.default_l3_flavor\n            if self.default_l3_flavor not in self.l3_plugins:\n                raise exc.Invalid(_('default_l3_flavor %s is not plugin list')\n                                  % self.default_l3_flavor)\n            self.supported_extension_aliases += ['router', 'ext-gw-mode',\n                                                 'extraroute']\n\n        if self.rpc_flavor and self.rpc_flavor not in self.plugins:\n            raise exc.Invalid(_('rpc_flavor %s is not plugin list') %\n                              self.rpc_flavor)\n\n        self.extension_map = {}\n        if not cfg.CONF.META.extension_map == '':\n            extension_list = [method_set.split(':')\n                              for method_set\n                              in cfg.CONF.META.extension_map.split(',')]\n            for method_name, flavor in extension_list:\n                self.extension_map[method_name] = flavor\n\n        # Register hooks.\n        # The hooks are applied for each target plugin instance when\n        # calling the base class to get networks/ports so that only records\n        # which belong to the plugin are selected.\n        #NOTE: Doing registration here (within __init__()) is to avoid\n        # registration when merely importing this file. This is only\n        # for running whole unit tests.\n        db_base_plugin_v2.NeutronDbPluginV2.register_model_query_hook(\n            models_v2.Network,\n            'metaplugin_net',\n            _meta_network_model_hook,\n            None,\n            _meta_flavor_filter_hook)\n        db_base_plugin_v2.NeutronDbPluginV2.register_model_query_hook(\n            models_v2.Port,\n            'metaplugin_port',\n            _meta_port_model_hook,\n            None,\n            _meta_flavor_filter_hook)\n\n    def _load_plugin(self, plugin_provider):\n        LOG.debug(_(\"Plugin location: %s\"), plugin_provider)\n        plugin_klass = importutils.import_class(plugin_provider)\n        return plugin_klass()\n\n    def _get_plugin(self, flavor):\n        if flavor not in self.plugins:\n            raise FlavorNotFound(flavor=flavor)\n        return self.plugins[flavor]\n\n    def _get_l3_plugin(self, flavor):\n        if flavor not in self.l3_plugins:\n            raise FlavorNotFound(flavor=flavor)\n        return self.l3_plugins[flavor]\n\n    def __getattr__(self, key):\n        # At first,  try to pickup extension command from extension_map\n\n        if key in self.extension_map:\n            flavor = self.extension_map[key]\n            plugin = self._get_plugin(flavor)\n            if plugin and hasattr(plugin, key):\n                return getattr(plugin, key)\n\n        # Second, try to match extension method in order of plugin list\n        for flavor, plugin in self.plugins.items():\n            if hasattr(plugin, key):\n                return getattr(plugin, key)\n\n        # if no plugin support the method, then raise\n        raise AttributeError\n\n    def _extend_network_dict(self, context, network):\n        flavor = self._get_flavor_by_network_id(context, network['id'])\n        network[FLAVOR_NETWORK] = flavor\n\n    def start_rpc_listener(self):\n        return self.plugins[self.rpc_flavor].start_rpc_listener()\n\n    def rpc_workers_supported(self):\n        #NOTE: If a plugin which supports multiple RPC workers is desired\n        # to handle RPC, rpc_flavor must be specified.\n        return (self.rpc_flavor and\n                self.plugins[self.rpc_flavor].rpc_workers_supported())\n\n    def create_network(self, context, network):\n        n = network['network']\n        flavor = n.get(FLAVOR_NETWORK)\n        if str(flavor) not in self.plugins:\n            flavor = self.default_flavor\n        plugin = self._get_plugin(flavor)\n        net = plugin.create_network(context, network)\n        LOG.debug(_(\"Created network: %(net_id)s with flavor \"\n                    \"%(flavor)s\"), {'net_id': net['id'], 'flavor': flavor})\n        try:\n            meta_db_v2.add_network_flavor_binding(context.session,\n                                                  flavor, str(net['id']))\n        except Exception:\n            LOG.exception(_('Failed to add flavor bindings'))\n            plugin.delete_network(context, net['id'])\n            raise FaildToAddFlavorBinding()\n\n        LOG.debug(_(\"Created network: %s\"), net['id'])\n        self._extend_network_dict(context, net)\n        return net\n\n    def update_network(self, context, id, network):\n        flavor = meta_db_v2.get_flavor_by_network(context.session, id)\n        plugin = self._get_plugin(flavor)\n        return plugin.update_network(context, id, network)\n\n    def delete_network(self, context, id):\n        flavor = meta_db_v2.get_flavor_by_network(context.session, id)\n        plugin = self._get_plugin(flavor)\n        return plugin.delete_network(context, id)\n\n    def get_network(self, context, id, fields=None):\n        flavor = meta_db_v2.get_flavor_by_network(context.session, id)\n        plugin = self._get_plugin(flavor)\n        net = plugin.get_network(context, id, fields)\n        net['id'] = id\n        if not fields or FLAVOR_NETWORK in fields:\n            self._extend_network_dict(context, net)\n        if fields and 'id' not in fields:\n            del net['id']\n        return net\n\n    def get_networks(self, context, filters=None, fields=None):\n        nets = []\n        for flavor, plugin in self.plugins.items():\n            if (filters and FLAVOR_NETWORK in filters and\n                    not flavor in filters[FLAVOR_NETWORK]):\n                continue\n            if filters:\n                #NOTE: copy each time since a target plugin may modify\n                # plugin_filters.\n                plugin_filters = filters.copy()\n            else:\n                plugin_filters = {}\n            plugin_filters[FLAVOR_NETWORK] = [flavor]\n            plugin_nets = plugin.get_networks(context, plugin_filters, fields)\n            for net in plugin_nets:\n                if not fields or FLAVOR_NETWORK in fields:\n                    net[FLAVOR_NETWORK] = flavor\n                nets.append(net)\n        return nets\n\n    def _get_flavor_by_network_id(self, context, network_id):\n        return meta_db_v2.get_flavor_by_network(context.session, network_id)\n\n    def _get_flavor_by_router_id(self, context, router_id):\n        return meta_db_v2.get_flavor_by_router(context.session, router_id)\n\n    def _get_plugin_by_network_id(self, context, network_id):\n        flavor = self._get_flavor_by_network_id(context, network_id)\n        return self._get_plugin(flavor)\n\n    def create_port(self, context, port):\n        p = port['port']\n        if 'network_id' not in p:\n            raise exc.NotFound\n        plugin = self._get_plugin_by_network_id(context, p['network_id'])\n        return plugin.create_port(context, port)\n\n    def update_port(self, context, id, port):\n        port_in_db = self._get_port(context, id)\n        plugin = self._get_plugin_by_network_id(context,\n                                                port_in_db['network_id'])\n        return plugin.update_port(context, id, port)\n\n    def delete_port(self, context, id, l3_port_check=True):\n        port_in_db = self._get_port(context, id)\n        plugin = self._get_plugin_by_network_id(context,\n                                                port_in_db['network_id'])\n        return plugin.delete_port(context, id, l3_port_check)\n\n    # This is necessary since there is a case that\n    # NeutronManager.get_plugin()._make_port_dict is called.\n    def _make_port_dict(self, port):\n        context = neutron_context.get_admin_context()\n        plugin = self._get_plugin_by_network_id(context,\n                                                port['network_id'])\n        return plugin._make_port_dict(port)\n\n    def get_port(self, context, id, fields=None):\n        port_in_db = self._get_port(context, id)\n        plugin = self._get_plugin_by_network_id(context,\n                                                port_in_db['network_id'])\n        return plugin.get_port(context, id, fields)\n\n    def get_ports(self, context, filters=None, fields=None):\n        all_ports = []\n        for flavor, plugin in self.plugins.items():\n            if filters:\n                #NOTE: copy each time since a target plugin may modify\n                # plugin_filters.\n                plugin_filters = filters.copy()\n            else:\n                plugin_filters = {}\n            plugin_filters[FLAVOR_NETWORK] = [flavor]\n            ports = plugin.get_ports(context, plugin_filters, fields)\n            all_ports += ports\n        return all_ports\n\n    def create_subnet(self, context, subnet):\n        s = subnet['subnet']\n        if 'network_id' not in s:\n            raise exc.NotFound\n        plugin = self._get_plugin_by_network_id(context,\n                                                s['network_id'])\n        return plugin.create_subnet(context, subnet)\n\n    def update_subnet(self, context, id, subnet):\n        s = self.get_subnet(context, id)\n        plugin = self._get_plugin_by_network_id(context,\n                                                s['network_id'])\n        return plugin.update_subnet(context, id, subnet)\n\n    def delete_subnet(self, context, id):\n        s = self.get_subnet(context, id)\n        plugin = self._get_plugin_by_network_id(context,\n                                                s['network_id'])\n        return plugin.delete_subnet(context, id)\n\n    def _extend_router_dict(self, context, router):\n        flavor = self._get_flavor_by_router_id(context, router['id'])\n        router[FLAVOR_ROUTER] = flavor\n\n    def create_router(self, context, router):\n        r = router['router']\n        flavor = r.get(FLAVOR_ROUTER)\n        if str(flavor) not in self.l3_plugins:\n            flavor = self.default_l3_flavor\n        plugin = self._get_l3_plugin(flavor)\n        r_in_db = plugin.create_router(context, router)\n        LOG.debug(_(\"Created router: %(router_id)s with flavor \"\n                    \"%(flavor)s\"),\n                {'router_id': r_in_db['id'], 'flavor': flavor})\n        try:\n            meta_db_v2.add_router_flavor_binding(context.session,\n                                                 flavor, str(r_in_db['id']))\n        except Exception:\n            LOG.exception(_('Failed to add flavor bindings'))\n            plugin.delete_router(context, r_in_db['id'])\n            raise FaildToAddFlavorBinding()\n\n        LOG.debug(_(\"Created router: %s\"), r_in_db['id'])\n        self._extend_router_dict(context, r_in_db)\n        return r_in_db\n\n    def update_router(self, context, id, router):\n        flavor = meta_db_v2.get_flavor_by_router(context.session, id)\n        plugin = self._get_l3_plugin(flavor)\n        return plugin.update_router(context, id, router)\n\n    def delete_router(self, context, id):\n        flavor = meta_db_v2.get_flavor_by_router(context.session, id)\n        plugin = self._get_l3_plugin(flavor)\n        return plugin.delete_router(context, id)\n\n    def get_router(self, context, id, fields=None):\n        flavor = meta_db_v2.get_flavor_by_router(context.session, id)\n        plugin = self._get_l3_plugin(flavor)\n        router = plugin.get_router(context, id, fields)\n        if not fields or FLAVOR_ROUTER in fields:\n            self._extend_router_dict(context, router)\n        return router\n\n    def get_routers_with_flavor(self, context, filters=None,\n                                fields=None):\n        collection = self._model_query(context, l3_db.Router)\n        r_model = RouterFlavor\n        collection = collection.join(r_model,\n                                     l3_db.Router.id == r_model.router_id)\n        if filters:\n            for key, value in filters.iteritems():\n                if key == FLAVOR_ROUTER:\n                    column = RouterFlavor.flavor\n                else:\n                    column = getattr(l3_db.Router, key, None)\n                if column:\n                    collection = collection.filter(column.in_(value))\n        return [self._make_router_dict(c, fields) for c in collection]\n\n    def get_routers(self, context, filters=None, fields=None):\n        routers = self.get_routers_with_flavor(context, filters,\n                                               None)\n        return [self.get_router(context, router['id'],\n                                fields)\n                for router in routers]\n" }
{ "repo_name": "libracore/erpnext", "ref": "refs/heads/v12", "path": "erpnext/setup/doctype/item_group/item_group.py", "content": "# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors\n# License: GNU General Public License v3. See license.txt\n\nfrom __future__ import unicode_literals\nimport frappe\nimport copy\nfrom frappe import _\nfrom frappe.utils import nowdate, cint, cstr\nfrom frappe.utils.nestedset import NestedSet\nfrom frappe.website.website_generator import WebsiteGenerator\nfrom frappe.website.render import clear_cache\nfrom frappe.website.doctype.website_slideshow.website_slideshow import get_slideshow\nfrom erpnext.shopping_cart.product_info import set_product_info_for_website\nfrom erpnext.utilities.product import get_qty_in_stock\nfrom six.moves.urllib.parse import quote\n\nclass ItemGroup(NestedSet, WebsiteGenerator):\n\tnsm_parent_field = 'parent_item_group'\n\twebsite = frappe._dict(\n\t\tcondition_field = \"show_in_website\",\n\t\ttemplate = \"templates/generators/item_group.html\",\n\t\tno_cache = 1\n\t)\n\n\tdef autoname(self):\n\t\tself.name = self.item_group_name\n\n\tdef validate(self):\n\t\tsuper(ItemGroup, self).validate()\n\n\t\tif not self.parent_item_group and not frappe.flags.in_test:\n\t\t\tif frappe.db.exists(\"Item Group\", _('All Item Groups')):\n\t\t\t\tself.parent_item_group = _('All Item Groups')\n\n\t\tself.make_route()\n\n\tdef on_update(self):\n\t\tNestedSet.on_update(self)\n\t\tinvalidate_cache_for(self)\n\t\tself.validate_name_with_item()\n\t\tself.validate_one_root()\n\n\tdef make_route(self):\n\t\t'''Make website route'''\n\t\tif not self.route:\n\t\t\tself.route = ''\n\t\t\tif self.parent_item_group:\n\t\t\t\tparent_item_group = frappe.get_doc('Item Group', self.parent_item_group)\n\n\t\t\t\t# make parent route only if not root\n\t\t\t\tif parent_item_group.parent_item_group and parent_item_group.route:\n\t\t\t\t\tself.route = parent_item_group.route + '/'\n\n\t\t\tself.route += self.scrub(self.item_group_name)\n\n\t\t\treturn self.route\n\n\tdef on_trash(self):\n\t\tNestedSet.on_trash(self)\n\t\tWebsiteGenerator.on_trash(self)\n\n\tdef validate_name_with_item(self):\n\t\tif frappe.db.exists(\"Item\", self.name):\n\t\t\tfrappe.throw(frappe._(\"An item exists with same name ({0}), please change the item group name or rename the item\").format(self.name), frappe.NameError)\n\n\tdef get_context(self, context):\n\t\tcontext.show_search=True\n\t\tcontext.page_length = cint(frappe.db.get_single_value('Products Settings', 'products_per_page')) or 6\n\t\tcontext.search_link = '/product_search'\n\n\t\tstart = int(frappe.form_dict.start or 0)\n\t\tif start < 0:\n\t\t\tstart = 0\n\t\tcontext.update({\n\t\t\t\"items\": get_product_list_for_group(product_group = self.name, start=start,\n\t\t\t\tlimit=context.page_length + 1, search=frappe.form_dict.get(\"search\")),\n\t\t\t\"parents\": get_parent_item_groups(self.parent_item_group),\n\t\t\t\"title\": self.name\n\t\t})\n\n\t\tif self.slideshow:\n\t\t\tcontext.update(get_slideshow(self))\n\n\t\treturn context\n\n@frappe.whitelist(allow_guest=True)\ndef get_product_list_for_group(product_group=None, start=0, limit=10, search=None):\n\tif product_group:\n\t\titem_group = frappe.get_cached_doc('Item Group', product_group)\n\t\tif item_group.is_group:\n\t\t\t# return child item groups if the type is of \"Is Group\"\n\t\t\treturn get_child_groups_for_list_in_html(item_group, start, limit, search)\n\n\tchild_groups = \", \".join([frappe.db.escape(i[0]) for i in get_child_groups(product_group)])\n\n\t# base query\n\tquery = \"\"\"select I.name, I.item_name, I.item_code, I.route, I.image, I.website_image, I.thumbnail, I.item_group,\n\t\t\tI.description, I.web_long_description as website_description, I.is_stock_item,\n\t\t\tcase when (S.actual_qty - S.reserved_qty) > 0 then 1 else 0 end as in_stock, I.website_warehouse,\n\t\t\tI.has_batch_no\n\t\tfrom `tabItem` I\n\t\tleft join tabBin S on I.item_code = S.item_code and I.website_warehouse = S.warehouse\n\t\twhere I.show_in_website = 1\n\t\t\tand I.disabled = 0\n\t\t\tand (I.end_of_life is null or I.end_of_life='0000-00-00' or I.end_of_life > %(today)s)\n\t\t\tand (I.variant_of = '' or I.variant_of is null)\n\t\t\tand (I.item_group in ({child_groups})\n\t\t\tor I.name in (select parent from `tabWebsite Item Group` where item_group in ({child_groups})))\n\t\t\t\"\"\".format(child_groups=child_groups)\n\t# search term condition\n\tif search:\n\t\tquery += \"\"\" and (I.web_long_description like %(search)s\n\t\t\t\tor I.item_name like %(search)s\n\t\t\t\tor I.name like %(search)s)\"\"\"\n\t\tsearch = \"%\" + cstr(search) + \"%\"\n\n\tquery += \"\"\"order by I.weightage desc, in_stock desc, I.modified desc limit %s, %s\"\"\" % (start, limit)\n\n\tdata = frappe.db.sql(query, {\"product_group\": product_group,\"search\": search, \"today\": nowdate()} as_dict=1)\n\tdata = adjust_qty_for_expired_items(data)\n\n\tif cint(frappe.db.get_single_value(\"Shopping Cart Settings\", \"enabled\")):\n\t\tfor item in data:\n\t\t\tset_product_info_for_website(item)\n\n\treturn data\n\ndef get_child_groups_for_list_in_html(item_group, start, limit, search):\n\tsearch_filters = None\n\tif search_filters:\n\t\tsearch_filters = [\n\t\t\tdict(name = ('like', '%{}%'.format(search))),\n\t\t\tdict(description = ('like', '%{}%'.format(search)))\n\t\t]\n\tdata = frappe.db.get_all('Item Group',\n\t\tfields = ['name', 'route', 'description', 'image'],\n\t\tfilters = dict(\n\t\t\tshow_in_website = 1,\n\t\t\tlft = ('>', item_group.lft),\n\t\t\trgt = ('<', item_group.rgt),\n\t\t),\n\t\tor_filters = search_filters,\n\t\torder_by = 'weightage desc, name asc',\n\t\tstart = start,\n\t\tlimit = limit\n\t)\n\n\treturn data\n\ndef adjust_qty_for_expired_items(data):\n\tadjusted_data = []\n\n\tfor item in data:\n\t\tif item.get('has_batch_no') and item.get('website_warehouse'):\n\t\t\tstock_qty_dict = get_qty_in_stock(\n\t\t\t\titem.get('name'), 'website_warehouse', item.get('website_warehouse'))\n\t\t\tqty = stock_qty_dict.stock_qty[0][0] if stock_qty_dict.stock_qty else 0\n\t\t\titem['in_stock'] = 1 if qty else 0\n\t\tadjusted_data.append(item)\n\n\treturn adjusted_data\n\n\ndef get_child_groups(item_group_name):\n\titem_group = frappe.get_doc(\"Item Group\", item_group_name)\n\treturn frappe.db.sql(\"\"\"select name\n\t\tfrom `tabItem Group` where lft>=%(lft)s and rgt<=%(rgt)s\n\t\t\tand show_in_website = 1\"\"\", {\"lft\": item_group.lft, \"rgt\": item_group.rgt})\n\ndef get_item_for_list_in_html(context):\n\t# add missing absolute link in files\n\t# user may forget it during upload\n\tif (context.get(\"website_image\") or \"\").startswith(\"files/\"):\n\t\tcontext[\"website_image\"] = \"/\" + quote(context[\"website_image\"])\n\n\tcontext[\"show_availability_status\"] = cint(frappe.db.get_single_value('Products Settings',\n\t\t'show_availability_status'))\n\n\tproducts_template = 'templates/includes/products_as_list.html'\n\n\treturn frappe.get_template(products_template).render(context)\n\ndef get_group_item_count(item_group):\n\tchild_groups = \", \".join(['\"' + i[0] + '\"' for i in get_child_groups(item_group)])\n\treturn frappe.db.sql(\"\"\"select count(*) from `tabItem`\n\t\twhere docstatus = 0 and show_in_website = 1\n\t\tand (item_group in (%s)\n\t\t\tor name in (select parent from `tabWebsite Item Group`\n\t\t\t\twhere item_group in (%s))) \"\"\" % (child_groups, child_groups))[0][0]\n\n\ndef get_parent_item_groups(item_group_name):\n\tbase_parents = [\n\t\t{\"name\": frappe._(\"Home\"), \"route\":\"/\"}\n\t\t{\"name\": frappe._(\"All Products\"), \"route\":\"/all-products\"}\n\t]\n\tif not item_group_name:\n\t\treturn base_parents\n\n\titem_group = frappe.get_doc(\"Item Group\", item_group_name)\n\tparent_groups = frappe.db.sql(\"\"\"select name, route from `tabItem Group`\n\t\twhere lft <= %s and rgt >= %s\n\t\tand show_in_website=1\n\t\torder by lft asc\"\"\", (item_group.lft, item_group.rgt), as_dict=True)\n\n\treturn base_parents + parent_groups\n\ndef invalidate_cache_for(doc, item_group=None):\n\tif not item_group:\n\t\titem_group = doc.name\n\n\tfor d in get_parent_item_groups(item_group):\n\t\titem_group_name = frappe.db.get_value(\"Item Group\", d.get('name'))\n\t\tif item_group_name:\n\t\t\tclear_cache(frappe.db.get_value('Item Group', item_group_name, 'route'))\n\ndef get_item_group_defaults(item, company):\n\titem = frappe.get_cached_doc(\"Item\", item)\n\titem_group = frappe.get_cached_doc(\"Item Group\", item.item_group)\n\n\tfor d in item_group.item_group_defaults or []:\n\t\tif d.company == company:\n\t\t\trow = copy.deepcopy(d.as_dict())\n\t\t\trow.pop(\"name\")\n\t\t\treturn row\n\n\treturn frappe._dict()\n" }
{ "repo_name": "ChameleonCloud/horizon", "ref": "refs/heads/chameleoncloud/train", "path": "openstack_dashboard/contrib/developer/resource_browser/urls.py", "content": "#    (c) Copyright 2015 Hewlett-Packard Development Company, L.P.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n# not use this file except in compliance with the License. You may obtain\n# a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n\nfrom django.conf.urls import url\n\nfrom horizon.browsers.views import AngularIndexView\n\nurlpatterns = [\n    url('', AngularIndexView.as_view(), name='index'),\n]\n" }
{ "repo_name": "idea4bsd/idea4bsd", "ref": "refs/heads/idea4bsd-master", "path": "python/testData/inspections/PyNumpyType/Sort.py", "content": "def sort(self, axis=-1, kind='quicksort', order=None): # real signature unknown; restored from __doc__\n    \"\"\"\n    a.sort(axis=-1, kind='quicksort', order=None)\n\n        Sort an array, in-place.\n\n        Parameters\n        ----------\n        axis : int, optional\n            Axis along which to sort. Default is -1, which means sort along the\n            last axis.\n        kind : {'quicksort', 'mergesort', 'heapsort'} optional\n            Sorting algorithm. Default is 'quicksort'.\n        order : list, optional\n            When `a` is an array with fields defined, this argument specifies\n            which fields to compare first, second, etc.  Not all fields need be\n            specified.\n\n    \"\"\"\n    pass\n\na = np.array([('a', 2), ('c', 1)], dtype=[('x', 'S1'), ('y', int)])\nprint(sort(a, order='y'))" }
{ "repo_name": "AmritaLonkar/trunk", "ref": "refs/heads/arcjet", "path": "SU2_PY/SU2/io/redirect.py", "content": "## \\file redirect.py\n#  \\brief python package for file redirection \n#  \\author Trent Lukaczyk, Aerospace Design Laboratory (Stanford University) <http://su2.stanford.edu>.\n#  \\version 2.0.6\n#\n# Stanford University Unstructured (SU2) Code\n# Copyright (C) 2012 Aerospace Design Laboratory\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\n# ----------------------------------------------------------------------\n#  Imports\n# ----------------------------------------------------------------------\n\nimport os, sys, shutil, copy, glob\nfrom .tools import add_suffix, make_link, expand_part\n\n# -------------------------------------------------------------------\n#  Output Redirection \n# -------------------------------------------------------------------\n# original source: http://stackoverflow.com/questions/6796492/python-temporarily-redirect-stdout-stderr\nclass output(object):\n    ''' with SU2.io.redirect_output(stdout,stderr)\n    \n        Temporarily redirects sys.stdout and sys.stderr when used in\n        a 'with' contextmanager\n        \n        Example:\n        with SU2.io.redirect_output('stdout.txt','stderr.txt'):\n            sys.stdout.write(\"standard out\")\n            sys.stderr.write(\"stanrard error\")\n            # code\n        #: with output redirection\n        \n        Inputs:\n            stdout - None, a filename, or a file stream\n            stderr - None, a filename, or a file stream\n        None will not redirect outptu\n        \n    '''\n    def __init__(self, stdout=None, stderr=None):\n        \n        _newout = False\n        _newerr = False\n        \n        if isinstance(stdout,str):\n            stdout = open(stdout,'a')\n            _newout = True            \n        if isinstance(stderr,str):\n            stderr = open(stderr,'a')\n            _newerr = True                   \n                \n        self._stdout = stdout or sys.stdout\n        self._stderr = stderr or sys.stderr\n        self._newout = _newout\n        self._newerr = _newerr\n\n    def __enter__(self):\n        self.old_stdout, self.old_stderr = sys.stdout, sys.stderr\n        self.old_stdout.flush(); self.old_stderr.flush()\n        sys.stdout, sys.stderr = self._stdout, self._stderr\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        self._stdout.flush(); self._stderr.flush()\n        sys.stdout = self.old_stdout\n        sys.stderr = self.old_stderr\n        \n        if self._newout:\n            self._stdout.close()\n        if self._newerr:\n            self._stderr.close()           \n\n#: class output()\n\n\n# -------------------------------------------------------------------\n#  Folder Redirection \n# -------------------------------------------------------------------\nclass folder(object):\n    ''' with SU2.io.redirect_folder(folder,pull,link,force) as push\n    \n        Temporarily redirects to a working folder, pulling \n        and pushing needed files\n        \n        Example:\n        \n        folder = 'temp'                    \n        pull   = ['file1.txt','file2.txt'] \n        link   = ['file3.big']             \n        force  = True                      \n        \n        # original path\n        import os\n        print os.getcwd()\n        \n        # enter folder\n        with SU2.io.redirect_folder(folder,pull,link,force) as push:\n            print os.getcwd()\n            # code\n            push.append('file4.txt')\n        #: with folder redirection\n        \n        # returned to original path\n        print os.getcwd()\n        \n        Inputs:\n            folder - working folder, relative or absolute\n            pull   - list of files to pull (copy to working folder)\n            link   - list of files to link (symbolic link in working folder)\n            force  - True/False overwrite existing files in working folder\n        \n        Targets:\n            push   - list of files to push (copy to originating path)\n        \n        Notes:\n            push must be appended or extended, not overwritten\n            links in Windows not supported, will simply copy\n    '''\n    \n    def __init__(self, folder, pull=None, link=None, force=True ):\n        ''' folder redirection initialization\n            see help( folder ) for more info\n        '''\n        \n        if pull is None: pull = []\n        if link is None: link = []\n        \n        if not isinstance(pull,list) : pull = [pull]\n        if not isinstance(link,list) : link = [link]\n        \n        origin = os.getcwd()\n        origin = os.path.abspath(origin).rstrip('/')+'/'\n        folder = os.path.abspath(folder).rstrip('/')+'/'\n        \n        self.origin = origin\n        self.folder = folder\n        self.pull   = copy.deepcopy(pull)\n        self.push   = []\n        self.link   = copy.deepcopy(link)\n        self.force  = force\n\n    def __enter__(self): \n        \n        origin = self.origin  # absolute path\n        folder = self.folder  # absolute path\n        pull   = self.pull\n        push   = self.push\n        link   = self.link\n        force  = self.force\n        \n        # check for no folder change\n        if folder == origin:\n            return []\n        \n        # relative folder path\n        #relative = os.path.relpath(folder,origin)\n        \n        # check, make folder\n        if not os.path.exists(folder):\n            os.makedirs(folder)\n        \n        # copy pull files\n        for name in pull:\n            old_name = os.path.abspath(name)\n            new_name = os.path.split(name)[-1]\n            new_name = os.path.join(folder,new_name)\n            if old_name == new_name: continue\n            if os.path.exists( new_name ): \n                if force: os.remove( new_name )\n                else: continue\n            shutil.copy(old_name,new_name)\n\n        # make links\n        for name in link:\n            old_name = os.path.abspath(name)\n            new_name = os.path.split(name)[-1]\n            new_name = os.path.join(folder,new_name)\n            if old_name == new_name: continue\n            if os.path.exists( new_name ): \n                if force: os.remove( new_name )\n                else: continue\n            make_link(old_name,new_name)\n            \n        # change directory\n        os.chdir(folder)\n        \n        # return empty list to append with files to push to super folder\n        return push\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        \n        origin = self.origin\n        folder = self.folder\n        push   = self.push\n        force  = self.force\n        \n        # check for no folder change\n        if folder == origin:\n            return\n        \n        # move assets\n        for name in push:\n            \n            old_name = os.path.abspath(name)\n            name = os.path.split(name)[-1]\n            new_name = os.path.join(origin,name)\n            \n            # links\n            if os.path.islink(old_name):\n                source = os.path.realpath(old_name)\n                if source == new_name: continue\n                if os.path.exists( new_name ):\n                    if force: os.remove( new_name )\n                    else: continue\n                make_link(source,new_name)\n            \n            # moves\n            else:\n                if old_name == new_name: continue\n                if os.path.exists( new_name ):\n                    if force: os.remove( new_name )\n                    else: continue\n                shutil.move(old_name,new_name)\n            \n        # change directory\n        os.chdir(origin)\n        \n#: class folder()\n" }
{ "repo_name": "mferenca/HMS-notifier", "ref": "refs/heads/HMS-Notifier", "path": "notifier/tests/test_commands.py", "content": "\"\"\"\n\"\"\"\nimport datetime\nimport json\nfrom os.path import dirname, join\n\nfrom django.conf import settings\nfrom django.test import TestCase\nfrom django.test.utils import override_settings\nfrom mock import patch, Mock\n\nfrom notifier.management.commands import forums_digest\n\nclass CommandsTestCase(TestCase):\n\n    \"\"\"\n    \"\"\"\n\n    @override_settings(CELERY_EAGER_PROPAGATES_EXCEPTIONS=True,\n                       CELERY_ALWAYS_EAGER=True,\n                       BROKER_BACKEND='memory',)\n    def test_forums_digest(self):\n        pass\n" }
{ "repo_name": "BiznetGIO/horizon", "ref": "refs/heads/stable/pike-gio", "path": "openstack_dashboard/contrib/developer/resource_browser/urls.py", "content": "#    (c) Copyright 2015 Hewlett-Packard Development Company, L.P.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n# not use this file except in compliance with the License. You may obtain\n# a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n\nfrom django.conf.urls import url\n\nfrom horizon.browsers.views import AngularIndexView\n\nurlpatterns = [\n    url('', AngularIndexView.as_view(), name='index'),\n]\n" }
{ "repo_name": "lucafavatella/intellij-community", "ref": "refs/heads/cli-wip", "path": "python/testData/inspections/PyNumpyType/Sort.py", "content": "def sort(self, axis=-1, kind='quicksort', order=None): # real signature unknown; restored from __doc__\n    \"\"\"\n    a.sort(axis=-1, kind='quicksort', order=None)\n\n        Sort an array, in-place.\n\n        Parameters\n        ----------\n        axis : int, optional\n            Axis along which to sort. Default is -1, which means sort along the\n            last axis.\n        kind : {'quicksort', 'mergesort', 'heapsort'} optional\n            Sorting algorithm. Default is 'quicksort'.\n        order : list, optional\n            When `a` is an array with fields defined, this argument specifies\n            which fields to compare first, second, etc.  Not all fields need be\n            specified.\n\n    \"\"\"\n    pass\n\na = np.array([('a', 2), ('c', 1)], dtype=[('x', 'S1'), ('y', int)])\nprint(sort(a, order='y'))" }
{ "repo_name": "appsembler/edx-platform", "ref": "refs/heads/appsembler/tahoe/master", "path": "cms/djangoapps/appsembler_tiers/views.py", "content": "\"\"\"\nStudio views for the tiers app.\n\"\"\"\n\nfrom django.contrib.auth.decorators import login_required\nfrom django.utils.decorators import method_decorator\nfrom django.views.generic import TemplateView\n\nfrom openedx.core.djangoapps.appsembler.sites.utils import get_single_user_organization\n\n\nclass SiteUnavailableRedirectView(TemplateView):\n    \"\"\"\n    Studio Site Unavailable view.\n\n    This works in the Studio and shows a message.\n    \"\"\"\n    template_name = 'site-unavailable.html'\n\n    def get_context_data(self, **kwargs):\n        context = super(SiteUnavailableRedirectView, self).get_context_data(**kwargs)\n        context['organization'] = get_single_user_organization(self.request.user)\n        return context\n\n    @method_decorator(login_required)\n    def get(self, request, *args, **kwargs):\n        return super(SiteUnavailableRedirectView, self).get(request, *args, **kwargs)\n" }
{ "repo_name": "NeCTAR-RC/horizon", "ref": "refs/heads/nectar/stein", "path": "openstack_dashboard/contrib/developer/resource_browser/urls.py", "content": "#    (c) Copyright 2015 Hewlett-Packard Development Company, L.P.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n# not use this file except in compliance with the License. You may obtain\n# a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n\nfrom django.conf.urls import url\n\nfrom horizon.browsers.views import AngularIndexView\n\nurlpatterns = [\n    url('', AngularIndexView.as_view(), name='index'),\n]\n" }
{ "repo_name": "libracore/erpnext", "ref": "refs/heads/v12", "path": "erpnext/config/stock.py", "content": "from __future__ import unicode_literals\nfrom frappe import _\n\ndef get_data():\n\treturn [\n\t\t{\n\t\t\t\"label\": _(\"Stock Transactions\"),\n\t\t\t\"items\": [\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"doctype\",\n\t\t\t\t\t\"name\": \"Stock Entry\",\n\t\t\t\t\t\"onboard\": 1,\n\t\t\t\t\t\"dependencies\": [\"Item\"],\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"doctype\",\n\t\t\t\t\t\"name\": \"Delivery Note\",\n\t\t\t\t\t\"onboard\": 1,\n\t\t\t\t\t\"dependencies\": [\"Item\", \"Customer\"],\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"doctype\",\n\t\t\t\t\t\"name\": \"Purchase Receipt\",\n\t\t\t\t\t\"onboard\": 1,\n\t\t\t\t\t\"dependencies\": [\"Item\", \"Supplier\"],\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"doctype\",\n\t\t\t\t\t\"name\": \"Material Request\",\n\t\t\t\t\t\"onboard\": 1,\n\t\t\t\t\t\"dependencies\": [\"Item\"],\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"doctype\",\n\t\t\t\t\t\"name\": \"Pick List\",\n\t\t\t\t\t\"onboard\": 1,\n\t\t\t\t\t\"dependencies\": [\"Item\"],\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"doctype\",\n\t\t\t\t\t\"name\": \"Delivery Trip\"\n\t\t\t\t}\n\t\t\t]\n\t\t}\n\t\t{\n\t\t\t\"label\": _(\"Stock Reports\"),\n\t\t\t\"items\": [\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"report\",\n\t\t\t\t\t\"is_query_report\": True,\n\t\t\t\t\t\"name\": \"Stock Ledger\",\n\t\t\t\t\t\"doctype\": \"Stock Ledger Entry\",\n\t\t\t\t\t\"onboard\": 1,\n\t\t\t\t\t\"dependencies\": [\"Item\"],\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"report\",\n\t\t\t\t\t\"is_query_report\": True,\n\t\t\t\t\t\"name\": \"Stock Balance\",\n\t\t\t\t\t\"doctype\": \"Stock Ledger Entry\",\n\t\t\t\t\t\"onboard\": 1,\n\t\t\t\t\t\"dependencies\": [\"Item\"],\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"report\",\n\t\t\t\t\t\"is_query_report\": True,\n\t\t\t\t\t\"name\": \"Stock Projected Qty\",\n\t\t\t\t\t\"doctype\": \"Item\",\n\t\t\t\t\t\"onboard\": 1,\n\t\t\t\t\t\"dependencies\": [\"Item\"],\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"page\",\n\t\t\t\t\t\"name\": \"stock-balance\",\n\t\t\t\t\t\"label\": _(\"Stock Summary\"),\n\t\t\t\t\t\"dependencies\": [\"Item\"],\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"report\",\n\t\t\t\t\t\"is_query_report\": True,\n\t\t\t\t\t\"name\": \"Stock Ageing\",\n\t\t\t\t\t\"doctype\": \"Item\",\n\t\t\t\t\t\"dependencies\": [\"Item\"],\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"report\",\n\t\t\t\t\t\"is_query_report\": True,\n\t\t\t\t\t\"name\": \"Item Price Stock\",\n\t\t\t\t\t\"doctype\": \"Item\",\n\t\t\t\t\t\"dependencies\": [\"Item\"],\n\t\t\t\t}\n\t\t\t]\n\t\t}\n\t\t{\n\t\t\t\"label\": _(\"Settings\"),\n\t\t\t\"icon\": \"fa fa-cog\",\n\t\t\t\"items\": [\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"doctype\",\n\t\t\t\t\t\"name\": \"Stock Settings\",\n\t\t\t\t\t\"onboard\": 1,\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"doctype\",\n\t\t\t\t\t\"name\": \"Warehouse\",\n\t\t\t\t\t\"onboard\": 1,\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"doctype\",\n\t\t\t\t\t\"name\": \"UOM\",\n\t\t\t\t\t\"label\": _(\"Unit of Measure\") + \" (UOM)\",\n\t\t\t\t\t\"onboard\": 1,\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"doctype\",\n\t\t\t\t\t\"name\": \"Brand\",\n\t\t\t\t\t\"onboard\": 1,\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"doctype\",\n\t\t\t\t\t\"name\": \"Item Attribute\",\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"doctype\",\n\t\t\t\t\t\"name\": \"Item Variant Settings\",\n\t\t\t\t}\n\t\t\t]\n\t\t}\n\t\t{\n\t\t\t\"label\": _(\"Items and Pricing\"),\n\t\t\t\"items\": [\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"doctype\",\n\t\t\t\t\t\"name\": \"Item\",\n\t\t\t\t\t\"onboard\": 1,\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"doctype\",\n\t\t\t\t\t\"name\": \"Product Bundle\",\n\t\t\t\t\t\"onboard\": 1,\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"doctype\",\n\t\t\t\t\t\"name\": \"Item Group\",\n\t\t\t\t\t\"icon\": \"fa fa-sitemap\",\n\t\t\t\t\t\"label\": _(\"Item Group\"),\n\t\t\t\t\t\"link\": \"Tree/Item Group\",\n\t\t\t\t\t\"onboard\": 1,\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"doctype\",\n\t\t\t\t\t\"name\": \"Price List\",\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"doctype\",\n\t\t\t\t\t\"name\": \"Item Price\",\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"doctype\",\n\t\t\t\t\t\"name\": \"Shipping Rule\",\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"doctype\",\n\t\t\t\t\t\"name\": \"Pricing Rule\",\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"doctype\",\n\t\t\t\t\t\"name\": \"Item Alternative\",\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"doctype\",\n\t\t\t\t\t\"name\": \"Item Manufacturer\",\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"doctype\",\n\t\t\t\t\t\"name\": \"Item Variant Settings\",\n\t\t\t\t}\n\t\t\t]\n\t\t}\n\t\t{\n\t\t\t\"label\": _(\"Serial No and Batch\"),\n\t\t\t\"items\": [\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"doctype\",\n\t\t\t\t\t\"name\": \"Serial No\",\n\t\t\t\t\t\"onboard\": 1,\n\t\t\t\t\t\"dependencies\": [\"Item\"],\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"doctype\",\n\t\t\t\t\t\"name\": \"Batch\",\n\t\t\t\t\t\"onboard\": 1,\n\t\t\t\t\t\"dependencies\": [\"Item\"],\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"doctype\",\n\t\t\t\t\t\"name\": \"Installation Note\",\n\t\t\t\t\t\"dependencies\": [\"Item\"],\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"report\",\n\t\t\t\t\t\"name\": \"Serial No Service Contract Expiry\",\n\t\t\t\t\t\"doctype\": \"Serial No\"\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"report\",\n\t\t\t\t\t\"name\": \"Serial No Status\",\n\t\t\t\t\t\"doctype\": \"Serial No\"\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"report\",\n\t\t\t\t\t\"name\": \"Serial No Warranty Expiry\",\n\t\t\t\t\t\"doctype\": \"Serial No\"\n\t\t\t\t}\n\t\t\t]\n\t\t}\n\t\t{\n\t\t\t\"label\": _(\"Tools\"),\n\t\t\t\"icon\": \"fa fa-wrench\",\n\t\t\t\"items\": [\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"doctype\",\n\t\t\t\t\t\"name\": \"Stock Reconciliation\",\n\t\t\t\t\t\"onboard\": 1,\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"doctype\",\n\t\t\t\t\t\"name\": \"Landed Cost Voucher\",\n\t\t\t\t\t\"onboard\": 1,\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"doctype\",\n\t\t\t\t\t\"name\": \"Packing Slip\",\n\t\t\t\t\t\"onboard\": 1,\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"doctype\",\n\t\t\t\t\t\"name\": \"Quality Inspection\",\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"doctype\",\n\t\t\t\t\t\"name\": \"Quality Inspection Template\",\n\t\t\t\t}\n\t\t\t]\n\t\t}\n\t\t{\n\t\t\t\"label\": _(\"Key Reports\"),\n\t\t\t\"icon\": \"fa fa-table\",\n\t\t\t\"items\": [\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"report\",\n\t\t\t\t\t\"is_query_report\": False,\n\t\t\t\t\t\"name\": \"Item-wise Price List Rate\",\n\t\t\t\t\t\"doctype\": \"Item Price\",\n\t\t\t\t\t\"onboard\": 1,\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"report\",\n\t\t\t\t\t\"is_query_report\": True,\n\t\t\t\t\t\"name\": \"Stock Analytics\",\n\t\t\t\t\t\"doctype\": \"Stock Entry\",\n\t\t\t\t\t\"onboard\": 1,\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"report\",\n\t\t\t\t\t\"is_query_report\": True,\n\t\t\t\t\t\"name\": \"Delivery Note Trends\",\n\t\t\t\t\t\"doctype\": \"Delivery Note\"\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"report\",\n\t\t\t\t\t\"is_query_report\": True,\n\t\t\t\t\t\"name\": \"Purchase Receipt Trends\",\n\t\t\t\t\t\"doctype\": \"Purchase Receipt\"\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"report\",\n\t\t\t\t\t\"is_query_report\": True,\n\t\t\t\t\t\"name\": \"Ordered Items To Be Delivered\",\n\t\t\t\t\t\"doctype\": \"Delivery Note\"\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"report\",\n\t\t\t\t\t\"is_query_report\": True,\n\t\t\t\t\t\"name\": \"Purchase Order Items To Be Received\",\n\t\t\t\t\t\"doctype\": \"Purchase Receipt\"\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"report\",\n\t\t\t\t\t\"is_query_report\": True,\n\t\t\t\t\t\"name\": \"Item Shortage Report\",\n\t\t\t\t\t\"doctype\": \"Bin\"\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"report\",\n\t\t\t\t\t\"is_query_report\": True,\n\t\t\t\t\t\"name\": \"Batch-Wise Balance History\",\n\t\t\t\t\t\"doctype\": \"Batch\"\n\t\t\t\t}\n\t\t\t]\n\t\t}\n\t\t{\n\t\t\t\"label\": _(\"Other Reports\"),\n\t\t\t\"icon\": \"fa fa-list\",\n\t\t\t\"items\": [\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"report\",\n\t\t\t\t\t\"is_query_report\": True,\n\t\t\t\t\t\"name\": \"Requested Items To Be Transferred\",\n\t\t\t\t\t\"doctype\": \"Material Request\"\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"report\",\n\t\t\t\t\t\"is_query_report\": True,\n\t\t\t\t\t\"name\": \"Batch Item Expiry Status\",\n\t\t\t\t\t\"doctype\": \"Stock Ledger Entry\"\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"report\",\n\t\t\t\t\t\"is_query_report\": True,\n\t\t\t\t\t\"name\": \"Item Prices\",\n\t\t\t\t\t\"doctype\": \"Price List\"\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"report\",\n\t\t\t\t\t\"is_query_report\": True,\n\t\t\t\t\t\"name\": \"Itemwise Recommended Reorder Level\",\n\t\t\t\t\t\"doctype\": \"Item\"\n\t\t\t\t}\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"report\",\n\t\t\t\t\t\"is_query_report\": True,\n\t\t\t\t\t\"name\": \"Item Variant Details\",\n\t\t\t\t\t\"doctype\": \"Item\"\n\t\t\t\t}\n\t\t\t]\n\t\t}\n\n\t]\n" }
{ "repo_name": "nttks/notifier", "ref": "refs/heads/gacco/dogwood", "path": "notifier/tests/test_commands.py", "content": "\"\"\"\n\"\"\"\nimport datetime\nimport json\nfrom os.path import dirname, join\n\nfrom django.conf import settings\nfrom django.test import TestCase\nfrom django.test.utils import override_settings\nfrom mock import patch, Mock\n\nfrom notifier.management.commands import forums_digest\n\nclass CommandsTestCase(TestCase):\n\n    \"\"\"\n    \"\"\"\n\n    @override_settings(CELERY_EAGER_PROPAGATES_EXCEPTIONS=True,\n                       CELERY_ALWAYS_EAGER=True,\n                       BROKER_BACKEND='memory',)\n    def test_forums_digest(self):\n        pass\n" }
{ "repo_name": "pllim/astropy", "ref": "refs/heads/placeholder", "path": "astropy/nddata/tests/test_compat.py", "content": "# Licensed under a 3-clause BSD style license - see LICENSE.rst\n# This module contains tests of a class equivalent to pre-1.0 NDData.\n\n\nimport pytest\nimport numpy as np\n\nfrom astropy.nddata.nddata import NDData\nfrom astropy.nddata.compat import NDDataArray\nfrom astropy.nddata.nduncertainty import StdDevUncertainty\nfrom astropy.wcs import WCS\nfrom astropy import units as u\n\n\nNDDATA_ATTRIBUTES = ['mask', 'flags', 'uncertainty', 'unit', 'shape', 'size',\n                     'dtype', 'ndim', 'wcs', 'convert_unit_to']\n\n\ndef test_nddataarray_has_attributes_of_old_nddata():\n    ndd = NDDataArray([1, 2, 3])\n    for attr in NDDATA_ATTRIBUTES:\n        assert hasattr(ndd, attr)\n\n\ndef test_nddata_simple():\n    nd = NDDataArray(np.zeros((10, 10)))\n    assert nd.shape == (10, 10)\n    assert nd.size == 100\n    assert nd.dtype == np.dtype(float)\n\n\ndef test_nddata_parameters():\n    # Test for issue 4620\n    nd = NDDataArray(data=np.zeros((10, 10)))\n    assert nd.shape == (10, 10)\n    assert nd.size == 100\n    assert nd.dtype == np.dtype(float)\n    # Change order; `data` has to be given explicitly here\n    nd = NDDataArray(meta={} data=np.zeros((10, 10)))\n    assert nd.shape == (10, 10)\n    assert nd.size == 100\n    assert nd.dtype == np.dtype(float)\n    # Pass uncertainty as second implicit argument\n    data = np.zeros((10, 10))\n    uncertainty = StdDevUncertainty(0.1 + np.zeros_like(data))\n    nd = NDDataArray(data, uncertainty)\n    assert nd.shape == (10, 10)\n    assert nd.size == 100\n    assert nd.dtype == np.dtype(float)\n    assert nd.uncertainty == uncertainty\n\n\ndef test_nddata_conversion():\n    nd = NDDataArray(np.array([[1, 2, 3], [4, 5, 6]]))\n    assert nd.size == 6\n    assert nd.dtype == np.dtype(int)\n\n\n@pytest.mark.parametrize('flags_in', [\n                         np.array([True, False]),\n                         np.array([1, 0]),\n                         [True, False],\n                         [1, 0],\n                         np.array(['a', 'b']),\n                         ['a', 'b']])\ndef test_nddata_flags_init_without_np_array(flags_in):\n    ndd = NDDataArray([1, 1], flags=flags_in)\n    assert (ndd.flags == flags_in).all()\n\n\n@pytest.mark.parametrize(('shape'), [(10,), (5, 5), (3, 10, 10)])\ndef test_nddata_flags_invalid_shape(shape):\n    with pytest.raises(ValueError) as exc:\n        NDDataArray(np.zeros((10, 10)), flags=np.ones(shape))\n    assert exc.value.args[0] == 'dimensions of flags do not match data'\n\n\ndef test_convert_unit_to():\n    # convert_unit_to should return a copy of its input\n    d = NDDataArray(np.ones((5, 5)))\n    d.unit = 'km'\n    d.uncertainty = StdDevUncertainty(0.1 + np.zeros_like(d))\n    # workaround because zeros_like does not support dtype arg until v1.6\n    # and NDData accepts only bool ndarray as mask\n    tmp = np.zeros_like(d.data)\n    d.mask = np.array(tmp, dtype=bool)\n    d1 = d.convert_unit_to('m')\n    assert np.all(d1.data == np.array(1000.0))\n    assert np.all(d1.uncertainty.array == 1000.0 * d.uncertainty.array)\n    assert d1.unit == u.m\n    # changing the output mask should not change the original\n    d1.mask[0, 0] = True\n    assert d.mask[0, 0] != d1.mask[0, 0]\n    d.flags = np.zeros_like(d.data)\n    d1 = d.convert_unit_to('m')\n\n\n# check that subclasses can require wcs and/or unit to be present and use\n# _arithmetic and convert_unit_to\nclass SubNDData(NDDataArray):\n    \"\"\"\n    Subclass for test initialization of subclasses in NDData._arithmetic and\n    NDData.convert_unit_to\n    \"\"\"\n    def __init__(self, *arg, **kwd):\n        super().__init__(*arg, **kwd)\n        if self.unit is None:\n            raise ValueError(\"Unit for subclass must be specified\")\n        if self.wcs is None:\n            raise ValueError(\"WCS for subclass must be specified\")\n\n\ndef test_init_of_subclass_in_convert_unit_to():\n    data = np.ones([10, 10])\n    arr1 = SubNDData(data, unit='m', wcs=WCS(naxis=2))\n    result = arr1.convert_unit_to('km')\n    np.testing.assert_array_equal(arr1.data, 1000 * result.data)\n\n\n# Test for issue #4129:\ndef test_nddataarray_from_nddataarray():\n    ndd1 = NDDataArray([1., 4., 9.],\n                       uncertainty=StdDevUncertainty([1., 2., 3.]),\n                       flags=[0, 1, 0])\n    ndd2 = NDDataArray(ndd1)\n    # Test that the 2 instances point to the same objects and aren't just\n    # equal; this is explicitly documented for the main data array and we\n    # probably want to catch any future change in behavior for the other\n    # attributes too and ensure they are intentional.\n    assert ndd2.data is ndd1.data\n    assert ndd2.uncertainty is ndd1.uncertainty\n    assert ndd2.flags is ndd1.flags\n    assert ndd2.meta == ndd1.meta\n\n\n# Test for issue #4137:\ndef test_nddataarray_from_nddata():\n    ndd1 = NDData([1., 4., 9.],\n                  uncertainty=StdDevUncertainty([1., 2., 3.]))\n    ndd2 = NDDataArray(ndd1)\n\n    assert ndd2.data is ndd1.data\n    assert ndd2.uncertainty is ndd1.uncertainty\n    assert ndd2.meta == ndd1.meta\n" }
{ "repo_name": "arpitn30/open-event-orga-server", "ref": "refs/heads/development", "path": "migrations/versions/ed4b4ba3274e_.py", "content": "\"\"\"empty message\n\nRevision ID: ed4b4ba3274e\nRevises: 784a1fc57171\nCreate Date: 2016-06-16 06:08:49.516538\n\n\"\"\"\n\n# revision identifiers, used by Alembic.\nrevision = 'ed4b4ba3274e'\ndown_revision = '784a1fc57171'\n\nfrom alembic import op\nimport sqlalchemy as sa\nimport sqlalchemy_utils\n\n\ndef upgrade():\n    ### commands auto generated by Alembic - please adjust! ###\n    op.create_table('service',\n    sa.Column('id', sa.Integer(), nullable=False),\n    sa.Column('name', sa.String(), nullable=False),\n    sa.PrimaryKeyConstraint('id'),\n    sa.UniqueConstraint('name')\n    )\n    op.add_column(u'permissions', sa.Column('can_create', sa.Boolean(), nullable=False))\n    op.add_column(u'permissions', sa.Column('can_delete', sa.Boolean(), nullable=False))\n    op.add_column(u'permissions', sa.Column('can_read', sa.Boolean(), nullable=False))\n    op.add_column(u'permissions', sa.Column('can_update', sa.Boolean(), nullable=False))\n    op.add_column(u'permissions', sa.Column('role_id', sa.Integer(), nullable=True))\n    op.alter_column(u'permissions', 'service_id',\n               existing_type=sa.INTEGER(),\n               nullable=True)\n    op.create_unique_constraint('role_service_uc', 'permissions', ['role_id', 'service_id'])\n    op.drop_constraint(u'user_service_uc', 'permissions', type_='unique')\n    op.drop_constraint(u'permissions_user_id_fkey', 'permissions', type_='foreignkey')\n    op.create_foreign_key(None, 'permissions', 'role', ['role_id'], ['id'])\n    op.create_foreign_key(None, 'permissions', 'service', ['service_id'], ['id'])\n    op.drop_column(u'permissions', 'user_id')\n    op.drop_column(u'permissions', 'modes')\n    op.drop_column(u'permissions', 'service')\n    op.alter_column(u'role', 'name',\n               existing_type=sa.VARCHAR(length=128),\n               nullable=False)\n    op.create_unique_constraint(None, 'role', ['name'])\n    op.drop_column(u'user', 'role')\n    ### end Alembic commands ###\n\n\ndef downgrade():\n    ### commands auto generated by Alembic - please adjust! ###\n    op.add_column(u'user', sa.Column('role', sa.VARCHAR(), autoincrement=False, nullable=True))\n    op.drop_constraint(None, 'role', type_='unique')\n    op.alter_column(u'role', 'name',\n               existing_type=sa.VARCHAR(length=128),\n               nullable=True)\n    op.add_column(u'permissions', sa.Column('service', sa.VARCHAR(), autoincrement=False, nullable=False))\n    op.add_column(u'permissions', sa.Column('modes', sa.INTEGER(), autoincrement=False, nullable=False))\n    op.add_column(u'permissions', sa.Column('user_id', sa.INTEGER(), autoincrement=False, nullable=False))\n    op.drop_constraint(None, 'permissions', type_='foreignkey')\n    op.drop_constraint(None, 'permissions', type_='foreignkey')\n    op.create_foreign_key(u'permissions_user_id_fkey', 'permissions', 'user', ['user_id'], ['id'])\n    op.create_unique_constraint(u'user_service_uc', 'permissions', ['user_id', 'service', 'service_id'])\n    op.drop_constraint('role_service_uc', 'permissions', type_='unique')\n    op.alter_column(u'permissions', 'service_id',\n               existing_type=sa.INTEGER(),\n               nullable=False)\n    op.drop_column(u'permissions', 'role_id')\n    op.drop_column(u'permissions', 'can_update')\n    op.drop_column(u'permissions', 'can_read')\n    op.drop_column(u'permissions', 'can_delete')\n    op.drop_column(u'permissions', 'can_create')\n    op.drop_table('service')\n    ### end Alembic commands ###\n" }
{ "repo_name": "lpsinger/astropy", "ref": "refs/heads/main", "path": "astropy/nddata/tests/test_compat.py", "content": "# Licensed under a 3-clause BSD style license - see LICENSE.rst\n# This module contains tests of a class equivalent to pre-1.0 NDData.\n\n\nimport pytest\nimport numpy as np\n\nfrom astropy.nddata.nddata import NDData\nfrom astropy.nddata.compat import NDDataArray\nfrom astropy.nddata.nduncertainty import StdDevUncertainty\nfrom astropy.wcs import WCS\nfrom astropy import units as u\n\n\nNDDATA_ATTRIBUTES = ['mask', 'flags', 'uncertainty', 'unit', 'shape', 'size',\n                     'dtype', 'ndim', 'wcs', 'convert_unit_to']\n\n\ndef test_nddataarray_has_attributes_of_old_nddata():\n    ndd = NDDataArray([1, 2, 3])\n    for attr in NDDATA_ATTRIBUTES:\n        assert hasattr(ndd, attr)\n\n\ndef test_nddata_simple():\n    nd = NDDataArray(np.zeros((10, 10)))\n    assert nd.shape == (10, 10)\n    assert nd.size == 100\n    assert nd.dtype == np.dtype(float)\n\n\ndef test_nddata_parameters():\n    # Test for issue 4620\n    nd = NDDataArray(data=np.zeros((10, 10)))\n    assert nd.shape == (10, 10)\n    assert nd.size == 100\n    assert nd.dtype == np.dtype(float)\n    # Change order; `data` has to be given explicitly here\n    nd = NDDataArray(meta={} data=np.zeros((10, 10)))\n    assert nd.shape == (10, 10)\n    assert nd.size == 100\n    assert nd.dtype == np.dtype(float)\n    # Pass uncertainty as second implicit argument\n    data = np.zeros((10, 10))\n    uncertainty = StdDevUncertainty(0.1 + np.zeros_like(data))\n    nd = NDDataArray(data, uncertainty)\n    assert nd.shape == (10, 10)\n    assert nd.size == 100\n    assert nd.dtype == np.dtype(float)\n    assert nd.uncertainty == uncertainty\n\n\ndef test_nddata_conversion():\n    nd = NDDataArray(np.array([[1, 2, 3], [4, 5, 6]]))\n    assert nd.size == 6\n    assert nd.dtype == np.dtype(int)\n\n\n@pytest.mark.parametrize('flags_in', [\n                         np.array([True, False]),\n                         np.array([1, 0]),\n                         [True, False],\n                         [1, 0],\n                         np.array(['a', 'b']),\n                         ['a', 'b']])\ndef test_nddata_flags_init_without_np_array(flags_in):\n    ndd = NDDataArray([1, 1], flags=flags_in)\n    assert (ndd.flags == flags_in).all()\n\n\n@pytest.mark.parametrize(('shape'), [(10,), (5, 5), (3, 10, 10)])\ndef test_nddata_flags_invalid_shape(shape):\n    with pytest.raises(ValueError) as exc:\n        NDDataArray(np.zeros((10, 10)), flags=np.ones(shape))\n    assert exc.value.args[0] == 'dimensions of flags do not match data'\n\n\ndef test_convert_unit_to():\n    # convert_unit_to should return a copy of its input\n    d = NDDataArray(np.ones((5, 5)))\n    d.unit = 'km'\n    d.uncertainty = StdDevUncertainty(0.1 + np.zeros_like(d))\n    # workaround because zeros_like does not support dtype arg until v1.6\n    # and NDData accepts only bool ndarray as mask\n    tmp = np.zeros_like(d.data)\n    d.mask = np.array(tmp, dtype=bool)\n    d1 = d.convert_unit_to('m')\n    assert np.all(d1.data == np.array(1000.0))\n    assert np.all(d1.uncertainty.array == 1000.0 * d.uncertainty.array)\n    assert d1.unit == u.m\n    # changing the output mask should not change the original\n    d1.mask[0, 0] = True\n    assert d.mask[0, 0] != d1.mask[0, 0]\n    d.flags = np.zeros_like(d.data)\n    d1 = d.convert_unit_to('m')\n\n\n# check that subclasses can require wcs and/or unit to be present and use\n# _arithmetic and convert_unit_to\nclass SubNDData(NDDataArray):\n    \"\"\"\n    Subclass for test initialization of subclasses in NDData._arithmetic and\n    NDData.convert_unit_to\n    \"\"\"\n    def __init__(self, *arg, **kwd):\n        super().__init__(*arg, **kwd)\n        if self.unit is None:\n            raise ValueError(\"Unit for subclass must be specified\")\n        if self.wcs is None:\n            raise ValueError(\"WCS for subclass must be specified\")\n\n\ndef test_init_of_subclass_in_convert_unit_to():\n    data = np.ones([10, 10])\n    arr1 = SubNDData(data, unit='m', wcs=WCS(naxis=2))\n    result = arr1.convert_unit_to('km')\n    np.testing.assert_array_equal(arr1.data, 1000 * result.data)\n\n\n# Test for issue #4129:\ndef test_nddataarray_from_nddataarray():\n    ndd1 = NDDataArray([1., 4., 9.],\n                       uncertainty=StdDevUncertainty([1., 2., 3.]),\n                       flags=[0, 1, 0])\n    ndd2 = NDDataArray(ndd1)\n    # Test that the 2 instances point to the same objects and aren't just\n    # equal; this is explicitly documented for the main data array and we\n    # probably want to catch any future change in behavior for the other\n    # attributes too and ensure they are intentional.\n    assert ndd2.data is ndd1.data\n    assert ndd2.uncertainty is ndd1.uncertainty\n    assert ndd2.flags is ndd1.flags\n    assert ndd2.meta == ndd1.meta\n\n\n# Test for issue #4137:\ndef test_nddataarray_from_nddata():\n    ndd1 = NDData([1., 4., 9.],\n                  uncertainty=StdDevUncertainty([1., 2., 3.]))\n    ndd2 = NDDataArray(ndd1)\n\n    assert ndd2.data is ndd1.data\n    assert ndd2.uncertainty is ndd1.uncertainty\n    assert ndd2.meta == ndd1.meta\n" }
{ "repo_name": "idea4bsd/idea4bsd", "ref": "refs/heads/idea4bsd-master", "path": "python/lib/Lib/site-packages/django/contrib/admin/widgets.py", "content": "\"\"\"\nForm Widget classes specific to the Django admin site.\n\"\"\"\n\nimport django.utils.copycompat as copy\n\nfrom django import forms\nfrom django.forms.widgets import RadioFieldRenderer\nfrom django.forms.util import flatatt\nfrom django.utils.html import escape\nfrom django.utils.text import truncate_words\nfrom django.utils.translation import ugettext as _\nfrom django.utils.safestring import mark_safe\nfrom django.utils.encoding import force_unicode\nfrom django.conf import settings\nfrom django.core.urlresolvers import reverse, NoReverseMatch\n\nclass FilteredSelectMultiple(forms.SelectMultiple):\n    \"\"\"\n    A SelectMultiple with a JavaScript filter interface.\n\n    Note that the resulting JavaScript assumes that the jsi18n\n    catalog has been loaded in the page\n    \"\"\"\n    class Media:\n        js = (settings.ADMIN_MEDIA_PREFIX + \"js/core.js\",\n              settings.ADMIN_MEDIA_PREFIX + \"js/SelectBox.js\",\n              settings.ADMIN_MEDIA_PREFIX + \"js/SelectFilter2.js\")\n\n    def __init__(self, verbose_name, is_stacked, attrs=None, choices=()):\n        self.verbose_name = verbose_name\n        self.is_stacked = is_stacked\n        super(FilteredSelectMultiple, self).__init__(attrs, choices)\n\n    def render(self, name, value, attrs=None, choices=()):\n        if attrs is None: attrs = {}\n        attrs['class'] = 'selectfilter'\n        if self.is_stacked: attrs['class'] += 'stacked'\n        output = [super(FilteredSelectMultiple, self).render(name, value, attrs, choices)]\n        output.append(u'<script type=\"text/javascript\">addEvent(window, \"load\", function(e) {')\n        # TODO: \"id_\" is hard-coded here. This should instead use the correct\n        # API to determine the ID dynamically.\n        output.append(u'SelectFilter.init(\"id_%s\", \"%s\", %s, \"%s\"); });</script>\\n' % \\\n            (name, self.verbose_name.replace('\"', '\\\\\"'), int(self.is_stacked), settings.ADMIN_MEDIA_PREFIX))\n        return mark_safe(u''.join(output))\n\nclass AdminDateWidget(forms.DateInput):\n    class Media:\n        js = (settings.ADMIN_MEDIA_PREFIX + \"js/calendar.js\",\n              settings.ADMIN_MEDIA_PREFIX + \"js/admin/DateTimeShortcuts.js\")\n\n    def __init__(self, attrs={} format=None):\n        super(AdminDateWidget, self).__init__(attrs={'class': 'vDateField', 'size': '10'} format=format)\n\nclass AdminTimeWidget(forms.TimeInput):\n    class Media:\n        js = (settings.ADMIN_MEDIA_PREFIX + \"js/calendar.js\",\n              settings.ADMIN_MEDIA_PREFIX + \"js/admin/DateTimeShortcuts.js\")\n\n    def __init__(self, attrs={} format=None):\n        super(AdminTimeWidget, self).__init__(attrs={'class': 'vTimeField', 'size': '8'} format=format)\n\nclass AdminSplitDateTime(forms.SplitDateTimeWidget):\n    \"\"\"\n    A SplitDateTime Widget that has some admin-specific styling.\n    \"\"\"\n    def __init__(self, attrs=None):\n        widgets = [AdminDateWidget, AdminTimeWidget]\n        # Note that we're calling MultiWidget, not SplitDateTimeWidget, because\n        # we want to define widgets.\n        forms.MultiWidget.__init__(self, widgets, attrs)\n\n    def format_output(self, rendered_widgets):\n        return mark_safe(u'<p class=\"datetime\">%s %s<br />%s %s</p>' % \\\n            (_('Date:'), rendered_widgets[0], _('Time:'), rendered_widgets[1]))\n\nclass AdminRadioFieldRenderer(RadioFieldRenderer):\n    def render(self):\n        \"\"\"Outputs a <ul> for this set of radio fields.\"\"\"\n        return mark_safe(u'<ul%s>\\n%s\\n</ul>' % (\n            flatatt(self.attrs),\n            u'\\n'.join([u'<li>%s</li>' % force_unicode(w) for w in self]))\n        )\n\nclass AdminRadioSelect(forms.RadioSelect):\n    renderer = AdminRadioFieldRenderer\n\nclass AdminFileWidget(forms.ClearableFileInput):\n    template_with_initial = (u'<p class=\"file-upload\">%s</p>'\n                            % forms.ClearableFileInput.template_with_initial)\n    template_with_clear = (u'<span class=\"clearable-file-input\">%s</span>'\n                           % forms.ClearableFileInput.template_with_clear)\n\n\nclass ForeignKeyRawIdWidget(forms.TextInput):\n    \"\"\"\n    A Widget for displaying ForeignKeys in the \"raw_id\" interface rather than\n    in a <select> box.\n    \"\"\"\n    def __init__(self, rel, attrs=None, using=None):\n        self.rel = rel\n        self.db = using\n        super(ForeignKeyRawIdWidget, self).__init__(attrs)\n\n    def render(self, name, value, attrs=None):\n        if attrs is None:\n            attrs = {}\n        related_url = '../../../%s/%s/' % (self.rel.to._meta.app_label, self.rel.to._meta.object_name.lower())\n        params = self.url_parameters()\n        if params:\n            url = '?' + '&amp;'.join(['%s=%s' % (k, v) for k, v in params.items()])\n        else:\n            url = ''\n        if \"class\" not in attrs:\n            attrs['class'] = 'vForeignKeyRawIdAdminField' # The JavaScript looks for this hook.\n        output = [super(ForeignKeyRawIdWidget, self).render(name, value, attrs)]\n        # TODO: \"id_\" is hard-coded here. This should instead use the correct\n        # API to determine the ID dynamically.\n        output.append('<a href=\"%s%s\" class=\"related-lookup\" id=\"lookup_id_%s\" onclick=\"return showRelatedObjectLookupPopup(this);\"> ' % \\\n            (related_url, url, name))\n        output.append('<img src=\"%simg/admin/selector-search.gif\" width=\"16\" height=\"16\" alt=\"%s\" /></a>' % (settings.ADMIN_MEDIA_PREFIX, _('Lookup')))\n        if value:\n            output.append(self.label_for_value(value))\n        return mark_safe(u''.join(output))\n\n    def base_url_parameters(self):\n        params = {}\n        if self.rel.limit_choices_to and hasattr(self.rel.limit_choices_to, 'items'):\n            items = []\n            for k, v in self.rel.limit_choices_to.items():\n                if isinstance(v, list):\n                    v = ','.join([str(x) for x in v])\n                else:\n                    v = str(v)\n                items.append((k, v))\n            params.update(dict(items))\n        return params\n\n    def url_parameters(self):\n        from django.contrib.admin.views.main import TO_FIELD_VAR\n        params = self.base_url_parameters()\n        params.update({TO_FIELD_VAR: self.rel.get_related_field().name})\n        return params\n\n    def label_for_value(self, value):\n        key = self.rel.get_related_field().name\n        try:\n            obj = self.rel.to._default_manager.using(self.db).get(**{key: value})\n            return '&nbsp;<strong>%s</strong>' % escape(truncate_words(obj, 14))\n        except (ValueError, self.rel.to.DoesNotExist):\n            return ''\n\nclass ManyToManyRawIdWidget(ForeignKeyRawIdWidget):\n    \"\"\"\n    A Widget for displaying ManyToMany ids in the \"raw_id\" interface rather than\n    in a <select multiple> box.\n    \"\"\"\n    def render(self, name, value, attrs=None):\n        if attrs is None:\n            attrs = {}\n        attrs['class'] = 'vManyToManyRawIdAdminField'\n        if value:\n            value = ','.join([force_unicode(v) for v in value])\n        else:\n            value = ''\n        return super(ManyToManyRawIdWidget, self).render(name, value, attrs)\n\n    def url_parameters(self):\n        return self.base_url_parameters()\n\n    def label_for_value(self, value):\n        return ''\n\n    def value_from_datadict(self, data, files, name):\n        value = data.get(name)\n        if value:\n            return value.split(',')\n\n    def _has_changed(self, initial, data):\n        if initial is None:\n            initial = []\n        if data is None:\n            data = []\n        if len(initial) != len(data):\n            return True\n        for pk1, pk2 in zip(initial, data):\n            if force_unicode(pk1) != force_unicode(pk2):\n                return True\n        return False\n\nclass RelatedFieldWidgetWrapper(forms.Widget):\n    \"\"\"\n    This class is a wrapper to a given widget to add the add icon for the\n    admin interface.\n    \"\"\"\n    def __init__(self, widget, rel, admin_site, can_add_related=None):\n        self.is_hidden = widget.is_hidden\n        self.needs_multipart_form = widget.needs_multipart_form\n        self.attrs = widget.attrs\n        self.choices = widget.choices\n        self.widget = widget\n        self.rel = rel\n        # Backwards compatible check for whether a user can add related\n        # objects.\n        if can_add_related is None:\n            can_add_related = rel.to in admin_site._registry\n        self.can_add_related = can_add_related\n        # so we can check if the related object is registered with this AdminSite\n        self.admin_site = admin_site\n\n    def __deepcopy__(self, memo):\n        obj = copy.copy(self)\n        obj.widget = copy.deepcopy(self.widget, memo)\n        obj.attrs = self.widget.attrs\n        memo[id(self)] = obj\n        return obj\n\n    def _media(self):\n        return self.widget.media\n    media = property(_media)\n\n    def render(self, name, value, *args, **kwargs):\n        rel_to = self.rel.to\n        info = (rel_to._meta.app_label, rel_to._meta.object_name.lower())\n        try:\n            related_url = reverse('admin:%s_%s_add' % info, current_app=self.admin_site.name)\n        except NoReverseMatch:\n            info = (self.admin_site.root_path, rel_to._meta.app_label, rel_to._meta.object_name.lower())\n            related_url = '%s%s/%s/add/' % info\n        self.widget.choices = self.choices\n        output = [self.widget.render(name, value, *args, **kwargs)]\n        if self.can_add_related:\n            # TODO: \"id_\" is hard-coded here. This should instead use the correct\n            # API to determine the ID dynamically.\n            output.append(u'<a href=\"%s\" class=\"add-another\" id=\"add_id_%s\" onclick=\"return showAddAnotherPopup(this);\"> ' % \\\n                (related_url, name))\n            output.append(u'<img src=\"%simg/admin/icon_addlink.gif\" width=\"10\" height=\"10\" alt=\"%s\"/></a>' % (settings.ADMIN_MEDIA_PREFIX, _('Add Another')))\n        return mark_safe(u''.join(output))\n\n    def build_attrs(self, extra_attrs=None, **kwargs):\n        \"Helper function for building an attribute dictionary.\"\n        self.attrs = self.widget.build_attrs(extra_attrs=None, **kwargs)\n        return self.attrs\n\n    def value_from_datadict(self, data, files, name):\n        return self.widget.value_from_datadict(data, files, name)\n\n    def _has_changed(self, initial, data):\n        return self.widget._has_changed(initial, data)\n\n    def id_for_label(self, id_):\n        return self.widget.id_for_label(id_)\n\nclass AdminTextareaWidget(forms.Textarea):\n    def __init__(self, attrs=None):\n        final_attrs = {'class': 'vLargeTextField'}\n        if attrs is not None:\n            final_attrs.update(attrs)\n        super(AdminTextareaWidget, self).__init__(attrs=final_attrs)\n\nclass AdminTextInputWidget(forms.TextInput):\n    def __init__(self, attrs=None):\n        final_attrs = {'class': 'vTextField'}\n        if attrs is not None:\n            final_attrs.update(attrs)\n        super(AdminTextInputWidget, self).__init__(attrs=final_attrs)\n\nclass AdminURLFieldWidget(forms.TextInput):\n    def __init__(self, attrs=None):\n        final_attrs = {'class': 'vURLField'}\n        if attrs is not None:\n            final_attrs.update(attrs)\n        super(AdminURLFieldWidget, self).__init__(attrs=final_attrs)\n\nclass AdminIntegerFieldWidget(forms.TextInput):\n    def __init__(self, attrs=None):\n        final_attrs = {'class': 'vIntegerField'}\n        if attrs is not None:\n            final_attrs.update(attrs)\n        super(AdminIntegerFieldWidget, self).__init__(attrs=final_attrs)\n\nclass AdminCommaSeparatedIntegerFieldWidget(forms.TextInput):\n    def __init__(self, attrs=None):\n        final_attrs = {'class': 'vCommaSeparatedIntegerField'}\n        if attrs is not None:\n            final_attrs.update(attrs)\n        super(AdminCommaSeparatedIntegerFieldWidget, self).__init__(attrs=final_attrs)\n" }
{ "repo_name": "mhvk/astropy", "ref": "refs/heads/placeholder", "path": "astropy/nddata/tests/test_compat.py", "content": "# Licensed under a 3-clause BSD style license - see LICENSE.rst\n# This module contains tests of a class equivalent to pre-1.0 NDData.\n\n\nimport pytest\nimport numpy as np\n\nfrom astropy.nddata.nddata import NDData\nfrom astropy.nddata.compat import NDDataArray\nfrom astropy.nddata.nduncertainty import StdDevUncertainty\nfrom astropy.wcs import WCS\nfrom astropy import units as u\n\n\nNDDATA_ATTRIBUTES = ['mask', 'flags', 'uncertainty', 'unit', 'shape', 'size',\n                     'dtype', 'ndim', 'wcs', 'convert_unit_to']\n\n\ndef test_nddataarray_has_attributes_of_old_nddata():\n    ndd = NDDataArray([1, 2, 3])\n    for attr in NDDATA_ATTRIBUTES:\n        assert hasattr(ndd, attr)\n\n\ndef test_nddata_simple():\n    nd = NDDataArray(np.zeros((10, 10)))\n    assert nd.shape == (10, 10)\n    assert nd.size == 100\n    assert nd.dtype == np.dtype(float)\n\n\ndef test_nddata_parameters():\n    # Test for issue 4620\n    nd = NDDataArray(data=np.zeros((10, 10)))\n    assert nd.shape == (10, 10)\n    assert nd.size == 100\n    assert nd.dtype == np.dtype(float)\n    # Change order; `data` has to be given explicitly here\n    nd = NDDataArray(meta={} data=np.zeros((10, 10)))\n    assert nd.shape == (10, 10)\n    assert nd.size == 100\n    assert nd.dtype == np.dtype(float)\n    # Pass uncertainty as second implicit argument\n    data = np.zeros((10, 10))\n    uncertainty = StdDevUncertainty(0.1 + np.zeros_like(data))\n    nd = NDDataArray(data, uncertainty)\n    assert nd.shape == (10, 10)\n    assert nd.size == 100\n    assert nd.dtype == np.dtype(float)\n    assert nd.uncertainty == uncertainty\n\n\ndef test_nddata_conversion():\n    nd = NDDataArray(np.array([[1, 2, 3], [4, 5, 6]]))\n    assert nd.size == 6\n    assert nd.dtype == np.dtype(int)\n\n\n@pytest.mark.parametrize('flags_in', [\n                         np.array([True, False]),\n                         np.array([1, 0]),\n                         [True, False],\n                         [1, 0],\n                         np.array(['a', 'b']),\n                         ['a', 'b']])\ndef test_nddata_flags_init_without_np_array(flags_in):\n    ndd = NDDataArray([1, 1], flags=flags_in)\n    assert (ndd.flags == flags_in).all()\n\n\n@pytest.mark.parametrize(('shape'), [(10,), (5, 5), (3, 10, 10)])\ndef test_nddata_flags_invalid_shape(shape):\n    with pytest.raises(ValueError) as exc:\n        NDDataArray(np.zeros((10, 10)), flags=np.ones(shape))\n    assert exc.value.args[0] == 'dimensions of flags do not match data'\n\n\ndef test_convert_unit_to():\n    # convert_unit_to should return a copy of its input\n    d = NDDataArray(np.ones((5, 5)))\n    d.unit = 'km'\n    d.uncertainty = StdDevUncertainty(0.1 + np.zeros_like(d))\n    # workaround because zeros_like does not support dtype arg until v1.6\n    # and NDData accepts only bool ndarray as mask\n    tmp = np.zeros_like(d.data)\n    d.mask = np.array(tmp, dtype=bool)\n    d1 = d.convert_unit_to('m')\n    assert np.all(d1.data == np.array(1000.0))\n    assert np.all(d1.uncertainty.array == 1000.0 * d.uncertainty.array)\n    assert d1.unit == u.m\n    # changing the output mask should not change the original\n    d1.mask[0, 0] = True\n    assert d.mask[0, 0] != d1.mask[0, 0]\n    d.flags = np.zeros_like(d.data)\n    d1 = d.convert_unit_to('m')\n\n\n# check that subclasses can require wcs and/or unit to be present and use\n# _arithmetic and convert_unit_to\nclass SubNDData(NDDataArray):\n    \"\"\"\n    Subclass for test initialization of subclasses in NDData._arithmetic and\n    NDData.convert_unit_to\n    \"\"\"\n    def __init__(self, *arg, **kwd):\n        super().__init__(*arg, **kwd)\n        if self.unit is None:\n            raise ValueError(\"Unit for subclass must be specified\")\n        if self.wcs is None:\n            raise ValueError(\"WCS for subclass must be specified\")\n\n\ndef test_init_of_subclass_in_convert_unit_to():\n    data = np.ones([10, 10])\n    arr1 = SubNDData(data, unit='m', wcs=WCS(naxis=2))\n    result = arr1.convert_unit_to('km')\n    np.testing.assert_array_equal(arr1.data, 1000 * result.data)\n\n\n# Test for issue #4129:\ndef test_nddataarray_from_nddataarray():\n    ndd1 = NDDataArray([1., 4., 9.],\n                       uncertainty=StdDevUncertainty([1., 2., 3.]),\n                       flags=[0, 1, 0])\n    ndd2 = NDDataArray(ndd1)\n    # Test that the 2 instances point to the same objects and aren't just\n    # equal; this is explicitly documented for the main data array and we\n    # probably want to catch any future change in behavior for the other\n    # attributes too and ensure they are intentional.\n    assert ndd2.data is ndd1.data\n    assert ndd2.uncertainty is ndd1.uncertainty\n    assert ndd2.flags is ndd1.flags\n    assert ndd2.meta == ndd1.meta\n\n\n# Test for issue #4137:\ndef test_nddataarray_from_nddata():\n    ndd1 = NDData([1., 4., 9.],\n                  uncertainty=StdDevUncertainty([1., 2., 3.]))\n    ndd2 = NDDataArray(ndd1)\n\n    assert ndd2.data is ndd1.data\n    assert ndd2.uncertainty is ndd1.uncertainty\n    assert ndd2.meta == ndd1.meta\n" }
{ "repo_name": "dhomeier/astropy", "ref": "refs/heads/wcs-datfix-unwarn", "path": "astropy/nddata/tests/test_compat.py", "content": "# Licensed under a 3-clause BSD style license - see LICENSE.rst\n# This module contains tests of a class equivalent to pre-1.0 NDData.\n\n\nimport pytest\nimport numpy as np\n\nfrom astropy.nddata.nddata import NDData\nfrom astropy.nddata.compat import NDDataArray\nfrom astropy.nddata.nduncertainty import StdDevUncertainty\nfrom astropy.wcs import WCS\nfrom astropy import units as u\n\n\nNDDATA_ATTRIBUTES = ['mask', 'flags', 'uncertainty', 'unit', 'shape', 'size',\n                     'dtype', 'ndim', 'wcs', 'convert_unit_to']\n\n\ndef test_nddataarray_has_attributes_of_old_nddata():\n    ndd = NDDataArray([1, 2, 3])\n    for attr in NDDATA_ATTRIBUTES:\n        assert hasattr(ndd, attr)\n\n\ndef test_nddata_simple():\n    nd = NDDataArray(np.zeros((10, 10)))\n    assert nd.shape == (10, 10)\n    assert nd.size == 100\n    assert nd.dtype == np.dtype(float)\n\n\ndef test_nddata_parameters():\n    # Test for issue 4620\n    nd = NDDataArray(data=np.zeros((10, 10)))\n    assert nd.shape == (10, 10)\n    assert nd.size == 100\n    assert nd.dtype == np.dtype(float)\n    # Change order; `data` has to be given explicitly here\n    nd = NDDataArray(meta={} data=np.zeros((10, 10)))\n    assert nd.shape == (10, 10)\n    assert nd.size == 100\n    assert nd.dtype == np.dtype(float)\n    # Pass uncertainty as second implicit argument\n    data = np.zeros((10, 10))\n    uncertainty = StdDevUncertainty(0.1 + np.zeros_like(data))\n    nd = NDDataArray(data, uncertainty)\n    assert nd.shape == (10, 10)\n    assert nd.size == 100\n    assert nd.dtype == np.dtype(float)\n    assert nd.uncertainty == uncertainty\n\n\ndef test_nddata_conversion():\n    nd = NDDataArray(np.array([[1, 2, 3], [4, 5, 6]]))\n    assert nd.size == 6\n    assert nd.dtype == np.dtype(int)\n\n\n@pytest.mark.parametrize('flags_in', [\n                         np.array([True, False]),\n                         np.array([1, 0]),\n                         [True, False],\n                         [1, 0],\n                         np.array(['a', 'b']),\n                         ['a', 'b']])\ndef test_nddata_flags_init_without_np_array(flags_in):\n    ndd = NDDataArray([1, 1], flags=flags_in)\n    assert (ndd.flags == flags_in).all()\n\n\n@pytest.mark.parametrize(('shape'), [(10,), (5, 5), (3, 10, 10)])\ndef test_nddata_flags_invalid_shape(shape):\n    with pytest.raises(ValueError) as exc:\n        NDDataArray(np.zeros((10, 10)), flags=np.ones(shape))\n    assert exc.value.args[0] == 'dimensions of flags do not match data'\n\n\ndef test_convert_unit_to():\n    # convert_unit_to should return a copy of its input\n    d = NDDataArray(np.ones((5, 5)))\n    d.unit = 'km'\n    d.uncertainty = StdDevUncertainty(0.1 + np.zeros_like(d))\n    # workaround because zeros_like does not support dtype arg until v1.6\n    # and NDData accepts only bool ndarray as mask\n    tmp = np.zeros_like(d.data)\n    d.mask = np.array(tmp, dtype=bool)\n    d1 = d.convert_unit_to('m')\n    assert np.all(d1.data == np.array(1000.0))\n    assert np.all(d1.uncertainty.array == 1000.0 * d.uncertainty.array)\n    assert d1.unit == u.m\n    # changing the output mask should not change the original\n    d1.mask[0, 0] = True\n    assert d.mask[0, 0] != d1.mask[0, 0]\n    d.flags = np.zeros_like(d.data)\n    d1 = d.convert_unit_to('m')\n\n\n# check that subclasses can require wcs and/or unit to be present and use\n# _arithmetic and convert_unit_to\nclass SubNDData(NDDataArray):\n    \"\"\"\n    Subclass for test initialization of subclasses in NDData._arithmetic and\n    NDData.convert_unit_to\n    \"\"\"\n    def __init__(self, *arg, **kwd):\n        super().__init__(*arg, **kwd)\n        if self.unit is None:\n            raise ValueError(\"Unit for subclass must be specified\")\n        if self.wcs is None:\n            raise ValueError(\"WCS for subclass must be specified\")\n\n\ndef test_init_of_subclass_in_convert_unit_to():\n    data = np.ones([10, 10])\n    arr1 = SubNDData(data, unit='m', wcs=WCS(naxis=2))\n    result = arr1.convert_unit_to('km')\n    np.testing.assert_array_equal(arr1.data, 1000 * result.data)\n\n\n# Test for issue #4129:\ndef test_nddataarray_from_nddataarray():\n    ndd1 = NDDataArray([1., 4., 9.],\n                       uncertainty=StdDevUncertainty([1., 2., 3.]),\n                       flags=[0, 1, 0])\n    ndd2 = NDDataArray(ndd1)\n    # Test that the 2 instances point to the same objects and aren't just\n    # equal; this is explicitly documented for the main data array and we\n    # probably want to catch any future change in behavior for the other\n    # attributes too and ensure they are intentional.\n    assert ndd2.data is ndd1.data\n    assert ndd2.uncertainty is ndd1.uncertainty\n    assert ndd2.flags is ndd1.flags\n    assert ndd2.meta == ndd1.meta\n\n\n# Test for issue #4137:\ndef test_nddataarray_from_nddata():\n    ndd1 = NDData([1., 4., 9.],\n                  uncertainty=StdDevUncertainty([1., 2., 3.]))\n    ndd2 = NDDataArray(ndd1)\n\n    assert ndd2.data is ndd1.data\n    assert ndd2.uncertainty is ndd1.uncertainty\n    assert ndd2.meta == ndd1.meta\n" }
{ "repo_name": "astropy/astropy", "ref": "refs/heads/main", "path": "astropy/nddata/tests/test_compat.py", "content": "# Licensed under a 3-clause BSD style license - see LICENSE.rst\n# This module contains tests of a class equivalent to pre-1.0 NDData.\n\n\nimport pytest\nimport numpy as np\n\nfrom astropy.nddata.nddata import NDData\nfrom astropy.nddata.compat import NDDataArray\nfrom astropy.nddata.nduncertainty import StdDevUncertainty\nfrom astropy.wcs import WCS\nfrom astropy import units as u\n\n\nNDDATA_ATTRIBUTES = ['mask', 'flags', 'uncertainty', 'unit', 'shape', 'size',\n                     'dtype', 'ndim', 'wcs', 'convert_unit_to']\n\n\ndef test_nddataarray_has_attributes_of_old_nddata():\n    ndd = NDDataArray([1, 2, 3])\n    for attr in NDDATA_ATTRIBUTES:\n        assert hasattr(ndd, attr)\n\n\ndef test_nddata_simple():\n    nd = NDDataArray(np.zeros((10, 10)))\n    assert nd.shape == (10, 10)\n    assert nd.size == 100\n    assert nd.dtype == np.dtype(float)\n\n\ndef test_nddata_parameters():\n    # Test for issue 4620\n    nd = NDDataArray(data=np.zeros((10, 10)))\n    assert nd.shape == (10, 10)\n    assert nd.size == 100\n    assert nd.dtype == np.dtype(float)\n    # Change order; `data` has to be given explicitly here\n    nd = NDDataArray(meta={} data=np.zeros((10, 10)))\n    assert nd.shape == (10, 10)\n    assert nd.size == 100\n    assert nd.dtype == np.dtype(float)\n    # Pass uncertainty as second implicit argument\n    data = np.zeros((10, 10))\n    uncertainty = StdDevUncertainty(0.1 + np.zeros_like(data))\n    nd = NDDataArray(data, uncertainty)\n    assert nd.shape == (10, 10)\n    assert nd.size == 100\n    assert nd.dtype == np.dtype(float)\n    assert nd.uncertainty == uncertainty\n\n\ndef test_nddata_conversion():\n    nd = NDDataArray(np.array([[1, 2, 3], [4, 5, 6]]))\n    assert nd.size == 6\n    assert nd.dtype == np.dtype(int)\n\n\n@pytest.mark.parametrize('flags_in', [\n                         np.array([True, False]),\n                         np.array([1, 0]),\n                         [True, False],\n                         [1, 0],\n                         np.array(['a', 'b']),\n                         ['a', 'b']])\ndef test_nddata_flags_init_without_np_array(flags_in):\n    ndd = NDDataArray([1, 1], flags=flags_in)\n    assert (ndd.flags == flags_in).all()\n\n\n@pytest.mark.parametrize(('shape'), [(10,), (5, 5), (3, 10, 10)])\ndef test_nddata_flags_invalid_shape(shape):\n    with pytest.raises(ValueError) as exc:\n        NDDataArray(np.zeros((10, 10)), flags=np.ones(shape))\n    assert exc.value.args[0] == 'dimensions of flags do not match data'\n\n\ndef test_convert_unit_to():\n    # convert_unit_to should return a copy of its input\n    d = NDDataArray(np.ones((5, 5)))\n    d.unit = 'km'\n    d.uncertainty = StdDevUncertainty(0.1 + np.zeros_like(d))\n    # workaround because zeros_like does not support dtype arg until v1.6\n    # and NDData accepts only bool ndarray as mask\n    tmp = np.zeros_like(d.data)\n    d.mask = np.array(tmp, dtype=bool)\n    d1 = d.convert_unit_to('m')\n    assert np.all(d1.data == np.array(1000.0))\n    assert np.all(d1.uncertainty.array == 1000.0 * d.uncertainty.array)\n    assert d1.unit == u.m\n    # changing the output mask should not change the original\n    d1.mask[0, 0] = True\n    assert d.mask[0, 0] != d1.mask[0, 0]\n    d.flags = np.zeros_like(d.data)\n    d1 = d.convert_unit_to('m')\n\n\n# check that subclasses can require wcs and/or unit to be present and use\n# _arithmetic and convert_unit_to\nclass SubNDData(NDDataArray):\n    \"\"\"\n    Subclass for test initialization of subclasses in NDData._arithmetic and\n    NDData.convert_unit_to\n    \"\"\"\n    def __init__(self, *arg, **kwd):\n        super().__init__(*arg, **kwd)\n        if self.unit is None:\n            raise ValueError(\"Unit for subclass must be specified\")\n        if self.wcs is None:\n            raise ValueError(\"WCS for subclass must be specified\")\n\n\ndef test_init_of_subclass_in_convert_unit_to():\n    data = np.ones([10, 10])\n    arr1 = SubNDData(data, unit='m', wcs=WCS(naxis=2))\n    result = arr1.convert_unit_to('km')\n    np.testing.assert_array_equal(arr1.data, 1000 * result.data)\n\n\n# Test for issue #4129:\ndef test_nddataarray_from_nddataarray():\n    ndd1 = NDDataArray([1., 4., 9.],\n                       uncertainty=StdDevUncertainty([1., 2., 3.]),\n                       flags=[0, 1, 0])\n    ndd2 = NDDataArray(ndd1)\n    # Test that the 2 instances point to the same objects and aren't just\n    # equal; this is explicitly documented for the main data array and we\n    # probably want to catch any future change in behavior for the other\n    # attributes too and ensure they are intentional.\n    assert ndd2.data is ndd1.data\n    assert ndd2.uncertainty is ndd1.uncertainty\n    assert ndd2.flags is ndd1.flags\n    assert ndd2.meta == ndd1.meta\n\n\n# Test for issue #4137:\ndef test_nddataarray_from_nddata():\n    ndd1 = NDData([1., 4., 9.],\n                  uncertainty=StdDevUncertainty([1., 2., 3.]))\n    ndd2 = NDDataArray(ndd1)\n\n    assert ndd2.data is ndd1.data\n    assert ndd2.uncertainty is ndd1.uncertainty\n    assert ndd2.meta == ndd1.meta\n" }
{ "repo_name": "daq-tools/kotori", "ref": "refs/heads/main", "path": "kotori/vendor/ilaundry/gpiodebug.py", "content": "#!/usr/bin/python\nimport os\nimport time\nimport Adafruit_BBIO.GPIO as GPIO\n\ndef hwports():\n    for portno in range(0, 25):\n        port = 'P8_' + str(portno)\n        yield port\n\nfor port in hwports():\n    GPIO.setup(port, GPIO.IN)\n\nwhile True:\n    os.system('clear')\n    for port in hwports():\n        value = GPIO.input(port)\n        print(port, value)\n    time.sleep(0.2)\n" }
{ "repo_name": "lucafavatella/intellij-community", "ref": "refs/heads/cli-wip", "path": "python/lib/Lib/site-packages/django/contrib/admin/widgets.py", "content": "\"\"\"\nForm Widget classes specific to the Django admin site.\n\"\"\"\n\nimport django.utils.copycompat as copy\n\nfrom django import forms\nfrom django.forms.widgets import RadioFieldRenderer\nfrom django.forms.util import flatatt\nfrom django.utils.html import escape\nfrom django.utils.text import truncate_words\nfrom django.utils.translation import ugettext as _\nfrom django.utils.safestring import mark_safe\nfrom django.utils.encoding import force_unicode\nfrom django.conf import settings\nfrom django.core.urlresolvers import reverse, NoReverseMatch\n\nclass FilteredSelectMultiple(forms.SelectMultiple):\n    \"\"\"\n    A SelectMultiple with a JavaScript filter interface.\n\n    Note that the resulting JavaScript assumes that the jsi18n\n    catalog has been loaded in the page\n    \"\"\"\n    class Media:\n        js = (settings.ADMIN_MEDIA_PREFIX + \"js/core.js\",\n              settings.ADMIN_MEDIA_PREFIX + \"js/SelectBox.js\",\n              settings.ADMIN_MEDIA_PREFIX + \"js/SelectFilter2.js\")\n\n    def __init__(self, verbose_name, is_stacked, attrs=None, choices=()):\n        self.verbose_name = verbose_name\n        self.is_stacked = is_stacked\n        super(FilteredSelectMultiple, self).__init__(attrs, choices)\n\n    def render(self, name, value, attrs=None, choices=()):\n        if attrs is None: attrs = {}\n        attrs['class'] = 'selectfilter'\n        if self.is_stacked: attrs['class'] += 'stacked'\n        output = [super(FilteredSelectMultiple, self).render(name, value, attrs, choices)]\n        output.append(u'<script type=\"text/javascript\">addEvent(window, \"load\", function(e) {')\n        # TODO: \"id_\" is hard-coded here. This should instead use the correct\n        # API to determine the ID dynamically.\n        output.append(u'SelectFilter.init(\"id_%s\", \"%s\", %s, \"%s\"); });</script>\\n' % \\\n            (name, self.verbose_name.replace('\"', '\\\\\"'), int(self.is_stacked), settings.ADMIN_MEDIA_PREFIX))\n        return mark_safe(u''.join(output))\n\nclass AdminDateWidget(forms.DateInput):\n    class Media:\n        js = (settings.ADMIN_MEDIA_PREFIX + \"js/calendar.js\",\n              settings.ADMIN_MEDIA_PREFIX + \"js/admin/DateTimeShortcuts.js\")\n\n    def __init__(self, attrs={} format=None):\n        super(AdminDateWidget, self).__init__(attrs={'class': 'vDateField', 'size': '10'} format=format)\n\nclass AdminTimeWidget(forms.TimeInput):\n    class Media:\n        js = (settings.ADMIN_MEDIA_PREFIX + \"js/calendar.js\",\n              settings.ADMIN_MEDIA_PREFIX + \"js/admin/DateTimeShortcuts.js\")\n\n    def __init__(self, attrs={} format=None):\n        super(AdminTimeWidget, self).__init__(attrs={'class': 'vTimeField', 'size': '8'} format=format)\n\nclass AdminSplitDateTime(forms.SplitDateTimeWidget):\n    \"\"\"\n    A SplitDateTime Widget that has some admin-specific styling.\n    \"\"\"\n    def __init__(self, attrs=None):\n        widgets = [AdminDateWidget, AdminTimeWidget]\n        # Note that we're calling MultiWidget, not SplitDateTimeWidget, because\n        # we want to define widgets.\n        forms.MultiWidget.__init__(self, widgets, attrs)\n\n    def format_output(self, rendered_widgets):\n        return mark_safe(u'<p class=\"datetime\">%s %s<br />%s %s</p>' % \\\n            (_('Date:'), rendered_widgets[0], _('Time:'), rendered_widgets[1]))\n\nclass AdminRadioFieldRenderer(RadioFieldRenderer):\n    def render(self):\n        \"\"\"Outputs a <ul> for this set of radio fields.\"\"\"\n        return mark_safe(u'<ul%s>\\n%s\\n</ul>' % (\n            flatatt(self.attrs),\n            u'\\n'.join([u'<li>%s</li>' % force_unicode(w) for w in self]))\n        )\n\nclass AdminRadioSelect(forms.RadioSelect):\n    renderer = AdminRadioFieldRenderer\n\nclass AdminFileWidget(forms.ClearableFileInput):\n    template_with_initial = (u'<p class=\"file-upload\">%s</p>'\n                            % forms.ClearableFileInput.template_with_initial)\n    template_with_clear = (u'<span class=\"clearable-file-input\">%s</span>'\n                           % forms.ClearableFileInput.template_with_clear)\n\n\nclass ForeignKeyRawIdWidget(forms.TextInput):\n    \"\"\"\n    A Widget for displaying ForeignKeys in the \"raw_id\" interface rather than\n    in a <select> box.\n    \"\"\"\n    def __init__(self, rel, attrs=None, using=None):\n        self.rel = rel\n        self.db = using\n        super(ForeignKeyRawIdWidget, self).__init__(attrs)\n\n    def render(self, name, value, attrs=None):\n        if attrs is None:\n            attrs = {}\n        related_url = '../../../%s/%s/' % (self.rel.to._meta.app_label, self.rel.to._meta.object_name.lower())\n        params = self.url_parameters()\n        if params:\n            url = '?' + '&amp;'.join(['%s=%s' % (k, v) for k, v in params.items()])\n        else:\n            url = ''\n        if \"class\" not in attrs:\n            attrs['class'] = 'vForeignKeyRawIdAdminField' # The JavaScript looks for this hook.\n        output = [super(ForeignKeyRawIdWidget, self).render(name, value, attrs)]\n        # TODO: \"id_\" is hard-coded here. This should instead use the correct\n        # API to determine the ID dynamically.\n        output.append('<a href=\"%s%s\" class=\"related-lookup\" id=\"lookup_id_%s\" onclick=\"return showRelatedObjectLookupPopup(this);\"> ' % \\\n            (related_url, url, name))\n        output.append('<img src=\"%simg/admin/selector-search.gif\" width=\"16\" height=\"16\" alt=\"%s\" /></a>' % (settings.ADMIN_MEDIA_PREFIX, _('Lookup')))\n        if value:\n            output.append(self.label_for_value(value))\n        return mark_safe(u''.join(output))\n\n    def base_url_parameters(self):\n        params = {}\n        if self.rel.limit_choices_to and hasattr(self.rel.limit_choices_to, 'items'):\n            items = []\n            for k, v in self.rel.limit_choices_to.items():\n                if isinstance(v, list):\n                    v = ','.join([str(x) for x in v])\n                else:\n                    v = str(v)\n                items.append((k, v))\n            params.update(dict(items))\n        return params\n\n    def url_parameters(self):\n        from django.contrib.admin.views.main import TO_FIELD_VAR\n        params = self.base_url_parameters()\n        params.update({TO_FIELD_VAR: self.rel.get_related_field().name})\n        return params\n\n    def label_for_value(self, value):\n        key = self.rel.get_related_field().name\n        try:\n            obj = self.rel.to._default_manager.using(self.db).get(**{key: value})\n            return '&nbsp;<strong>%s</strong>' % escape(truncate_words(obj, 14))\n        except (ValueError, self.rel.to.DoesNotExist):\n            return ''\n\nclass ManyToManyRawIdWidget(ForeignKeyRawIdWidget):\n    \"\"\"\n    A Widget for displaying ManyToMany ids in the \"raw_id\" interface rather than\n    in a <select multiple> box.\n    \"\"\"\n    def render(self, name, value, attrs=None):\n        if attrs is None:\n            attrs = {}\n        attrs['class'] = 'vManyToManyRawIdAdminField'\n        if value:\n            value = ','.join([force_unicode(v) for v in value])\n        else:\n            value = ''\n        return super(ManyToManyRawIdWidget, self).render(name, value, attrs)\n\n    def url_parameters(self):\n        return self.base_url_parameters()\n\n    def label_for_value(self, value):\n        return ''\n\n    def value_from_datadict(self, data, files, name):\n        value = data.get(name)\n        if value:\n            return value.split(',')\n\n    def _has_changed(self, initial, data):\n        if initial is None:\n            initial = []\n        if data is None:\n            data = []\n        if len(initial) != len(data):\n            return True\n        for pk1, pk2 in zip(initial, data):\n            if force_unicode(pk1) != force_unicode(pk2):\n                return True\n        return False\n\nclass RelatedFieldWidgetWrapper(forms.Widget):\n    \"\"\"\n    This class is a wrapper to a given widget to add the add icon for the\n    admin interface.\n    \"\"\"\n    def __init__(self, widget, rel, admin_site, can_add_related=None):\n        self.is_hidden = widget.is_hidden\n        self.needs_multipart_form = widget.needs_multipart_form\n        self.attrs = widget.attrs\n        self.choices = widget.choices\n        self.widget = widget\n        self.rel = rel\n        # Backwards compatible check for whether a user can add related\n        # objects.\n        if can_add_related is None:\n            can_add_related = rel.to in admin_site._registry\n        self.can_add_related = can_add_related\n        # so we can check if the related object is registered with this AdminSite\n        self.admin_site = admin_site\n\n    def __deepcopy__(self, memo):\n        obj = copy.copy(self)\n        obj.widget = copy.deepcopy(self.widget, memo)\n        obj.attrs = self.widget.attrs\n        memo[id(self)] = obj\n        return obj\n\n    def _media(self):\n        return self.widget.media\n    media = property(_media)\n\n    def render(self, name, value, *args, **kwargs):\n        rel_to = self.rel.to\n        info = (rel_to._meta.app_label, rel_to._meta.object_name.lower())\n        try:\n            related_url = reverse('admin:%s_%s_add' % info, current_app=self.admin_site.name)\n        except NoReverseMatch:\n            info = (self.admin_site.root_path, rel_to._meta.app_label, rel_to._meta.object_name.lower())\n            related_url = '%s%s/%s/add/' % info\n        self.widget.choices = self.choices\n        output = [self.widget.render(name, value, *args, **kwargs)]\n        if self.can_add_related:\n            # TODO: \"id_\" is hard-coded here. This should instead use the correct\n            # API to determine the ID dynamically.\n            output.append(u'<a href=\"%s\" class=\"add-another\" id=\"add_id_%s\" onclick=\"return showAddAnotherPopup(this);\"> ' % \\\n                (related_url, name))\n            output.append(u'<img src=\"%simg/admin/icon_addlink.gif\" width=\"10\" height=\"10\" alt=\"%s\"/></a>' % (settings.ADMIN_MEDIA_PREFIX, _('Add Another')))\n        return mark_safe(u''.join(output))\n\n    def build_attrs(self, extra_attrs=None, **kwargs):\n        \"Helper function for building an attribute dictionary.\"\n        self.attrs = self.widget.build_attrs(extra_attrs=None, **kwargs)\n        return self.attrs\n\n    def value_from_datadict(self, data, files, name):\n        return self.widget.value_from_datadict(data, files, name)\n\n    def _has_changed(self, initial, data):\n        return self.widget._has_changed(initial, data)\n\n    def id_for_label(self, id_):\n        return self.widget.id_for_label(id_)\n\nclass AdminTextareaWidget(forms.Textarea):\n    def __init__(self, attrs=None):\n        final_attrs = {'class': 'vLargeTextField'}\n        if attrs is not None:\n            final_attrs.update(attrs)\n        super(AdminTextareaWidget, self).__init__(attrs=final_attrs)\n\nclass AdminTextInputWidget(forms.TextInput):\n    def __init__(self, attrs=None):\n        final_attrs = {'class': 'vTextField'}\n        if attrs is not None:\n            final_attrs.update(attrs)\n        super(AdminTextInputWidget, self).__init__(attrs=final_attrs)\n\nclass AdminURLFieldWidget(forms.TextInput):\n    def __init__(self, attrs=None):\n        final_attrs = {'class': 'vURLField'}\n        if attrs is not None:\n            final_attrs.update(attrs)\n        super(AdminURLFieldWidget, self).__init__(attrs=final_attrs)\n\nclass AdminIntegerFieldWidget(forms.TextInput):\n    def __init__(self, attrs=None):\n        final_attrs = {'class': 'vIntegerField'}\n        if attrs is not None:\n            final_attrs.update(attrs)\n        super(AdminIntegerFieldWidget, self).__init__(attrs=final_attrs)\n\nclass AdminCommaSeparatedIntegerFieldWidget(forms.TextInput):\n    def __init__(self, attrs=None):\n        final_attrs = {'class': 'vCommaSeparatedIntegerField'}\n        if attrs is not None:\n            final_attrs.update(attrs)\n        super(AdminCommaSeparatedIntegerFieldWidget, self).__init__(attrs=final_attrs)\n" }
{ "repo_name": "AnhellO/DAS_Sistemas", "ref": "refs/heads/development", "path": "Ene-Jun-2021/morales-ramos-manuel-gerardo/Primer Parcial/Ejercicio 1/ejercicio_1.py", "content": "import abc\n\n#Clase de la página web\nclass WebPage:\n    def __init__(self, url, route, page_format, content, title, slug, meta_tags = []):\n        self._url: str = url\n        self._route: str = route\n        self._format: str = page_format\n        self._content: str = content\n        self._title: str = title\n        self._slug: str = slug\n        self._meta_tags: list = meta_tags\n\n    def __str__(self) -> str:\n        return f'\\nTitle: {self._title}\\nURL: {self._url}\\nSlug: {self._slug}\\nRoute: {self._route}\\nFormat: {self._format}\\nContent: {self._content}\\nMeta tags: {self.get_tags()}'\n    \n    def get_tags(self):\n        tags = ''\n        for tag in self._meta_tags:\n            tags += str(tag)\n\n        return tags\n\n#Interface para el proxy\nclass ServiceInterface(metaclass=abc.ABCMeta):\n    @abc.abstractmethod\n    def login(self, user: str, passw: str):\n        pass\n\n#Clase para el sitio web\nclass WebSite(ServiceInterface):\n    def __init__(self, domain, category, pages:list):\n        self._domain: str = domain\n        self._category: str = category\n        self._pages: WebPage = pages\n\n    def __str__(self) -> str:\n        return f'\\r\\nCategory: {self._category}\\n\\rDomain: {self._domain}\\r\\n\\nWeb Pages: \\r\\n{self.get_pages()}'\n\n    def get_pages(self) -> WebPage:\n        pages = ''\n        for page in self._pages:\n            pages += str(page)\n\n        return pages\n\n    def login(self, user: str, passw: str):\n        return f'Welcome, {user}!'\n\n#Clase que hará la autenticación\nclass Authentication(ServiceInterface):\n    def __init__(self, s: WebSite):\n        self._service = s\n\n    def authenticate(self, user: str, passw: str):\n        if(user == 'gerardo' and passw == '123456'):\n            return True\n        else:\n            return False\n\n    def login(self, user: str, passw: str):\n        if(self.authenticate(user, passw)):\n            return self._service.login(user, passw)\n        else:\n            return 'Invalid data!'\n\ndef main():\n    webpage1 = WebPage('https://www.wp.com/home', 'https://www.wp.com/index.html', 'HTML', '<main></main>', 'Home', 'home', ['<meta>', '<meta>'])\n    webpage2 = WebPage('https://www.wp.com/contact-me', 'https://www.wp.com/contact-me.html', 'HTML', '<main></main>', 'Contact Me', 'contact-me', ['<meta>', '<meta>'])\n    webpage3 = WebPage('https://www.wp.com/faq', 'https://www.wp.com/faq.html', 'HTML', '<main></main>', 'FAQ', 'faq', ['<meta>', '<meta>'])\n    \n    pages = [webpage1, webpage2, webpage3]\n    \n    website = WebSite('wp', 'Educational', pages)\n    print(website)\n    print('--------------------------------')\n    print(Authentication(website).login('gerardo', '123456'))\n\nif __name__ == \"__main__\":     \n    main()" }
{ "repo_name": "gaeun/open-event-orga-server", "ref": "refs/heads/development", "path": "migrations/versions/ed4b4ba3274e_.py", "content": "\"\"\"empty message\n\nRevision ID: ed4b4ba3274e\nRevises: 784a1fc57171\nCreate Date: 2016-06-16 06:08:49.516538\n\n\"\"\"\n\n# revision identifiers, used by Alembic.\nrevision = 'ed4b4ba3274e'\ndown_revision = '784a1fc57171'\n\nfrom alembic import op\nimport sqlalchemy as sa\nimport sqlalchemy_utils\n\n\ndef upgrade():\n    ### commands auto generated by Alembic - please adjust! ###\n    op.create_table('service',\n    sa.Column('id', sa.Integer(), nullable=False),\n    sa.Column('name', sa.String(), nullable=False),\n    sa.PrimaryKeyConstraint('id'),\n    sa.UniqueConstraint('name')\n    )\n    op.add_column(u'permissions', sa.Column('can_create', sa.Boolean(), nullable=False))\n    op.add_column(u'permissions', sa.Column('can_delete', sa.Boolean(), nullable=False))\n    op.add_column(u'permissions', sa.Column('can_read', sa.Boolean(), nullable=False))\n    op.add_column(u'permissions', sa.Column('can_update', sa.Boolean(), nullable=False))\n    op.add_column(u'permissions', sa.Column('role_id', sa.Integer(), nullable=True))\n    op.alter_column(u'permissions', 'service_id',\n               existing_type=sa.INTEGER(),\n               nullable=True)\n    op.create_unique_constraint('role_service_uc', 'permissions', ['role_id', 'service_id'])\n    op.drop_constraint(u'user_service_uc', 'permissions', type_='unique')\n    op.drop_constraint(u'permissions_user_id_fkey', 'permissions', type_='foreignkey')\n    op.create_foreign_key(None, 'permissions', 'role', ['role_id'], ['id'])\n    op.create_foreign_key(None, 'permissions', 'service', ['service_id'], ['id'])\n    op.drop_column(u'permissions', 'user_id')\n    op.drop_column(u'permissions', 'modes')\n    op.drop_column(u'permissions', 'service')\n    op.alter_column(u'role', 'name',\n               existing_type=sa.VARCHAR(length=128),\n               nullable=False)\n    op.create_unique_constraint(None, 'role', ['name'])\n    op.drop_column(u'user', 'role')\n    ### end Alembic commands ###\n\n\ndef downgrade():\n    ### commands auto generated by Alembic - please adjust! ###\n    op.add_column(u'user', sa.Column('role', sa.VARCHAR(), autoincrement=False, nullable=True))\n    op.drop_constraint(None, 'role', type_='unique')\n    op.alter_column(u'role', 'name',\n               existing_type=sa.VARCHAR(length=128),\n               nullable=True)\n    op.add_column(u'permissions', sa.Column('service', sa.VARCHAR(), autoincrement=False, nullable=False))\n    op.add_column(u'permissions', sa.Column('modes', sa.INTEGER(), autoincrement=False, nullable=False))\n    op.add_column(u'permissions', sa.Column('user_id', sa.INTEGER(), autoincrement=False, nullable=False))\n    op.drop_constraint(None, 'permissions', type_='foreignkey')\n    op.drop_constraint(None, 'permissions', type_='foreignkey')\n    op.create_foreign_key(u'permissions_user_id_fkey', 'permissions', 'user', ['user_id'], ['id'])\n    op.create_unique_constraint(u'user_service_uc', 'permissions', ['user_id', 'service', 'service_id'])\n    op.drop_constraint('role_service_uc', 'permissions', type_='unique')\n    op.alter_column(u'permissions', 'service_id',\n               existing_type=sa.INTEGER(),\n               nullable=False)\n    op.drop_column(u'permissions', 'role_id')\n    op.drop_column(u'permissions', 'can_update')\n    op.drop_column(u'permissions', 'can_read')\n    op.drop_column(u'permissions', 'can_delete')\n    op.drop_column(u'permissions', 'can_create')\n    op.drop_table('service')\n    ### end Alembic commands ###\n" }
{ "repo_name": "Princu7/open-event-orga-server", "ref": "refs/heads/development", "path": "migrations/versions/ed4b4ba3274e_.py", "content": "\"\"\"empty message\n\nRevision ID: ed4b4ba3274e\nRevises: 784a1fc57171\nCreate Date: 2016-06-16 06:08:49.516538\n\n\"\"\"\n\n# revision identifiers, used by Alembic.\nrevision = 'ed4b4ba3274e'\ndown_revision = '784a1fc57171'\n\nfrom alembic import op\nimport sqlalchemy as sa\nimport sqlalchemy_utils\n\n\ndef upgrade():\n    ### commands auto generated by Alembic - please adjust! ###\n    op.create_table('service',\n    sa.Column('id', sa.Integer(), nullable=False),\n    sa.Column('name', sa.String(), nullable=False),\n    sa.PrimaryKeyConstraint('id'),\n    sa.UniqueConstraint('name')\n    )\n    op.add_column(u'permissions', sa.Column('can_create', sa.Boolean(), nullable=False))\n    op.add_column(u'permissions', sa.Column('can_delete', sa.Boolean(), nullable=False))\n    op.add_column(u'permissions', sa.Column('can_read', sa.Boolean(), nullable=False))\n    op.add_column(u'permissions', sa.Column('can_update', sa.Boolean(), nullable=False))\n    op.add_column(u'permissions', sa.Column('role_id', sa.Integer(), nullable=True))\n    op.alter_column(u'permissions', 'service_id',\n               existing_type=sa.INTEGER(),\n               nullable=True)\n    op.create_unique_constraint('role_service_uc', 'permissions', ['role_id', 'service_id'])\n    op.drop_constraint(u'user_service_uc', 'permissions', type_='unique')\n    op.drop_constraint(u'permissions_user_id_fkey', 'permissions', type_='foreignkey')\n    op.create_foreign_key(None, 'permissions', 'role', ['role_id'], ['id'])\n    op.create_foreign_key(None, 'permissions', 'service', ['service_id'], ['id'])\n    op.drop_column(u'permissions', 'user_id')\n    op.drop_column(u'permissions', 'modes')\n    op.drop_column(u'permissions', 'service')\n    op.alter_column(u'role', 'name',\n               existing_type=sa.VARCHAR(length=128),\n               nullable=False)\n    op.create_unique_constraint(None, 'role', ['name'])\n    op.drop_column(u'user', 'role')\n    ### end Alembic commands ###\n\n\ndef downgrade():\n    ### commands auto generated by Alembic - please adjust! ###\n    op.add_column(u'user', sa.Column('role', sa.VARCHAR(), autoincrement=False, nullable=True))\n    op.drop_constraint(None, 'role', type_='unique')\n    op.alter_column(u'role', 'name',\n               existing_type=sa.VARCHAR(length=128),\n               nullable=True)\n    op.add_column(u'permissions', sa.Column('service', sa.VARCHAR(), autoincrement=False, nullable=False))\n    op.add_column(u'permissions', sa.Column('modes', sa.INTEGER(), autoincrement=False, nullable=False))\n    op.add_column(u'permissions', sa.Column('user_id', sa.INTEGER(), autoincrement=False, nullable=False))\n    op.drop_constraint(None, 'permissions', type_='foreignkey')\n    op.drop_constraint(None, 'permissions', type_='foreignkey')\n    op.create_foreign_key(u'permissions_user_id_fkey', 'permissions', 'user', ['user_id'], ['id'])\n    op.create_unique_constraint(u'user_service_uc', 'permissions', ['user_id', 'service', 'service_id'])\n    op.drop_constraint('role_service_uc', 'permissions', type_='unique')\n    op.alter_column(u'permissions', 'service_id',\n               existing_type=sa.INTEGER(),\n               nullable=False)\n    op.drop_column(u'permissions', 'role_id')\n    op.drop_column(u'permissions', 'can_update')\n    op.drop_column(u'permissions', 'can_read')\n    op.drop_column(u'permissions', 'can_delete')\n    op.drop_column(u'permissions', 'can_create')\n    op.drop_table('service')\n    ### end Alembic commands ###\n" }
{ "repo_name": "saimn/astropy", "ref": "refs/heads/main", "path": "astropy/nddata/tests/test_compat.py", "content": "# Licensed under a 3-clause BSD style license - see LICENSE.rst\n# This module contains tests of a class equivalent to pre-1.0 NDData.\n\n\nimport pytest\nimport numpy as np\n\nfrom astropy.nddata.nddata import NDData\nfrom astropy.nddata.compat import NDDataArray\nfrom astropy.nddata.nduncertainty import StdDevUncertainty\nfrom astropy.wcs import WCS\nfrom astropy import units as u\n\n\nNDDATA_ATTRIBUTES = ['mask', 'flags', 'uncertainty', 'unit', 'shape', 'size',\n                     'dtype', 'ndim', 'wcs', 'convert_unit_to']\n\n\ndef test_nddataarray_has_attributes_of_old_nddata():\n    ndd = NDDataArray([1, 2, 3])\n    for attr in NDDATA_ATTRIBUTES:\n        assert hasattr(ndd, attr)\n\n\ndef test_nddata_simple():\n    nd = NDDataArray(np.zeros((10, 10)))\n    assert nd.shape == (10, 10)\n    assert nd.size == 100\n    assert nd.dtype == np.dtype(float)\n\n\ndef test_nddata_parameters():\n    # Test for issue 4620\n    nd = NDDataArray(data=np.zeros((10, 10)))\n    assert nd.shape == (10, 10)\n    assert nd.size == 100\n    assert nd.dtype == np.dtype(float)\n    # Change order; `data` has to be given explicitly here\n    nd = NDDataArray(meta={} data=np.zeros((10, 10)))\n    assert nd.shape == (10, 10)\n    assert nd.size == 100\n    assert nd.dtype == np.dtype(float)\n    # Pass uncertainty as second implicit argument\n    data = np.zeros((10, 10))\n    uncertainty = StdDevUncertainty(0.1 + np.zeros_like(data))\n    nd = NDDataArray(data, uncertainty)\n    assert nd.shape == (10, 10)\n    assert nd.size == 100\n    assert nd.dtype == np.dtype(float)\n    assert nd.uncertainty == uncertainty\n\n\ndef test_nddata_conversion():\n    nd = NDDataArray(np.array([[1, 2, 3], [4, 5, 6]]))\n    assert nd.size == 6\n    assert nd.dtype == np.dtype(int)\n\n\n@pytest.mark.parametrize('flags_in', [\n                         np.array([True, False]),\n                         np.array([1, 0]),\n                         [True, False],\n                         [1, 0],\n                         np.array(['a', 'b']),\n                         ['a', 'b']])\ndef test_nddata_flags_init_without_np_array(flags_in):\n    ndd = NDDataArray([1, 1], flags=flags_in)\n    assert (ndd.flags == flags_in).all()\n\n\n@pytest.mark.parametrize(('shape'), [(10,), (5, 5), (3, 10, 10)])\ndef test_nddata_flags_invalid_shape(shape):\n    with pytest.raises(ValueError) as exc:\n        NDDataArray(np.zeros((10, 10)), flags=np.ones(shape))\n    assert exc.value.args[0] == 'dimensions of flags do not match data'\n\n\ndef test_convert_unit_to():\n    # convert_unit_to should return a copy of its input\n    d = NDDataArray(np.ones((5, 5)))\n    d.unit = 'km'\n    d.uncertainty = StdDevUncertainty(0.1 + np.zeros_like(d))\n    # workaround because zeros_like does not support dtype arg until v1.6\n    # and NDData accepts only bool ndarray as mask\n    tmp = np.zeros_like(d.data)\n    d.mask = np.array(tmp, dtype=bool)\n    d1 = d.convert_unit_to('m')\n    assert np.all(d1.data == np.array(1000.0))\n    assert np.all(d1.uncertainty.array == 1000.0 * d.uncertainty.array)\n    assert d1.unit == u.m\n    # changing the output mask should not change the original\n    d1.mask[0, 0] = True\n    assert d.mask[0, 0] != d1.mask[0, 0]\n    d.flags = np.zeros_like(d.data)\n    d1 = d.convert_unit_to('m')\n\n\n# check that subclasses can require wcs and/or unit to be present and use\n# _arithmetic and convert_unit_to\nclass SubNDData(NDDataArray):\n    \"\"\"\n    Subclass for test initialization of subclasses in NDData._arithmetic and\n    NDData.convert_unit_to\n    \"\"\"\n    def __init__(self, *arg, **kwd):\n        super().__init__(*arg, **kwd)\n        if self.unit is None:\n            raise ValueError(\"Unit for subclass must be specified\")\n        if self.wcs is None:\n            raise ValueError(\"WCS for subclass must be specified\")\n\n\ndef test_init_of_subclass_in_convert_unit_to():\n    data = np.ones([10, 10])\n    arr1 = SubNDData(data, unit='m', wcs=WCS(naxis=2))\n    result = arr1.convert_unit_to('km')\n    np.testing.assert_array_equal(arr1.data, 1000 * result.data)\n\n\n# Test for issue #4129:\ndef test_nddataarray_from_nddataarray():\n    ndd1 = NDDataArray([1., 4., 9.],\n                       uncertainty=StdDevUncertainty([1., 2., 3.]),\n                       flags=[0, 1, 0])\n    ndd2 = NDDataArray(ndd1)\n    # Test that the 2 instances point to the same objects and aren't just\n    # equal; this is explicitly documented for the main data array and we\n    # probably want to catch any future change in behavior for the other\n    # attributes too and ensure they are intentional.\n    assert ndd2.data is ndd1.data\n    assert ndd2.uncertainty is ndd1.uncertainty\n    assert ndd2.flags is ndd1.flags\n    assert ndd2.meta == ndd1.meta\n\n\n# Test for issue #4137:\ndef test_nddataarray_from_nddata():\n    ndd1 = NDData([1., 4., 9.],\n                  uncertainty=StdDevUncertainty([1., 2., 3.]))\n    ndd2 = NDDataArray(ndd1)\n\n    assert ndd2.data is ndd1.data\n    assert ndd2.uncertainty is ndd1.uncertainty\n    assert ndd2.meta == ndd1.meta\n" }
{ "repo_name": "Achint08/open-event-orga-server", "ref": "refs/heads/development", "path": "migrations/versions/ed4b4ba3274e_.py", "content": "\"\"\"empty message\n\nRevision ID: ed4b4ba3274e\nRevises: 784a1fc57171\nCreate Date: 2016-06-16 06:08:49.516538\n\n\"\"\"\n\n# revision identifiers, used by Alembic.\nrevision = 'ed4b4ba3274e'\ndown_revision = '784a1fc57171'\n\nfrom alembic import op\nimport sqlalchemy as sa\nimport sqlalchemy_utils\n\n\ndef upgrade():\n    ### commands auto generated by Alembic - please adjust! ###\n    op.create_table('service',\n    sa.Column('id', sa.Integer(), nullable=False),\n    sa.Column('name', sa.String(), nullable=False),\n    sa.PrimaryKeyConstraint('id'),\n    sa.UniqueConstraint('name')\n    )\n    op.add_column(u'permissions', sa.Column('can_create', sa.Boolean(), nullable=False))\n    op.add_column(u'permissions', sa.Column('can_delete', sa.Boolean(), nullable=False))\n    op.add_column(u'permissions', sa.Column('can_read', sa.Boolean(), nullable=False))\n    op.add_column(u'permissions', sa.Column('can_update', sa.Boolean(), nullable=False))\n    op.add_column(u'permissions', sa.Column('role_id', sa.Integer(), nullable=True))\n    op.alter_column(u'permissions', 'service_id',\n               existing_type=sa.INTEGER(),\n               nullable=True)\n    op.create_unique_constraint('role_service_uc', 'permissions', ['role_id', 'service_id'])\n    op.drop_constraint(u'user_service_uc', 'permissions', type_='unique')\n    op.drop_constraint(u'permissions_user_id_fkey', 'permissions', type_='foreignkey')\n    op.create_foreign_key(None, 'permissions', 'role', ['role_id'], ['id'])\n    op.create_foreign_key(None, 'permissions', 'service', ['service_id'], ['id'])\n    op.drop_column(u'permissions', 'user_id')\n    op.drop_column(u'permissions', 'modes')\n    op.drop_column(u'permissions', 'service')\n    op.alter_column(u'role', 'name',\n               existing_type=sa.VARCHAR(length=128),\n               nullable=False)\n    op.create_unique_constraint(None, 'role', ['name'])\n    op.drop_column(u'user', 'role')\n    ### end Alembic commands ###\n\n\ndef downgrade():\n    ### commands auto generated by Alembic - please adjust! ###\n    op.add_column(u'user', sa.Column('role', sa.VARCHAR(), autoincrement=False, nullable=True))\n    op.drop_constraint(None, 'role', type_='unique')\n    op.alter_column(u'role', 'name',\n               existing_type=sa.VARCHAR(length=128),\n               nullable=True)\n    op.add_column(u'permissions', sa.Column('service', sa.VARCHAR(), autoincrement=False, nullable=False))\n    op.add_column(u'permissions', sa.Column('modes', sa.INTEGER(), autoincrement=False, nullable=False))\n    op.add_column(u'permissions', sa.Column('user_id', sa.INTEGER(), autoincrement=False, nullable=False))\n    op.drop_constraint(None, 'permissions', type_='foreignkey')\n    op.drop_constraint(None, 'permissions', type_='foreignkey')\n    op.create_foreign_key(u'permissions_user_id_fkey', 'permissions', 'user', ['user_id'], ['id'])\n    op.create_unique_constraint(u'user_service_uc', 'permissions', ['user_id', 'service', 'service_id'])\n    op.drop_constraint('role_service_uc', 'permissions', type_='unique')\n    op.alter_column(u'permissions', 'service_id',\n               existing_type=sa.INTEGER(),\n               nullable=False)\n    op.drop_column(u'permissions', 'role_id')\n    op.drop_column(u'permissions', 'can_update')\n    op.drop_column(u'permissions', 'can_read')\n    op.drop_column(u'permissions', 'can_delete')\n    op.drop_column(u'permissions', 'can_create')\n    op.drop_table('service')\n    ### end Alembic commands ###\n" }
{ "repo_name": "larrybradley/astropy", "ref": "refs/heads/main", "path": "astropy/nddata/tests/test_compat.py", "content": "# Licensed under a 3-clause BSD style license - see LICENSE.rst\n# This module contains tests of a class equivalent to pre-1.0 NDData.\n\n\nimport pytest\nimport numpy as np\n\nfrom astropy.nddata.nddata import NDData\nfrom astropy.nddata.compat import NDDataArray\nfrom astropy.nddata.nduncertainty import StdDevUncertainty\nfrom astropy.wcs import WCS\nfrom astropy import units as u\n\n\nNDDATA_ATTRIBUTES = ['mask', 'flags', 'uncertainty', 'unit', 'shape', 'size',\n                     'dtype', 'ndim', 'wcs', 'convert_unit_to']\n\n\ndef test_nddataarray_has_attributes_of_old_nddata():\n    ndd = NDDataArray([1, 2, 3])\n    for attr in NDDATA_ATTRIBUTES:\n        assert hasattr(ndd, attr)\n\n\ndef test_nddata_simple():\n    nd = NDDataArray(np.zeros((10, 10)))\n    assert nd.shape == (10, 10)\n    assert nd.size == 100\n    assert nd.dtype == np.dtype(float)\n\n\ndef test_nddata_parameters():\n    # Test for issue 4620\n    nd = NDDataArray(data=np.zeros((10, 10)))\n    assert nd.shape == (10, 10)\n    assert nd.size == 100\n    assert nd.dtype == np.dtype(float)\n    # Change order; `data` has to be given explicitly here\n    nd = NDDataArray(meta={} data=np.zeros((10, 10)))\n    assert nd.shape == (10, 10)\n    assert nd.size == 100\n    assert nd.dtype == np.dtype(float)\n    # Pass uncertainty as second implicit argument\n    data = np.zeros((10, 10))\n    uncertainty = StdDevUncertainty(0.1 + np.zeros_like(data))\n    nd = NDDataArray(data, uncertainty)\n    assert nd.shape == (10, 10)\n    assert nd.size == 100\n    assert nd.dtype == np.dtype(float)\n    assert nd.uncertainty == uncertainty\n\n\ndef test_nddata_conversion():\n    nd = NDDataArray(np.array([[1, 2, 3], [4, 5, 6]]))\n    assert nd.size == 6\n    assert nd.dtype == np.dtype(int)\n\n\n@pytest.mark.parametrize('flags_in', [\n                         np.array([True, False]),\n                         np.array([1, 0]),\n                         [True, False],\n                         [1, 0],\n                         np.array(['a', 'b']),\n                         ['a', 'b']])\ndef test_nddata_flags_init_without_np_array(flags_in):\n    ndd = NDDataArray([1, 1], flags=flags_in)\n    assert (ndd.flags == flags_in).all()\n\n\n@pytest.mark.parametrize(('shape'), [(10,), (5, 5), (3, 10, 10)])\ndef test_nddata_flags_invalid_shape(shape):\n    with pytest.raises(ValueError) as exc:\n        NDDataArray(np.zeros((10, 10)), flags=np.ones(shape))\n    assert exc.value.args[0] == 'dimensions of flags do not match data'\n\n\ndef test_convert_unit_to():\n    # convert_unit_to should return a copy of its input\n    d = NDDataArray(np.ones((5, 5)))\n    d.unit = 'km'\n    d.uncertainty = StdDevUncertainty(0.1 + np.zeros_like(d))\n    # workaround because zeros_like does not support dtype arg until v1.6\n    # and NDData accepts only bool ndarray as mask\n    tmp = np.zeros_like(d.data)\n    d.mask = np.array(tmp, dtype=bool)\n    d1 = d.convert_unit_to('m')\n    assert np.all(d1.data == np.array(1000.0))\n    assert np.all(d1.uncertainty.array == 1000.0 * d.uncertainty.array)\n    assert d1.unit == u.m\n    # changing the output mask should not change the original\n    d1.mask[0, 0] = True\n    assert d.mask[0, 0] != d1.mask[0, 0]\n    d.flags = np.zeros_like(d.data)\n    d1 = d.convert_unit_to('m')\n\n\n# check that subclasses can require wcs and/or unit to be present and use\n# _arithmetic and convert_unit_to\nclass SubNDData(NDDataArray):\n    \"\"\"\n    Subclass for test initialization of subclasses in NDData._arithmetic and\n    NDData.convert_unit_to\n    \"\"\"\n    def __init__(self, *arg, **kwd):\n        super().__init__(*arg, **kwd)\n        if self.unit is None:\n            raise ValueError(\"Unit for subclass must be specified\")\n        if self.wcs is None:\n            raise ValueError(\"WCS for subclass must be specified\")\n\n\ndef test_init_of_subclass_in_convert_unit_to():\n    data = np.ones([10, 10])\n    arr1 = SubNDData(data, unit='m', wcs=WCS(naxis=2))\n    result = arr1.convert_unit_to('km')\n    np.testing.assert_array_equal(arr1.data, 1000 * result.data)\n\n\n# Test for issue #4129:\ndef test_nddataarray_from_nddataarray():\n    ndd1 = NDDataArray([1., 4., 9.],\n                       uncertainty=StdDevUncertainty([1., 2., 3.]),\n                       flags=[0, 1, 0])\n    ndd2 = NDDataArray(ndd1)\n    # Test that the 2 instances point to the same objects and aren't just\n    # equal; this is explicitly documented for the main data array and we\n    # probably want to catch any future change in behavior for the other\n    # attributes too and ensure they are intentional.\n    assert ndd2.data is ndd1.data\n    assert ndd2.uncertainty is ndd1.uncertainty\n    assert ndd2.flags is ndd1.flags\n    assert ndd2.meta == ndd1.meta\n\n\n# Test for issue #4137:\ndef test_nddataarray_from_nddata():\n    ndd1 = NDData([1., 4., 9.],\n                  uncertainty=StdDevUncertainty([1., 2., 3.]))\n    ndd2 = NDDataArray(ndd1)\n\n    assert ndd2.data is ndd1.data\n    assert ndd2.uncertainty is ndd1.uncertainty\n    assert ndd2.meta == ndd1.meta\n" } 
{ "repo_name": "sridevikoushik31/nova", "ref": "refs/heads/port_id_in_vif_on_devide", "path": "nova/openstack/common/rootwrap/filters.py", "content": "# vim: tabstop=4 shiftwidth=4 softtabstop=4\n\n# Copyright (c) 2011 OpenStack Foundation.\n# All Rights Reserved.\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\nimport os\nimport re\n\n\nclass CommandFilter(object):\n    \"\"\"Command filter only checking that the 1st argument matches exec_path\"\"\"\n\n    def __init__(self, exec_path, run_as, *args):\n        self.name = ''\n        self.exec_path = exec_path\n        self.run_as = run_as\n        self.args = args\n        self.real_exec = None\n\n    def get_exec(self, exec_dirs=[]):\n        \"\"\"Returns existing executable, or empty string if none found\"\"\"\n        if self.real_exec is not None:\n            return self.real_exec\n        self.real_exec = \"\"\n        if self.exec_path.startswith('/'):\n            if os.access(self.exec_path, os.X_OK):\n                self.real_exec = self.exec_path\n        else:\n            for binary_path in exec_dirs:\n                expanded_path = os.path.join(binary_path, self.exec_path)\n                if os.access(expanded_path, os.X_OK):\n                    self.real_exec = expanded_path\n                    break\n        return self.real_exec\n\n    def match(self, userargs):\n        \"\"\"Only check that the first argument (command) matches exec_path\"\"\"\n        if (os.path.basename(self.exec_path) == userargs[0]):\n            return True\n        return False\n\n    def get_command(self, userargs, exec_dirs=[]):\n        \"\"\"Returns command to execute (with sudo -u if run_as != root).\"\"\"\n        to_exec = self.get_exec(exec_dirs=exec_dirs) or self.exec_path\n        if (self.run_as != 'root'):\n            # Used to run commands at lesser privileges\n            return ['sudo', '-u', self.run_as, to_exec] + userargs[1:]\n        return [to_exec] + userargs[1:]\n\n    def get_environment(self, userargs):\n        \"\"\"Returns specific environment to set, None if none\"\"\"\n        return None\n\n\nclass RegExpFilter(CommandFilter):\n    \"\"\"Command filter doing regexp matching for every argument\"\"\"\n\n    def match(self, userargs):\n        # Early skip if command or number of args don't match\n        if (len(self.args) != len(userargs)):\n            # DENY: argument numbers don't match\n            return False\n        # Compare each arg (anchoring pattern explicitly at end of string)\n        for (pattern, arg) in zip(self.args, userargs):\n            try:\n                if not re.match(pattern + '$', arg):\n                    break\n            except re.error:\n                # DENY: Badly-formed filter\n                return False\n        else:\n            # ALLOW: All arguments matched\n            return True\n\n        # DENY: Some arguments did not match\n        return False\n\n\nclass PathFilter(CommandFilter):\n    \"\"\"Command filter checking that path arguments are within given dirs\n\n        One can specify the following constraints for command arguments:\n            1) pass     - pass an argument as is to the resulting command\n            2) some_str - check if an argument is equal to the given string\n            3) abs path - check if a path argument is within the given base dir\n\n        A typical rootwrapper filter entry looks like this:\n            # cmdname: filter name, raw command, user, arg_i_constraint [, ...]\n            chown: PathFilter, /bin/chown, root, nova, /var/lib/images\n\n    \"\"\"\n\n    def match(self, userargs):\n        command, arguments = userargs[0], userargs[1:]\n\n        equal_args_num = len(self.args) == len(arguments)\n        exec_is_valid = super(PathFilter, self).match(userargs)\n        args_equal_or_pass = all(\n            arg == 'pass' or arg == value\n            for arg, value in zip(self.args, arguments)\n            if not os.path.isabs(arg)  # arguments not specifying abs paths\n        )\n        paths_are_within_base_dirs = all(\n            os.path.commonprefix([arg, os.path.realpath(value)]) == arg\n            for arg, value in zip(self.args, arguments)\n            if os.path.isabs(arg)  # arguments specifying abs paths\n        )\n\n        return (equal_args_num and\n                exec_is_valid and\n                args_equal_or_pass and\n                paths_are_within_base_dirs)\n\n    def get_command(self, userargs, exec_dirs=[]):\n        command, arguments = userargs[0], userargs[1:]\n\n        # convert path values to canonical ones; copy other args as is\n        args = [os.path.realpath(value) if os.path.isabs(arg) else value\n                for arg, value in zip(self.args, arguments)]\n\n        return super(PathFilter, self).get_command([command] + args,\n                                                   exec_dirs)\n\n\nclass DnsmasqFilter(CommandFilter):\n    \"\"\"Specific filter for the dnsmasq call (which includes env)\"\"\"\n\n    CONFIG_FILE_ARG = 'CONFIG_FILE'\n\n    def match(self, userargs):\n        if (userargs[0] == 'env' and\n                userargs[1].startswith(self.CONFIG_FILE_ARG) and\n                userargs[2].startswith('NETWORK_ID=') and\n                userargs[3] == 'dnsmasq'):\n            return True\n        return False\n\n    def get_command(self, userargs, exec_dirs=[]):\n        to_exec = self.get_exec(exec_dirs=exec_dirs) or self.exec_path\n        dnsmasq_pos = userargs.index('dnsmasq')\n        return [to_exec] + userargs[dnsmasq_pos + 1:]\n\n    def get_environment(self, userargs):\n        env = os.environ.copy()\n        env[self.CONFIG_FILE_ARG] = userargs[1].split('=')[-1]\n        env['NETWORK_ID'] = userargs[2].split('=')[-1]\n        return env\n\n\nclass DeprecatedDnsmasqFilter(DnsmasqFilter):\n    \"\"\"Variant of dnsmasq filter to support old-style FLAGFILE\"\"\"\n    CONFIG_FILE_ARG = 'FLAGFILE'\n\n\nclass KillFilter(CommandFilter):\n    \"\"\"Specific filter for the kill calls.\n       1st argument is the user to run /bin/kill under\n       2nd argument is the location of the affected executable\n       Subsequent arguments list the accepted signals (if any)\n\n       This filter relies on /proc to accurately determine affected\n       executable, so it will only work on procfs-capable systems (not OSX).\n    \"\"\"\n\n    def __init__(self, *args):\n        super(KillFilter, self).__init__(\"/bin/kill\", *args)\n\n    def match(self, userargs):\n        if userargs[0] != \"kill\":\n            return False\n        args = list(userargs)\n        if len(args) == 3:\n            # A specific signal is requested\n            signal = args.pop(1)\n            if signal not in self.args[1:]:\n                # Requested signal not in accepted list\n                return False\n        else:\n            if len(args) != 2:\n                # Incorrect number of arguments\n                return False\n            if len(self.args) > 1:\n                # No signal requested, but filter requires specific signal\n                return False\n        try:\n            command = os.readlink(\"/proc/%d/exe\" % int(args[1]))\n            # NOTE(dprince): /proc/PID/exe may have ' (deleted)' on\n            # the end if an executable is updated or deleted\n            if command.endswith(\" (deleted)\"):\n                command = command[:command.rindex(\" \")]\n            if command != self.args[0]:\n                # Affected executable does not match\n                return False\n        except (ValueError, OSError):\n            # Incorrect PID\n            return False\n        return True\n\n\nclass ReadFileFilter(CommandFilter):\n    \"\"\"Specific filter for the utils.read_file_as_root call\"\"\"\n\n    def __init__(self, file_path, *args):\n        self.file_path = file_path\n        super(ReadFileFilter, self).__init__(\"/bin/cat\", \"root\", *args)\n\n    def match(self, userargs):\n        if userargs[0] != 'cat':\n            return False\n        if userargs[1] != self.file_path:\n            return False\n        if len(userargs) != 2:\n            return False\n        return True\n" }
{ "repo_name": "rafalkowalski/open-event-orga-server", "ref": "refs/heads/development", "path": "migrations/versions/ed4b4ba3274e_.py", "content": "\"\"\"empty message\n\nRevision ID: ed4b4ba3274e\nRevises: 784a1fc57171\nCreate Date: 2016-06-16 06:08:49.516538\n\n\"\"\"\n\n# revision identifiers, used by Alembic.\nrevision = 'ed4b4ba3274e'\ndown_revision = '784a1fc57171'\n\nfrom alembic import op\nimport sqlalchemy as sa\nimport sqlalchemy_utils\n\n\ndef upgrade():\n    ### commands auto generated by Alembic - please adjust! ###\n    op.create_table('service',\n    sa.Column('id', sa.Integer(), nullable=False),\n    sa.Column('name', sa.String(), nullable=False),\n    sa.PrimaryKeyConstraint('id'),\n    sa.UniqueConstraint('name')\n    )\n    op.add_column(u'permissions', sa.Column('can_create', sa.Boolean(), nullable=False))\n    op.add_column(u'permissions', sa.Column('can_delete', sa.Boolean(), nullable=False))\n    op.add_column(u'permissions', sa.Column('can_read', sa.Boolean(), nullable=False))\n    op.add_column(u'permissions', sa.Column('can_update', sa.Boolean(), nullable=False))\n    op.add_column(u'permissions', sa.Column('role_id', sa.Integer(), nullable=True))\n    op.alter_column(u'permissions', 'service_id',\n               existing_type=sa.INTEGER(),\n               nullable=True)\n    op.create_unique_constraint('role_service_uc', 'permissions', ['role_id', 'service_id'])\n    op.drop_constraint(u'user_service_uc', 'permissions', type_='unique')\n    op.drop_constraint(u'permissions_user_id_fkey', 'permissions', type_='foreignkey')\n    op.create_foreign_key(None, 'permissions', 'role', ['role_id'], ['id'])\n    op.create_foreign_key(None, 'permissions', 'service', ['service_id'], ['id'])\n    op.drop_column(u'permissions', 'user_id')\n    op.drop_column(u'permissions', 'modes')\n    op.drop_column(u'permissions', 'service')\n    op.alter_column(u'role', 'name',\n               existing_type=sa.VARCHAR(length=128),\n               nullable=False)\n    op.create_unique_constraint(None, 'role', ['name'])\n    op.drop_column(u'user', 'role')\n    ### end Alembic commands ###\n\n\ndef downgrade():\n    ### commands auto generated by Alembic - please adjust! ###\n    op.add_column(u'user', sa.Column('role', sa.VARCHAR(), autoincrement=False, nullable=True))\n    op.drop_constraint(None, 'role', type_='unique')\n    op.alter_column(u'role', 'name',\n               existing_type=sa.VARCHAR(length=128),\n               nullable=True)\n    op.add_column(u'permissions', sa.Column('service', sa.VARCHAR(), autoincrement=False, nullable=False))\n    op.add_column(u'permissions', sa.Column('modes', sa.INTEGER(), autoincrement=False, nullable=False))\n    op.add_column(u'permissions', sa.Column('user_id', sa.INTEGER(), autoincrement=False, nullable=False))\n    op.drop_constraint(None, 'permissions', type_='foreignkey')\n    op.drop_constraint(None, 'permissions', type_='foreignkey')\n    op.create_foreign_key(u'permissions_user_id_fkey', 'permissions', 'user', ['user_id'], ['id'])\n    op.create_unique_constraint(u'user_service_uc', 'permissions', ['user_id', 'service', 'service_id'])\n    op.drop_constraint('role_service_uc', 'permissions', type_='unique')\n    op.alter_column(u'permissions', 'service_id',\n               existing_type=sa.INTEGER(),\n               nullable=False)\n    op.drop_column(u'permissions', 'role_id')\n    op.drop_column(u'permissions', 'can_update')\n    op.drop_column(u'permissions', 'can_read')\n    op.drop_column(u'permissions', 'can_delete')\n    op.drop_column(u'permissions', 'can_create')\n    op.drop_table('service')\n    ### end Alembic commands ###\n" }
{ "repo_name": "aviaryan/open-event-orga-server", "ref": "refs/heads/development", "path": "migrations/versions/ed4b4ba3274e_.py", "content": "\"\"\"empty message\n\nRevision ID: ed4b4ba3274e\nRevises: 784a1fc57171\nCreate Date: 2016-06-16 06:08:49.516538\n\n\"\"\"\n\n# revision identifiers, used by Alembic.\nrevision = 'ed4b4ba3274e'\ndown_revision = '784a1fc57171'\n\nfrom alembic import op\nimport sqlalchemy as sa\nimport sqlalchemy_utils\n\n\ndef upgrade():\n    ### commands auto generated by Alembic - please adjust! ###\n    op.create_table('service',\n    sa.Column('id', sa.Integer(), nullable=False),\n    sa.Column('name', sa.String(), nullable=False),\n    sa.PrimaryKeyConstraint('id'),\n    sa.UniqueConstraint('name')\n    )\n    op.add_column(u'permissions', sa.Column('can_create', sa.Boolean(), nullable=False))\n    op.add_column(u'permissions', sa.Column('can_delete', sa.Boolean(), nullable=False))\n    op.add_column(u'permissions', sa.Column('can_read', sa.Boolean(), nullable=False))\n    op.add_column(u'permissions', sa.Column('can_update', sa.Boolean(), nullable=False))\n    op.add_column(u'permissions', sa.Column('role_id', sa.Integer(), nullable=True))\n    op.alter_column(u'permissions', 'service_id',\n               existing_type=sa.INTEGER(),\n               nullable=True)\n    op.create_unique_constraint('role_service_uc', 'permissions', ['role_id', 'service_id'])\n    op.drop_constraint(u'user_service_uc', 'permissions', type_='unique')\n    op.drop_constraint(u'permissions_user_id_fkey', 'permissions', type_='foreignkey')\n    op.create_foreign_key(None, 'permissions', 'role', ['role_id'], ['id'])\n    op.create_foreign_key(None, 'permissions', 'service', ['service_id'], ['id'])\n    op.drop_column(u'permissions', 'user_id')\n    op.drop_column(u'permissions', 'modes')\n    op.drop_column(u'permissions', 'service')\n    op.alter_column(u'role', 'name',\n               existing_type=sa.VARCHAR(length=128),\n               nullable=False)\n    op.create_unique_constraint(None, 'role', ['name'])\n    op.drop_column(u'user', 'role')\n    ### end Alembic commands ###\n\n\ndef downgrade():\n    ### commands auto generated by Alembic - please adjust! ###\n    op.add_column(u'user', sa.Column('role', sa.VARCHAR(), autoincrement=False, nullable=True))\n    op.drop_constraint(None, 'role', type_='unique')\n    op.alter_column(u'role', 'name',\n               existing_type=sa.VARCHAR(length=128),\n               nullable=True)\n    op.add_column(u'permissions', sa.Column('service', sa.VARCHAR(), autoincrement=False, nullable=False))\n    op.add_column(u'permissions', sa.Column('modes', sa.INTEGER(), autoincrement=False, nullable=False))\n    op.add_column(u'permissions', sa.Column('user_id', sa.INTEGER(), autoincrement=False, nullable=False))\n    op.drop_constraint(None, 'permissions', type_='foreignkey')\n    op.drop_constraint(None, 'permissions', type_='foreignkey')\n    op.create_foreign_key(u'permissions_user_id_fkey', 'permissions', 'user', ['user_id'], ['id'])\n    op.create_unique_constraint(u'user_service_uc', 'permissions', ['user_id', 'service', 'service_id'])\n    op.drop_constraint('role_service_uc', 'permissions', type_='unique')\n    op.alter_column(u'permissions', 'service_id',\n               existing_type=sa.INTEGER(),\n               nullable=False)\n    op.drop_column(u'permissions', 'role_id')\n    op.drop_column(u'permissions', 'can_update')\n    op.drop_column(u'permissions', 'can_read')\n    op.drop_column(u'permissions', 'can_delete')\n    op.drop_column(u'permissions', 'can_create')\n    op.drop_table('service')\n    ### end Alembic commands ###\n" }
{ "repo_name": "DirectXMan12/nova-hacking", "ref": "refs/heads/feature_novnc_krb", "path": "nova/openstack/common/rootwrap/filters.py", "content": "# vim: tabstop=4 shiftwidth=4 softtabstop=4\n\n# Copyright (c) 2011 OpenStack Foundation.\n# All Rights Reserved.\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\nimport os\nimport re\n\n\nclass CommandFilter(object):\n    \"\"\"Command filter only checking that the 1st argument matches exec_path\"\"\"\n\n    def __init__(self, exec_path, run_as, *args):\n        self.name = ''\n        self.exec_path = exec_path\n        self.run_as = run_as\n        self.args = args\n        self.real_exec = None\n\n    def get_exec(self, exec_dirs=[]):\n        \"\"\"Returns existing executable, or empty string if none found\"\"\"\n        if self.real_exec is not None:\n            return self.real_exec\n        self.real_exec = \"\"\n        if self.exec_path.startswith('/'):\n            if os.access(self.exec_path, os.X_OK):\n                self.real_exec = self.exec_path\n        else:\n            for binary_path in exec_dirs:\n                expanded_path = os.path.join(binary_path, self.exec_path)\n                if os.access(expanded_path, os.X_OK):\n                    self.real_exec = expanded_path\n                    break\n        return self.real_exec\n\n    def match(self, userargs):\n        \"\"\"Only check that the first argument (command) matches exec_path\"\"\"\n        if (os.path.basename(self.exec_path) == userargs[0]):\n            return True\n        return False\n\n    def get_command(self, userargs, exec_dirs=[]):\n        \"\"\"Returns command to execute (with sudo -u if run_as != root).\"\"\"\n        to_exec = self.get_exec(exec_dirs=exec_dirs) or self.exec_path\n        if (self.run_as != 'root'):\n            # Used to run commands at lesser privileges\n            return ['sudo', '-u', self.run_as, to_exec] + userargs[1:]\n        return [to_exec] + userargs[1:]\n\n    def get_environment(self, userargs):\n        \"\"\"Returns specific environment to set, None if none\"\"\"\n        return None\n\n\nclass RegExpFilter(CommandFilter):\n    \"\"\"Command filter doing regexp matching for every argument\"\"\"\n\n    def match(self, userargs):\n        # Early skip if command or number of args don't match\n        if (len(self.args) != len(userargs)):\n            # DENY: argument numbers don't match\n            return False\n        # Compare each arg (anchoring pattern explicitly at end of string)\n        for (pattern, arg) in zip(self.args, userargs):\n            try:\n                if not re.match(pattern + '$', arg):\n                    break\n            except re.error:\n                # DENY: Badly-formed filter\n                return False\n        else:\n            # ALLOW: All arguments matched\n            return True\n\n        # DENY: Some arguments did not match\n        return False\n\n\nclass PathFilter(CommandFilter):\n    \"\"\"Command filter checking that path arguments are within given dirs\n\n        One can specify the following constraints for command arguments:\n            1) pass     - pass an argument as is to the resulting command\n            2) some_str - check if an argument is equal to the given string\n            3) abs path - check if a path argument is within the given base dir\n\n        A typical rootwrapper filter entry looks like this:\n            # cmdname: filter name, raw command, user, arg_i_constraint [, ...]\n            chown: PathFilter, /bin/chown, root, nova, /var/lib/images\n\n    \"\"\"\n\n    def match(self, userargs):\n        command, arguments = userargs[0], userargs[1:]\n\n        equal_args_num = len(self.args) == len(arguments)\n        exec_is_valid = super(PathFilter, self).match(userargs)\n        args_equal_or_pass = all(\n            arg == 'pass' or arg == value\n            for arg, value in zip(self.args, arguments)\n            if not os.path.isabs(arg)  # arguments not specifying abs paths\n        )\n        paths_are_within_base_dirs = all(\n            os.path.commonprefix([arg, os.path.realpath(value)]) == arg\n            for arg, value in zip(self.args, arguments)\n            if os.path.isabs(arg)  # arguments specifying abs paths\n        )\n\n        return (equal_args_num and\n                exec_is_valid and\n                args_equal_or_pass and\n                paths_are_within_base_dirs)\n\n    def get_command(self, userargs, exec_dirs=[]):\n        command, arguments = userargs[0], userargs[1:]\n\n        # convert path values to canonical ones; copy other args as is\n        args = [os.path.realpath(value) if os.path.isabs(arg) else value\n                for arg, value in zip(self.args, arguments)]\n\n        return super(PathFilter, self).get_command([command] + args,\n                                                   exec_dirs)\n\n\nclass DnsmasqFilter(CommandFilter):\n    \"\"\"Specific filter for the dnsmasq call (which includes env)\"\"\"\n\n    CONFIG_FILE_ARG = 'CONFIG_FILE'\n\n    def match(self, userargs):\n        if (userargs[0] == 'env' and\n                userargs[1].startswith(self.CONFIG_FILE_ARG) and\n                userargs[2].startswith('NETWORK_ID=') and\n                userargs[3] == 'dnsmasq'):\n            return True\n        return False\n\n    def get_command(self, userargs, exec_dirs=[]):\n        to_exec = self.get_exec(exec_dirs=exec_dirs) or self.exec_path\n        dnsmasq_pos = userargs.index('dnsmasq')\n        return [to_exec] + userargs[dnsmasq_pos + 1:]\n\n    def get_environment(self, userargs):\n        env = os.environ.copy()\n        env[self.CONFIG_FILE_ARG] = userargs[1].split('=')[-1]\n        env['NETWORK_ID'] = userargs[2].split('=')[-1]\n        return env\n\n\nclass DeprecatedDnsmasqFilter(DnsmasqFilter):\n    \"\"\"Variant of dnsmasq filter to support old-style FLAGFILE\"\"\"\n    CONFIG_FILE_ARG = 'FLAGFILE'\n\n\nclass KillFilter(CommandFilter):\n    \"\"\"Specific filter for the kill calls.\n       1st argument is the user to run /bin/kill under\n       2nd argument is the location of the affected executable\n       Subsequent arguments list the accepted signals (if any)\n\n       This filter relies on /proc to accurately determine affected\n       executable, so it will only work on procfs-capable systems (not OSX).\n    \"\"\"\n\n    def __init__(self, *args):\n        super(KillFilter, self).__init__(\"/bin/kill\", *args)\n\n    def match(self, userargs):\n        if userargs[0] != \"kill\":\n            return False\n        args = list(userargs)\n        if len(args) == 3:\n            # A specific signal is requested\n            signal = args.pop(1)\n            if signal not in self.args[1:]:\n                # Requested signal not in accepted list\n                return False\n        else:\n            if len(args) != 2:\n                # Incorrect number of arguments\n                return False\n            if len(self.args) > 1:\n                # No signal requested, but filter requires specific signal\n                return False\n        try:\n            command = os.readlink(\"/proc/%d/exe\" % int(args[1]))\n            # NOTE(dprince): /proc/PID/exe may have ' (deleted)' on\n            # the end if an executable is updated or deleted\n            if command.endswith(\" (deleted)\"):\n                command = command[:command.rindex(\" \")]\n            if command != self.args[0]:\n                # Affected executable does not match\n                return False\n        except (ValueError, OSError):\n            # Incorrect PID\n            return False\n        return True\n\n\nclass ReadFileFilter(CommandFilter):\n    \"\"\"Specific filter for the utils.read_file_as_root call\"\"\"\n\n    def __init__(self, file_path, *args):\n        self.file_path = file_path\n        super(ReadFileFilter, self).__init__(\"/bin/cat\", \"root\", *args)\n\n    def match(self, userargs):\n        if userargs[0] != 'cat':\n            return False\n        if userargs[1] != self.file_path:\n            return False\n        if len(userargs) != 2:\n            return False\n        return True\n" }
{ "repo_name": "stargaser/astropy", "ref": "refs/heads/placeholder", "path": "astropy/nddata/tests/test_compat.py", "content": "# Licensed under a 3-clause BSD style license - see LICENSE.rst\n# This module contains tests of a class equivalent to pre-1.0 NDData.\n\n\nimport pytest\nimport numpy as np\n\nfrom astropy.nddata.nddata import NDData\nfrom astropy.nddata.compat import NDDataArray\nfrom astropy.nddata.nduncertainty import StdDevUncertainty\nfrom astropy.wcs import WCS\nfrom astropy import units as u\n\n\nNDDATA_ATTRIBUTES = ['mask', 'flags', 'uncertainty', 'unit', 'shape', 'size',\n                     'dtype', 'ndim', 'wcs', 'convert_unit_to']\n\n\ndef test_nddataarray_has_attributes_of_old_nddata():\n    ndd = NDDataArray([1, 2, 3])\n    for attr in NDDATA_ATTRIBUTES:\n        assert hasattr(ndd, attr)\n\n\ndef test_nddata_simple():\n    nd = NDDataArray(np.zeros((10, 10)))\n    assert nd.shape == (10, 10)\n    assert nd.size == 100\n    assert nd.dtype == np.dtype(float)\n\n\ndef test_nddata_parameters():\n    # Test for issue 4620\n    nd = NDDataArray(data=np.zeros((10, 10)))\n    assert nd.shape == (10, 10)\n    assert nd.size == 100\n    assert nd.dtype == np.dtype(float)\n    # Change order; `data` has to be given explicitly here\n    nd = NDDataArray(meta={} data=np.zeros((10, 10)))\n    assert nd.shape == (10, 10)\n    assert nd.size == 100\n    assert nd.dtype == np.dtype(float)\n    # Pass uncertainty as second implicit argument\n    data = np.zeros((10, 10))\n    uncertainty = StdDevUncertainty(0.1 + np.zeros_like(data))\n    nd = NDDataArray(data, uncertainty)\n    assert nd.shape == (10, 10)\n    assert nd.size == 100\n    assert nd.dtype == np.dtype(float)\n    assert nd.uncertainty == uncertainty\n\n\ndef test_nddata_conversion():\n    nd = NDDataArray(np.array([[1, 2, 3], [4, 5, 6]]))\n    assert nd.size == 6\n    assert nd.dtype == np.dtype(int)\n\n\n@pytest.mark.parametrize('flags_in', [\n                         np.array([True, False]),\n                         np.array([1, 0]),\n                         [True, False],\n                         [1, 0],\n                         np.array(['a', 'b']),\n                         ['a', 'b']])\ndef test_nddata_flags_init_without_np_array(flags_in):\n    ndd = NDDataArray([1, 1], flags=flags_in)\n    assert (ndd.flags == flags_in).all()\n\n\n@pytest.mark.parametrize(('shape'), [(10,), (5, 5), (3, 10, 10)])\ndef test_nddata_flags_invalid_shape(shape):\n    with pytest.raises(ValueError) as exc:\n        NDDataArray(np.zeros((10, 10)), flags=np.ones(shape))\n    assert exc.value.args[0] == 'dimensions of flags do not match data'\n\n\ndef test_convert_unit_to():\n    # convert_unit_to should return a copy of its input\n    d = NDDataArray(np.ones((5, 5)))\n    d.unit = 'km'\n    d.uncertainty = StdDevUncertainty(0.1 + np.zeros_like(d))\n    # workaround because zeros_like does not support dtype arg until v1.6\n    # and NDData accepts only bool ndarray as mask\n    tmp = np.zeros_like(d.data)\n    d.mask = np.array(tmp, dtype=bool)\n    d1 = d.convert_unit_to('m')\n    assert np.all(d1.data == np.array(1000.0))\n    assert np.all(d1.uncertainty.array == 1000.0 * d.uncertainty.array)\n    assert d1.unit == u.m\n    # changing the output mask should not change the original\n    d1.mask[0, 0] = True\n    assert d.mask[0, 0] != d1.mask[0, 0]\n    d.flags = np.zeros_like(d.data)\n    d1 = d.convert_unit_to('m')\n\n\n# check that subclasses can require wcs and/or unit to be present and use\n# _arithmetic and convert_unit_to\nclass SubNDData(NDDataArray):\n    \"\"\"\n    Subclass for test initialization of subclasses in NDData._arithmetic and\n    NDData.convert_unit_to\n    \"\"\"\n    def __init__(self, *arg, **kwd):\n        super().__init__(*arg, **kwd)\n        if self.unit is None:\n            raise ValueError(\"Unit for subclass must be specified\")\n        if self.wcs is None:\n            raise ValueError(\"WCS for subclass must be specified\")\n\n\ndef test_init_of_subclass_in_convert_unit_to():\n    data = np.ones([10, 10])\n    arr1 = SubNDData(data, unit='m', wcs=WCS(naxis=2))\n    result = arr1.convert_unit_to('km')\n    np.testing.assert_array_equal(arr1.data, 1000 * result.data)\n\n\n# Test for issue #4129:\ndef test_nddataarray_from_nddataarray():\n    ndd1 = NDDataArray([1., 4., 9.],\n                       uncertainty=StdDevUncertainty([1., 2., 3.]),\n                       flags=[0, 1, 0])\n    ndd2 = NDDataArray(ndd1)\n    # Test that the 2 instances point to the same objects and aren't just\n    # equal; this is explicitly documented for the main data array and we\n    # probably want to catch any future change in behavior for the other\n    # attributes too and ensure they are intentional.\n    assert ndd2.data is ndd1.data\n    assert ndd2.uncertainty is ndd1.uncertainty\n    assert ndd2.flags is ndd1.flags\n    assert ndd2.meta == ndd1.meta\n\n\n# Test for issue #4137:\ndef test_nddataarray_from_nddata():\n    ndd1 = NDData([1., 4., 9.],\n                  uncertainty=StdDevUncertainty([1., 2., 3.]))\n    ndd2 = NDDataArray(ndd1)\n\n    assert ndd2.data is ndd1.data\n    assert ndd2.uncertainty is ndd1.uncertainty\n    assert ndd2.meta == ndd1.meta\n" }
{ "repo_name": "tangfeixiong/nova", "ref": "refs/heads/stable/juno", "path": "nova/scheduler/__init__.py", "content": "# Copyright (c) 2010 OpenStack Foundation\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\n\"\"\"\n:mod:`nova.scheduler` -- Scheduler Nodes\n=====================================================\n\n.. automodule:: nova.scheduler\n   :platform: Unix\n   :synopsis: Module that picks a compute node to run a VM instance.\n\"\"\"\n" }
{ "repo_name": "BeyondTheClouds/nova", "ref": "refs/heads/disco/mitaka", "path": "nova/scheduler/__init__.py", "content": "# Copyright (c) 2010 OpenStack Foundation\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\n\"\"\"\n:mod:`nova.scheduler` -- Scheduler Nodes\n=====================================================\n\n.. automodule:: nova.scheduler\n   :platform: Unix\n   :synopsis: Module that picks a compute node to run a VM instance.\n\"\"\"\n" }
{ "repo_name": "cyx1231st/nova", "ref": "refs/heads/eventually-consistent-host-state-mitaka", "path": "nova/scheduler/__init__.py", "content": "# Copyright (c) 2010 OpenStack Foundation\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\n\"\"\"\n:mod:`nova.scheduler` -- Scheduler Nodes\n=====================================================\n\n.. automodule:: nova.scheduler\n   :platform: Unix\n   :synopsis: Module that picks a compute node to run a VM instance.\n\"\"\"\n" }
{ "repo_name": "projectcalico/calico-nova", "ref": "refs/heads/calico-readme", "path": "nova/scheduler/__init__.py", "content": "# Copyright (c) 2010 OpenStack Foundation\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\n\"\"\"\n:mod:`nova.scheduler` -- Scheduler Nodes\n=====================================================\n\n.. automodule:: nova.scheduler\n   :platform: Unix\n   :synopsis: Module that picks a compute node to run a VM instance.\n\"\"\"\n" }
{ "repo_name": "changsimon/trove", "ref": "refs/heads/bug/1347114-dev", "path": "trove/openstack/common/notifier/rabbit_notifier.py", "content": "# Copyright 2012 Red Hat, Inc.\n# All Rights Reserved.\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\n\nfrom trove.openstack.common.gettextutils import _\nfrom trove.openstack.common import log as logging\nfrom trove.openstack.common.notifier import rpc_notifier\n\nLOG = logging.getLogger(__name__)\n\n\ndef notify(context, message):\n    \"\"\"Deprecated in Grizzly. Please use rpc_notifier instead.\"\"\"\n\n    LOG.deprecated(_(\"The rabbit_notifier is now deprecated.\"\n                     \" Please use rpc_notifier instead.\"))\n    rpc_notifier.notify(context, message)\n" }
{ "repo_name": "erdincay/pyload", "ref": "refs/heads/stable", "path": "module/plugins/internal/Container.py", "content": "# -*- coding: utf-8 -*-\n\nfrom __future__ import with_statement\n\nimport os\nimport re\nimport traceback\n\nfrom module.plugins.internal.Crypter import Crypter\nfrom module.plugins.internal.Plugin import exists\nfrom module.utils import save_join as fs_join\n\n\nclass Container(Crypter):\n    __name__    = \"Container\"\n    __type__    = \"container\"\n    __version__ = \"0.06\"\n    __status__  = \"testing\"\n\n    __pattern__ = r'^unmatchable$'\n    __config__  = []  #: [(\"name\", \"type\", \"desc\", \"default\")]\n\n    __description__ = \"\"\"Base container decrypter plugin\"\"\"\n    __license__     = \"GPLv3\"\n    __authors__     = [(\"mkaay\", \"mkaay@mkaay.de\")]\n\n\n    def process(self, pyfile):\n        \"\"\"\n        Main method\n        \"\"\"\n        self._load2disk()\n\n        self.decrypt(pyfile)\n\n        self.delete_tmp()\n\n        if self.urls:\n            self._generate_packages()\n\n        elif not self.packages:\n            self.error(_(\"No link grabbed\"), \"decrypt\")\n\n        self._create_packages()\n\n\n    #: Deprecated method, use `_load2disk` instead (Remove in 0.4.10)\n    def loadToDisk(self, *args, **kwargs):\n        return self._load2disk(*args, **kwargs)\n\n\n    def _load2disk(self):\n        \"\"\"\n        Loads container to disk if its stored remotely and overwrite url,\n        or check existent on several places at disk\n        \"\"\"\n        if self.pyfile.url.startswith(\"http\"):\n            self.pyfile.name = re.findall(\"([^\\/=]+)\", self.pyfile.url)[-1]\n            content = self.load(self.pyfile.url)\n            self.pyfile.url = fs_join(self.pyload.config.get(\"general\", \"download_folder\"), self.pyfile.name)\n            try:\n                with open(self.pyfile.url, \"wb\") as f:\n                    f.write(content)\n\n            except IOError, e:\n                self.fail(e)\n\n        else:\n            self.pyfile.name = os.path.basename(self.pyfile.url)\n            if not exists(self.pyfile.url):\n                if exists(fs_join(pypath, self.pyfile.url)):\n                    self.pyfile.url = fs_join(pypath, self.pyfile.url)\n                else:\n                    self.fail(_(\"File not exists\"))\n\n\n    #: Deprecated method, use `delete_tmp` instead (Remove in 0.4.10)\n    def deleteTmp(self, *args, **kwargs):\n        return self.delete_tmp(*args, **kwargs)\n\n\n    def delete_tmp(self):\n        if not self.pyfile.name.startswith(\"tmp_\"):\n            return\n\n        try:\n            os.remove(self.pyfile.url)\n        except OSError, e:\n            self.log_warning(_(\"Error removing: %s\") % self.pyfile.url, e)\n            if self.pyload.debug:\n                traceback.print_exc()\n" }
{ "repo_name": "pwong-mapr/private-hue", "ref": "refs/heads/HUE-1096-abe", "path": "desktop/core/ext-py/pysqlite/doc/includes/sqlite3/connect_db_1.py", "content": "from pysqlite2 import dbapi2 as sqlite3\n\ncon = sqlite3.connect(\"mydb\")\n" }
{ "repo_name": "NeCTAR-RC/nova", "ref": "refs/heads/nectar/mitaka", "path": "nova/scheduler/__init__.py", "content": "# Copyright (c) 2010 OpenStack Foundation\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\n\"\"\"\n:mod:`nova.scheduler` -- Scheduler Nodes\n=====================================================\n\n.. automodule:: nova.scheduler\n   :platform: Unix\n   :synopsis: Module that picks a compute node to run a VM instance.\n\"\"\"\n" }
{ "repo_name": "CCI-MOC/nova", "ref": "refs/heads/k2k-liberty", "path": "nova/scheduler/__init__.py", "content": "# Copyright (c) 2010 OpenStack Foundation\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\n\"\"\"\n:mod:`nova.scheduler` -- Scheduler Nodes\n=====================================================\n\n.. automodule:: nova.scheduler\n   :platform: Unix\n   :synopsis: Module that picks a compute node to run a VM instance.\n\"\"\"\n" }
{ "repo_name": "redhat-openstack/nova", "ref": "refs/heads/f22-patches", "path": "nova/scheduler/__init__.py", "content": "# Copyright (c) 2010 OpenStack Foundation\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\n\"\"\"\n:mod:`nova.scheduler` -- Scheduler Nodes\n=====================================================\n\n.. automodule:: nova.scheduler\n   :platform: Unix\n   :synopsis: Module that picks a compute node to run a VM instance.\n\"\"\"\n" }
{ "repo_name": "citrix-openstack/build-trove", "ref": "refs/heads/ctx-nova-network-smoke-latest", "path": "trove/openstack/common/notifier/rabbit_notifier.py", "content": "# Copyright 2012 Red Hat, Inc.\n# All Rights Reserved.\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\n\nfrom trove.openstack.common.gettextutils import _\nfrom trove.openstack.common import log as logging\nfrom trove.openstack.common.notifier import rpc_notifier\n\nLOG = logging.getLogger(__name__)\n\n\ndef notify(context, message):\n    \"\"\"Deprecated in Grizzly. Please use rpc_notifier instead.\"\"\"\n\n    LOG.deprecated(_(\"The rabbit_notifier is now deprecated.\"\n                     \" Please use rpc_notifier instead.\"))\n    rpc_notifier.notify(context, message)\n" }
{ "repo_name": "Metaswitch/calico-nova", "ref": "refs/heads/calico-readme", "path": "nova/scheduler/__init__.py", "content": "# Copyright (c) 2010 OpenStack Foundation\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\n\"\"\"\n:mod:`nova.scheduler` -- Scheduler Nodes\n=====================================================\n\n.. automodule:: nova.scheduler\n   :platform: Unix\n   :synopsis: Module that picks a compute node to run a VM instance.\n\"\"\"\n" }
{ "repo_name": "OCA/sale-reporting", "ref": "refs/heads/12.0", "path": "sale_comment_template/tests/test_sale_order_report.py", "content": "# Copyright 2017 Simone Rubino - Agile Business Group\n# Copyright 2018 Tecnativa - Pedro M. Baeza\n# License AGPL-3.0 or later (https://www.gnu.org/licenses/agpl).\n\nimport odoo.tests\nfrom odoo.tests.common import TransactionCase\n\n\n@odoo.tests.common.at_install(False)\n@odoo.tests.common.post_install(True)\nclass TestAccountInvoiceReport(TransactionCase):\n    def setUp(self, *args, **kwargs):\n        super(TestAccountInvoiceReport, self).setUp()\n        self.base_comment_model = self.env['base.comment.template']\n        self.before_comment = self._create_comment('before_lines')\n        self.after_comment = self._create_comment('after_lines')\n        self.partner_id = self.env['res.partner'].create({\n            'name': 'Partner Test'\n      })\n        self.sale_order = self.env.ref('sale.sale_order_7')\n        # Trigger qty_to_invoice again\n        for order_line in self.sale_order.order_line:\n            order_line.product_id.invoice_policy = 'order'\n        self.sale_order.action_confirm()\n\n        self.sale_order.update({\n            'comment_template1_id': self.before_comment.id,\n            'comment_template2_id': self.after_comment.id\n      })\n        self.sale_order._set_note1()\n        self.sale_order._set_note2()\n\n    def _create_comment(self, position):\n        return self.base_comment_model.create({\n            'name': 'Comment ' + position,\n            'position': position,\n            'text': 'Text ' + position\n      })\n\n    def test_comments_in_sale_order(self):\n        res = self.env['ir.actions.report']._get_report_from_name(\n            'sale.report_saleorder'\n        ).render_qweb_html(self.sale_order.ids)\n        self.assertRegexpMatches(str(res[0]), self.before_comment.text)\n        self.assertRegexpMatches(str(res[0]), self.after_comment.text)\n\n    def test_comments_in_generated_invoice(self):\n        invoice_ids = self.sale_order.action_invoice_create()\n        invoice = self.env['account.invoice'].browse(invoice_ids)\n        self.assertEqual(\n            invoice.comment_template1_id,\n            self.sale_order.comment_template1_id,\n        )\n        self.assertEqual(\n            invoice.comment_template2_id,\n            self.sale_order.comment_template2_id,\n        )\n\n    def test_onchange_partner_id(self):\n        self.partner_id.property_comment_template_id = self.after_comment.id\n        vals = {\n            'partner_id': self.partner_id.id,\n      }\n        new_sale = self.env['sale.order'].new(vals)\n        new_sale.onchange_partner_id_sale_comment()\n        sale_dict = new_sale._convert_to_write(new_sale._cache)\n        new_sale = self.env['sale.order'].create(sale_dict)\n        self.assertEqual(new_sale.comment_template2_id, self.after_comment)\n        self.partner_id.property_comment_template_id = self.before_comment.id\n        new_sale = self.env['sale.order'].new(vals)\n        new_sale.onchange_partner_id_sale_comment()\n        sale_dict = new_sale._convert_to_write(new_sale._cache)\n        new_sale = self.env['sale.order'].create(sale_dict)\n        self.assertEqual(new_sale.comment_template1_id, self.before_comment)\n" }
{ "repo_name": "alexryndin/ambari", "ref": "refs/heads/branch-adh-1.5", "path": "ambari-server/src/main/resources/stacks/ADH/1.4/services/KNOX/package/scripts/knox.py", "content": "\"\"\"\nLicensed to the Apache Software Foundation (ASF) under one\nor more contributor license agreements.  See the NOTICE file\ndistributed with this work for additional information\nregarding copyright ownership.  The ASF licenses this file\nto you under the Apache License, Version 2.0 (the\n\"License\"); you may not use this file except in compliance\nwith the License.  You may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n\"\"\"\n\nimport os\nfrom resource_management.libraries.script.script import Script\nfrom resource_management.libraries.resources.xml_config import XmlConfig\nfrom resource_management.core.resources.service import ServiceConfig\nfrom resource_management.libraries.functions.format import format\nfrom resource_management.libraries.resources.template_config import TemplateConfig\nfrom resource_management.core.resources.system import File, Execute, Directory\nfrom resource_management.core.shell import as_user\nfrom resource_management.core.source import InlineTemplate\n\nfrom ambari_commons import OSConst\nfrom ambari_commons.os_family_impl import OsFamilyFuncImpl, OsFamilyImpl\n\nfrom resource_management.core.logger import Logger\n\n@OsFamilyFuncImpl(os_family=OSConst.WINSRV_FAMILY)\ndef knox():\n  import params\n\n  XmlConfig(\"gateway-site.xml\",\n            conf_dir=params.knox_conf_dir,\n            configurations=params.config['configurations']['gateway-site'],\n            configuration_attributes=params.config['configuration_attributes']['gateway-site'],\n            owner=params.knox_user\n  )\n\n  # Manually overriding service logon user & password set by the installation package\n  ServiceConfig(params.knox_gateway_win_service_name,\n                action=\"change_user\",\n                username = params.knox_user,\n                password = Script.get_password(params.knox_user))\n\n  File(os.path.join(params.knox_conf_dir, \"gateway-log4j.properties\"),\n       owner=params.knox_user,\n       content=params.gateway_log4j\n  )\n\n  File(os.path.join(params.knox_conf_dir, \"topologies\", \"default.xml\"),\n       group=params.knox_group,\n       owner=params.knox_user,\n       content=InlineTemplate(params.topology_template)\n  )\n\n  if params.security_enabled:\n    TemplateConfig( os.path.join(params.knox_conf_dir, \"krb5JAASLogin.conf\"),\n        owner = params.knox_user,\n        template_tag = None\n    )\n\n  if not os.path.isfile(params.knox_master_secret_path):\n    cmd = format('cmd /C {knox_client_bin} create-master --master {knox_master_secret!p}')\n    Execute(cmd)\n    cmd = format('cmd /C {knox_client_bin} create-cert --hostname {knox_host_name_in_cluster}')\n    Execute(cmd)\n\n@OsFamilyFuncImpl(os_family=OsFamilyImpl.DEFAULT)\ndef knox():\n    import params\n\n    directories = [params.knox_data_dir, params.knox_logs_dir, params.knox_pid_dir, params.knox_conf_dir, os.path.join(params.knox_conf_dir, \"topologies\")]\n    for directory in directories:\n      Directory(directory,\n                owner = params.knox_user,\n                group = params.knox_group,\n                create_parents = True,\n                cd_access = \"a\",\n                mode = 0755,\n      )\n\n    XmlConfig(\"gateway-site.xml\",\n              conf_dir=params.knox_conf_dir,\n              configurations=params.config['configurations']['gateway-site'],\n              configuration_attributes=params.config['configuration_attributes']['gateway-site'],\n              owner=params.knox_user,\n              group=params.knox_group,\n    )\n\n    File(format(\"{params.knox_conf_dir}/gateway-log4j.properties\"),\n         mode=0644,\n         group=params.knox_group,\n         owner=params.knox_user,\n         content=params.gateway_log4j\n    )\n\n    File(format(\"{params.knox_conf_dir}/topologies/default.xml\"),\n         group=params.knox_group,\n         owner=params.knox_user,\n         content=InlineTemplate(params.topology_template)\n    )\n    if params.security_enabled:\n      TemplateConfig( format(\"{knox_conf_dir}/krb5JAASLogin.conf\"),\n                      owner = params.knox_user,\n                      template_tag = None\n      )\n\n    dirs_to_chown = tuple(directories)\n    cmd = ('chown','-R',format('{knox_user}:{knox_group}')) + dirs_to_chown\n    Execute(cmd,\n            sudo = True,\n    )\n\n    cmd = format('{knox_client_bin} create-master --master {knox_master_secret!p}')\n    master_secret_exist = as_user(format('test -f {knox_master_secret_path}'), params.knox_user)\n\n    Execute(cmd,\n            user=params.knox_user,\n            environment={'JAVA_HOME': params.java_home}\n            not_if=master_secret_exist,\n    )\n\n    cmd = format('{knox_client_bin} create-cert --hostname {knox_host_name_in_cluster}')\n    cert_store_exist = as_user(format('test -f {knox_cert_store_path}'), params.knox_user)\n\n    Execute(cmd,\n            user=params.knox_user,\n            environment={'JAVA_HOME': params.java_home}\n            not_if=cert_store_exist,\n    )\n\n\n@OsFamilyFuncImpl(os_family=OSConst.WINSRV_FAMILY)\ndef update_knox_folder_permissions():\n  import params\n  Directory(params.knox_logs_dir,\n            owner = params.knox_user,\n            group = params.knox_group\n            )\n\n\n@OsFamilyFuncImpl(os_family=OsFamilyImpl.DEFAULT)\ndef update_knox_logfolder_permissions():\n  \"\"\"\n   Fix for the bug with rpm/deb packages. During installation of the package, they re-apply permissions to the\n   folders below; such behaviour will affect installations with non-standard user name/group and will put\n   cluster in non-working state\n  \"\"\"\n  import params\n  knox_dirs = [params.knox_logs_dir]\n\n  Directory(params.knox_logs_dir,\n            owner = params.knox_user,\n            group = params.knox_group,\n            create_parents = True,\n            cd_access = \"a\",\n            mode = 0755,\n            )\n\n  for d in knox_dirs:\n    if len(d) > 1:  # If path is empty or a single slash, may corrupt filesystem permissions\n      Execute(('chown', '-R', format(\"{knox_user}:{knox_group}\"), d),\n              sudo=True\n              )\n    else:\n      Logger.warning(\"Permissions for the Knox folder \\\"%s\\\" was not updated due to empty path passed\" % d)\n" }
{ "repo_name": "waqasbhatti/astroph-coffee", "ref": "refs/heads/github", "path": "pysqlite/doc/includes/sqlite3/connect_db_1.py", "content": "from pysqlite2 import dbapi2 as sqlite3\n\ncon = sqlite3.connect(\"mydb\")\n" }
{ "repo_name": "Mausy5043/upsdiagd", "ref": "refs/heads/v2", "path": "daemons/ups32d.py", "content": "#!/usr/bin/env python3\n\n# Communicates with the UPS.\n\nimport configparser\nimport os\nimport sys\nimport syslog\nimport subprocess\nimport time\nimport traceback\n\nfrom mausy5043libs.libdaemon3 import Daemon\nimport mausy5043funcs.fileops3 as mf\n\n# constants\nDEBUG       = False\nIS_JOURNALD = os.path.isfile('/bin/journalctl')\nMYID        = \"\".join(list(filter(str.isdigit, os.path.realpath(__file__).split('/')[-1])))\nMYAPP       = os.path.realpath(__file__).split('/')[-3]\nMYAPPDIR    = \"/\".join(list(filter(str, os.path.realpath(__file__).split('/')[:-2])))\nNODE        = os.uname()[1]\n\n# initialise logging\nsyslog.openlog(ident=MYAPP, facility=syslog.LOG_LOCAL0)\n\nclass MyDaemon(Daemon):\n  \"\"\"Definition of daemon.\"\"\"\n  @staticmethod\n  def run():\n    iniconf         = configparser.ConfigParser()\n    inisection      = MYID\n    s               = iniconf.read('/' + MYAPPDIR + '/config.ini')\n    mf.syslog_trace(\"Config file   : {0}\".format(s), False, DEBUG)\n    mf.syslog_trace(\"Options       : {0}\".format(iniconf.items(inisection)), False, DEBUG)\n    reporttime      = iniconf.getint(inisection, \"reporttime\")\n    cycles          = iniconf.getint(inisection, \"cycles\")\n    samplespercycle = iniconf.getint(inisection, \"samplespercycle\")\n    flock           = iniconf.get(inisection, \"lockfile\")\n    fdata           = iniconf.get(inisection, \"resultfile\")\n\n    samples         = samplespercycle * cycles           # total number of samples averaged\n    sampletime      = reporttime/samplespercycle         # time [s] between samples\n\n    data            = []                                 # array for holding sampledata\n    # raw             = [0] * 8                            # array for holding previous\n\n    while True:\n      try:\n        starttime     = time.time()\n\n        result        = do_work()\n        result        = result.split(',')\n        mf.syslog_trace(\"Result   : {0}\".format(result), False, DEBUG)\n        # data.append(list(map(int, result)))\n        data.append([float(d) for d in result])\n        if (len(data) > samples):\n          data.pop(0)\n        mf.syslog_trace(\"Data     : {0}\".format(data),   False, DEBUG)\n\n        # report sample average\n        if (starttime % reporttime < sampletime):\n          # somma       = list(map(sum, zip(*data)))\n          somma = [sum(d) for d in zip(*data)]\n          # not all entries should be float\n          # ['234.000', '13.700', '100.000', '20.000', '1447.000']\n          averages = [float(format(d / len(data), '.3f')) for d in somma]\n          mf.syslog_trace(\"Averages : {0}\".format(averages),  False, DEBUG)\n          do_report(averages, flock, fdata)\n\n        waittime    = sampletime - (time.time() - starttime) - (starttime % sampletime)\n        if (waittime > 0):\n          mf.syslog_trace(\"Waiting  : {0}s\".format(waittime), False, DEBUG)\n          mf.syslog_trace(\"................................\", False, DEBUG)\n          time.sleep(waittime)\n        else:\n          mf.syslog_trace(\"Behind   : {0}s\".format(waittime), False, DEBUG)\n          mf.syslog_trace(\"................................\", False, DEBUG)\n      except Exception:\n        mf.syslog_trace(\"Unexpected error in run()\", syslog.LOG_CRIT, DEBUG)\n        mf.syslog_trace(traceback.format_exc(), syslog.LOG_CRIT, DEBUG)\n        raise\n\ndef do_work():\n  # 5 datapoints gathered here\n  try:\n    upsc = str(subprocess.check_output(['upsc', 'ups@localhost']), 'utf-8').splitlines()\n  except subprocess.CalledProcessError:\n    # mf.syslog_trace(\"Unexpected error in do_work()\", syslog.LOG_CRIT, DEBUG)\n    # mf.syslog_trace(traceback.format_exc(), syslog.LOG_CRIT, DEBUG)\n    syslog.syslog(syslog.LOG_ALERT, \"Waiting 10s ...\")\n\n    time.sleep(10)    # wait to let the driver crash properly\n    # mf.syslog_trace(\"*** RESTARTING nut-driver.service ***\", syslog.LOG_ALERT, DEBUG)\n    # r = str(subprocess.check_output(['sudo', 'systemctl', 'restart',  'nut-driver.service']), 'utf-8').splitlines()\n    mf.syslog_trace(\"*** RESTARTING nut-server.service ***\", syslog.LOG_ALERT, DEBUG)\n    r = str(subprocess.check_output(['sudo', 'systemctl', 'restart',  'nut-server.service']), 'utf-8').splitlines()\n    mf.syslog_trace(\"Returned : {0}\".format(r), False, DEBUG)\n\n    time.sleep(15)\n    mf.syslog_trace(\"!!! Retrying communication with UPS !!!\", syslog.LOG_ALERT, DEBUG)\n    upsc = str(subprocess.check_output(['upsc', 'ups@localhost']), 'utf-8').splitlines()\n    pass\n\n  # ups0 and ups1 are disabled, because the current UPS (EATON) does not supply\n  # usable data for these graphs\n  ups0 = -1.0\n  ups1 = -1.0\n  for element in range(0, len(upsc) - 1):\n    var = upsc[element].split(': ')\n    # if (var[0] == 'input.voltage'):\n    if (var[0] == 'output.voltage'):\n      ups0 = float(var[1])\n    if (var[0] == 'battery.voltage'):\n      ups1 = float(var[1])\n    if (var[0] == 'battery.charge'):\n      ups2 = float(var[1])\n    if (var[0] == 'ups.load'):\n      ups3 = float(var[1])*10\n    if (var[0] == 'battery.runtime'):\n      ups4 = float(var[1])\n\n  return '{0} {1} {2} {3} ,{4}'.format(ups0, ups1, ups2, ups3, ups4)\n\ndef do_report(result, flock, fdata):\n  # Get the time and date in human-readable form and UN*X-epoch...\n  outdate  = time.strftime('%Y-%m-%dT%H:%M:%S')\n  outepoch = int(time.strftime('%s'))\n  # round to current minute to ease database JOINs\n  # outEpoch = outEpoch - (outEpoch % 60)\n  result   = ', '.join(map(str, result))\n  mf.lock(flock)\n  with open(fdata, 'a') as f:\n    f.write('{0} {1} {2}\\n'.format(outdate, outepoch, result))\n  mf.unlock(flock)\n\n\nif __name__ == \"__main__\":\n  daemon = MyDaemon('/tmp/' + MYAPP + '/' + MYID + '.pid')\n  if len(sys.argv) == 2:\n    if 'start' == sys.argv[1]:\n      daemon.start()\n    elif 'stop' == sys.argv[1]:\n      daemon.stop()\n    elif 'restart' == sys.argv[1]:\n      daemon.restart()\n    elif 'foreground' == sys.argv[1]:\n      # assist with debugging.\n      print(\"Debug-mode started. Use <Ctrl>+C to stop.\")\n      DEBUG = True\n      mf.syslog_trace(\"Daemon logging is ON\", syslog.LOG_DEBUG, DEBUG)\n      daemon.run()\n    else:\n      print(\"Unknown command\")\n      sys.exit(2)\n    sys.exit(0)\n  else:\n    print(\"usage: {0!s} start|stop|restart|foreground\".format(sys.argv[0]))\n    sys.exit(2)\n" }
{ "repo_name": "cloudbase/nova-virtualbox", "ref": "refs/heads/virtualbox_driver", "path": "nova/scheduler/__init__.py", "content": "# Copyright (c) 2010 OpenStack Foundation\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\n\"\"\"\n:mod:`nova.scheduler` -- Scheduler Nodes\n=====================================================\n\n.. automodule:: nova.scheduler\n   :platform: Unix\n   :synopsis: Module that picks a compute node to run a VM instance.\n\"\"\"\n" }
{ "repo_name": "lumig242/Hue-Integration-with-CDAP", "ref": "refs/heads/pull3", "path": "desktop/core/ext-py/pysqlite/doc/includes/sqlite3/connect_db_1.py", "content": "from pysqlite2 import dbapi2 as sqlite3\n\ncon = sqlite3.connect(\"mydb\")\n" }
{ "repo_name": "mapr/hue", "ref": "refs/heads/hue-3.9.0-mapr", "path": "desktop/core/ext-py/pysqlite/doc/includes/sqlite3/connect_db_1.py", "content": "from pysqlite2 import dbapi2 as sqlite3\n\ncon = sqlite3.connect(\"mydb\")\n" }
{ "repo_name": "virtualopensystems/nova", "ref": "refs/heads/bp/vif-vhostuser", "path": "nova/scheduler/__init__.py", "content": "# Copyright (c) 2010 OpenStack Foundation\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\n\"\"\"\n:mod:`nova.scheduler` -- Scheduler Nodes\n=====================================================\n\n.. automodule:: nova.scheduler\n   :platform: Unix\n   :synopsis: Module that picks a compute node to run a VM instance.\n\"\"\"\n" }
{ "repo_name": "tianweizhang/nova", "ref": "refs/heads/v0", "path": "nova/scheduler/__init__.py", "content": "# Copyright (c) 2010 OpenStack Foundation\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\n\"\"\"\n:mod:`nova.scheduler` -- Scheduler Nodes\n=====================================================\n\n.. automodule:: nova.scheduler\n   :platform: Unix\n   :synopsis: Module that picks a compute node to run a VM instance.\n\"\"\"\n" }
{ "repo_name": "apple/llvm-project", "ref": "refs/heads/llvm.org/main", "path": "lldb/test/API/functionalities/thread/concurrent_events/TestConcurrentWatchpointWithDelayWatchpointThreads.py", "content": "\nimport unittest2\n\nfrom lldbsuite.test.decorators import *\nfrom lldbsuite.test.concurrent_base import ConcurrentEventsBase\nfrom lldbsuite.test.lldbtest import TestBase\n\n\n@skipIfWindows\nclass ConcurrentWatchpointWithDelayWatchpointThreads(ConcurrentEventsBase):\n\n    mydir = ConcurrentEventsBase.compute_mydir(__file__)\n\n    # Atomic sequences are not supported yet for MIPS in LLDB.\n    @skipIf(triple='^mips')\n    @add_test_categories([\"watchpoint\"])\n    def test(self):\n        \"\"\"Test two threads that trigger a watchpoint where one thread has a 1 second delay. \"\"\"\n        self.build(dictionary=self.getBuildFlags())\n        self.do_thread_actions(num_watchpoint_threads=1,\n                               num_delay_watchpoint_threads=1)\n" }
{ "repo_name": "oscaro/django", "ref": "refs/heads/oscaro-backports-1.7.10", "path": "django/http/cookie.py", "content": "from __future__ import unicode_literals\n\nfrom django.utils.encoding import force_str\nfrom django.utils import six\nfrom django.utils.six.moves import http_cookies\n\n\n# Some versions of Python 2.7 and later won't need this encoding bug fix:\n_cookie_encodes_correctly = http_cookies.SimpleCookie().value_encode(';') == (';', '\"\\\\073\"')\n# See ticket #13007, http://bugs.python.org/issue2193 and http://trac.edgewall.org/ticket/2256\n_tc = http_cookies.SimpleCookie()\ntry:\n    _tc.load(str('foo:bar=1'))\n    _cookie_allows_colon_in_names = True\nexcept http_cookies.CookieError:\n    _cookie_allows_colon_in_names = False\n\nif _cookie_encodes_correctly and _cookie_allows_colon_in_names:\n    SimpleCookie = http_cookies.SimpleCookie\nelse:\n    Morsel = http_cookies.Morsel\n\n    class SimpleCookie(http_cookies.SimpleCookie):\n        if not _cookie_encodes_correctly:\n            def value_encode(self, val):\n                # Some browsers do not support quoted-string from RFC 2109,\n                # including some versions of Safari and Internet Explorer.\n                # These browsers split on ';', and some versions of Safari\n                # are known to split on ', '. Therefore, we encode ';' and ','\n\n                # SimpleCookie already does the hard work of encoding and decoding.\n                # It uses octal sequences like '\\\\012' for newline etc.\n                # and non-ASCII chars. We just make use of this mechanism, to\n                # avoid introducing two encoding schemes which would be confusing\n                # and especially awkward for javascript.\n\n                # NB, contrary to Python docs, value_encode returns a tuple containing\n                # (real val, encoded_val)\n                val, encoded = super(SimpleCookie, self).value_encode(val)\n\n                encoded = encoded.replace(\";\", \"\\\\073\").replace(\",\", \"\\\\054\")\n                # If encoded now contains any quoted chars, we need double quotes\n                # around the whole string.\n                if \"\\\\\" in encoded and not encoded.startswith('\"'):\n                    encoded = '\"' + encoded + '\"'\n\n                return val, encoded\n\n        if not _cookie_allows_colon_in_names:\n            def load(self, rawdata):\n                self.bad_cookies = set()\n                if six.PY2 and isinstance(rawdata, six.text_type):\n                    rawdata = force_str(rawdata)\n                super(SimpleCookie, self).load(rawdata)\n                for key in self.bad_cookies:\n                    del self[key]\n\n            # override private __set() method:\n            # (needed for using our Morsel, and for laxness with CookieError\n            def _BaseCookie__set(self, key, real_value, coded_value):\n                key = force_str(key)\n                try:\n                    M = self.get(key, Morsel())\n                    M.set(key, real_value, coded_value)\n                    dict.__setitem__(self, key, M)\n                except http_cookies.CookieError:\n                    if not hasattr(self, 'bad_cookies'):\n                        self.bad_cookies = set()\n                    self.bad_cookies.add(key)\n                    dict.__setitem__(self, key, http_cookies.Morsel())\n\n\ndef parse_cookie(cookie):\n    if cookie == '':\n        return {}\n    if not isinstance(cookie, http_cookies.BaseCookie):\n        try:\n            c = SimpleCookie()\n            c.load(cookie)\n        except http_cookies.CookieError:\n            # Invalid cookie\n            return {}\n    else:\n        c = cookie\n    cookiedict = {}\n    for key in c.keys():\n        cookiedict[key] = c.get(key).value\n    return cookiedict\n" }
{ "repo_name": "OCA/stock-logistics-workflow", "ref": "refs/heads/12.0", "path": "stock_change_price_at_date/wizards/__init__.py", "content": "from . import stock_change_standard_price\n" }
{ "repo_name": "leeon/annotated-django", "ref": "refs/heads/note", "path": "django/http/cookie.py", "content": "from __future__ import unicode_literals\n\nfrom django.utils.encoding import force_str\nfrom django.utils import six\nfrom django.utils.six.moves import http_cookies\n\n\n# Some versions of Python 2.7 and later won't need this encoding bug fix:\n_cookie_encodes_correctly = http_cookies.SimpleCookie().value_encode(';') == (';', '\"\\\\073\"')\n# See ticket #13007, http://bugs.python.org/issue2193 and http://trac.edgewall.org/ticket/2256\n_tc = http_cookies.SimpleCookie()\ntry:\n    _tc.load(str('foo:bar=1'))\n    _cookie_allows_colon_in_names = True\nexcept http_cookies.CookieError:\n    _cookie_allows_colon_in_names = False\n\nif _cookie_encodes_correctly and _cookie_allows_colon_in_names:\n    SimpleCookie = http_cookies.SimpleCookie\nelse:\n    Morsel = http_cookies.Morsel\n\n    class SimpleCookie(http_cookies.SimpleCookie):\n        if not _cookie_encodes_correctly:\n            def value_encode(self, val):\n                # Some browsers do not support quoted-string from RFC 2109,\n                # including some versions of Safari and Internet Explorer.\n                # These browsers split on ';', and some versions of Safari\n                # are known to split on ', '. Therefore, we encode ';' and ','\n\n                # SimpleCookie already does the hard work of encoding and decoding.\n                # It uses octal sequences like '\\\\012' for newline etc.\n                # and non-ASCII chars. We just make use of this mechanism, to\n                # avoid introducing two encoding schemes which would be confusing\n                # and especially awkward for javascript.\n\n                # NB, contrary to Python docs, value_encode returns a tuple containing\n                # (real val, encoded_val)\n                val, encoded = super(SimpleCookie, self).value_encode(val)\n\n                encoded = encoded.replace(\";\", \"\\\\073\").replace(\",\", \"\\\\054\")\n                # If encoded now contains any quoted chars, we need double quotes\n                # around the whole string.\n                if \"\\\\\" in encoded and not encoded.startswith('\"'):\n                    encoded = '\"' + encoded + '\"'\n\n                return val, encoded\n\n        if not _cookie_allows_colon_in_names:\n            def load(self, rawdata):\n                self.bad_cookies = set()\n                if six.PY2 and isinstance(rawdata, six.text_type):\n                    rawdata = force_str(rawdata)\n                super(SimpleCookie, self).load(rawdata)\n                for key in self.bad_cookies:\n                    del self[key]\n\n            # override private __set() method:\n            # (needed for using our Morsel, and for laxness with CookieError\n            def _BaseCookie__set(self, key, real_value, coded_value):\n                key = force_str(key)\n                try:\n                    M = self.get(key, Morsel())\n                    M.set(key, real_value, coded_value)\n                    dict.__setitem__(self, key, M)\n                except http_cookies.CookieError:\n                    if not hasattr(self, 'bad_cookies'):\n                        self.bad_cookies = set()\n                    self.bad_cookies.add(key)\n                    dict.__setitem__(self, key, http_cookies.Morsel())\n\n\ndef parse_cookie(cookie):\n    if cookie == '':\n        return {}\n    if not isinstance(cookie, http_cookies.BaseCookie):\n        try:\n            c = SimpleCookie()\n            c.load(cookie)\n        except http_cookies.CookieError:\n            # Invalid cookie\n            return {}\n    else:\n        c = cookie\n    cookiedict = {}\n    for key in c.keys():\n        cookiedict[key] = c.get(key).value\n    return cookiedict\n" }
{ "repo_name": "tturpen/django-csaesrapp", "ref": "refs/heads/version01", "path": "apps/elicitation/factories.py", "content": "from apps.common.factories import ModelFactory\nfrom apps.elicitation.handlers import ElicitationModelHandler\nfrom apps.audio.handlers import RecordingHandler, WavHandler\nimport os\nimport sys\n\n\nclass ElicitationModelFactory(ModelFactory):\n    def __init__(self):\n        ModelFactory.__init__(self)\n        self.mh = ElicitationModelHandler()\n        self.rh = RecordingHandler()\n        self.wh = WavHandler()\n                \n    def create_elicitation_hit_model(self,\n                                     hit_id,\n                                     hit_type_id,\n                                     prompt_ids,\n                                     prompt_source_name,\n                                     template_name,\n                                     redundancy):        \n        if type(prompt_ids) != list:\n            raise IOError\n        search = {\"hit_id\":hit_id}\n        document ={\"hit_id\":hit_id,\n                     \"hit_type_id\": hit_type_id,\n                     \"prompts\" : prompt_ids,\n                     \"prompt_source_name\": prompt_source_name,\n                     \"template_name\": template_name,\n                     \"redundancy\": redundancy}\n        return self.create_model(\"hits\",search,document)\n    \n    def create_word_prompt_model(self,source, words, normalized_words,line_number,prompt_id,word_count):\n        \"\"\"A -1 endtime means to the end of the clip.\"\"\"\n        search = {\"source\" : source,\n                    \"line_number\" : line_number,\n                    \"prompt_id\" : prompt_id,\n                    \"word_count\": word_count}\n        document = {\"source\" : source,\n                    \"line_number\" : line_number,\n                    \"prompt_id\" : prompt_id,\n                    \"words\" : words,\n                    \"normalized_words\": normalized_words,\n                    \"word_count\": word_count}\n        art_id = self.create_model(\"prompts\", search, document,update=False)\n        return art_id\n    \n    def create_prompt_source_model(self,prompt_file_uri, disk_space, prompt_count):\n        \"\"\"Create the prompt source model give the location on disk,\n            size on disk\n            and number of prompts\"\"\"\n        search = {\"uri\" : prompt_file_uri,\n                    \"disk_space\" : disk_space,\n                    \"prompt_count\": prompt_count}    \n        document = {\"uri\" : prompt_file_uri,\n                    \"disk_space\" : disk_space,\n                    \"prompt_count\": prompt_count} \n        model= self.create_model(\"prompt_sources\", search, document)\n        return model\n    \n    def create_recording_source_model(self,prompt,recording_url,worker=None,prompt_words=None):\n        \"\"\"Use the recording handler to download the recording\n            and create the artifact\"\"\"\n        recording_uri = self.rh.download_vocaroo_recording(recording_url,\n                                                           worker_id=worker.worker_id,\n                                                           prompt_words=prompt_words)\n        if not recording_uri:\n            print(\"Failed to retrieve url(%s)\"%recording_url)\n            return False\n        disk_space = os.stat(recording_uri).st_size\n        length_seconds = self.wh.get_audio_length(recording_uri)\n        encoding = \".wav\"\n        sample_rate = -1\n        \n        search = {\"recording_url\" : recording_url}\n        document = {\"recording_url\": recording_url,\n                    \"prompt\": prompt,\n                    \"disk_space\" : disk_space,\n                    \"uri\" : recording_uri,\n                    \"worker_id\": worker.worker_id,\n                    \"length_seconds\": length_seconds,\n                    \"encoding\" : encoding,\n                    \"sample_rate\" : sample_rate,\n                    \"filename\": os.path.basename(recording_uri)} \n        return self.create_model(\"recording_sources\", search, document)\n    \n    " }
{ "repo_name": "redhat-openstack/trove", "ref": "refs/heads/mitaka-patches", "path": "trove/instance/tasks.py", "content": "# Copyright 2012 OpenStack Foundation\n# All Rights Reserved.\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\"\"\"\nCommon instance status code used across Trove API.\n\"\"\"\n\n\nclass InstanceTask(object):\n    \"\"\"\n    Stores the different kind of tasks being performed by an instance.\n    \"\"\"\n    # TODO(tim.simpson): Figure out someway to migrate this to the TaskManager\n    #                    once that revs up.\n    _lookup = {}\n\n    def __init__(self, code, action, db_text, is_error=False):\n        self._code = int(code)\n        self._action = action\n        self._db_text = db_text\n        self._is_error = is_error\n        InstanceTask._lookup[self._code] = self\n\n    @property\n    def action(self):\n        return self._action\n\n    @property\n    def code(self):\n        return self._code\n\n    @property\n    def db_text(self):\n        return self._db_text\n\n    @property\n    def is_error(self):\n        return self._is_error\n\n    def __eq__(self, other):\n        if not isinstance(other, InstanceTask):\n            return False\n        return self._db_text == other._db_text\n\n    @classmethod\n    def from_code(cls, code):\n        if code not in cls._lookup:\n            return None\n        return cls._lookup[code]\n\n    def __str__(self):\n        return \"(%d %s %s)\" % (self._code, self._action, self._db_text)\n\n    def __repr__(self):\n        return \"InstanceTask.%s (%s)\" % (self._action, self._db_text)\n\n\nclass InstanceTasks(object):\n    NONE = InstanceTask(0x01, 'NONE', 'No tasks for the instance.')\n    DELETING = InstanceTask(0x02, 'DELETING', 'Deleting the instance.')\n    REBOOTING = InstanceTask(0x03, 'REBOOTING', 'Rebooting the instance.')\n    RESIZING = InstanceTask(0x04, 'RESIZING', 'Resizing the instance.')\n    BUILDING = InstanceTask(0x05, 'BUILDING', 'The instance is building.')\n    MIGRATING = InstanceTask(0x06, 'MIGRATING', 'Migrating the instance.')\n    RESTART_REQUIRED = InstanceTask(0x07, 'RESTART_REQUIRED',\n                                    'Instance requires a restart.')\n    PROMOTING = InstanceTask(0x08, 'PROMOTING',\n                             'Promoting the instance to replica source.')\n    EJECTING = InstanceTask(0x09, 'EJECTING',\n                            'Ejecting the replica source.')\n    LOGGING = InstanceTask(0x0a, 'LOGGING', 'Transferring guest logs.')\n\n    BUILDING_ERROR_DNS = InstanceTask(0x50, 'BUILDING', 'Build error: DNS.',\n                                      is_error=True)\n    BUILDING_ERROR_SERVER = InstanceTask(0x51, 'BUILDING',\n                                         'Build error: Server.',\n                                         is_error=True)\n    BUILDING_ERROR_VOLUME = InstanceTask(0x52, 'BUILDING',\n                                         'Build error: Volume.',\n                                         is_error=True)\n    BUILDING_ERROR_TIMEOUT_GA = InstanceTask(0x54, 'ERROR',\n                                             'Build error: '\n                                             'guestagent timeout.',\n                                             is_error=True)\n    BUILDING_ERROR_SEC_GROUP = InstanceTask(0x53, 'BUILDING',\n                                            'Build error: Secgroup '\n                                            'or rule.',\n                                            is_error=True)\n    BUILDING_ERROR_REPLICA = InstanceTask(0x54, 'BUILDING',\n                                          'Build error: Replica.',\n                                          is_error=True)\n    PROMOTION_ERROR = InstanceTask(0x55, 'PROMOTING',\n                                         'Replica Promotion Error.',\n                                         is_error=True)\n    EJECTION_ERROR = InstanceTask(0x56, 'EJECTING',\n                                        'Replica Source Ejection Error.',\n                                        is_error=True)\n    GROWING_ERROR = InstanceTask(0x57, 'GROWING',\n                                       'Growing Cluster Error.',\n                                       is_error=True)\n    SHRINKING_ERROR = InstanceTask(0x58, 'SHRINKING',\n                                         'Shrinking Cluster Error.',\n                                         is_error=True)\n\n# Dissuade further additions at run-time.\nInstanceTask.__init__ = None\n" }
{ "repo_name": "matte1/mavlink", "ref": "refs/heads/matt_dev", "path": "pymavlink/tools/mavparms.py", "content": "#!/usr/bin/env python\n\n'''\nextract mavlink parameter values\n'''\n\nimport sys, time, os\n\nfrom optparse import OptionParser\nparser = OptionParser(\"mavparms.py [options]\")\nparser.add_option(\"-c\", \"--changes\", dest=\"changesOnly\", default=False, action=\"store_true\", help=\"Show only changes to parameters.\")\n\n(opts, args) = parser.parse_args()\n\nfrom pymavlink import mavutil\n\nif len(args) < 1:\n    print(\"Usage: mavparms.py [options] <LOGFILE...>\")\n    sys.exit(1)\n\nparms = {}\n\ndef mavparms(logfile):\n    '''extract mavlink parameters'''\n    mlog = mavutil.mavlink_connection(filename)\n\n    while True:\n        try:\n            m = mlog.recv_match(type=['PARAM_VALUE', 'PARM'])\n            if m is None:\n                return\n        except Exception:\n            return\n        if m.get_type() == 'PARAM_VALUE':\n            pname = str(m.param_id).strip()\n            value = m.param_value\n        else:\n            pname = m.Name\n            value = m.Value\n        if len(pname) > 0:\n            if opts.changesOnly is True and pname in parms and parms[pname] != value:\n                print(\"%s %-15s %.6f -> %.6f\" % (time.asctime(time.localtime(m._timestamp)), pname, parms[pname], value))\n            \n            parms[pname] = value\n\ntotal = 0.0\nfor filename in args:\n    mavparms(filename)\n\nif (opts.changesOnly is False):\n    keys = parms.keys()\n    keys.sort()\n    for p in keys:\n        print(\"%-15s %.6f\" % (p, parms[p]))\n" }
{ "repo_name": "idea4bsd/idea4bsd", "ref": "refs/heads/idea4bsd-master", "path": "python/testData/refactoring/extractsuperclass/withImport.before.py", "content": "import os\n\nclass A(object):\n  def foo(self):\n    os.stat_result.n_fields()\n" }
{ "repo_name": "semprebon/mapnik", "ref": "refs/heads/svg", "path": "scons/scons-local-1.2.0/SCons/Options/PathOption.py", "content": "#\n# Copyright (c) 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008 The SCons Foundation\n#\n# Permission is hereby granted, free of charge, to any person obtaining\n# a copy of this software and associated documentation files (the\n# \"Software\"), to deal in the Software without restriction, including\n# without limitation the rights to use, copy, modify, merge, publish,\n# distribute, sublicense, and/or sell copies of the Software, and to\n# permit persons to whom the Software is furnished to do so, subject to\n# the following conditions:\n#\n# The above copyright notice and this permission notice shall be included\n# in all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY\n# KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE\n# WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n# LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n# OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n# WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n#\n\n__revision__ = \"src/engine/SCons/Options/PathOption.py 3842 2008/12/20 22:59:52 scons\"\n\n__doc__ = \"\"\"Place-holder for the old SCons.Options module hierarchy\n\nThis is for backwards compatibility.  The new equivalent is the Variables/\nclass hierarchy.  These will have deprecation warnings added (some day),\nand will then be removed entirely (some day).\n\"\"\"\n\nimport SCons.Variables\nimport SCons.Warnings\n\nwarned = False\n\nclass _PathOptionClass:\n    def warn(self):\n        global warned\n        if not warned:\n            msg = \"The PathOption() function is deprecated; use the PathVariable() function instead.\"\n            SCons.Warnings.warn(SCons.Warnings.DeprecatedOptionsWarning, msg)\n            warned = True\n\n    def __call__(self, *args, **kw):\n        self.warn()\n        return apply(SCons.Variables.PathVariable, args, kw)\n\n    def PathAccept(self, *args, **kw):\n        self.warn()\n        return apply(SCons.Variables.PathVariable.PathAccept, args, kw)\n\n    def PathIsDir(self, *args, **kw):\n        self.warn()\n        return apply(SCons.Variables.PathVariable.PathIsDir, args, kw)\n\n    def PathIsDirCreate(self, *args, **kw):\n        self.warn()\n        return apply(SCons.Variables.PathVariable.PathIsDirCreate, args, kw)\n\n    def PathIsFile(self, *args, **kw):\n        self.warn()\n        return apply(SCons.Variables.PathVariable.PathIsFile, args, kw)\n\n    def PathExists(self, *args, **kw):\n        self.warn()\n        return apply(SCons.Variables.PathVariable.PathExists, args, kw)\n\nPathOption = _PathOptionClass()\n" }
{ "repo_name": "lucafavatella/intellij-community", "ref": "refs/heads/cli-wip", "path": "python/testData/refactoring/extractsuperclass/withImport.before.py", "content": "import os\n\nclass A(object):\n  def foo(self):\n    os.stat_result.n_fields()\n" }
{ "repo_name": "kylon/pacman-fakeroot", "ref": "refs/heads/upstream", "path": "test/pacman/tests/sync401.py", "content": "self.description = \"Ensure we choose provider already in target list\"\n\nsp1 = pmpkg(\"pkg1\")\nsp1.depends = [\"dep\"]\nself.addpkg2db(\"sync\", sp1)\n\nsp2 = pmpkg(\"pkg2\")\nsp2.provides = [\"dep\"]\nself.addpkg2db(\"sync\", sp2)\n\nsp3 = pmpkg(\"pkg3\")\nsp3.conflicts = [\"pkg2\"]\nsp3.provides = [\"dep\"]\nself.addpkg2db(\"sync\", sp3)\n\nself.args = \"-S pkg1 pkg2\"\n\nself.addrule(\"PACMAN_RETCODE=0\")\nself.addrule(\"PKG_EXIST=pkg1\")\nself.addrule(\"PKG_EXIST=pkg2\")\nself.addrule(\"!PKG_EXIST=pkg3\")\n" }
{ "repo_name": "rubikloud/scikit-learn", "ref": "refs/heads/0.17.1-RUBIKLOUD", "path": "sklearn/metrics/__init__.py", "content": "\"\"\"\nThe :mod:`sklearn.metrics` module includes score functions, performance metrics\nand pairwise metrics and distance computations.\n\"\"\"\n\n\nfrom .ranking import auc\nfrom .ranking import average_precision_score\nfrom .ranking import coverage_error\nfrom .ranking import label_ranking_average_precision_score\nfrom .ranking import label_ranking_loss\nfrom .ranking import precision_recall_curve\nfrom .ranking import roc_auc_score\nfrom .ranking import roc_curve\n\nfrom .classification import accuracy_score\nfrom .classification import classification_report\nfrom .classification import cohen_kappa_score\nfrom .classification import confusion_matrix\nfrom .classification import f1_score\nfrom .classification import fbeta_score\nfrom .classification import hamming_loss\nfrom .classification import hinge_loss\nfrom .classification import jaccard_similarity_score\nfrom .classification import log_loss\nfrom .classification import matthews_corrcoef\nfrom .classification import precision_recall_fscore_support\nfrom .classification import precision_score\nfrom .classification import recall_score\nfrom .classification import zero_one_loss\nfrom .classification import brier_score_loss\n\nfrom . import cluster\nfrom .cluster import adjusted_mutual_info_score\nfrom .cluster import adjusted_rand_score\nfrom .cluster import completeness_score\nfrom .cluster import consensus_score\nfrom .cluster import homogeneity_completeness_v_measure\nfrom .cluster import homogeneity_score\nfrom .cluster import mutual_info_score\nfrom .cluster import normalized_mutual_info_score\nfrom .cluster import silhouette_samples\nfrom .cluster import silhouette_score\nfrom .cluster import v_measure_score\n\nfrom .pairwise import euclidean_distances\nfrom .pairwise import pairwise_distances\nfrom .pairwise import pairwise_distances_argmin\nfrom .pairwise import pairwise_distances_argmin_min\nfrom .pairwise import pairwise_kernels\n\nfrom .regression import explained_variance_score\nfrom .regression import mean_absolute_error\nfrom .regression import mean_squared_error\nfrom .regression import median_absolute_error\nfrom .regression import r2_score\n\nfrom .scorer import make_scorer\nfrom .scorer import SCORERS\nfrom .scorer import get_scorer\n\n__all__ = [\n    'accuracy_score',\n    'adjusted_mutual_info_score',\n    'adjusted_rand_score',\n    'auc',\n    'average_precision_score',\n    'classification_report',\n    'cluster',\n    'completeness_score',\n    'confusion_matrix',\n    'consensus_score',\n    'coverage_error',\n    'euclidean_distances',\n    'explained_variance_score',\n    'f1_score',\n    'fbeta_score',\n    'get_scorer',\n    'hamming_loss',\n    'hinge_loss',\n    'homogeneity_completeness_v_measure',\n    'homogeneity_score',\n    'jaccard_similarity_score',\n    'label_ranking_average_precision_score',\n    'label_ranking_loss',\n    'log_loss',\n    'make_scorer',\n    'matthews_corrcoef',\n    'mean_absolute_error',\n    'mean_squared_error',\n    'median_absolute_error',\n    'mutual_info_score',\n    'normalized_mutual_info_score',\n    'pairwise_distances',\n    'pairwise_distances_argmin',\n    'pairwise_distances_argmin_min',\n    'pairwise_distances_argmin_min',\n    'pairwise_kernels',\n    'precision_recall_curve',\n    'precision_recall_fscore_support',\n    'precision_score',\n    'r2_score',\n    'recall_score',\n    'roc_auc_score',\n    'roc_curve',\n    'SCORERS',\n    'silhouette_samples',\n    'silhouette_score',\n    'v_measure_score',\n    'zero_one_loss',\n    'brier_score_loss',\n]\n" }
{ "repo_name": "chinmaygarde/mojo", "ref": "refs/heads/ios", "path": "build/android/pylib/instrumentation/instrumentation_test_instance.py", "content": "# Copyright 2015 The Chromium Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\nimport logging\nimport os\nimport pickle\nimport re\nimport sys\n\nfrom pylib import cmd_helper\nfrom pylib import constants\nfrom pylib import flag_changer\nfrom pylib.base import base_test_result\nfrom pylib.base import test_instance\nfrom pylib.instrumentation import test_result\nfrom pylib.instrumentation import instrumentation_parser\nfrom pylib.utils import apk_helper\nfrom pylib.utils import md5sum\nfrom pylib.utils import proguard\n\nsys.path.append(\n    os.path.join(constants.DIR_SOURCE_ROOT, 'build', 'util', 'lib', 'common'))\nimport unittest_util\n\n# Ref: http://developer.android.com/reference/android/app/Activity.html\n_ACTIVITY_RESULT_CANCELED = 0\n_ACTIVITY_RESULT_OK = -1\n\n_DEFAULT_ANNOTATIONS = [\n    'Smoke', 'SmallTest', 'MediumTest', 'LargeTest',\n    'EnormousTest', 'IntegrationTest']\n_EXTRA_ENABLE_HTTP_SERVER = (\n    'org.chromium.chrome.test.ChromeInstrumentationTestRunner.'\n        + 'EnableTestHttpServer')\n_EXTRA_DRIVER_TEST_LIST = (\n    'org.chromium.test.driver.OnDeviceInstrumentationDriver.TestList')\n_EXTRA_DRIVER_TEST_LIST_FILE = (\n    'org.chromium.test.driver.OnDeviceInstrumentationDriver.TestListFile')\n_EXTRA_DRIVER_TARGET_PACKAGE = (\n    'org.chromium.test.driver.OnDeviceInstrumentationDriver.TargetPackage')\n_EXTRA_DRIVER_TARGET_CLASS = (\n    'org.chromium.test.driver.OnDeviceInstrumentationDriver.TargetClass')\n_NATIVE_CRASH_RE = re.compile('native crash', re.IGNORECASE)\n_PICKLE_FORMAT_VERSION = 10\n\n\n# TODO(jbudorick): Make these private class methods of\n# InstrumentationTestInstance once the instrumentation test_runner is\n# deprecated.\ndef ParseAmInstrumentRawOutput(raw_output):\n  \"\"\"Parses the output of an |am instrument -r| call.\n\n  Args:\n    raw_output: the output of an |am instrument -r| call as a list of lines\n  Returns:\n    A 3-tuple containing:\n      - the instrumentation code as an integer\n      - the instrumentation result as a list of lines\n      - the instrumentation statuses received as a list of 2-tuples\n        containing:\n        - the status code as an integer\n        - the bundle dump as a dict mapping string keys to a list of\n          strings, one for each line.\n  \"\"\"\n  parser = instrumentation_parser.InstrumentationParser(raw_output)\n  statuses = list(parser.IterStatus())\n  code, bundle = parser.GetResult()\n  return (code, bundle, statuses)\n\n\ndef GenerateTestResults(\n    result_code, result_bundle, statuses, start_ms, duration_ms):\n  \"\"\"Generate test results from |statuses|.\n\n  Args:\n    result_code: The overall status code as an integer.\n    result_bundle: The summary bundle dump as a dict.\n    statuses: A list of 2-tuples containing:\n      - the status code as an integer\n      - the bundle dump as a dict mapping string keys to string values\n      Note that this is the same as the third item in the 3-tuple returned by\n      |_ParseAmInstrumentRawOutput|.\n    start_ms: The start time of the test in milliseconds.\n    duration_ms: The duration of the test in milliseconds.\n\n  Returns:\n    A list containing an instance of InstrumentationTestResult for each test\n    parsed.\n  \"\"\"\n\n  results = []\n\n  current_result = None\n\n  for status_code, bundle in statuses:\n    test_class = bundle.get('class', '')\n    test_method = bundle.get('test', '')\n    if test_class and test_method:\n      test_name = '%s#%s' % (test_class, test_method)\n    else:\n      continue\n\n    if status_code == instrumentation_parser.STATUS_CODE_START:\n      if current_result:\n        results.append(current_result)\n      current_result = test_result.InstrumentationTestResult(\n          test_name, base_test_result.ResultType.UNKNOWN, start_ms, duration_ms)\n    else:\n      if status_code == instrumentation_parser.STATUS_CODE_OK:\n        if bundle.get('test_skipped', '').lower() in ('true', '1', 'yes'):\n          current_result.SetType(base_test_result.ResultType.SKIP)\n        elif current_result.GetType() == base_test_result.ResultType.UNKNOWN:\n          current_result.SetType(base_test_result.ResultType.PASS)\n      else:\n        if status_code not in (instrumentation_parser.STATUS_CODE_ERROR,\n                               instrumentation_parser.STATUS_CODE_FAILURE):\n          logging.error('Unrecognized status code %d. Handling as an error.',\n                        status_code)\n        current_result.SetType(base_test_result.ResultType.FAIL)\n        if 'stack' in bundle:\n          current_result.SetLog(bundle['stack'])\n\n  if current_result:\n    if current_result.GetType() == base_test_result.ResultType.UNKNOWN:\n      crashed = (result_code == _ACTIVITY_RESULT_CANCELED\n                 and any(_NATIVE_CRASH_RE.search(l)\n                         for l in result_bundle.itervalues()))\n      if crashed:\n        current_result.SetType(base_test_result.ResultType.CRASH)\n\n    results.append(current_result)\n\n  return results\n\n\nclass InstrumentationTestInstance(test_instance.TestInstance):\n\n  def __init__(self, args, isolate_delegate, error_func):\n    super(InstrumentationTestInstance, self).__init__()\n\n    self._apk_under_test = None\n    self._package_info = None\n    self._suite = None\n    self._test_apk = None\n    self._test_jar = None\n    self._test_package = None\n    self._test_runner = None\n    self._test_support_apk = None\n    self._initializeApkAttributes(args, error_func)\n\n    self._data_deps = None\n    self._isolate_abs_path = None\n    self._isolate_delegate = None\n    self._isolated_abs_path = None\n    self._test_data = None\n    self._initializeDataDependencyAttributes(args, isolate_delegate)\n\n    self._annotations = None\n    self._excluded_annotations = None\n    self._test_filter = None\n    self._initializeTestFilterAttributes(args)\n\n    self._flags = None\n    self._initializeFlagAttributes(args)\n\n    self._driver_apk = None\n    self._driver_package = None\n    self._driver_name = None\n    self._initializeDriverAttributes()\n\n  def _initializeApkAttributes(self, args, error_func):\n    if args.apk_under_test.endswith('.apk'):\n      self._apk_under_test = args.apk_under_test\n    else:\n      self._apk_under_test = os.path.join(\n          constants.GetOutDirectory(), constants.SDK_BUILD_APKS_DIR,\n          '%s.apk' % args.apk_under_test)\n\n    if not os.path.exists(self._apk_under_test):\n      error_func('Unable to find APK under test: %s' % self._apk_under_test)\n\n    if args.test_apk.endswith('.apk'):\n      self._suite = os.path.splitext(os.path.basename(args.test_apk))[0]\n      self._test_apk = args.test_apk\n    else:\n      self._suite = args.test_apk\n      self._test_apk = os.path.join(\n          constants.GetOutDirectory(), constants.SDK_BUILD_APKS_DIR,\n          '%s.apk' % args.test_apk)\n\n    self._test_jar = os.path.join(\n        constants.GetOutDirectory(), constants.SDK_BUILD_TEST_JAVALIB_DIR,\n        '%s.jar' % self._suite)\n    self._test_support_apk = os.path.join(\n        constants.GetOutDirectory(), constants.SDK_BUILD_TEST_JAVALIB_DIR,\n        '%sSupport.apk' % self._suite)\n\n    if not os.path.exists(self._test_apk):\n      error_func('Unable to find test APK: %s' % self._test_apk)\n    if not os.path.exists(self._test_jar):\n      error_func('Unable to find test JAR: %s' % self._test_jar)\n\n    apk = apk_helper.ApkHelper(self.test_apk)\n    self._test_package = apk.GetPackageName()\n    self._test_runner = apk.GetInstrumentationName()\n\n    self._package_info = None\n    for package_info in constants.PACKAGE_INFO.itervalues():\n      if self._test_package == package_info.test_package:\n        self._package_info = package_info\n    if not self._package_info:\n      logging.warning('Unable to find package info for %s', self._test_package)\n\n  def _initializeDataDependencyAttributes(self, args, isolate_delegate):\n    self._data_deps = []\n    if args.isolate_file_path:\n      self._isolate_abs_path = os.path.abspath(args.isolate_file_path)\n      self._isolate_delegate = isolate_delegate\n      self._isolated_abs_path = os.path.join(\n          constants.GetOutDirectory(), '%s.isolated' % self._test_package)\n    else:\n      self._isolate_delegate = None\n\n    # TODO(jbudorick): Deprecate and remove --test-data once data dependencies\n    # are fully converted to isolate.\n    if args.test_data:\n      logging.info('Data dependencies specified via --test-data')\n      self._test_data = args.test_data\n    else:\n      self._test_data = None\n\n    if not self._isolate_delegate and not self._test_data:\n      logging.warning('No data dependencies will be pushed.')\n\n  def _initializeTestFilterAttributes(self, args):\n    self._test_filter = args.test_filter\n\n    def annotation_dict_element(a):\n      a = a.split('=')\n      return (a[0], a[1] if len(a) == 2 else None)\n\n    if args.annotation_str:\n      self._annotations = dict(\n          annotation_dict_element(a)\n          for a in args.annotation_str.split(','))\n    elif not self._test_filter:\n      self._annotations = dict(\n          annotation_dict_element(a)\n          for a in _DEFAULT_ANNOTATIONS)\n    else:\n      self._annotations = {}\n\n    if args.exclude_annotation_str:\n      self._excluded_annotations = dict(\n          annotation_dict_element(a)\n          for a in args.exclude_annotation_str.split(','))\n    else:\n      self._excluded_annotations = {}\n\n  def _initializeFlagAttributes(self, args):\n    self._flags = ['--disable-fre', '--enable-test-intents']\n    # TODO(jbudorick): Transition \"--device-flags\" to \"--device-flags-file\"\n    if hasattr(args, 'device_flags') and args.device_flags:\n      with open(args.device_flags) as device_flags_file:\n        stripped_lines = (l.strip() for l in device_flags_file)\n        self._flags.extend([flag for flag in stripped_lines if flag])\n    if hasattr(args, 'device_flags_file') and args.device_flags_file:\n      with open(args.device_flags_file) as device_flags_file:\n        stripped_lines = (l.strip() for l in device_flags_file)\n        self._flags.extend([flag for flag in stripped_lines if flag])\n\n  def _initializeDriverAttributes(self):\n    self._driver_apk = os.path.join(\n        constants.GetOutDirectory(), constants.SDK_BUILD_APKS_DIR,\n        'OnDeviceInstrumentationDriver.apk')\n    if os.path.exists(self._driver_apk):\n      driver_apk = apk_helper.ApkHelper(self._driver_apk)\n      self._driver_package = driver_apk.GetPackageName()\n      self._driver_name = driver_apk.GetInstrumentationName()\n    else:\n      self._driver_apk = None\n\n  @property\n  def apk_under_test(self):\n    return self._apk_under_test\n\n  @property\n  def flags(self):\n    return self._flags\n\n  @property\n  def driver_apk(self):\n    return self._driver_apk\n\n  @property\n  def driver_package(self):\n    return self._driver_package\n\n  @property\n  def driver_name(self):\n    return self._driver_name\n\n  @property\n  def package_info(self):\n    return self._package_info\n\n  @property\n  def suite(self):\n    return self._suite\n\n  @property\n  def test_apk(self):\n    return self._test_apk\n\n  @property\n  def test_jar(self):\n    return self._test_jar\n\n  @property\n  def test_support_apk(self):\n    return self._test_support_apk\n\n  @property\n  def test_package(self):\n    return self._test_package\n\n  @property\n  def test_runner(self):\n    return self._test_runner\n\n  #override\n  def TestType(self):\n    return 'instrumentation'\n\n  #override\n  def SetUp(self):\n    if self._isolate_delegate:\n      self._isolate_delegate.Remap(\n          self._isolate_abs_path, self._isolated_abs_path)\n      self._isolate_delegate.MoveOutputDeps()\n      self._data_deps.extend([(constants.ISOLATE_DEPS_DIR, None)])\n\n    # TODO(jbudorick): Convert existing tests that depend on the --test-data\n    # mechanism to isolate, then remove this.\n    if self._test_data:\n      for t in self._test_data:\n        device_rel_path, host_rel_path = t.split(':')\n        host_abs_path = os.path.join(constants.DIR_SOURCE_ROOT, host_rel_path)\n        self._data_deps.extend(\n            [(host_abs_path,\n              [None, 'chrome', 'test', 'data', device_rel_path])])\n\n  def GetDataDependencies(self):\n    return self._data_deps\n\n  def GetTests(self):\n    pickle_path = '%s-proguard.pickle' % self.test_jar\n    try:\n      tests = self._GetTestsFromPickle(pickle_path, self.test_jar)\n    except self.ProguardPickleException as e:\n      logging.info('Getting tests from JAR via proguard. (%s)' % str(e))\n      tests = self._GetTestsFromProguard(self.test_jar)\n      self._SaveTestsToPickle(pickle_path, self.test_jar, tests)\n    return self._InflateTests(self._FilterTests(tests))\n\n  class ProguardPickleException(Exception):\n    pass\n\n  def _GetTestsFromPickle(self, pickle_path, jar_path):\n    if not os.path.exists(pickle_path):\n      raise self.ProguardPickleException('%s does not exist.' % pickle_path)\n    if os.path.getmtime(pickle_path) <= os.path.getmtime(jar_path):\n      raise self.ProguardPickleException(\n          '%s newer than %s.' % (jar_path, pickle_path))\n\n    with open(pickle_path, 'r') as pickle_file:\n      pickle_data = pickle.loads(pickle_file.read())\n    jar_md5 = md5sum.CalculateHostMd5Sums(jar_path)[jar_path]\n\n    try:\n      if pickle_data['VERSION'] != _PICKLE_FORMAT_VERSION:\n        raise self.ProguardPickleException('PICKLE_FORMAT_VERSION has changed.')\n      if pickle_data['JAR_MD5SUM'] != jar_md5:\n        raise self.ProguardPickleException('JAR file MD5 sum differs.')\n      return pickle_data['TEST_METHODS']\n    except TypeError as e:\n      logging.error(pickle_data)\n      raise self.ProguardPickleException(str(e))\n\n  def _GetTestsFromProguard(self, jar_path):\n    p = proguard.Dump(jar_path)\n\n    def is_test_class(c):\n      return c['class'].endswith('Test')\n\n    def is_test_method(m):\n      return m['method'].startswith('test')\n\n    class_lookup = dict((c['class'], c) for c in p['classes'])\n    def recursive_get_class_annotations(c):\n      s = c['superclass']\n      if s in class_lookup:\n        a = recursive_get_class_annotations(class_lookup[s])\n      else:\n        a = {}\n      a.update(c['annotations'])\n      return a\n\n    def stripped_test_class(c):\n      return {\n        'class': c['class'],\n        'annotations': recursive_get_class_annotations(c),\n        'methods': [m for m in c['methods'] if is_test_method(m)],\n    }\n\n    return [stripped_test_class(c) for c in p['classes']\n            if is_test_class(c)]\n\n  def _SaveTestsToPickle(self, pickle_path, jar_path, tests):\n    jar_md5 = md5sum.CalculateHostMd5Sums(jar_path)[jar_path]\n    pickle_data = {\n      'VERSION': _PICKLE_FORMAT_VERSION,\n      'JAR_MD5SUM': jar_md5,\n      'TEST_METHODS': tests,\n  }\n    with open(pickle_path, 'w') as pickle_file:\n      pickle.dump(pickle_data, pickle_file)\n\n  def _FilterTests(self, tests):\n\n    def gtest_filter(c, m):\n      t = ['%s.%s' % (c['class'].split('.')[-1], m['method'])]\n      return (not self._test_filter\n              or unittest_util.FilterTestNames(t, self._test_filter))\n\n    def annotation_filter(all_annotations):\n      if not self._annotations:\n        return True\n      return any_annotation_matches(self._annotations, all_annotations)\n\n    def excluded_annotation_filter(all_annotations):\n      if not self._excluded_annotations:\n        return True\n      return not any_annotation_matches(self._excluded_annotations,\n                                        all_annotations)\n\n    def any_annotation_matches(annotations, all_annotations):\n      return any(\n          ak in all_annotations and (av is None or av == all_annotations[ak])\n          for ak, av in annotations.iteritems())\n\n    filtered_classes = []\n    for c in tests:\n      filtered_methods = []\n      for m in c['methods']:\n        # Gtest filtering\n        if not gtest_filter(c, m):\n          continue\n\n        all_annotations = dict(c['annotations'])\n        all_annotations.update(m['annotations'])\n        if (not annotation_filter(all_annotations)\n            or not excluded_annotation_filter(all_annotations)):\n          continue\n\n        filtered_methods.append(m)\n\n      if filtered_methods:\n        filtered_class = dict(c)\n        filtered_class['methods'] = filtered_methods\n        filtered_classes.append(filtered_class)\n\n    return filtered_classes\n\n  def _InflateTests(self, tests):\n    inflated_tests = []\n    for c in tests:\n      for m in c['methods']:\n        a = dict(c['annotations'])\n        a.update(m['annotations'])\n        inflated_tests.append({\n            'class': c['class'],\n            'method': m['method'],\n            'annotations': a,\n      })\n    return inflated_tests\n\n  @staticmethod\n  def GetHttpServerEnvironmentVars():\n    return {\n      _EXTRA_ENABLE_HTTP_SERVER: None,\n  }\n\n  def GetDriverEnvironmentVars(\n      self, test_list=None, test_list_file_path=None):\n    env = {\n      _EXTRA_DRIVER_TARGET_PACKAGE: self.test_package,\n      _EXTRA_DRIVER_TARGET_CLASS: self.test_runner,\n  }\n\n    if test_list:\n      env[_EXTRA_DRIVER_TEST_LIST] = ','.join(test_list)\n\n    if test_list_file_path:\n      env[_EXTRA_DRIVER_TEST_LIST_FILE] = (\n          os.path.basename(test_list_file_path))\n\n    return env\n\n  @staticmethod\n  def ParseAmInstrumentRawOutput(raw_output):\n    return ParseAmInstrumentRawOutput(raw_output)\n\n  @staticmethod\n  def GenerateTestResults(\n      result_code, result_bundle, statuses, start_ms, duration_ms):\n    return GenerateTestResults(result_code, result_bundle, statuses,\n                               start_ms, duration_ms)\n\n  #override\n  def TearDown(self):\n    if self._isolate_delegate:\n      self._isolate_delegate.Clear()\n\n" }
{ "repo_name": "ronin13/Pacman", "ref": "refs/heads/rprabhu", "path": "test/pacman/tests/sync401.py", "content": "self.description = \"Ensure we choose provider already in target list\"\n\nsp1 = pmpkg(\"pkg1\")\nsp1.depends = [\"dep\"]\nself.addpkg2db(\"sync\", sp1)\n\nsp2 = pmpkg(\"pkg2\")\nsp2.provides = [\"dep\"]\nself.addpkg2db(\"sync\", sp2)\n\nsp3 = pmpkg(\"pkg3\")\nsp3.conflicts = [\"pkg2\"]\nsp3.provides = [\"dep\"]\nself.addpkg2db(\"sync\", sp3)\n\nself.args = \"-S pkg1 pkg2\"\n\nself.addrule(\"PACMAN_RETCODE=0\")\nself.addrule(\"PKG_EXIST=pkg1\")\nself.addrule(\"PKG_EXIST=pkg2\")\nself.addrule(\"!PKG_EXIST=pkg3\")\n" }
{ "repo_name": "TheSLinux-forks/pacman", "ref": "refs/heads/theslinux", "path": "test/pacman/tests/sync401.py", "content": "self.description = \"Ensure we choose provider already in target list\"\n\nsp1 = pmpkg(\"pkg1\")\nsp1.depends = [\"dep\"]\nself.addpkg2db(\"sync\", sp1)\n\nsp2 = pmpkg(\"pkg2\")\nsp2.provides = [\"dep\"]\nself.addpkg2db(\"sync\", sp2)\n\nsp3 = pmpkg(\"pkg3\")\nsp3.conflicts = [\"pkg2\"]\nsp3.provides = [\"dep\"]\nself.addpkg2db(\"sync\", sp3)\n\nself.args = \"-S pkg1 pkg2\"\n\nself.addrule(\"PACMAN_RETCODE=0\")\nself.addrule(\"PKG_EXIST=pkg1\")\nself.addrule(\"PKG_EXIST=pkg2\")\nself.addrule(\"!PKG_EXIST=pkg3\")\n" }
{ "repo_name": "ibarbech/learnbot", "ref": "refs/heads/version-3", "path": "learnbot_dsl/learnbotCode/guiTabLibrary.py", "content": "from __future__ import print_function, absolute_import\nimport os, sys\nfrom PySide2 import QtGui, QtWidgets\nimport learnbot_dsl.guis.TabLibrary as TabLibrary\nfrom learnbot_dsl.blocksConfig.parserConfigBlock import reload_functions\nfrom learnbot_dsl.blocksConfig.blocks import *\nfrom learnbot_dsl.blocksConfig.blocks import pathBlocks as imgPath\nfrom learnbot_dsl.learnbotCode.Block import *\nfrom learnbot_dsl.learnbotCode.Button import Block_Button\n\n\nclass Library(QtWidgets.QWidget):\n\n    def __init__(self, parent, path):\n        QtWidgets.QWidget.__init__(self)\n        self.ui = TabLibrary.Ui_Form()\n        self.parent = parent\n        self.ui.setupUi(self)\n        self.ui.tableLibrary.verticalHeader().setVisible(False)\n        self.ui.tableLibrary.horizontalHeader().setVisible(False)\n        self.ui.tableLibrary.setColumnCount(1)\n        self.ui.tableLibrary.setRowCount(0)\n        self.namesFunctions = []\n        self.listButons = []\n        if not os.path.exists(path):\n            dirs = [self.parent.libraryPath]\n            exist = False\n            for dir in dirs:\n                for p in os.listdir(dir):\n                    if p == os.path.basename(path):\n                        path = os.path.join(dir, p)\n                        dirs = []\n                        exist = True\n                        break\n                    if os.path.isdir(os.path.join(dir, p)):\n                        dirs.append(os.path.join(dir, p))\n                    if os.path.isfile(os.path.join(dir, p)):\n                        continue\n            if not exist:\n                path = None\n        self.pathLibrary = path\n        if path is not None:\n            for subPath in [os.path.join(path, x) for x in os.listdir(path)]:\n                if os.path.isdir(os.path.abspath(subPath)):\n                    for subsubPath in [os.path.join(subPath, x) for x in os.listdir(subPath)]:\n                        if os.path.splitext(subsubPath)[-1] == \".conf\":\n                            self.load(reload_functions(subsubPath))\n\n    def load(self, blocks):\n        listRepitFuntions = []\n        for b in blocks:\n            if b[\"name\"] in self.parent.listNameUserFunctions or b[\"name\"] in self.parent.listNameLibraryFunctions:\n                listRepitFuntions.append(b[\"name\"])\n                continue\n            self.namesFunctions.append(b[\"name\"])\n            self.parent.listNameLibraryFunctions.append(b[\"name\"])\n            variables = []\n            funtionType = LIBRARY\n            HUE = HUE_LIBRARY\n            for img in b[\"img\"]:\n                img = os.path.join(imgPath, img)\n                blockType, connections = loadConfigBlock(img)\n                table = self.ui.tableLibrary\n                table.insertRow(table.rowCount())\n                tooltip = {}\n                languages = {}\n                if \"languages\" in b:\n                    languages = b[\"languages\"]\n                if \"tooltip\" in b:\n                    tooltip = b[\"tooltip\"]\n                button = Block_Button((self.parent, b[\"name\"], languages, HUE, self.parent.view, self.parent.scene,\n                                       img + \".png\", connections,\n                                       variables, blockType, table, table.rowCount() - 1,\n                                       funtionType, tooltip))\n                self.parent.listButtons.append(button)\n                self.listButons.append((button, table.rowCount() - 1))\n                table.setCellWidget(table.rowCount() - 1, 0, button)\n        if len(listRepitFuntions) is not 0:\n            text = \"\"\n            for name in listRepitFuntions:\n                text += \"\\t * \" + name + \"\\n\"\n            msgBox = QtWidgets.QMessageBox()\n            msgBox.setWindowTitle(self.tr(\"Warning\"))\n            msgBox.setIcon(QtWidgets.QMessageBox.Warning)\n            msgBox.setText(\n                self.tr(\"The following functions have not been imported because there are others with the same name:\"))\n            msgBox.setInformativeText(text)\n            msgBox.setStandardButtons(QtWidgets.QMessageBox.Ok)\n            msgBox.setDefaultButton(QtWidgets.QMessageBox.Ok)\n            ret = msgBox.exec_()\n\n    def delete(self):\n        for button, row in self.listButons:\n            self.parent.listButtons.remove(button)\n            button.delete(row)\n        for name in self.namesFunctions:\n            self.parent.listNameLibraryFunctions.remove(name)\n\n    def __del__(self):\n        print(\"delete Library\")\n" }
{ "repo_name": "MinchinWeb/topydo", "ref": "refs/heads/stable", "path": "topydo/lib/Colors.py", "content": "# Topydo - A todo.txt client written in Python.\n# Copyright (C) 2014 - 2015 Bram Schoenmakers <me@bramschoenmakers.nl>\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\n\"\"\" This module serves for managing output colors. \"\"\"\n\nfrom topydo.lib.Config import config\n\nNEUTRAL_COLOR  = '\\033[0m'\n\nclass Colors(object):\n    def __init__(self):\n        self.priority_colors = config().priority_colors()\n        self.project_color = config().project_color()\n        self.context_color = config().context_color()\n        self.metadata_color = config().metadata_color()\n        self.link_color = config().link_color()\n\n    def _int_to_ansi(self, p_int, p_decorator='normal', p_safe=True):\n        \"\"\"\n        Returns ansi code for color based on xterm color id (0-255) and\n        decoration, where decoration can be one of: normal, bold, faint,\n        italic, or underline. When p_safe is True, resulting ansi code is\n        constructed in most compatible way, but with support for only base 16\n        colors.\n        \"\"\"\n        decoration_dict = {\n                'normal': '0',\n                'bold': '1',\n                'faint': '2',\n                'italic': '3',\n                'underline': '4'\n      }\n\n        decoration = decoration_dict[p_decorator]\n\n        try:\n            if p_safe:\n                if 8 > int(p_int) >=0:\n                    return '\\033[{};3{}m'.format(decoration, str(p_int))\n                elif 16 > int(p_int):\n                    p_int = int(p_int) - 8\n                    return '\\033[{};1;3{}m'.format(decoration, str(p_int))\n\n            if 256 > int(p_int) >=0:\n                return '\\033[{};38;5;{}m'.format(decoration, str(p_int))\n            else:\n                return NEUTRAL_COLOR\n        except ValueError:\n            return None\n\n    def _name_to_int(self, p_color_name):\n        \"\"\" Returns xterm color id from color name. \"\"\"\n        color_names_dict = {\n                'black': 0,\n                'red': 1,\n                'green': 2,\n                'yellow': 3,\n                'blue': 4,\n                'magenta': 5,\n                'cyan': 6,\n                'gray': 7,\n                'darkgray': 8,\n                'light-red': 9,\n                'light-green': 10,\n                'light-yellow': 11,\n                'light-blue': 12,\n                'light-magenta': 13,\n                'light-cyan': 14,\n                'white': 15,\n      }\n\n        try:\n            return color_names_dict[p_color_name]\n        except KeyError:\n            return 404\n\n    def _name_to_ansi(self, p_color_name, p_decorator):\n        \"\"\" Returns ansi color code from color name. \"\"\"\n        number = self._name_to_int(p_color_name)\n\n        return self._int_to_ansi(number, p_decorator)\n\n    def _get_ansi(self, p_color, p_decorator):\n        \"\"\" Returns ansi color code from color name or xterm color id. \"\"\"\n        if p_color == '':\n            ansi = ''\n        else:\n            ansi = self._int_to_ansi(p_color, p_decorator, False)\n\n            if not ansi:\n                ansi = self._name_to_ansi(p_color, p_decorator)\n\n        return ansi\n\n    def get_priority_colors(self):\n        pri_ansi_colors = dict()\n\n        for pri in self.priority_colors:\n            color = self._get_ansi(self.priority_colors[pri], 'normal')\n\n            if color == '':\n                color = NEUTRAL_COLOR\n\n            pri_ansi_colors[pri] = color\n\n        return pri_ansi_colors\n\n    def get_project_color(self):\n        return self._get_ansi(self.project_color, 'bold')\n\n    def get_context_color(self):\n        return self._get_ansi(self.context_color, 'bold')\n\n    def get_metadata_color(self):\n        return self._get_ansi(self.metadata_color, 'bold')\n\n    def get_link_color(self):\n        return self._get_ansi(self.link_color, 'underline')\n" }
{ "repo_name": "yelizariev/mail-addons", "ref": "refs/heads/9.0", "path": "mail_to/__openerp__.py", "content": "# -*- coding: utf-8 -*-\n{\n    \"name\": \"\"\"Show message recipients\"\"\",\n    \"summary\": \"\"\"Allows you be sure, that all discussion participants were notified\"\"\",\n    \"category\": \"Discuss\",\n    \"images\": ['images/1.png'],\n    \"version\": \"1.0.0\",\n\n    \"author\": \"IT-Projects LLC, Pavel Romanchenko\",\n    \"website\": \"https://it-projects.info\",\n    \"license\": \"LGPL-3\",\n    \"price\": 40.00,\n    \"currency\": \"EUR\",\n\n    \"depends\": [\n        'mail_base',\n    ],\n    \"external_dependencies\": {\"python\": [], \"bin\": []}\n    \"data\": [\n        'templates.xml',\n    ],\n    \"qweb\": [\n        'static/src/xml/recipient.xml',\n    ],\n    \"demo\": [],\n    \"installable\": True,\n    \"auto_install\": False,\n}\n" }
{ "repo_name": "ProgVal/Limnoria-test", "ref": "refs/heads/debug-pypy-sqlite", "path": "plugins/Anonymous/plugin.py", "content": "###\n# Copyright (c) 2005, Daniel DiPaolo\n# Copyright (c) 2014, James McCoy\n# All rights reserved.\n#\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n#\n#   * Redistributions of source code must retain the above copyright notice,\n#     this list of conditions, and the following disclaimer.\n#   * Redistributions in binary form must reproduce the above copyright notice,\n#     this list of conditions, and the following disclaimer in the\n#     documentation and/or other materials provided with the distribution.\n#   * Neither the name of the author of this software nor the name of\n#     contributors to this software may be used to endorse or promote products\n#     derived from this software without specific prior written consent.\n#\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n###\n\nimport supybot.ircdb as ircdb\nimport supybot.utils as utils\nfrom supybot.commands import *\nimport supybot.ircmsgs as ircmsgs\nimport supybot.callbacks as callbacks\nimport supybot.ircutils as ircutils\nfrom supybot.i18n import PluginInternationalization, internationalizeDocstring\n_ = PluginInternationalization('Anonymous')\n\nclass Anonymous(callbacks.Plugin):\n    \"\"\"This plugin allows users to act through the bot anonymously.  The 'do'\n    command has the bot perform an anonymous action in a given channel, and\n    the 'say' command allows other people to speak through the bot.  Since\n    this can be fairly well abused, you might want to set\n    supybot.plugins.Anonymous.requireCapability so only users with that\n    capability can use this plugin.  For extra security, you can require that\n    the user be *in* the channel they are trying to address anonymously with\n    supybot.plugins.Anonymous.requirePresenceInChannel, or you can require\n    that the user be registered by setting\n    supybot.plugins.Anonymous.requireRegistration.\n    \"\"\"\n    def _preCheck(self, irc, msg, target, action):\n        if self.registryValue('requireRegistration', target):\n            try:\n                foo = ircdb.users.getUser(msg.prefix)\n            except KeyError:\n                irc.errorNotRegistered(Raise=True)\n        capability = self.registryValue('requireCapability', target)\n        if capability:\n            if not ircdb.checkCapability(msg.prefix, capability):\n                irc.errorNoCapability(capability, Raise=True)\n        if action != 'tell':\n            if self.registryValue('requirePresenceInChannel', target) and \\\n               msg.nick not in irc.state.channels[target].users:\n                irc.error(format(_('You must be in %s to %q in there.'),\n                                 target, action), Raise=True)\n            c = ircdb.channels.getChannel(target)\n            if c.lobotomized:\n                irc.error(format(_('I\\'m lobotomized in %s.'), target),\n                          Raise=True)\n            if not c._checkCapability(self.name()):\n                irc.error(_('That channel has set its capabilities so as to '\n                          'disallow the use of this plugin.'), Raise=True)\n        elif not self.registryValue('allowPrivateTarget'):\n            irc.error(_('This command is disabled (supybot.plugins.Anonymous.'\n                      'allowPrivateTarget is False).'), Raise=True)\n\n    @internationalizeDocstring\n    def say(self, irc, msg, args, target, text):\n        \"\"\"<channel> <text>\n\n        Sends <text> to <channel>.\n        \"\"\"\n        self._preCheck(irc, msg, target, 'say')\n        self.log.info('Saying %q in %s due to %s.',\n                      text, target, msg.prefix)\n        irc.queueMsg(ircmsgs.privmsg(target, text))\n        irc.noReply()\n    say = wrap(say, ['inChannel', 'text'])\n\n    def tell(self, irc, msg, args, target, text):\n        \"\"\"<nick> <text>\n\n        Sends <text> to <nick>.  Can only be used if\n        supybot.plugins.Anonymous.allowPrivateTarget is True.\n        \"\"\"\n        self._preCheck(irc, msg, target, 'tell')\n        self.log.info('Telling %q to %s due to %s.',\n                      text, target, msg.prefix)\n        irc.queueMsg(ircmsgs.privmsg(target, text))\n        irc.noReply()\n    tell = wrap(tell, ['nick', 'text'])\n\n    @internationalizeDocstring\n    def do(self, irc, msg, args, channel, text):\n        \"\"\"<channel> <action>\n\n        Performs <action> in <channel>.\n        \"\"\"\n        self._preCheck(irc, msg, channel, 'do')\n        self.log.info('Performing %q in %s due to %s.',\n                      text, channel, msg.prefix)\n        irc.reply(text, action=True, to=channel)\n    do = wrap(do, ['inChannel', 'text'])\nAnonymous = internationalizeDocstring(Anonymous)\n\nClass = Anonymous\n\n\n# vim:set shiftwidth=4 softtabstop=4 expandtab textwidth=79:\n" }
{ "repo_name": "Bitl/RBXLegacy-src", "ref": "refs/heads/stable", "path": "Cut/RBXLegacyDiscordBot/lib/youtube_dl/extractor/rai.py", "content": "from __future__ import unicode_literals\n\nimport re\n\nfrom .common import InfoExtractor\nfrom ..compat import (\n    compat_urlparse,\n    compat_str,\n)\nfrom ..utils import (\n    ExtractorError,\n    determine_ext,\n    find_xpath_attr,\n    fix_xml_ampersands,\n    GeoRestrictedError,\n    int_or_none,\n    parse_duration,\n    strip_or_none,\n    try_get,\n    unified_strdate,\n    unified_timestamp,\n    update_url_query,\n    urljoin,\n    xpath_text,\n)\n\n\nclass RaiBaseIE(InfoExtractor):\n    _UUID_RE = r'[\\da-f]{8}-[\\da-f]{4}-[\\da-f]{4}-[\\da-f]{4}-[\\da-f]{12}'\n    _GEO_COUNTRIES = ['IT']\n    _GEO_BYPASS = False\n\n    def _extract_relinker_info(self, relinker_url, video_id):\n        formats = []\n        geoprotection = None\n        is_live = None\n        duration = None\n\n        for platform in ('mon', 'flash', 'native'):\n            relinker = self._download_xml(\n                relinker_url, video_id,\n                note='Downloading XML metadata for platform %s' % platform,\n                transform_source=fix_xml_ampersands,\n                query={'output': 45, 'pl': platform}\n                headers=self.geo_verification_headers())\n\n            if not geoprotection:\n                geoprotection = xpath_text(\n                    relinker, './geoprotection', default=None) == 'Y'\n\n            if not is_live:\n                is_live = xpath_text(\n                    relinker, './is_live', default=None) == 'Y'\n            if not duration:\n                duration = parse_duration(xpath_text(\n                    relinker, './duration', default=None))\n\n            url_elem = find_xpath_attr(relinker, './url', 'type', 'content')\n            if url_elem is None:\n                continue\n\n            media_url = url_elem.text\n\n            # This does not imply geo restriction (e.g.\n            # http://www.raisport.rai.it/dl/raiSport/media/rassegna-stampa-04a9f4bd-b563-40cf-82a6-aad3529cb4a9.html)\n            if media_url == 'http://download.rai.it/video_no_available.mp4':\n                continue\n\n            ext = determine_ext(media_url)\n            if (ext == 'm3u8' and platform != 'mon') or (ext == 'f4m' and platform != 'flash'):\n                continue\n\n            if ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    media_url, video_id, 'mp4', 'm3u8_native',\n                    m3u8_id='hls', fatal=False))\n            elif ext == 'f4m':\n                manifest_url = update_url_query(\n                    media_url.replace('manifest#live_hds.f4m', 'manifest.f4m'),\n                  {'hdcore': '3.7.0', 'plugin': 'aasp-3.7.0.39.44'})\n                formats.extend(self._extract_f4m_formats(\n                    manifest_url, video_id, f4m_id='hds', fatal=False))\n            else:\n                bitrate = int_or_none(xpath_text(relinker, 'bitrate'))\n                formats.append({\n                    'url': media_url,\n                    'tbr': bitrate if bitrate > 0 else None,\n                    'format_id': 'http-%d' % bitrate if bitrate > 0 else 'http',\n              })\n\n        if not formats and geoprotection is True:\n            self.raise_geo_restricted(countries=self._GEO_COUNTRIES)\n\n        return dict((k, v) for k, v in {\n            'is_live': is_live,\n            'duration': duration,\n            'formats': formats,\n      }.items() if v is not None)\n\n    @staticmethod\n    def _extract_subtitles(url, subtitle_url):\n        subtitles = {}\n        if subtitle_url and isinstance(subtitle_url, compat_str):\n            subtitle_url = urljoin(url, subtitle_url)\n            STL_EXT = '.stl'\n            SRT_EXT = '.srt'\n            subtitles['it'] = [{\n                'ext': 'stl',\n                'url': subtitle_url,\n          }]\n            if subtitle_url.endswith(STL_EXT):\n                srt_url = subtitle_url[:-len(STL_EXT)] + SRT_EXT\n                subtitles['it'].append({\n                    'ext': 'srt',\n                    'url': srt_url,\n              })\n        return subtitles\n\n\nclass RaiPlayIE(RaiBaseIE):\n    _VALID_URL = r'(?P<url>https?://(?:www\\.)?raiplay\\.it/.+?-(?P<id>%s)\\.html)' % RaiBaseIE._UUID_RE\n    _TESTS = [{\n        'url': 'http://www.raiplay.it/video/2016/10/La-Casa-Bianca-e06118bb-59a9-4636-b914-498e4cfd2c66.html?source=twitter',\n        'md5': '340aa3b7afb54bfd14a8c11786450d76',\n        'info_dict': {\n            'id': 'e06118bb-59a9-4636-b914-498e4cfd2c66',\n            'ext': 'mp4',\n            'title': 'La Casa Bianca',\n            'alt_title': 'S2016 - Puntata del 23/10/2016',\n            'description': 'md5:a09d45890850458077d1f68bb036e0a5',\n            'thumbnail': r're:^https?://.*\\.jpg$',\n            'uploader': 'Rai 3',\n            'creator': 'Rai 3',\n            'duration': 3278,\n            'timestamp': 1477764300,\n            'upload_date': '20161029',\n            'series': 'La Casa Bianca',\n            'season': '2016',\n      }\n  } {\n        'url': 'http://www.raiplay.it/video/2014/04/Report-del-07042014-cb27157f-9dd0-4aee-b788-b1f67643a391.html',\n        'md5': '8970abf8caf8aef4696e7b1f2adfc696',\n        'info_dict': {\n            'id': 'cb27157f-9dd0-4aee-b788-b1f67643a391',\n            'ext': 'mp4',\n            'title': 'Report del 07/04/2014',\n            'alt_title': 'S2013/14 - Puntata del 07/04/2014',\n            'description': 'md5:f27c544694cacb46a078db84ec35d2d9',\n            'thumbnail': r're:^https?://.*\\.jpg$',\n            'uploader': 'Rai 5',\n            'creator': 'Rai 5',\n            'duration': 6160,\n            'series': 'Report',\n            'season_number': 5,\n            'season': '2013/14',\n      }\n        'params': {\n            'skip_download': True,\n      }\n  } {\n        'url': 'http://www.raiplay.it/video/2016/11/gazebotraindesi-efebe701-969c-4593-92f3-285f0d1ce750.html?',\n        'only_matching': True,\n  }]\n\n    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        url, video_id = mobj.group('url', 'id')\n\n        media = self._download_json(\n            '%s?json' % url, video_id, 'Downloading video JSON')\n\n        title = media['name']\n\n        video = media['video']\n\n        relinker_info = self._extract_relinker_info(video['contentUrl'], video_id)\n        self._sort_formats(relinker_info['formats'])\n\n        thumbnails = []\n        if 'images' in media:\n            for _, value in media.get('images').items():\n                if value:\n                    thumbnails.append({\n                        'url': value.replace('[RESOLUTION]', '600x400')\n                  })\n\n        timestamp = unified_timestamp(try_get(\n            media, lambda x: x['availabilities'][0]['start'], compat_str))\n\n        subtitles = self._extract_subtitles(url, video.get('subtitles'))\n\n        info = {\n            'id': video_id,\n            'title': self._live_title(title) if relinker_info.get(\n                'is_live') else title,\n            'alt_title': media.get('subtitle'),\n            'description': media.get('description'),\n            'uploader': strip_or_none(media.get('channel')),\n            'creator': strip_or_none(media.get('editor')),\n            'duration': parse_duration(video.get('duration')),\n            'timestamp': timestamp,\n            'thumbnails': thumbnails,\n            'series': try_get(\n                media, lambda x: x['isPartOf']['name'], compat_str),\n            'season_number': int_or_none(try_get(\n                media, lambda x: x['isPartOf']['numeroStagioni'])),\n            'season': media.get('stagione') or None,\n            'subtitles': subtitles,\n      }\n\n        info.update(relinker_info)\n        return info\n\n\nclass RaiPlayLiveIE(RaiBaseIE):\n    _VALID_URL = r'https?://(?:www\\.)?raiplay\\.it/dirette/(?P<id>[^/?#&]+)'\n    _TEST = {\n        'url': 'http://www.raiplay.it/dirette/rainews24',\n        'info_dict': {\n            'id': 'd784ad40-e0ae-4a69-aa76-37519d238a9c',\n            'display_id': 'rainews24',\n            'ext': 'mp4',\n            'title': 're:^Diretta di Rai News 24 [0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}$',\n            'description': 'md5:6eca31500550f9376819f174e5644754',\n            'uploader': 'Rai News 24',\n            'creator': 'Rai News 24',\n            'is_live': True,\n      }\n        'params': {\n            'skip_download': True,\n      }\n  }\n\n    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        video_id = self._search_regex(\n            r'data-uniquename=[\"\\']ContentItem-(%s)' % RaiBaseIE._UUID_RE,\n            webpage, 'content id')\n\n        return {\n            '_type': 'url_transparent',\n            'ie_key': RaiPlayIE.ie_key(),\n            'url': 'http://www.raiplay.it/dirette/ContentItem-%s.html' % video_id,\n            'id': video_id,\n            'display_id': display_id,\n      }\n\n\nclass RaiIE(RaiBaseIE):\n    _VALID_URL = r'https?://[^/]+\\.(?:rai\\.(?:it|tv)|rainews\\.it)/dl/.+?-(?P<id>%s)(?:-.+?)?\\.html' % RaiBaseIE._UUID_RE\n    _TESTS = [{\n        # var uniquename = \"ContentItem-...\"\n        # data-id=\"ContentItem-...\"\n        'url': 'http://www.raisport.rai.it/dl/raiSport/media/rassegna-stampa-04a9f4bd-b563-40cf-82a6-aad3529cb4a9.html',\n        'info_dict': {\n            'id': '04a9f4bd-b563-40cf-82a6-aad3529cb4a9',\n            'ext': 'mp4',\n            'title': 'TG PRIMO TEMPO',\n            'thumbnail': r're:^https?://.*\\.jpg$',\n            'duration': 1758,\n            'upload_date': '20140612',\n      }\n  } {\n        # with ContentItem in many metas\n        'url': 'http://www.rainews.it/dl/rainews/media/Weekend-al-cinema-da-Hollywood-arriva-il-thriller-di-Tate-Taylor-La-ragazza-del-treno-1632c009-c843-4836-bb65-80c33084a64b.html',\n        'info_dict': {\n            'id': '1632c009-c843-4836-bb65-80c33084a64b',\n            'ext': 'mp4',\n            'title': 'Weekend al cinema, da Hollywood arriva il thriller di Tate Taylor \"La ragazza del treno\"',\n            'description': 'I film in uscita questa settimana.',\n            'thumbnail': r're:^https?://.*\\.png$',\n            'duration': 833,\n            'upload_date': '20161103',\n      }\n  } {\n        # with ContentItem in og:url\n        'url': 'http://www.rai.it/dl/RaiTV/programmi/media/ContentItem-efb17665-691c-45d5-a60c-5301333cbb0c.html',\n        'md5': '11959b4e44fa74de47011b5799490adf',\n        'info_dict': {\n            'id': 'efb17665-691c-45d5-a60c-5301333cbb0c',\n            'ext': 'mp4',\n            'title': 'TG1 ore 20:00 del 03/11/2016',\n            'description': 'TG1 edizione integrale ore 20:00 del giorno 03/11/2016',\n            'thumbnail': r're:^https?://.*\\.jpg$',\n            'duration': 2214,\n            'upload_date': '20161103',\n      }\n  } {\n        # drawMediaRaiTV(...)\n        'url': 'http://www.report.rai.it/dl/Report/puntata/ContentItem-0c7a664b-d0f4-4b2c-8835-3f82e46f433e.html',\n        'md5': '2dd727e61114e1ee9c47f0da6914e178',\n        'info_dict': {\n            'id': '59d69d28-6bb6-409d-a4b5-ed44096560af',\n            'ext': 'mp4',\n            'title': 'Il pacco',\n            'description': 'md5:4b1afae1364115ce5d78ed83cd2e5b3a',\n            'thumbnail': r're:^https?://.*\\.jpg$',\n            'upload_date': '20141221',\n      }\n  } {\n        # initEdizione('ContentItem-...'\n        'url': 'http://www.tg1.rai.it/dl/tg1/2010/edizioni/ContentSet-9b6e0cba-4bef-4aef-8cf0-9f7f665b7dfb-tg1.html?item=undefined',\n        'info_dict': {\n            'id': 'c2187016-8484-4e3a-8ac8-35e475b07303',\n            'ext': 'mp4',\n            'title': r're:TG1 ore \\d{2}:\\d{2} del \\d{2}/\\d{2}/\\d{4}',\n            'duration': 2274,\n            'upload_date': '20170401',\n      }\n        'skip': 'Changes daily',\n  } {\n        # HDS live stream with only relinker URL\n        'url': 'http://www.rai.tv/dl/RaiTV/dirette/PublishingBlock-1912dbbf-3f96-44c3-b4cf-523681fbacbc.html?channel=EuroNews',\n        'info_dict': {\n            'id': '1912dbbf-3f96-44c3-b4cf-523681fbacbc',\n            'ext': 'flv',\n            'title': 'EuroNews',\n      }\n        'params': {\n            'skip_download': True,\n      }\n  } {\n        # HLS live stream with ContentItem in og:url\n        'url': 'http://www.rainews.it/dl/rainews/live/ContentItem-3156f2f2-dc70-4953-8e2f-70d7489d4ce9.html',\n        'info_dict': {\n            'id': '3156f2f2-dc70-4953-8e2f-70d7489d4ce9',\n            'ext': 'mp4',\n            'title': 'La diretta di Rainews24',\n      }\n        'params': {\n            'skip_download': True,\n      }\n  }]\n\n    def _extract_from_content_id(self, content_id, url):\n        media = self._download_json(\n            'http://www.rai.tv/dl/RaiTV/programmi/media/ContentItem-%s.html?json' % content_id,\n            content_id, 'Downloading video JSON')\n\n        title = media['name'].strip()\n\n        media_type = media['type']\n        if 'Audio' in media_type:\n            relinker_info = {\n                'formats': {\n                    'format_id': media.get('formatoAudio'),\n                    'url': media['audioUrl'],\n                    'ext': media.get('formatoAudio'),\n              }\n          }\n        elif 'Video' in media_type:\n            relinker_info = self._extract_relinker_info(media['mediaUri'], content_id)\n        else:\n            raise ExtractorError('not a media file')\n\n        self._sort_formats(relinker_info['formats'])\n\n        thumbnails = []\n        for image_type in ('image', 'image_medium', 'image_300'):\n            thumbnail_url = media.get(image_type)\n            if thumbnail_url:\n                thumbnails.append({\n                    'url': compat_urlparse.urljoin(url, thumbnail_url),\n              })\n\n        subtitles = self._extract_subtitles(url, media.get('subtitlesUrl'))\n\n        info = {\n            'id': content_id,\n            'title': title,\n            'description': strip_or_none(media.get('desc')),\n            'thumbnails': thumbnails,\n            'uploader': media.get('author'),\n            'upload_date': unified_strdate(media.get('date')),\n            'duration': parse_duration(media.get('length')),\n            'subtitles': subtitles,\n      }\n\n        info.update(relinker_info)\n\n        return info\n\n    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        content_item_id = None\n\n        content_item_url = self._html_search_meta(\n            ('og:url', 'og:video', 'og:video:secure_url', 'twitter:url',\n             'twitter:player', 'jsonlink'), webpage, default=None)\n        if content_item_url:\n            content_item_id = self._search_regex(\n                r'ContentItem-(%s)' % self._UUID_RE, content_item_url,\n                'content item id', default=None)\n\n        if not content_item_id:\n            content_item_id = self._search_regex(\n                r'''(?x)\n                    (?:\n                        (?:initEdizione|drawMediaRaiTV)\\(|\n                        <(?:[^>]+\\bdata-id|var\\s+uniquename)=\n                    )\n                    ([\"\\'])\n                    (?:(?!\\1).)*\\bContentItem-(?P<id>%s)\n                ''' % self._UUID_RE,\n                webpage, 'content item id', default=None, group='id')\n\n        content_item_ids = set()\n        if content_item_id:\n            content_item_ids.add(content_item_id)\n        if video_id not in content_item_ids:\n            content_item_ids.add(video_id)\n\n        for content_item_id in content_item_ids:\n            try:\n                return self._extract_from_content_id(content_item_id, url)\n            except GeoRestrictedError:\n                raise\n            except ExtractorError:\n                pass\n\n        relinker_url = self._search_regex(\n            r'''(?x)\n                (?:\n                    var\\s+videoURL|\n                    mediaInfo\\.mediaUri\n                )\\s*=\\s*\n                ([\\'\"])\n                (?P<url>\n                    (?:https?:)?\n                    //mediapolis(?:vod)?\\.rai\\.it/relinker/relinkerServlet\\.htm\\?\n                    (?:(?!\\1).)*\\bcont=(?:(?!\\1).)+)\\1\n            ''',\n            webpage, 'relinker URL', group='url')\n\n        relinker_info = self._extract_relinker_info(\n            urljoin(url, relinker_url), video_id)\n        self._sort_formats(relinker_info['formats'])\n\n        title = self._search_regex(\n            r'var\\s+videoTitolo\\s*=\\s*([\\'\"])(?P<title>[^\\'\"]+)\\1',\n            webpage, 'title', group='title',\n            default=None) or self._og_search_title(webpage)\n\n        info = {\n            'id': video_id,\n            'title': title,\n      }\n\n        info.update(relinker_info)\n\n        return info\n" }
{ "repo_name": "mhuwiler/rootauto", "ref": "refs/heads/mhuwiler", "path": "tutorials/pyroot/tree.py", "content": "## \\file\n## \\ingroup tutorial_pyroot\n## \\notebook\n## This macro displays the Tree data structures\n##\n## \\macro_image\n## \\macro_code\n##\n## \\author Wim Lavrijsen\n\nfrom ROOT import TCanvas, TPaveLabel, TPaveText, TPavesText, TText\nfrom ROOT import TArrow, TLine\nfrom ROOT import gROOT, gBenchmark\n\n#gROOT.Reset()\n\nc1 = TCanvas('c1','Tree Data Structure',200,10,750,940)\nc1.Range(0,-0.1,1,1.15)\n\ngBenchmark.Start('tree')\n\nbranchcolor = 26\nleafcolor   = 30\nbasketcolor = 42\noffsetcolor = 43\n#title = TPaveLabel(.3,1.05,.8,1.13,c1.GetTitle())\ntitle = TPaveLabel(.3,1.05,.8,1.13,'Tree Data Structure')\ntitle.SetFillColor(16)\ntitle.Draw()\ntree = TPaveText(.01,.75,.15,1.00)\ntree.SetFillColor(18)\ntree.SetTextAlign(12)\ntnt = tree.AddText('Tree')\ntnt.SetTextAlign(22)\ntnt.SetTextSize(0.030)\ntree.AddText('fScanField')\ntree.AddText('fMaxEventLoop')\ntree.AddText('fMaxVirtualSize')\ntree.AddText('fEntries')\ntree.AddText('fDimension')\ntree.AddText('fSelectedRows')\ntree.Draw()\nfarm = TPavesText(.01,1.02,.15,1.1,9,'tr')\ntfarm = farm.AddText('CHAIN')\ntfarm.SetTextSize(0.024)\nfarm.AddText('Collection')\nfarm.AddText('of Trees')\nfarm.Draw()\nlink = TLine(.15,.92,.80,.92)\nlink.SetLineWidth(2)\nlink.SetLineColor(1)\nlink.Draw()\nlink.DrawLine(.21,.87,.21,.275)\nlink.DrawLine(.23,.87,.23,.375)\nlink.DrawLine(.25,.87,.25,.775)\nlink.DrawLine(.41,.25,.41,-.025)\nlink.DrawLine(.43,.25,.43,.075)\nlink.DrawLine(.45,.25,.45,.175)\nbranch0 = TPaveLabel(.20,.87,.35,.97,'Branch 0')\nbranch0.SetTextSize(0.35)\nbranch0.SetFillColor(branchcolor)\nbranch0.Draw()\nbranch1 = TPaveLabel(.40,.87,.55,.97,'Branch 1')\nbranch1.SetTextSize(0.35)\nbranch1.SetFillColor(branchcolor)\nbranch1.Draw()\nbranch2 = TPaveLabel(.60,.87,.75,.97,'Branch 2')\nbranch2.SetTextSize(0.35)\nbranch2.SetFillColor(branchcolor)\nbranch2.Draw()\nbranch3 = TPaveLabel(.80,.87,.95,.97,'Branch 3')\nbranch3.SetTextSize(0.35)\nbranch3.SetFillColor(branchcolor)\nbranch3.Draw()\nleaf0 = TPaveLabel(.4,.75,.5,.8,'Leaf 0')\nleaf0.SetFillColor(leafcolor)\nleaf0.Draw()\nleaf1 = TPaveLabel(.6,.75,.7,.8,'Leaf 1')\nleaf1.SetFillColor(leafcolor)\nleaf1.Draw()\nleaf2 = TPaveLabel(.8,.75,.9,.8,'Leaf 2')\nleaf2.SetFillColor(leafcolor)\nleaf2.Draw()\nfirstevent = TPaveText(.4,.35,.9,.4)\nfirstevent.AddText('First event of each basket')\nfirstevent.AddText('Array of fMaxBaskets Integers')\nfirstevent.SetFillColor(basketcolor)\nfirstevent.Draw()\nbasket0 = TPaveLabel(.4,.25,.5,.3,'Basket 0')\nbasket0.SetFillColor(basketcolor)\nbasket0.Draw()\nbasket1 = TPaveLabel(.6,.25,.7,.3,'Basket 1')\nbasket1.SetFillColor(basketcolor)\nbasket1.Draw()\nbasket2 = TPaveLabel(.8,.25,.9,.3,'Basket 2')\nbasket2.SetFillColor(basketcolor)\nbasket2.Draw()\n\noffset = TPaveText(.55,.15,.9,.2)\noffset.AddText('Offset of events in fBuffer')\noffset.AddText('Array of fEventOffsetLen Integers')\noffset.AddText('(if variable length structure)')\noffset.SetFillColor(offsetcolor)\noffset.Draw()\nbuffer = TPaveText(.55,.05,.9,.1)\nbuffer.AddText('Basket buffer')\nbuffer.AddText('Array of fBasketSize chars')\nbuffer.SetFillColor(offsetcolor)\nbuffer.Draw()\nzipbuffer = TPaveText(.55,-.05,.75,.0)\nzipbuffer.AddText('Basket compressed buffer')\nzipbuffer.AddText('(if compression)')\nzipbuffer.SetFillColor(offsetcolor)\nzipbuffer.Draw()\nar1 = TArrow()\nar1.SetLineWidth(2)\nar1.SetLineColor(1)\nar1.SetFillStyle(1001)\nar1.SetFillColor(1)\nar1.DrawArrow(.21,.275,.39,.275,0.015,'|>')\nar1.DrawArrow(.23,.375,.39,.375,0.015,'|>')\nar1.DrawArrow(.25,.775,.39,.775,0.015,'|>')\nar1.DrawArrow(.50,.775,.59,.775,0.015,'|>')\nar1.DrawArrow(.70,.775,.79,.775,0.015,'|>')\nar1.DrawArrow(.50,.275,.59,.275,0.015,'|>')\nar1.DrawArrow(.70,.275,.79,.275,0.015,'|>')\nar1.DrawArrow(.45,.175,.54,.175,0.015,'|>')\nar1.DrawArrow(.43,.075,.54,.075,0.015,'|>')\nar1.DrawArrow(.41,-.025,.54,-.025,0.015,'|>')\nldot = TLine(.95,.92,.99,.92)\nldot.SetLineStyle(3)\nldot.Draw()\nldot.DrawLine(.9,.775,.99,.775)\nldot.DrawLine(.9,.275,.99,.275)\nldot.DrawLine(.55,.05,.55,0)\nldot.DrawLine(.9,.05,.75,0)\npname = TText(.46,.21,'fEventOffset')\npname.SetTextFont(72)\npname.SetTextSize(0.018)\npname.Draw()\npname.DrawText(.44,.11,'fBuffer')\npname.DrawText(.42,.01,'fZipBuffer')\npname.DrawText(.26,.81,'fLeaves = TObjArray of TLeaf')\npname.DrawText(.24,.40,'fBasketEvent')\npname.DrawText(.22,.31,'fBaskets = TObjArray of TBasket')\npname.DrawText(.20,1.0,'fBranches = TObjArray of TBranch')\nntleaf = TPaveText(0.30,.42,.62,.7)\nntleaf.SetTextSize(0.014)\nntleaf.SetFillColor(leafcolor)\nntleaf.SetTextAlign(12)\nntleaf.AddText('fLen: number of fixed elements')\nntleaf.AddText('fLenType: number of bytes of data type')\nntleaf.AddText('fOffset: relative to Leaf0-fAddress')\nntleaf.AddText('fNbytesIO: number of bytes used for I/O')\nntleaf.AddText('fIsPointer: True if pointer')\nntleaf.AddText('fIsRange: True if leaf has a range')\nntleaf.AddText('fIsUnsigned: True if unsigned')\nntleaf.AddText('*fLeafCount: points to Leaf counter')\nntleaf.AddText(' ')\nntleaf.AddLine(0,0,0,0)\nntleaf.AddText('fName = Leaf name')\nntleaf.AddText('fTitle = Leaf type (see Type codes)')\nntleaf.Draw()\ntype = TPaveText(.65,.42,.95,.7)\ntype.SetTextAlign(12)\ntype.SetFillColor(leafcolor)\ntype.AddText(' ')\ntype.AddText('C : a character string')\ntype.AddText('B : an 8 bit signed integer')\ntype.AddText('b : an 8 bit unsigned integer')\ntype.AddText('S : a 16 bit signed short integer')\ntype.AddText('s : a 16 bit unsigned short integer')\ntype.AddText('I : a 32 bit signed integer')\ntype.AddText('i : a 32 bit unsigned integer')\ntype.AddText('F : a 32 bit floating point')\ntype.AddText('D : a 64 bit floating point')\ntype.AddText('TXXXX : a class name TXXXX')\ntype.Draw()\ntypecode = TPaveLabel(.7,.68,.9,.72,'fType codes')\ntypecode.SetFillColor(leafcolor)\ntypecode.Draw()\nldot.DrawLine(.4,.75,.30,.7)\nldot.DrawLine(.5,.75,.62,.7)\nntbasket = TPaveText(0.02,-0.07,0.35,.25)\nntbasket.SetFillColor(basketcolor)\nntbasket.SetTextSize(0.014)\nntbasket.SetTextAlign(12)\nntbasket.AddText('fNbytes: Size of compressed Basket')\nntbasket.AddText('fObjLen: Size of uncompressed Basket')\nntbasket.AddText('fDatime: Date/Time when written to store')\nntbasket.AddText('fKeylen: Number of bytes for the key')\nntbasket.AddText('fCycle : Cycle number')\nntbasket.AddText('fSeekKey: Pointer to Basket on file')\nntbasket.AddText('fSeekPdir: Pointer to directory on file')\nntbasket.AddText(\"fClassName: 'TBasket'\")\nntbasket.AddText('fName: Branch name')\nntbasket.AddText('fTitle: Tree name')\nntbasket.AddText(' ')\nntbasket.AddLine(0,0,0,0)\nntbasket.AddText('fNevBuf: Number of events in Basket')\nntbasket.AddText('fLast: pointer to last used byte in Basket')\nntbasket.Draw()\nldot.DrawLine(.4,.3,0.02,0.25)\nldot.DrawLine(.5,.25,0.35,-.07)\nldot.DrawLine(.5,.3,0.35,0.25)\nntbranch = TPaveText(0.02,0.40,0.18,0.68)\nntbranch.SetFillColor(branchcolor)\nntbranch.SetTextSize(0.015)\nntbranch.SetTextAlign(12)\nntbranch.AddText('fBasketSize')\nntbranch.AddText('fEventOffsetLen')\nntbranch.AddText('fMaxBaskets')\nntbranch.AddText('fEntries')\nntbranch.AddText('fAddress of Leaf0')\nntbranch.AddText(' ')\nntbranch.AddLine(0,0,0,0)\nntbranch.AddText('fName: Branchname')\nntbranch.AddText('fTitle: leaflist')\nntbranch.Draw()\nldot.DrawLine(.2,.97,.02,.68)\nldot.DrawLine(.35,.97,.18,.68)\nldot.DrawLine(.35,.87,.18,.40)\nbasketstore = TPavesText(.8,-0.088,0.952,-0.0035,7,'tr')\nbasketstore.SetFillColor(28)\nbasketstore.AddText('Baskets')\nbasketstore.AddText('Stores')\nbasketstore.Draw()\nc1.Update()\n\ngBenchmark.Show('tree')\n" }
{ "repo_name": "schleichdi2/OPENNFR-6.3-CORE", "ref": "refs/heads/nextp3-ssl111", "path": "bitbake/lib/toaster/toastermain/settings_test.py", "content": "#\n# BitBake Toaster Implementation\n#\n# Copyright (C) 2016        Intel Corporation\n#\n# SPDX-License-Identifier: GPL-2.0-only\n#\n\n# Django settings for Toaster project.\n\n# Settings overlay to use for running tests\n# DJANGO_SETTINGS_MODULE=toastermain.settings-test\n\nfrom toastermain.settings import *\n\nDEBUG = True\nTEMPLATE_DEBUG = DEBUG\n\nDATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.sqlite3',\n        'NAME': '/tmp/toaster-test-db.sqlite',\n        'TEST': {\n            'ENGINE': 'django.db.backends.sqlite3',\n            'NAME': '/tmp/toaster-test-db.sqlite',\n      }\n  }\n}\n" }
{ "repo_name": "cselis86/edx-platform", "ref": "refs/heads/installer", "path": "openedx/core/djangoapps/course_groups/management/commands/remove_users_from_multiple_cohorts.py", "content": "\"\"\"\nScript for removing users with multiple cohorts of a course from cohorts\nto ensure user's uniqueness for a course cohorts\n\"\"\"\nfrom django.contrib.auth.models import User\nfrom django.core.management.base import BaseCommand\nfrom django.db.models import Count\n\nfrom openedx.core.djangoapps.course_groups.models import CourseUserGroup\n\n\nclass Command(BaseCommand):\n    \"\"\"\n    Remove users with multiple cohorts of a course from all cohorts\n    \"\"\"\n    help = 'Remove all users from multiple cohorts (except one) of each course'\n\n    def handle(self, *args, **options):\n        \"\"\"\n        Execute the command\n        \"\"\"\n        # Get entries of cohorts which have same user added multiple times for a single course\n        multiple_objects_cohorts = CourseUserGroup.objects.filter(group_type=CourseUserGroup.COHORT).\\\n            values_list('users', 'course_id').annotate(user_count=Count('users')).filter(user_count__gt=1).\\\n            order_by('users')\n        multiple_objects_cohorts_count = multiple_objects_cohorts.count()\n        multiple_course_cohorts_users = set(multiple_objects_cohorts.values_list('users', flat=True))\n        users_failed_to_cleanup = []\n\n        for user in User.objects.filter(id__in=multiple_course_cohorts_users):\n            print u\"Removing user with id '{0}' from cohort groups\".format(user.id)\n            try:\n                # remove user from only cohorts\n                user.course_groups.remove(*user.course_groups.filter(group_type=CourseUserGroup.COHORT))\n            except AttributeError as err:\n                users_failed_to_cleanup.append(user.email)\n                print u\"Failed to remove user with id {0} from cohort groups, error: {1}\".format(user.id, err)\n\n        print \"=\" * 80\n        print u\"=\" * 30 + u\"> Cohorts summary\"\n        print(\n            u\"Total number of CourseUserGroup of type '{0}' with multiple users: {1}\".format(\n                CourseUserGroup.COHORT, multiple_objects_cohorts_count\n            )\n        )\n        print(\n            u\"Total number of unique users with multiple course cohorts: {0}\".format(\n                len(multiple_course_cohorts_users)\n            )\n        )\n        print(\n            u\"Users which failed on cohorts cleanup [{0}]: [{1}]\".format(\n                len(users_failed_to_cleanup), (', '.join(users_failed_to_cleanup))\n            )\n        )\n        print \"=\" * 80\n" }
{ "repo_name": "thinker3197/zeroclickinfo-fathead", "ref": "refs/heads/jquery-fathead-issue319", "path": "lib/fathead/firefox_about_config/parse.py", "content": "#!/usr/bin/env python2\n\nfrom BeautifulSoup import BeautifulSoup, NavigableString\nimport urllib\nimport string\nimport re\n\n\nclass Entry(object):\n    def __init__(self, name, value, description, url):\n        self.name = name\n        self.value = value\n        self.description = description\n        self.url = url\n\n    def __str__(self):\n        fields = [\n                self.name,              # title\n                'A',                    # type\n                '',                     # redirect\n                '',                     # otheruses\n                '',                     # categories\n                '',                     # references\n                '',                     # see_also\n                '',                     # further_reading\n                '',                     # external_links\n                '',                     # disambiguation\n                '',                     # images\n                self.description,       # abstract\n                self.url                # source_url\n                ]\n        return '%s' % ('\\t'.join(fields))\n\n\nclass Parser(object):\n    def __init__(self, input='download/About:config_entries'):\n        self.soup = BeautifulSoup(open(input))\n        # Requires trailing / for relative link replacement\n        self.baseURL = \"http://kb.mozillazine.org/\"\n\n    def findEntries(self):\n        self.entries = []\n        headers = map(lambda x: x.string, self.soup.findAll('h1')[2:])\n        table = self.soup.findAll('div', id=\"bodyContent\")[0]\n        for table in table.findAll('table'):\n            header = True\n            for tr in table.findAll('tr'):\n                if header:\n                    header = False\n                    continue\n                i = 0\n                for th in tr.findAll('td'):\n                    description = ''\n                    if i == 0:\n                        name = ''.join(th.b.findAll(text=True)).replace(' ','')\n                        anchor = string.capitalize(urllib.quote(name.split('.')[0])) + \".\"\n                        if anchor in headers:\n                            url = self.baseURL + 'About:config_entries#' + anchor\n                        else:\n                            url = self.baseURL + 'About:config_entries'\n                    elif i == 1:\n                        value = th.text\n                    elif i == 2:\n                        if value:\n                            article = 'a'\n                            if value[0] == 'I': article += 'n'\n                            optionType = \"it accepts \" + article + \" \" + value.lower() + \".\"\n                        synopsis = '\"' + name + '\"'  + ' is a configuration option ' \\\n                                'for the Firefox web browser; ' + optionType + \"<br>\"\n                        for tag in th.findAll('br'):\n                            tag.insert(0, NavigableString(\"\\n\"))\n                        description = ''.join(th.findAll(text=True))\n                        description = description.rstrip().replace('\\n', '<br>').strip()\n                        expandedURL = 'href=\"' + self.baseURL\n                        description = description.replace('href=\"/', expandedURL)\n                        description = re.sub('<\\s*b\\s*>', '<i>', description)\n                        description = re.sub('<\\s*/\\s*b\\s*>', '</i>', description)\n                        description = '<blockquote>' + description + '</blockquote>'\n                        description = synopsis + description\n                        i = -1\n                        self.entries.append(Entry(name, value, description.strip(), url))\n                    i += 1\n\n\nif __name__ == \"__main__\":\n    parser = Parser()\n    parser.findEntries()\n    with open('output.txt', 'w') as file:\n        for entry in parser.entries:\n            file.write(entry.__str__().encode('UTF-8') + '\\n')\n" }
{ "repo_name": "hadesbox/luigi", "ref": "refs/heads/cloud-tasks", "path": "examples/foo.py", "content": "# -*- coding: utf-8 -*-\n#\n# Copyright 2012-2015 Spotify AB\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\nimport os\nimport shutil\nimport time\n\nimport luigi\n\n\nclass MyExternal(luigi.ExternalTask):\n\n    def complete(self):\n        return False\n\n\nclass Foo(luigi.Task):\n\n    def run(self):\n        print \"Running Foo\"\n\n    def requires(self):\n        #        yield MyExternal()\n        for i in xrange(10):\n            yield Bar(i)\n\n\nclass Bar(luigi.Task):\n    num = luigi.IntParameter()\n\n    def run(self):\n        time.sleep(1)\n        self.output().open('w').close()\n\n    def output(self):\n        \"\"\"\n        Returns the target output for this task.\n\n        :return: the target output for this task.\n        :rtype: object (:py:class:`~luigi.target.Target`)\n        \"\"\"\n        time.sleep(1)\n        return luigi.LocalTarget('/tmp/bar/%d' % self.num)\n\n\nif __name__ == \"__main__\":\n    if os.path.exists('/tmp/bar'):\n        shutil.rmtree('/tmp/bar')\n\n    luigi.run(['--task', 'Foo', '--workers', '2'], use_optparse=True)\n" }
{ "repo_name": "Linaro/lava-dispatcher", "ref": "refs/heads/release", "path": "lava_dispatcher/utils/decorator.py", "content": "# -*- coding: utf-8 -*-\n#\n# Copyright (C) 2017 Linaro Limited\n#\n# Author: Remi Duraffort <remi.duraffort@linaro.org>\n#\n# This file is part of LAVA Dispatcher.\n#\n# LAVA Dispatcher is free software; you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation; either version 2 of the License, or\n# (at your option) any later version.\n#\n# LAVA Dispatcher is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program; if not, see <http://www.gnu.org/licenses>.\n\nfrom functools import wraps\n\n\ndef replace_exception(cls_from, cls_to):\n    def replace_exception_wrapper(func):\n        @wraps(func)\n        def function_wrapper(*args, **kwargs):\n            try:\n                return func(*args, **kwargs)\n            except cls_from as exc:\n                raise cls_to(exc)\n        return function_wrapper\n    return replace_exception_wrapper\n" }
{ "repo_name": "ubc/edx-platform", "ref": "refs/heads/release", "path": "openedx/core/djangoapps/course_groups/management/commands/remove_users_from_multiple_cohorts.py", "content": "\"\"\"\nScript for removing users with multiple cohorts of a course from cohorts\nto ensure user's uniqueness for a course cohorts\n\"\"\"\nfrom django.contrib.auth.models import User\nfrom django.core.management.base import BaseCommand\nfrom django.db.models import Count\n\nfrom openedx.core.djangoapps.course_groups.models import CourseUserGroup\n\n\nclass Command(BaseCommand):\n    \"\"\"\n    Remove users with multiple cohorts of a course from all cohorts\n    \"\"\"\n    help = 'Remove all users from multiple cohorts (except one) of each course'\n\n    def handle(self, *args, **options):\n        \"\"\"\n        Execute the command\n        \"\"\"\n        # Get entries of cohorts which have same user added multiple times for a single course\n        multiple_objects_cohorts = CourseUserGroup.objects.filter(group_type=CourseUserGroup.COHORT).\\\n            values_list('users', 'course_id').annotate(user_count=Count('users')).filter(user_count__gt=1).\\\n            order_by('users')\n        multiple_objects_cohorts_count = multiple_objects_cohorts.count()\n        multiple_course_cohorts_users = set(multiple_objects_cohorts.values_list('users', flat=True))\n        users_failed_to_cleanup = []\n\n        for user in User.objects.filter(id__in=multiple_course_cohorts_users):\n            print u\"Removing user with id '{0}' from cohort groups\".format(user.id)\n            try:\n                # remove user from only cohorts\n                user.course_groups.remove(*user.course_groups.filter(group_type=CourseUserGroup.COHORT))\n            except AttributeError as err:\n                users_failed_to_cleanup.append(user.email)\n                print u\"Failed to remove user with id {0} from cohort groups, error: {1}\".format(user.id, err)\n\n        print \"=\" * 80\n        print u\"=\" * 30 + u\"> Cohorts summary\"\n        print(\n            u\"Total number of CourseUserGroup of type '{0}' with multiple users: {1}\".format(\n                CourseUserGroup.COHORT, multiple_objects_cohorts_count\n            )\n        )\n        print(\n            u\"Total number of unique users with multiple course cohorts: {0}\".format(\n                len(multiple_course_cohorts_users)\n            )\n        )\n        print(\n            u\"Users which failed on cohorts cleanup [{0}]: [{1}]\".format(\n                len(users_failed_to_cleanup), (', '.join(users_failed_to_cleanup))\n            )\n        )\n        print \"=\" * 80\n" }
{ "repo_name": "chand3040/cloud_that", "ref": "refs/heads/named-release/cypress.rc", "path": "openedx/core/djangoapps/course_groups/management/commands/remove_users_from_multiple_cohorts.py", "content": "\"\"\"\nScript for removing users with multiple cohorts of a course from cohorts\nto ensure user's uniqueness for a course cohorts\n\"\"\"\nfrom django.contrib.auth.models import User\nfrom django.core.management.base import BaseCommand\nfrom django.db.models import Count\n\nfrom openedx.core.djangoapps.course_groups.models import CourseUserGroup\n\n\nclass Command(BaseCommand):\n    \"\"\"\n    Remove users with multiple cohorts of a course from all cohorts\n    \"\"\"\n    help = 'Remove all users from multiple cohorts (except one) of each course'\n\n    def handle(self, *args, **options):\n        \"\"\"\n        Execute the command\n        \"\"\"\n        # Get entries of cohorts which have same user added multiple times for a single course\n        multiple_objects_cohorts = CourseUserGroup.objects.filter(group_type=CourseUserGroup.COHORT).\\\n            values_list('users', 'course_id').annotate(user_count=Count('users')).filter(user_count__gt=1).\\\n            order_by('users')\n        multiple_objects_cohorts_count = multiple_objects_cohorts.count()\n        multiple_course_cohorts_users = set(multiple_objects_cohorts.values_list('users', flat=True))\n        users_failed_to_cleanup = []\n\n        for user in User.objects.filter(id__in=multiple_course_cohorts_users):\n            print u\"Removing user with id '{0}' from cohort groups\".format(user.id)\n            try:\n                # remove user from only cohorts\n                user.course_groups.remove(*user.course_groups.filter(group_type=CourseUserGroup.COHORT))\n            except AttributeError as err:\n                users_failed_to_cleanup.append(user.email)\n                print u\"Failed to remove user with id {0} from cohort groups, error: {1}\".format(user.id, err)\n\n        print \"=\" * 80\n        print u\"=\" * 30 + u\"> Cohorts summary\"\n        print(\n            u\"Total number of CourseUserGroup of type '{0}' with multiple users: {1}\".format(\n                CourseUserGroup.COHORT, multiple_objects_cohorts_count\n            )\n        )\n        print(\n            u\"Total number of unique users with multiple course cohorts: {0}\".format(\n                len(multiple_course_cohorts_users)\n            )\n        )\n        print(\n            u\"Users which failed on cohorts cleanup [{0}]: [{1}]\".format(\n                len(users_failed_to_cleanup), (', '.join(users_failed_to_cleanup))\n            )\n        )\n        print \"=\" * 80\n" }
{ "repo_name": "motion2015/a3", "ref": "refs/heads/a3", "path": "openedx/core/djangoapps/course_groups/management/commands/remove_users_from_multiple_cohorts.py", "content": "\"\"\"\nScript for removing users with multiple cohorts of a course from cohorts\nto ensure user's uniqueness for a course cohorts\n\"\"\"\nfrom django.contrib.auth.models import User\nfrom django.core.management.base import BaseCommand\nfrom django.db.models import Count\n\nfrom openedx.core.djangoapps.course_groups.models import CourseUserGroup\n\n\nclass Command(BaseCommand):\n    \"\"\"\n    Remove users with multiple cohorts of a course from all cohorts\n    \"\"\"\n    help = 'Remove all users from multiple cohorts (except one) of each course'\n\n    def handle(self, *args, **options):\n        \"\"\"\n        Execute the command\n        \"\"\"\n        # Get entries of cohorts which have same user added multiple times for a single course\n        multiple_objects_cohorts = CourseUserGroup.objects.filter(group_type=CourseUserGroup.COHORT).\\\n            values_list('users', 'course_id').annotate(user_count=Count('users')).filter(user_count__gt=1).\\\n            order_by('users')\n        multiple_objects_cohorts_count = multiple_objects_cohorts.count()\n        multiple_course_cohorts_users = set(multiple_objects_cohorts.values_list('users', flat=True))\n        users_failed_to_cleanup = []\n\n        for user in User.objects.filter(id__in=multiple_course_cohorts_users):\n            print u\"Removing user with id '{0}' from cohort groups\".format(user.id)\n            try:\n                # remove user from only cohorts\n                user.course_groups.remove(*user.course_groups.filter(group_type=CourseUserGroup.COHORT))\n            except AttributeError as err:\n                users_failed_to_cleanup.append(user.email)\n                print u\"Failed to remove user with id {0} from cohort groups, error: {1}\".format(user.id, err)\n\n        print \"=\" * 80\n        print u\"=\" * 30 + u\"> Cohorts summary\"\n        print(\n            u\"Total number of CourseUserGroup of type '{0}' with multiple users: {1}\".format(\n                CourseUserGroup.COHORT, multiple_objects_cohorts_count\n            )\n        )\n        print(\n            u\"Total number of unique users with multiple course cohorts: {0}\".format(\n                len(multiple_course_cohorts_users)\n            )\n        )\n        print(\n            u\"Users which failed on cohorts cleanup [{0}]: [{1}]\".format(\n                len(users_failed_to_cleanup), (', '.join(users_failed_to_cleanup))\n            )\n        )\n        print \"=\" * 80\n" }
{ "repo_name": "kamalx/edx-platform", "ref": "refs/heads/release", "path": "openedx/core/djangoapps/course_groups/management/commands/remove_users_from_multiple_cohorts.py", "content": "\"\"\"\nScript for removing users with multiple cohorts of a course from cohorts\nto ensure user's uniqueness for a course cohorts\n\"\"\"\nfrom django.contrib.auth.models import User\nfrom django.core.management.base import BaseCommand\nfrom django.db.models import Count\n\nfrom openedx.core.djangoapps.course_groups.models import CourseUserGroup\n\n\nclass Command(BaseCommand):\n    \"\"\"\n    Remove users with multiple cohorts of a course from all cohorts\n    \"\"\"\n    help = 'Remove all users from multiple cohorts (except one) of each course'\n\n    def handle(self, *args, **options):\n        \"\"\"\n        Execute the command\n        \"\"\"\n        # Get entries of cohorts which have same user added multiple times for a single course\n        multiple_objects_cohorts = CourseUserGroup.objects.filter(group_type=CourseUserGroup.COHORT).\\\n            values_list('users', 'course_id').annotate(user_count=Count('users')).filter(user_count__gt=1).\\\n            order_by('users')\n        multiple_objects_cohorts_count = multiple_objects_cohorts.count()\n        multiple_course_cohorts_users = set(multiple_objects_cohorts.values_list('users', flat=True))\n        users_failed_to_cleanup = []\n\n        for user in User.objects.filter(id__in=multiple_course_cohorts_users):\n            print u\"Removing user with id '{0}' from cohort groups\".format(user.id)\n            try:\n                # remove user from only cohorts\n                user.course_groups.remove(*user.course_groups.filter(group_type=CourseUserGroup.COHORT))\n            except AttributeError as err:\n                users_failed_to_cleanup.append(user.email)\n                print u\"Failed to remove user with id {0} from cohort groups, error: {1}\".format(user.id, err)\n\n        print \"=\" * 80\n        print u\"=\" * 30 + u\"> Cohorts summary\"\n        print(\n            u\"Total number of CourseUserGroup of type '{0}' with multiple users: {1}\".format(\n                CourseUserGroup.COHORT, multiple_objects_cohorts_count\n            )\n        )\n        print(\n            u\"Total number of unique users with multiple course cohorts: {0}\".format(\n                len(multiple_course_cohorts_users)\n            )\n        )\n        print(\n            u\"Users which failed on cohorts cleanup [{0}]: [{1}]\".format(\n                len(users_failed_to_cleanup), (', '.join(users_failed_to_cleanup))\n            )\n        )\n        print \"=\" * 80\n" }
{ "repo_name": "zzxuanyuan/root-compressor-dummy", "ref": "refs/heads/compressionbench", "path": "tutorials/pyroot/tree.py", "content": "## \\file\n## \\ingroup tutorial_pyroot\n## \\notebook\n## This macro displays the Tree data structures\n##\n## \\macro_image\n## \\macro_code\n##\n## \\author Wim Lavrijsen\n\nfrom ROOT import TCanvas, TPaveLabel, TPaveText, TPavesText, TText\nfrom ROOT import TArrow, TLine\nfrom ROOT import gROOT, gBenchmark\n\n#gROOT.Reset()\n\nc1 = TCanvas('c1','Tree Data Structure',200,10,750,940)\nc1.Range(0,-0.1,1,1.15)\n\ngBenchmark.Start('tree')\n\nbranchcolor = 26\nleafcolor   = 30\nbasketcolor = 42\noffsetcolor = 43\n#title = TPaveLabel(.3,1.05,.8,1.13,c1.GetTitle())\ntitle = TPaveLabel(.3,1.05,.8,1.13,'Tree Data Structure')\ntitle.SetFillColor(16)\ntitle.Draw()\ntree = TPaveText(.01,.75,.15,1.00)\ntree.SetFillColor(18)\ntree.SetTextAlign(12)\ntnt = tree.AddText('Tree')\ntnt.SetTextAlign(22)\ntnt.SetTextSize(0.030)\ntree.AddText('fScanField')\ntree.AddText('fMaxEventLoop')\ntree.AddText('fMaxVirtualSize')\ntree.AddText('fEntries')\ntree.AddText('fDimension')\ntree.AddText('fSelectedRows')\ntree.Draw()\nfarm = TPavesText(.01,1.02,.15,1.1,9,'tr')\ntfarm = farm.AddText('CHAIN')\ntfarm.SetTextSize(0.024)\nfarm.AddText('Collection')\nfarm.AddText('of Trees')\nfarm.Draw()\nlink = TLine(.15,.92,.80,.92)\nlink.SetLineWidth(2)\nlink.SetLineColor(1)\nlink.Draw()\nlink.DrawLine(.21,.87,.21,.275)\nlink.DrawLine(.23,.87,.23,.375)\nlink.DrawLine(.25,.87,.25,.775)\nlink.DrawLine(.41,.25,.41,-.025)\nlink.DrawLine(.43,.25,.43,.075)\nlink.DrawLine(.45,.25,.45,.175)\nbranch0 = TPaveLabel(.20,.87,.35,.97,'Branch 0')\nbranch0.SetTextSize(0.35)\nbranch0.SetFillColor(branchcolor)\nbranch0.Draw()\nbranch1 = TPaveLabel(.40,.87,.55,.97,'Branch 1')\nbranch1.SetTextSize(0.35)\nbranch1.SetFillColor(branchcolor)\nbranch1.Draw()\nbranch2 = TPaveLabel(.60,.87,.75,.97,'Branch 2')\nbranch2.SetTextSize(0.35)\nbranch2.SetFillColor(branchcolor)\nbranch2.Draw()\nbranch3 = TPaveLabel(.80,.87,.95,.97,'Branch 3')\nbranch3.SetTextSize(0.35)\nbranch3.SetFillColor(branchcolor)\nbranch3.Draw()\nleaf0 = TPaveLabel(.4,.75,.5,.8,'Leaf 0')\nleaf0.SetFillColor(leafcolor)\nleaf0.Draw()\nleaf1 = TPaveLabel(.6,.75,.7,.8,'Leaf 1')\nleaf1.SetFillColor(leafcolor)\nleaf1.Draw()\nleaf2 = TPaveLabel(.8,.75,.9,.8,'Leaf 2')\nleaf2.SetFillColor(leafcolor)\nleaf2.Draw()\nfirstevent = TPaveText(.4,.35,.9,.4)\nfirstevent.AddText('First event of each basket')\nfirstevent.AddText('Array of fMaxBaskets Integers')\nfirstevent.SetFillColor(basketcolor)\nfirstevent.Draw()\nbasket0 = TPaveLabel(.4,.25,.5,.3,'Basket 0')\nbasket0.SetFillColor(basketcolor)\nbasket0.Draw()\nbasket1 = TPaveLabel(.6,.25,.7,.3,'Basket 1')\nbasket1.SetFillColor(basketcolor)\nbasket1.Draw()\nbasket2 = TPaveLabel(.8,.25,.9,.3,'Basket 2')\nbasket2.SetFillColor(basketcolor)\nbasket2.Draw()\n\noffset = TPaveText(.55,.15,.9,.2)\noffset.AddText('Offset of events in fBuffer')\noffset.AddText('Array of fEventOffsetLen Integers')\noffset.AddText('(if variable length structure)')\noffset.SetFillColor(offsetcolor)\noffset.Draw()\nbuffer = TPaveText(.55,.05,.9,.1)\nbuffer.AddText('Basket buffer')\nbuffer.AddText('Array of fBasketSize chars')\nbuffer.SetFillColor(offsetcolor)\nbuffer.Draw()\nzipbuffer = TPaveText(.55,-.05,.75,.0)\nzipbuffer.AddText('Basket compressed buffer')\nzipbuffer.AddText('(if compression)')\nzipbuffer.SetFillColor(offsetcolor)\nzipbuffer.Draw()\nar1 = TArrow()\nar1.SetLineWidth(2)\nar1.SetLineColor(1)\nar1.SetFillStyle(1001)\nar1.SetFillColor(1)\nar1.DrawArrow(.21,.275,.39,.275,0.015,'|>')\nar1.DrawArrow(.23,.375,.39,.375,0.015,'|>')\nar1.DrawArrow(.25,.775,.39,.775,0.015,'|>')\nar1.DrawArrow(.50,.775,.59,.775,0.015,'|>')\nar1.DrawArrow(.70,.775,.79,.775,0.015,'|>')\nar1.DrawArrow(.50,.275,.59,.275,0.015,'|>')\nar1.DrawArrow(.70,.275,.79,.275,0.015,'|>')\nar1.DrawArrow(.45,.175,.54,.175,0.015,'|>')\nar1.DrawArrow(.43,.075,.54,.075,0.015,'|>')\nar1.DrawArrow(.41,-.025,.54,-.025,0.015,'|>')\nldot = TLine(.95,.92,.99,.92)\nldot.SetLineStyle(3)\nldot.Draw()\nldot.DrawLine(.9,.775,.99,.775)\nldot.DrawLine(.9,.275,.99,.275)\nldot.DrawLine(.55,.05,.55,0)\nldot.DrawLine(.9,.05,.75,0)\npname = TText(.46,.21,'fEventOffset')\npname.SetTextFont(72)\npname.SetTextSize(0.018)\npname.Draw()\npname.DrawText(.44,.11,'fBuffer')\npname.DrawText(.42,.01,'fZipBuffer')\npname.DrawText(.26,.81,'fLeaves = TObjArray of TLeaf')\npname.DrawText(.24,.40,'fBasketEvent')\npname.DrawText(.22,.31,'fBaskets = TObjArray of TBasket')\npname.DrawText(.20,1.0,'fBranches = TObjArray of TBranch')\nntleaf = TPaveText(0.30,.42,.62,.7)\nntleaf.SetTextSize(0.014)\nntleaf.SetFillColor(leafcolor)\nntleaf.SetTextAlign(12)\nntleaf.AddText('fLen: number of fixed elements')\nntleaf.AddText('fLenType: number of bytes of data type')\nntleaf.AddText('fOffset: relative to Leaf0-fAddress')\nntleaf.AddText('fNbytesIO: number of bytes used for I/O')\nntleaf.AddText('fIsPointer: True if pointer')\nntleaf.AddText('fIsRange: True if leaf has a range')\nntleaf.AddText('fIsUnsigned: True if unsigned')\nntleaf.AddText('*fLeafCount: points to Leaf counter')\nntleaf.AddText(' ')\nntleaf.AddLine(0,0,0,0)\nntleaf.AddText('fName = Leaf name')\nntleaf.AddText('fTitle = Leaf type (see Type codes)')\nntleaf.Draw()\ntype = TPaveText(.65,.42,.95,.7)\ntype.SetTextAlign(12)\ntype.SetFillColor(leafcolor)\ntype.AddText(' ')\ntype.AddText('C : a character string')\ntype.AddText('B : an 8 bit signed integer')\ntype.AddText('b : an 8 bit unsigned integer')\ntype.AddText('S : a 16 bit signed short integer')\ntype.AddText('s : a 16 bit unsigned short integer')\ntype.AddText('I : a 32 bit signed integer')\ntype.AddText('i : a 32 bit unsigned integer')\ntype.AddText('F : a 32 bit floating point')\ntype.AddText('D : a 64 bit floating point')\ntype.AddText('TXXXX : a class name TXXXX')\ntype.Draw()\ntypecode = TPaveLabel(.7,.68,.9,.72,'fType codes')\ntypecode.SetFillColor(leafcolor)\ntypecode.Draw()\nldot.DrawLine(.4,.75,.30,.7)\nldot.DrawLine(.5,.75,.62,.7)\nntbasket = TPaveText(0.02,-0.07,0.35,.25)\nntbasket.SetFillColor(basketcolor)\nntbasket.SetTextSize(0.014)\nntbasket.SetTextAlign(12)\nntbasket.AddText('fNbytes: Size of compressed Basket')\nntbasket.AddText('fObjLen: Size of uncompressed Basket')\nntbasket.AddText('fDatime: Date/Time when written to store')\nntbasket.AddText('fKeylen: Number of bytes for the key')\nntbasket.AddText('fCycle : Cycle number')\nntbasket.AddText('fSeekKey: Pointer to Basket on file')\nntbasket.AddText('fSeekPdir: Pointer to directory on file')\nntbasket.AddText(\"fClassName: 'TBasket'\")\nntbasket.AddText('fName: Branch name')\nntbasket.AddText('fTitle: Tree name')\nntbasket.AddText(' ')\nntbasket.AddLine(0,0,0,0)\nntbasket.AddText('fNevBuf: Number of events in Basket')\nntbasket.AddText('fLast: pointer to last used byte in Basket')\nntbasket.Draw()\nldot.DrawLine(.4,.3,0.02,0.25)\nldot.DrawLine(.5,.25,0.35,-.07)\nldot.DrawLine(.5,.3,0.35,0.25)\nntbranch = TPaveText(0.02,0.40,0.18,0.68)\nntbranch.SetFillColor(branchcolor)\nntbranch.SetTextSize(0.015)\nntbranch.SetTextAlign(12)\nntbranch.AddText('fBasketSize')\nntbranch.AddText('fEventOffsetLen')\nntbranch.AddText('fMaxBaskets')\nntbranch.AddText('fEntries')\nntbranch.AddText('fAddress of Leaf0')\nntbranch.AddText(' ')\nntbranch.AddLine(0,0,0,0)\nntbranch.AddText('fName: Branchname')\nntbranch.AddText('fTitle: leaflist')\nntbranch.Draw()\nldot.DrawLine(.2,.97,.02,.68)\nldot.DrawLine(.35,.97,.18,.68)\nldot.DrawLine(.35,.87,.18,.40)\nbasketstore = TPavesText(.8,-0.088,0.952,-0.0035,7,'tr')\nbasketstore.SetFillColor(28)\nbasketstore.AddText('Baskets')\nbasketstore.AddText('Stores')\nbasketstore.Draw()\nc1.Update()\n\ngBenchmark.Show('tree')\n" }
{ "repo_name": "knehez/edx-platform", "ref": "refs/heads/memooc", "path": "openedx/core/djangoapps/course_groups/management/commands/remove_users_from_multiple_cohorts.py", "content": "\"\"\"\nScript for removing users with multiple cohorts of a course from cohorts\nto ensure user's uniqueness for a course cohorts\n\"\"\"\nfrom django.contrib.auth.models import User\nfrom django.core.management.base import BaseCommand\nfrom django.db.models import Count\n\nfrom openedx.core.djangoapps.course_groups.models import CourseUserGroup\n\n\nclass Command(BaseCommand):\n    \"\"\"\n    Remove users with multiple cohorts of a course from all cohorts\n    \"\"\"\n    help = 'Remove all users from multiple cohorts (except one) of each course'\n\n    def handle(self, *args, **options):\n        \"\"\"\n        Execute the command\n        \"\"\"\n        # Get entries of cohorts which have same user added multiple times for a single course\n        multiple_objects_cohorts = CourseUserGroup.objects.filter(group_type=CourseUserGroup.COHORT).\\\n            values_list('users', 'course_id').annotate(user_count=Count('users')).filter(user_count__gt=1).\\\n            order_by('users')\n        multiple_objects_cohorts_count = multiple_objects_cohorts.count()\n        multiple_course_cohorts_users = set(multiple_objects_cohorts.values_list('users', flat=True))\n        users_failed_to_cleanup = []\n\n        for user in User.objects.filter(id__in=multiple_course_cohorts_users):\n            print u\"Removing user with id '{0}' from cohort groups\".format(user.id)\n            try:\n                # remove user from only cohorts\n                user.course_groups.remove(*user.course_groups.filter(group_type=CourseUserGroup.COHORT))\n            except AttributeError as err:\n                users_failed_to_cleanup.append(user.email)\n                print u\"Failed to remove user with id {0} from cohort groups, error: {1}\".format(user.id, err)\n\n        print \"=\" * 80\n        print u\"=\" * 30 + u\"> Cohorts summary\"\n        print(\n            u\"Total number of CourseUserGroup of type '{0}' with multiple users: {1}\".format(\n                CourseUserGroup.COHORT, multiple_objects_cohorts_count\n            )\n        )\n        print(\n            u\"Total number of unique users with multiple course cohorts: {0}\".format(\n                len(multiple_course_cohorts_users)\n            )\n        )\n        print(\n            u\"Users which failed on cohorts cleanup [{0}]: [{1}]\".format(\n                len(users_failed_to_cleanup), (', '.join(users_failed_to_cleanup))\n            )\n        )\n        print \"=\" * 80\n" }
{ "repo_name": "michael-dev2rights/ansible", "ref": "refs/heads/ansible-d2r", "path": "lib/ansible/module_utils/aruba.py", "content": "# This code is part of Ansible, but is an independent component.\n# This particular file snippet, and this file snippet only, is BSD licensed.\n# Modules you write using this snippet, which is embedded dynamically by Ansible\n# still belong to the author of the module, and may assign their own license\n# to the complete work.\n#\n# (c) 2016 Red Hat Inc.\n#\n# Redistribution and use in source and binary forms, with or without modification,\n# are permitted provided that the following conditions are met:\n#\n#    * Redistributions of source code must retain the above copyright\n#      notice, this list of conditions and the following disclaimer.\n#    * Redistributions in binary form must reproduce the above copyright notice,\n#      this list of conditions and the following disclaimer in the documentation\n#      and/or other materials provided with the distribution.\n#\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\n# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n# WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n# IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,\n# INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\n# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n# LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE\n# USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n#\nfrom ansible.module_utils._text import to_text\nfrom ansible.module_utils.basic import env_fallback, return_values\nfrom ansible.module_utils.network_common import to_list, ComplexList\nfrom ansible.module_utils.connection import exec_command\n\n_DEVICE_CONFIGS = {}\n\naruba_provider_spec = {\n    'host': dict(),\n    'port': dict(type='int'),\n    'username': dict(fallback=(env_fallback, ['ANSIBLE_NET_USERNAME'])),\n    'password': dict(fallback=(env_fallback, ['ANSIBLE_NET_PASSWORD']), no_log=True),\n    'ssh_keyfile': dict(fallback=(env_fallback, ['ANSIBLE_NET_SSH_KEYFILE']), type='path'),\n    'timeout': dict(type='int'),\n}\naruba_argument_spec = {\n    'provider': dict(type='dict', options=aruba_provider_spec)\n}\naruba_argument_spec.update(aruba_provider_spec)\n\n# Add argument's default value here\nARGS_DEFAULT_VALUE = {}\n\n\ndef get_argspec():\n    return aruba_argument_spec\n\n\ndef check_args(module, warnings):\n    for key in aruba_argument_spec:\n        if key not in ['provider', 'authorize'] and module.params[key]:\n            warnings.append('argument %s has been deprecated and will be removed in a future version' % key)\n\n    # set argument's default value if not provided in input\n    # This is done to avoid unwanted argument deprecation warning\n    # in case argument is not given as input (outside provider).\n    for key in ARGS_DEFAULT_VALUE:\n        if not module.params.get(key, None):\n            module.params[key] = ARGS_DEFAULT_VALUE[key]\n\n\ndef get_config(module, flags=[]):\n    cmd = 'show running-config '\n    cmd += ' '.join(flags)\n    cmd = cmd.strip()\n\n    try:\n        return _DEVICE_CONFIGS[cmd]\n    except KeyError:\n        rc, out, err = exec_command(module, cmd)\n        if rc != 0:\n            module.fail_json(msg='unable to retrieve current config', stderr=to_text(err, errors='surrogate_then_replace'))\n        cfg = to_text(out, errors='surrogate_then_replace').strip()\n        _DEVICE_CONFIGS[cmd] = cfg\n        return cfg\n\n\ndef to_commands(module, commands):\n    spec = {\n        'command': dict(key=True),\n        'prompt': dict(),\n        'answer': dict()\n  }\n    transform = ComplexList(spec, module)\n    return transform(commands)\n\n\ndef run_commands(module, commands, check_rc=True):\n    responses = list()\n    commands = to_commands(module, to_list(commands))\n    for cmd in commands:\n        cmd = module.jsonify(cmd)\n        rc, out, err = exec_command(module, cmd)\n        if check_rc and rc != 0:\n            module.fail_json(msg=to_text(err, errors='surrogate_then_replace'), rc=rc)\n        responses.append(to_text(out, errors='surrogate_then_replace'))\n    return responses\n\n\ndef load_config(module, commands):\n\n    rc, out, err = exec_command(module, 'configure terminal')\n    if rc != 0:\n        module.fail_json(msg='unable to enter configuration mode', err=to_text(out, errors='surrogate_then_replace'))\n\n    for command in to_list(commands):\n        if command == 'end':\n            continue\n        rc, out, err = exec_command(module, command)\n        if rc != 0:\n            module.fail_json(msg=to_text(err, errors='surrogate_then_replace'), command=command, rc=rc)\n\n    exec_command(module, 'end')\n" }
{ "repo_name": "jrmendozat/mtvm", "ref": "refs/heads/nuevomaster", "path": "Segmento/migrations/0003_auto_20150320_0842.py", "content": "# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('Segmento', '0002_auto_20150313_1430'),\n    ]\n\n    operations = [\n        migrations.AlterField(\n            model_name='segmento',\n            name='segmento',\n            field=models.CharField(unique=True, max_length=50),\n            preserve_default=True,\n        ),\n    ]\n" }
{ "repo_name": "SomethingExplosive/android_external_chromium_org", "ref": "refs/heads/somex-4.4", "path": "chrome/common/extensions/docs/server2/test_data/canned_data.py", "content": "# Copyright 2013 The Chromium Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\nimport json\n\nCANNED_CHANNELS = {\n  'trunk': 'trunk',\n  'dev': 28,\n  'beta': 27,\n  'stable': 26\n}\n\nCANNED_BRANCHES = {\n  'trunk': 'trunk',\n  28: 1500,\n  27: 1453,\n  26: 1410,\n  25: 1364,\n  24: 1312,\n  23: 1271,\n  22: 1229,\n  21: 1180,\n  20: 1132,\n  19: 1084,\n  18: 1025,\n  17: 963,\n  16: 912,\n  15: 874,\n  14: 835,\n  13: 782,\n  12: 742,\n  11: 696,\n  10: 648,\n   9: 597,\n   8: 552,\n   7: 544,\n   6: 495,\n   5: 396\n}\n\nCANNED_TEST_FILE_SYSTEM_DATA = {\n  'api': {\n    '_api_features.json': json.dumps({\n      'ref_test': { 'dependencies': ['permission:ref_test'] }\n      'tester': { 'dependencies': ['permission:tester', 'manifest:tester'] }\n  }),\n    '_manifest_features.json': json.dumps({\n      'manifest': 'features'\n  }),\n    '_permission_features.json': json.dumps({\n      'permission': 'features'\n  })\n}\n  'docs': {\n    'templates': {\n      'intros': {\n        'test.html': '<h1>hi</h1>you<h2>first</h2><h3>inner</h3><h2>second</h2>'\n    }\n      'json': {\n        'api_availabilities.json': json.dumps({\n          'tester': {\n              'channel': 'stable',\n              'version': 42\n          }\n        }),\n        'intro_tables.json': json.dumps({\n          'tester': {\n            'Permissions': [\n            {\n                'class': 'override',\n                'text': '\"tester\"'\n            }\n            {\n                'text': 'is an API for testing things.'\n            }\n            ],\n            'Learn More': [\n            {\n                'link': 'https://tester.test.com/welcome.html',\n                'text': 'Welcome!'\n            }\n            ]\n        }\n      })\n    }\n      'private': {\n        'intro_tables': {\n          'trunk_message.html': 'available on trunk'\n      }\n    }\n  }\n}\n}\n\nCANNED_API_FILE_SYSTEM_DATA = {\n  'trunk': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'contextMenus': {\n          'channel': 'stable'\n      }\n        'events': {\n          'channel': 'stable'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'history': {\n          'channel': 'beta'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'beta'\n      }\n        'sync': {\n          'channel': 'trunk'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'cookies': {\n          'channel': 'dev'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'falseBetaAPI': {\n          'channel': 'beta'\n      }\n        'trunkAPI': {\n          'channel': 'trunk'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n    'docs': {\n      'templates': {\n        'json': {\n          'api_availabilities.json': json.dumps({\n            'jsonAPI1': {\n              'channel': 'stable',\n              'version': 10\n          }\n            'jsonAPI2': {\n              'channel': 'trunk'\n          }\n            'jsonAPI3': {\n              'channel': 'dev'\n          }\n        }),\n          'intro_tables.json': json.dumps({\n            'test': [\n            {\n                'Permissions': 'probably none'\n            }\n            ]\n        })\n      }\n    }\n  }\n}\n  '1500': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'events': {\n          'channel': 'trunk'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n        'systemInfo.stuff': {\n          'channel': 'dev'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'contextMenus': {\n          'channel': 'trunk'\n      }\n        'notifications': {\n          'channel': 'beta'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'dev'\n      }\n        'sync': {\n          'channel': 'trunk'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'cookies': {\n          'channel': 'dev'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'downloads': {\n          'channel': 'beta'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1453': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'events': {\n          'channel': 'dev'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n        'systemInfo.cpu': {\n          'channel': 'stable'\n      }\n        'systemInfo.stuff': {\n          'channel': 'dev'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'notifications': {\n          'channel': 'dev'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'dev'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'context_menus': {\n          'channel': 'trunk'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'downloads': {\n          'channel': 'dev'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1410': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'events': {\n          'channel': 'beta'\n      }\n        'notifications': {\n          'channel': 'dev'\n      }\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'context_menus': {\n          'channel': 'trunk'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1364': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1312': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1271': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'system_info_display': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'beta'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'alarms.idl': 'alarms contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1229': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'beta'\n      }\n    }),\n      'alarms.idl': 'alarms contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'system_info_display.idl': 'systemInfo.display contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1180': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'bookmarks.json': 'bookmarks contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1132': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'trunk'\n      }\n        'page_action': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'bookmarks.json': 'bookmarks contents',\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1084': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'contents': 'nothing of interest here,really'\n    }),\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'pageAction.json': 'pageAction contents',\n      'tabs.json': 'tabs contents',\n      'webRequest.json': 'webRequest contents'\n  }\n}\n  '1025': {\n    'api': {\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'pageAction.json': 'pageAction contents',\n      'tabs.json': 'tabs contents',\n      'webRequest.json': 'webRequest contents'\n  }\n}\n  '963': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      {\n          'namespace': 'webRequest'\n      }\n      ])\n  }\n}\n  '912': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      {\n          'namespace': 'experimental.webRequest'\n      }\n      ])\n  }\n}\n  '874': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '835': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '782': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '742': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '696': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '648': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '597': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '552': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '544': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      ])\n  }\n}\n  '495': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      ])\n  }\n}\n  '396': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'experimental.menus'\n      }\n      ])\n  }\n}\n}\n" }
{ "repo_name": "ModdedPA/android_external_chromium_org", "ref": "refs/heads/kitkat", "path": "chrome/common/extensions/docs/server2/test_data/canned_data.py", "content": "# Copyright 2013 The Chromium Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\nimport json\n\nCANNED_CHANNELS = {\n  'trunk': 'trunk',\n  'dev': 28,\n  'beta': 27,\n  'stable': 26\n}\n\nCANNED_BRANCHES = {\n  'trunk': 'trunk',\n  28: 1500,\n  27: 1453,\n  26: 1410,\n  25: 1364,\n  24: 1312,\n  23: 1271,\n  22: 1229,\n  21: 1180,\n  20: 1132,\n  19: 1084,\n  18: 1025,\n  17: 963,\n  16: 912,\n  15: 874,\n  14: 835,\n  13: 782,\n  12: 742,\n  11: 696,\n  10: 648,\n   9: 597,\n   8: 552,\n   7: 544,\n   6: 495,\n   5: 396\n}\n\nCANNED_TEST_FILE_SYSTEM_DATA = {\n  'api': {\n    '_api_features.json': json.dumps({\n      'ref_test': { 'dependencies': ['permission:ref_test'] }\n      'tester': { 'dependencies': ['permission:tester', 'manifest:tester'] }\n  }),\n    '_manifest_features.json': json.dumps({\n      'manifest': 'features'\n  }),\n    '_permission_features.json': json.dumps({\n      'permission': 'features'\n  })\n}\n  'docs': {\n    'templates': {\n      'intros': {\n        'test.html': '<h1>hi</h1>you<h2>first</h2><h3>inner</h3><h2>second</h2>'\n    }\n      'json': {\n        'api_availabilities.json': json.dumps({\n          'tester': {\n              'channel': 'stable',\n              'version': 42\n          }\n        }),\n        'intro_tables.json': json.dumps({\n          'tester': {\n            'Permissions': [\n            {\n                'class': 'override',\n                'text': '\"tester\"'\n            }\n            {\n                'text': 'is an API for testing things.'\n            }\n            ],\n            'Learn More': [\n            {\n                'link': 'https://tester.test.com/welcome.html',\n                'text': 'Welcome!'\n            }\n            ]\n        }\n      })\n    }\n      'private': {\n        'intro_tables': {\n          'trunk_message.html': 'available on trunk'\n      }\n    }\n  }\n}\n}\n\nCANNED_API_FILE_SYSTEM_DATA = {\n  'trunk': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'contextMenus': {\n          'channel': 'stable'\n      }\n        'events': {\n          'channel': 'stable'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'history': {\n          'channel': 'beta'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'beta'\n      }\n        'sync': {\n          'channel': 'trunk'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'cookies': {\n          'channel': 'dev'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'falseBetaAPI': {\n          'channel': 'beta'\n      }\n        'trunkAPI': {\n          'channel': 'trunk'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n    'docs': {\n      'templates': {\n        'json': {\n          'api_availabilities.json': json.dumps({\n            'jsonAPI1': {\n              'channel': 'stable',\n              'version': 10\n          }\n            'jsonAPI2': {\n              'channel': 'trunk'\n          }\n            'jsonAPI3': {\n              'channel': 'dev'\n          }\n        }),\n          'intro_tables.json': json.dumps({\n            'test': [\n            {\n                'Permissions': 'probably none'\n            }\n            ]\n        })\n      }\n    }\n  }\n}\n  '1500': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'events': {\n          'channel': 'trunk'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n        'systemInfo.stuff': {\n          'channel': 'dev'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'contextMenus': {\n          'channel': 'trunk'\n      }\n        'notifications': {\n          'channel': 'beta'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'dev'\n      }\n        'sync': {\n          'channel': 'trunk'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'cookies': {\n          'channel': 'dev'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'downloads': {\n          'channel': 'beta'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1453': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'events': {\n          'channel': 'dev'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n        'systemInfo.cpu': {\n          'channel': 'stable'\n      }\n        'systemInfo.stuff': {\n          'channel': 'dev'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'notifications': {\n          'channel': 'dev'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'dev'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'context_menus': {\n          'channel': 'trunk'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'downloads': {\n          'channel': 'dev'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1410': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'events': {\n          'channel': 'beta'\n      }\n        'notifications': {\n          'channel': 'dev'\n      }\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'context_menus': {\n          'channel': 'trunk'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1364': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1312': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1271': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'system_info_display': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'beta'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'alarms.idl': 'alarms contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1229': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'beta'\n      }\n    }),\n      'alarms.idl': 'alarms contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'system_info_display.idl': 'systemInfo.display contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1180': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'bookmarks.json': 'bookmarks contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1132': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'trunk'\n      }\n        'page_action': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'bookmarks.json': 'bookmarks contents',\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1084': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'contents': 'nothing of interest here,really'\n    }),\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'pageAction.json': 'pageAction contents',\n      'tabs.json': 'tabs contents',\n      'webRequest.json': 'webRequest contents'\n  }\n}\n  '1025': {\n    'api': {\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'pageAction.json': 'pageAction contents',\n      'tabs.json': 'tabs contents',\n      'webRequest.json': 'webRequest contents'\n  }\n}\n  '963': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      {\n          'namespace': 'webRequest'\n      }\n      ])\n  }\n}\n  '912': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      {\n          'namespace': 'experimental.webRequest'\n      }\n      ])\n  }\n}\n  '874': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '835': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '782': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '742': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '696': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '648': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '597': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '552': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '544': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      ])\n  }\n}\n  '495': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      ])\n  }\n}\n  '396': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'experimental.menus'\n      }\n      ])\n  }\n}\n}\n" }
{ "repo_name": "timduru/platform-external-chromium_org", "ref": "refs/heads/katkiss-4.4", "path": "chrome/common/extensions/docs/server2/test_data/canned_data.py", "content": "# Copyright 2013 The Chromium Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\nimport json\n\nCANNED_CHANNELS = {\n  'trunk': 'trunk',\n  'dev': 28,\n  'beta': 27,\n  'stable': 26\n}\n\nCANNED_BRANCHES = {\n  'trunk': 'trunk',\n  28: 1500,\n  27: 1453,\n  26: 1410,\n  25: 1364,\n  24: 1312,\n  23: 1271,\n  22: 1229,\n  21: 1180,\n  20: 1132,\n  19: 1084,\n  18: 1025,\n  17: 963,\n  16: 912,\n  15: 874,\n  14: 835,\n  13: 782,\n  12: 742,\n  11: 696,\n  10: 648,\n   9: 597,\n   8: 552,\n   7: 544,\n   6: 495,\n   5: 396\n}\n\nCANNED_TEST_FILE_SYSTEM_DATA = {\n  'api': {\n    '_api_features.json': json.dumps({\n      'ref_test': { 'dependencies': ['permission:ref_test'] }\n      'tester': { 'dependencies': ['permission:tester', 'manifest:tester'] }\n  }),\n    '_manifest_features.json': json.dumps({\n      'manifest': 'features'\n  }),\n    '_permission_features.json': json.dumps({\n      'permission': 'features'\n  })\n}\n  'docs': {\n    'templates': {\n      'intros': {\n        'test.html': '<h1>hi</h1>you<h2>first</h2><h3>inner</h3><h2>second</h2>'\n    }\n      'json': {\n        'api_availabilities.json': json.dumps({\n          'tester': {\n              'channel': 'stable',\n              'version': 42\n          }\n        }),\n        'intro_tables.json': json.dumps({\n          'tester': {\n            'Permissions': [\n            {\n                'class': 'override',\n                'text': '\"tester\"'\n            }\n            {\n                'text': 'is an API for testing things.'\n            }\n            ],\n            'Learn More': [\n            {\n                'link': 'https://tester.test.com/welcome.html',\n                'text': 'Welcome!'\n            }\n            ]\n        }\n      })\n    }\n      'private': {\n        'intro_tables': {\n          'trunk_message.html': 'available on trunk'\n      }\n    }\n  }\n}\n}\n\nCANNED_API_FILE_SYSTEM_DATA = {\n  'trunk': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'contextMenus': {\n          'channel': 'stable'\n      }\n        'events': {\n          'channel': 'stable'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'history': {\n          'channel': 'beta'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'beta'\n      }\n        'sync': {\n          'channel': 'trunk'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'cookies': {\n          'channel': 'dev'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'falseBetaAPI': {\n          'channel': 'beta'\n      }\n        'trunkAPI': {\n          'channel': 'trunk'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n    'docs': {\n      'templates': {\n        'json': {\n          'api_availabilities.json': json.dumps({\n            'jsonAPI1': {\n              'channel': 'stable',\n              'version': 10\n          }\n            'jsonAPI2': {\n              'channel': 'trunk'\n          }\n            'jsonAPI3': {\n              'channel': 'dev'\n          }\n        }),\n          'intro_tables.json': json.dumps({\n            'test': [\n            {\n                'Permissions': 'probably none'\n            }\n            ]\n        })\n      }\n    }\n  }\n}\n  '1500': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'events': {\n          'channel': 'trunk'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n        'systemInfo.stuff': {\n          'channel': 'dev'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'contextMenus': {\n          'channel': 'trunk'\n      }\n        'notifications': {\n          'channel': 'beta'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'dev'\n      }\n        'sync': {\n          'channel': 'trunk'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'cookies': {\n          'channel': 'dev'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'downloads': {\n          'channel': 'beta'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1453': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'events': {\n          'channel': 'dev'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n        'systemInfo.cpu': {\n          'channel': 'stable'\n      }\n        'systemInfo.stuff': {\n          'channel': 'dev'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'notifications': {\n          'channel': 'dev'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'dev'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'context_menus': {\n          'channel': 'trunk'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'downloads': {\n          'channel': 'dev'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1410': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'events': {\n          'channel': 'beta'\n      }\n        'notifications': {\n          'channel': 'dev'\n      }\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'context_menus': {\n          'channel': 'trunk'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1364': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1312': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1271': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'system_info_display': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'beta'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'alarms.idl': 'alarms contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1229': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'beta'\n      }\n    }),\n      'alarms.idl': 'alarms contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'system_info_display.idl': 'systemInfo.display contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1180': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'bookmarks.json': 'bookmarks contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1132': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'trunk'\n      }\n        'page_action': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'bookmarks.json': 'bookmarks contents',\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1084': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'contents': 'nothing of interest here,really'\n    }),\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'pageAction.json': 'pageAction contents',\n      'tabs.json': 'tabs contents',\n      'webRequest.json': 'webRequest contents'\n  }\n}\n  '1025': {\n    'api': {\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'pageAction.json': 'pageAction contents',\n      'tabs.json': 'tabs contents',\n      'webRequest.json': 'webRequest contents'\n  }\n}\n  '963': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      {\n          'namespace': 'webRequest'\n      }\n      ])\n  }\n}\n  '912': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      {\n          'namespace': 'experimental.webRequest'\n      }\n      ])\n  }\n}\n  '874': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '835': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '782': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '742': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '696': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '648': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '597': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '552': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '544': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      ])\n  }\n}\n  '495': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      ])\n  }\n}\n  '396': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'experimental.menus'\n      }\n      ])\n  }\n}\n}\n" }
{ "repo_name": "ustramooner/CouchPotato", "ref": "refs/heads/NzbIndexCom", "path": "library/sqlalchemy/connectors/mxodbc.py", "content": "\"\"\"\nProvide an SQLALchemy connector for the eGenix mxODBC commercial\nPython adapter for ODBC. This is not a free product, but eGenix\nprovides SQLAlchemy with a license for use in continuous integration\ntesting.\n\nThis has been tested for use with mxODBC 3.1.2 on SQL Server 2005\nand 2008, using the SQL Server Native driver. However, it is\npossible for this to be used on other database platforms.\n\nFor more info on mxODBC, see http://www.egenix.com/\n\n\"\"\"\n\nimport sys\nimport re\nimport warnings\nfrom decimal import Decimal\n\nfrom sqlalchemy.connectors import Connector\nfrom sqlalchemy import types as sqltypes\nimport sqlalchemy.processors as processors\n\nclass MxODBCConnector(Connector):\n    driver='mxodbc'\n    \n    supports_sane_multi_rowcount = False\n    supports_unicode_statements = False\n    supports_unicode_binds = False\n    \n    supports_native_decimal = True\n    \n    @classmethod\n    def dbapi(cls):\n        # this classmethod will normally be replaced by an instance\n        # attribute of the same name, so this is normally only called once.\n        cls._load_mx_exceptions()\n        platform = sys.platform\n        if platform == 'win32':\n            from mx.ODBC import Windows as module\n        # this can be the string \"linux2\", and possibly others\n        elif 'linux' in platform:\n            from mx.ODBC import unixODBC as module\n        elif platform == 'darwin':\n            from mx.ODBC import iODBC as module\n        else:\n            raise ImportError, \"Unrecognized platform for mxODBC import\"\n        return module\n\n    @classmethod\n    def _load_mx_exceptions(cls):\n        \"\"\" Import mxODBC exception classes into the module namespace,\n        as if they had been imported normally. This is done here\n        to avoid requiring all SQLAlchemy users to install mxODBC.\n        \"\"\"\n        global InterfaceError, ProgrammingError\n        from mx.ODBC import InterfaceError\n        from mx.ODBC import ProgrammingError\n\n    def on_connect(self):\n        def connect(conn):\n            conn.stringformat = self.dbapi.MIXED_STRINGFORMAT\n            conn.datetimeformat = self.dbapi.PYDATETIME_DATETIMEFORMAT\n            conn.decimalformat = self.dbapi.DECIMAL_DECIMALFORMAT\n            conn.errorhandler = self._error_handler()\n        return connect\n    \n    def _error_handler(self):\n        \"\"\" Return a handler that adjusts mxODBC's raised Warnings to\n        emit Python standard warnings.\n        \"\"\"\n        from mx.ODBC.Error import Warning as MxOdbcWarning\n        def error_handler(connection, cursor, errorclass, errorvalue):\n\n            if issubclass(errorclass, MxOdbcWarning):\n                errorclass.__bases__ = (Warning,)\n                warnings.warn(message=str(errorvalue),\n                          category=errorclass,\n                          stacklevel=2)\n            else:\n                raise errorclass, errorvalue\n        return error_handler\n\n    def create_connect_args(self, url):\n        \"\"\" Return a tuple of *args,**kwargs for creating a connection.\n\n        The mxODBC 3.x connection constructor looks like this:\n\n            connect(dsn, user='', password='',\n                    clear_auto_commit=1, errorhandler=None)\n\n        This method translates the values in the provided uri\n        into args and kwargs needed to instantiate an mxODBC Connection.\n\n        The arg 'errorhandler' is not used by SQLAlchemy and will\n        not be populated.\n        \n        \"\"\"\n        opts = url.translate_connect_args(username='user')\n        opts.update(url.query)\n        args = opts.pop('host')\n        opts.pop('port', None)\n        opts.pop('database', None)\n        return (args,), opts\n\n    def is_disconnect(self, e):\n        # eGenix recommends checking connection.closed here,\n        # but how can we get a handle on the current connection?\n        if isinstance(e, self.dbapi.ProgrammingError):\n            return \"connection already closed\" in str(e)\n        elif isinstance(e, self.dbapi.Error):\n            return '[08S01]' in str(e)\n        else:\n            return False\n\n    def _get_server_version_info(self, connection):\n        # eGenix suggests using conn.dbms_version instead \n        # of what we're doing here\n        dbapi_con = connection.connection\n        version = []\n        r = re.compile('[.\\-]')\n        # 18 == pyodbc.SQL_DBMS_VER\n        for n in r.split(dbapi_con.getinfo(18)[1]):\n            try:\n                version.append(int(n))\n            except ValueError:\n                version.append(n)\n        return tuple(version)\n\n    def do_execute(self, cursor, statement, parameters, context=None):\n        if context:\n            native_odbc_execute = context.execution_options.\\\n                                        get('native_odbc_execute', 'auto')\n            if native_odbc_execute is True:\n                # user specified native_odbc_execute=True\n                cursor.execute(statement, parameters)\n            elif native_odbc_execute is False:\n                # user specified native_odbc_execute=False\n                cursor.executedirect(statement, parameters)\n            elif context.is_crud:\n                # statement is UPDATE, DELETE, INSERT\n                cursor.execute(statement, parameters)\n            else:\n                # all other statements\n                cursor.executedirect(statement, parameters)\n        else:\n            cursor.executedirect(statement, parameters)\n" }
{ "repo_name": "msincenselee/vnpy", "ref": "refs/heads/vnpy2", "path": "vnpy/app/cta_strategy/strategies/multi_signal_strategy.py", "content": "from vnpy.app.cta_strategy import (\n    StopOrder,\n    TickData,\n    BarData,\n    TradeData,\n    OrderData,\n    BarGenerator,\n    ArrayManager,\n    CtaSignal,\n    TargetPosTemplate\n)\n\n\nclass RsiSignal(CtaSignal):\n    \"\"\"\"\"\"\n\n    def __init__(self, rsi_window: int, rsi_level: float):\n        \"\"\"Constructor\"\"\"\n        super().__init__()\n\n        self.rsi_window = rsi_window\n        self.rsi_level = rsi_level\n        self.rsi_long = 50 + self.rsi_level\n        self.rsi_short = 50 - self.rsi_level\n\n        self.bg = BarGenerator(self.on_bar)\n        self.am = ArrayManager()\n\n    def on_tick(self, tick: TickData):\n        \"\"\"\n        Callback of new tick data update.\n        \"\"\"\n        self.bg.update_tick(tick)\n\n    def on_bar(self, bar: BarData):\n        \"\"\"\n        Callback of new bar data update.\n        \"\"\"\n        self.am.update_bar(bar)\n        if not self.am.inited:\n            self.set_signal_pos(0)\n\n        rsi_value = self.am.rsi(self.rsi_window)\n\n        if rsi_value >= self.rsi_long:\n            self.set_signal_pos(1)\n        elif rsi_value <= self.rsi_short:\n            self.set_signal_pos(-1)\n        else:\n            self.set_signal_pos(0)\n\n\nclass CciSignal(CtaSignal):\n    \"\"\"\"\"\"\n\n    def __init__(self, cci_window: int, cci_level: float):\n        \"\"\"\"\"\"\n        super().__init__()\n\n        self.cci_window = cci_window\n        self.cci_level = cci_level\n        self.cci_long = self.cci_level\n        self.cci_short = -self.cci_level\n\n        self.bg = BarGenerator(self.on_bar)\n        self.am = ArrayManager()\n\n    def on_tick(self, tick: TickData):\n        \"\"\"\n        Callback of new tick data update.\n        \"\"\"\n        self.bg.update_tick(tick)\n\n    def on_bar(self, bar: BarData):\n        \"\"\"\n        Callback of new bar data update.\n        \"\"\"\n        self.am.update_bar(bar)\n        if not self.am.inited:\n            self.set_signal_pos(0)\n\n        cci_value = self.am.cci(self.cci_window)\n\n        if cci_value >= self.cci_long:\n            self.set_signal_pos(1)\n        elif cci_value <= self.cci_short:\n            self.set_signal_pos(-1)\n        else:\n            self.set_signal_pos(0)\n\n\nclass MaSignal(CtaSignal):\n    \"\"\"\"\"\"\n\n    def __init__(self, fast_window: int, slow_window: int):\n        \"\"\"\"\"\"\n        super().__init__()\n\n        self.fast_window = fast_window\n        self.slow_window = slow_window\n\n        self.bg = BarGenerator(self.on_bar, 5, self.on_5min_bar)\n        self.am = ArrayManager()\n\n    def on_tick(self, tick: TickData):\n        \"\"\"\n        Callback of new tick data update.\n        \"\"\"\n        self.bg.update_tick(tick)\n\n    def on_bar(self, bar: BarData):\n        \"\"\"\n        Callback of new bar data update.\n        \"\"\"\n        self.bg.update_bar(bar)\n\n    def on_5min_bar(self, bar: BarData):\n        \"\"\"\"\"\"\n        self.am.update_bar(bar)\n        if not self.am.inited:\n            self.set_signal_pos(0)\n\n        fast_ma = self.am.sma(self.fast_window)\n        slow_ma = self.am.sma(self.slow_window)\n\n        if fast_ma > slow_ma:\n            self.set_signal_pos(1)\n        elif fast_ma < slow_ma:\n            self.set_signal_pos(-1)\n        else:\n            self.set_signal_pos(0)\n\n\nclass MultiSignalStrategy(TargetPosTemplate):\n    \"\"\"\"\"\"\n\n    author = \"用Python的交易员\"\n\n    rsi_window = 14\n    rsi_level = 20\n    cci_window = 30\n    cci_level = 10\n    fast_window = 5\n    slow_window = 20\n\n    signal_pos = {}\n\n    parameters = [\"rsi_window\", \"rsi_level\", \"cci_window\",\n                  \"cci_level\", \"fast_window\", \"slow_window\"]\n    variables = [\"signal_pos\", \"target_pos\"]\n\n    def __init__(self, cta_engine, strategy_name, vt_symbol, setting):\n        \"\"\"\"\"\"\n        super().__init__(cta_engine, strategy_name, vt_symbol, setting)\n\n        self.rsi_signal = RsiSignal(self.rsi_window, self.rsi_level)\n        self.cci_signal = CciSignal(self.cci_window, self.cci_level)\n        self.ma_signal = MaSignal(self.fast_window, self.slow_window)\n\n        self.signal_pos = {\n            \"rsi\": 0,\n            \"cci\": 0,\n            \"ma\": 0\n      }\n\n    def on_init(self):\n        \"\"\"\n        Callback when strategy is inited.\n        \"\"\"\n        self.write_log(\"策略初始化\")\n        self.load_bar(10)\n\n    def on_start(self):\n        \"\"\"\n        Callback when strategy is started.\n        \"\"\"\n        self.write_log(\"策略启动\")\n\n    def on_stop(self):\n        \"\"\"\n        Callback when strategy is stopped.\n        \"\"\"\n        self.write_log(\"策略停止\")\n\n    def on_tick(self, tick: TickData):\n        \"\"\"\n        Callback of new tick data update.\n        \"\"\"\n        super(MultiSignalStrategy, self).on_tick(tick)\n\n        self.rsi_signal.on_tick(tick)\n        self.cci_signal.on_tick(tick)\n        self.ma_signal.on_tick(tick)\n\n        self.calculate_target_pos()\n\n    def on_bar(self, bar: BarData):\n        \"\"\"\n        Callback of new bar data update.\n        \"\"\"\n        super(MultiSignalStrategy, self).on_bar(bar)\n\n        self.rsi_signal.on_bar(bar)\n        self.cci_signal.on_bar(bar)\n        self.ma_signal.on_bar(bar)\n\n        self.calculate_target_pos()\n\n    def calculate_target_pos(self):\n        \"\"\"\"\"\"\n        self.signal_pos[\"rsi\"] = self.rsi_signal.get_signal_pos()\n        self.signal_pos[\"cci\"] = self.cci_signal.get_signal_pos()\n        self.signal_pos[\"ma\"] = self.ma_signal.get_signal_pos()\n\n        target_pos = 0\n        for v in self.signal_pos.values():\n            target_pos += v\n\n        self.set_target_pos(target_pos)\n\n    def on_order(self, order: OrderData):\n        \"\"\"\n        Callback of new order data update.\n        \"\"\"\n        super(MultiSignalStrategy, self).on_order(order)\n\n    def on_trade(self, trade: TradeData):\n        \"\"\"\n        Callback of new trade data update.\n        \"\"\"\n        self.put_event()\n\n    def on_stop_order(self, stop_order: StopOrder):\n        \"\"\"\n        Callback of stop order update.\n        \"\"\"\n        pass\n" }
{ "repo_name": "JCROM-Android/jcrom_external_chromium_org", "ref": "refs/heads/kitkat", "path": "chrome/common/extensions/docs/server2/test_data/canned_data.py", "content": "# Copyright 2013 The Chromium Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\nimport json\n\nCANNED_CHANNELS = {\n  'trunk': 'trunk',\n  'dev': 28,\n  'beta': 27,\n  'stable': 26\n}\n\nCANNED_BRANCHES = {\n  'trunk': 'trunk',\n  28: 1500,\n  27: 1453,\n  26: 1410,\n  25: 1364,\n  24: 1312,\n  23: 1271,\n  22: 1229,\n  21: 1180,\n  20: 1132,\n  19: 1084,\n  18: 1025,\n  17: 963,\n  16: 912,\n  15: 874,\n  14: 835,\n  13: 782,\n  12: 742,\n  11: 696,\n  10: 648,\n   9: 597,\n   8: 552,\n   7: 544,\n   6: 495,\n   5: 396\n}\n\nCANNED_TEST_FILE_SYSTEM_DATA = {\n  'api': {\n    '_api_features.json': json.dumps({\n      'ref_test': { 'dependencies': ['permission:ref_test'] }\n      'tester': { 'dependencies': ['permission:tester', 'manifest:tester'] }\n  }),\n    '_manifest_features.json': json.dumps({\n      'manifest': 'features'\n  }),\n    '_permission_features.json': json.dumps({\n      'permission': 'features'\n  })\n}\n  'docs': {\n    'templates': {\n      'intros': {\n        'test.html': '<h1>hi</h1>you<h2>first</h2><h3>inner</h3><h2>second</h2>'\n    }\n      'json': {\n        'api_availabilities.json': json.dumps({\n          'tester': {\n              'channel': 'stable',\n              'version': 42\n          }\n        }),\n        'intro_tables.json': json.dumps({\n          'tester': {\n            'Permissions': [\n            {\n                'class': 'override',\n                'text': '\"tester\"'\n            }\n            {\n                'text': 'is an API for testing things.'\n            }\n            ],\n            'Learn More': [\n            {\n                'link': 'https://tester.test.com/welcome.html',\n                'text': 'Welcome!'\n            }\n            ]\n        }\n      })\n    }\n      'private': {\n        'intro_tables': {\n          'trunk_message.html': 'available on trunk'\n      }\n    }\n  }\n}\n}\n\nCANNED_API_FILE_SYSTEM_DATA = {\n  'trunk': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'contextMenus': {\n          'channel': 'stable'\n      }\n        'events': {\n          'channel': 'stable'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'history': {\n          'channel': 'beta'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'beta'\n      }\n        'sync': {\n          'channel': 'trunk'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'cookies': {\n          'channel': 'dev'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'falseBetaAPI': {\n          'channel': 'beta'\n      }\n        'trunkAPI': {\n          'channel': 'trunk'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n    'docs': {\n      'templates': {\n        'json': {\n          'api_availabilities.json': json.dumps({\n            'jsonAPI1': {\n              'channel': 'stable',\n              'version': 10\n          }\n            'jsonAPI2': {\n              'channel': 'trunk'\n          }\n            'jsonAPI3': {\n              'channel': 'dev'\n          }\n        }),\n          'intro_tables.json': json.dumps({\n            'test': [\n            {\n                'Permissions': 'probably none'\n            }\n            ]\n        })\n      }\n    }\n  }\n}\n  '1500': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'events': {\n          'channel': 'trunk'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n        'systemInfo.stuff': {\n          'channel': 'dev'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'contextMenus': {\n          'channel': 'trunk'\n      }\n        'notifications': {\n          'channel': 'beta'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'dev'\n      }\n        'sync': {\n          'channel': 'trunk'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'cookies': {\n          'channel': 'dev'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'downloads': {\n          'channel': 'beta'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1453': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'events': {\n          'channel': 'dev'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n        'systemInfo.cpu': {\n          'channel': 'stable'\n      }\n        'systemInfo.stuff': {\n          'channel': 'dev'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'notifications': {\n          'channel': 'dev'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'dev'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'context_menus': {\n          'channel': 'trunk'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'downloads': {\n          'channel': 'dev'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1410': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'events': {\n          'channel': 'beta'\n      }\n        'notifications': {\n          'channel': 'dev'\n      }\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'context_menus': {\n          'channel': 'trunk'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1364': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1312': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1271': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'system_info_display': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'beta'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'alarms.idl': 'alarms contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1229': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'beta'\n      }\n    }),\n      'alarms.idl': 'alarms contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'system_info_display.idl': 'systemInfo.display contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1180': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'bookmarks.json': 'bookmarks contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1132': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'trunk'\n      }\n        'page_action': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'bookmarks.json': 'bookmarks contents',\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1084': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'contents': 'nothing of interest here,really'\n    }),\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'pageAction.json': 'pageAction contents',\n      'tabs.json': 'tabs contents',\n      'webRequest.json': 'webRequest contents'\n  }\n}\n  '1025': {\n    'api': {\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'pageAction.json': 'pageAction contents',\n      'tabs.json': 'tabs contents',\n      'webRequest.json': 'webRequest contents'\n  }\n}\n  '963': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      {\n          'namespace': 'webRequest'\n      }\n      ])\n  }\n}\n  '912': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      {\n          'namespace': 'experimental.webRequest'\n      }\n      ])\n  }\n}\n  '874': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '835': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '782': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '742': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '696': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '648': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '597': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '552': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '544': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      ])\n  }\n}\n  '495': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      ])\n  }\n}\n  '396': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'experimental.menus'\n      }\n      ])\n  }\n}\n}\n" }
{ "repo_name": "XXMrHyde/android_external_chromium_org", "ref": "refs/heads/darkkat-4.4", "path": "chrome/common/extensions/docs/server2/test_data/canned_data.py", "content": "# Copyright 2013 The Chromium Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\nimport json\n\nCANNED_CHANNELS = {\n  'trunk': 'trunk',\n  'dev': 28,\n  'beta': 27,\n  'stable': 26\n}\n\nCANNED_BRANCHES = {\n  'trunk': 'trunk',\n  28: 1500,\n  27: 1453,\n  26: 1410,\n  25: 1364,\n  24: 1312,\n  23: 1271,\n  22: 1229,\n  21: 1180,\n  20: 1132,\n  19: 1084,\n  18: 1025,\n  17: 963,\n  16: 912,\n  15: 874,\n  14: 835,\n  13: 782,\n  12: 742,\n  11: 696,\n  10: 648,\n   9: 597,\n   8: 552,\n   7: 544,\n   6: 495,\n   5: 396\n}\n\nCANNED_TEST_FILE_SYSTEM_DATA = {\n  'api': {\n    '_api_features.json': json.dumps({\n      'ref_test': { 'dependencies': ['permission:ref_test'] }\n      'tester': { 'dependencies': ['permission:tester', 'manifest:tester'] }\n  }),\n    '_manifest_features.json': json.dumps({\n      'manifest': 'features'\n  }),\n    '_permission_features.json': json.dumps({\n      'permission': 'features'\n  })\n}\n  'docs': {\n    'templates': {\n      'intros': {\n        'test.html': '<h1>hi</h1>you<h2>first</h2><h3>inner</h3><h2>second</h2>'\n    }\n      'json': {\n        'api_availabilities.json': json.dumps({\n          'tester': {\n              'channel': 'stable',\n              'version': 42\n          }\n        }),\n        'intro_tables.json': json.dumps({\n          'tester': {\n            'Permissions': [\n            {\n                'class': 'override',\n                'text': '\"tester\"'\n            }\n            {\n                'text': 'is an API for testing things.'\n            }\n            ],\n            'Learn More': [\n            {\n                'link': 'https://tester.test.com/welcome.html',\n                'text': 'Welcome!'\n            }\n            ]\n        }\n      })\n    }\n      'private': {\n        'intro_tables': {\n          'trunk_message.html': 'available on trunk'\n      }\n    }\n  }\n}\n}\n\nCANNED_API_FILE_SYSTEM_DATA = {\n  'trunk': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'contextMenus': {\n          'channel': 'stable'\n      }\n        'events': {\n          'channel': 'stable'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'history': {\n          'channel': 'beta'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'beta'\n      }\n        'sync': {\n          'channel': 'trunk'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'cookies': {\n          'channel': 'dev'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'falseBetaAPI': {\n          'channel': 'beta'\n      }\n        'trunkAPI': {\n          'channel': 'trunk'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n    'docs': {\n      'templates': {\n        'json': {\n          'api_availabilities.json': json.dumps({\n            'jsonAPI1': {\n              'channel': 'stable',\n              'version': 10\n          }\n            'jsonAPI2': {\n              'channel': 'trunk'\n          }\n            'jsonAPI3': {\n              'channel': 'dev'\n          }\n        }),\n          'intro_tables.json': json.dumps({\n            'test': [\n            {\n                'Permissions': 'probably none'\n            }\n            ]\n        })\n      }\n    }\n  }\n}\n  '1500': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'events': {\n          'channel': 'trunk'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n        'systemInfo.stuff': {\n          'channel': 'dev'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'contextMenus': {\n          'channel': 'trunk'\n      }\n        'notifications': {\n          'channel': 'beta'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'dev'\n      }\n        'sync': {\n          'channel': 'trunk'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'cookies': {\n          'channel': 'dev'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'downloads': {\n          'channel': 'beta'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1453': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'events': {\n          'channel': 'dev'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n        'systemInfo.cpu': {\n          'channel': 'stable'\n      }\n        'systemInfo.stuff': {\n          'channel': 'dev'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'notifications': {\n          'channel': 'dev'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'dev'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'context_menus': {\n          'channel': 'trunk'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'downloads': {\n          'channel': 'dev'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1410': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'events': {\n          'channel': 'beta'\n      }\n        'notifications': {\n          'channel': 'dev'\n      }\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'context_menus': {\n          'channel': 'trunk'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1364': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1312': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1271': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'system_info_display': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'beta'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'alarms.idl': 'alarms contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1229': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'beta'\n      }\n    }),\n      'alarms.idl': 'alarms contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'system_info_display.idl': 'systemInfo.display contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1180': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'bookmarks.json': 'bookmarks contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1132': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'trunk'\n      }\n        'page_action': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'bookmarks.json': 'bookmarks contents',\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1084': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'contents': 'nothing of interest here,really'\n    }),\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'pageAction.json': 'pageAction contents',\n      'tabs.json': 'tabs contents',\n      'webRequest.json': 'webRequest contents'\n  }\n}\n  '1025': {\n    'api': {\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'pageAction.json': 'pageAction contents',\n      'tabs.json': 'tabs contents',\n      'webRequest.json': 'webRequest contents'\n  }\n}\n  '963': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      {\n          'namespace': 'webRequest'\n      }\n      ])\n  }\n}\n  '912': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      {\n          'namespace': 'experimental.webRequest'\n      }\n      ])\n  }\n}\n  '874': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '835': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '782': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '742': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '696': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '648': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '597': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '552': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '544': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      ])\n  }\n}\n  '495': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      ])\n  }\n}\n  '396': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'experimental.menus'\n      }\n      ])\n  }\n}\n}\n" }
{ "repo_name": "ThinkingBridge/platform_external_chromium_org", "ref": "refs/heads/kitkat", "path": "chrome/common/extensions/docs/server2/test_data/canned_data.py", "content": "# Copyright 2013 The Chromium Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\nimport json\n\nCANNED_CHANNELS = {\n  'trunk': 'trunk',\n  'dev': 28,\n  'beta': 27,\n  'stable': 26\n}\n\nCANNED_BRANCHES = {\n  'trunk': 'trunk',\n  28: 1500,\n  27: 1453,\n  26: 1410,\n  25: 1364,\n  24: 1312,\n  23: 1271,\n  22: 1229,\n  21: 1180,\n  20: 1132,\n  19: 1084,\n  18: 1025,\n  17: 963,\n  16: 912,\n  15: 874,\n  14: 835,\n  13: 782,\n  12: 742,\n  11: 696,\n  10: 648,\n   9: 597,\n   8: 552,\n   7: 544,\n   6: 495,\n   5: 396\n}\n\nCANNED_TEST_FILE_SYSTEM_DATA = {\n  'api': {\n    '_api_features.json': json.dumps({\n      'ref_test': { 'dependencies': ['permission:ref_test'] }\n      'tester': { 'dependencies': ['permission:tester', 'manifest:tester'] }\n  }),\n    '_manifest_features.json': json.dumps({\n      'manifest': 'features'\n  }),\n    '_permission_features.json': json.dumps({\n      'permission': 'features'\n  })\n}\n  'docs': {\n    'templates': {\n      'intros': {\n        'test.html': '<h1>hi</h1>you<h2>first</h2><h3>inner</h3><h2>second</h2>'\n    }\n      'json': {\n        'api_availabilities.json': json.dumps({\n          'tester': {\n              'channel': 'stable',\n              'version': 42\n          }\n        }),\n        'intro_tables.json': json.dumps({\n          'tester': {\n            'Permissions': [\n            {\n                'class': 'override',\n                'text': '\"tester\"'\n            }\n            {\n                'text': 'is an API for testing things.'\n            }\n            ],\n            'Learn More': [\n            {\n                'link': 'https://tester.test.com/welcome.html',\n                'text': 'Welcome!'\n            }\n            ]\n        }\n      })\n    }\n      'private': {\n        'intro_tables': {\n          'trunk_message.html': 'available on trunk'\n      }\n    }\n  }\n}\n}\n\nCANNED_API_FILE_SYSTEM_DATA = {\n  'trunk': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'contextMenus': {\n          'channel': 'stable'\n      }\n        'events': {\n          'channel': 'stable'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'history': {\n          'channel': 'beta'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'beta'\n      }\n        'sync': {\n          'channel': 'trunk'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'cookies': {\n          'channel': 'dev'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'falseBetaAPI': {\n          'channel': 'beta'\n      }\n        'trunkAPI': {\n          'channel': 'trunk'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n    'docs': {\n      'templates': {\n        'json': {\n          'api_availabilities.json': json.dumps({\n            'jsonAPI1': {\n              'channel': 'stable',\n              'version': 10\n          }\n            'jsonAPI2': {\n              'channel': 'trunk'\n          }\n            'jsonAPI3': {\n              'channel': 'dev'\n          }\n        }),\n          'intro_tables.json': json.dumps({\n            'test': [\n            {\n                'Permissions': 'probably none'\n            }\n            ]\n        })\n      }\n    }\n  }\n}\n  '1500': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'events': {\n          'channel': 'trunk'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n        'systemInfo.stuff': {\n          'channel': 'dev'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'contextMenus': {\n          'channel': 'trunk'\n      }\n        'notifications': {\n          'channel': 'beta'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'dev'\n      }\n        'sync': {\n          'channel': 'trunk'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'cookies': {\n          'channel': 'dev'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'downloads': {\n          'channel': 'beta'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1453': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'events': {\n          'channel': 'dev'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n        'systemInfo.cpu': {\n          'channel': 'stable'\n      }\n        'systemInfo.stuff': {\n          'channel': 'dev'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'notifications': {\n          'channel': 'dev'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'dev'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'context_menus': {\n          'channel': 'trunk'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'downloads': {\n          'channel': 'dev'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1410': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'events': {\n          'channel': 'beta'\n      }\n        'notifications': {\n          'channel': 'dev'\n      }\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'context_menus': {\n          'channel': 'trunk'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1364': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1312': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1271': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'system_info_display': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'beta'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'alarms.idl': 'alarms contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1229': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'beta'\n      }\n    }),\n      'alarms.idl': 'alarms contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'system_info_display.idl': 'systemInfo.display contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1180': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'bookmarks.json': 'bookmarks contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1132': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'trunk'\n      }\n        'page_action': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'bookmarks.json': 'bookmarks contents',\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1084': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'contents': 'nothing of interest here,really'\n    }),\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'pageAction.json': 'pageAction contents',\n      'tabs.json': 'tabs contents',\n      'webRequest.json': 'webRequest contents'\n  }\n}\n  '1025': {\n    'api': {\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'pageAction.json': 'pageAction contents',\n      'tabs.json': 'tabs contents',\n      'webRequest.json': 'webRequest contents'\n  }\n}\n  '963': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      {\n          'namespace': 'webRequest'\n      }\n      ])\n  }\n}\n  '912': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      {\n          'namespace': 'experimental.webRequest'\n      }\n      ])\n  }\n}\n  '874': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '835': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '782': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '742': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '696': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '648': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '597': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '552': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '544': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      ])\n  }\n}\n  '495': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      ])\n  }\n}\n  '396': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'experimental.menus'\n      }\n      ])\n  }\n}\n}\n" }
{ "repo_name": "klusark/android_external_chromium_org", "ref": "refs/heads/cm-11.0", "path": "chrome/common/extensions/docs/server2/test_data/canned_data.py", "content": "# Copyright 2013 The Chromium Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\nimport json\n\nCANNED_CHANNELS = {\n  'trunk': 'trunk',\n  'dev': 28,\n  'beta': 27,\n  'stable': 26\n}\n\nCANNED_BRANCHES = {\n  'trunk': 'trunk',\n  28: 1500,\n  27: 1453,\n  26: 1410,\n  25: 1364,\n  24: 1312,\n  23: 1271,\n  22: 1229,\n  21: 1180,\n  20: 1132,\n  19: 1084,\n  18: 1025,\n  17: 963,\n  16: 912,\n  15: 874,\n  14: 835,\n  13: 782,\n  12: 742,\n  11: 696,\n  10: 648,\n   9: 597,\n   8: 552,\n   7: 544,\n   6: 495,\n   5: 396\n}\n\nCANNED_TEST_FILE_SYSTEM_DATA = {\n  'api': {\n    '_api_features.json': json.dumps({\n      'ref_test': { 'dependencies': ['permission:ref_test'] }\n      'tester': { 'dependencies': ['permission:tester', 'manifest:tester'] }\n  }),\n    '_manifest_features.json': json.dumps({\n      'manifest': 'features'\n  }),\n    '_permission_features.json': json.dumps({\n      'permission': 'features'\n  })\n}\n  'docs': {\n    'templates': {\n      'intros': {\n        'test.html': '<h1>hi</h1>you<h2>first</h2><h3>inner</h3><h2>second</h2>'\n    }\n      'json': {\n        'api_availabilities.json': json.dumps({\n          'tester': {\n              'channel': 'stable',\n              'version': 42\n          }\n        }),\n        'intro_tables.json': json.dumps({\n          'tester': {\n            'Permissions': [\n            {\n                'class': 'override',\n                'text': '\"tester\"'\n            }\n            {\n                'text': 'is an API for testing things.'\n            }\n            ],\n            'Learn More': [\n            {\n                'link': 'https://tester.test.com/welcome.html',\n                'text': 'Welcome!'\n            }\n            ]\n        }\n      })\n    }\n      'private': {\n        'intro_tables': {\n          'trunk_message.html': 'available on trunk'\n      }\n    }\n  }\n}\n}\n\nCANNED_API_FILE_SYSTEM_DATA = {\n  'trunk': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'contextMenus': {\n          'channel': 'stable'\n      }\n        'events': {\n          'channel': 'stable'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'history': {\n          'channel': 'beta'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'beta'\n      }\n        'sync': {\n          'channel': 'trunk'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'cookies': {\n          'channel': 'dev'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'falseBetaAPI': {\n          'channel': 'beta'\n      }\n        'trunkAPI': {\n          'channel': 'trunk'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n    'docs': {\n      'templates': {\n        'json': {\n          'api_availabilities.json': json.dumps({\n            'jsonAPI1': {\n              'channel': 'stable',\n              'version': 10\n          }\n            'jsonAPI2': {\n              'channel': 'trunk'\n          }\n            'jsonAPI3': {\n              'channel': 'dev'\n          }\n        }),\n          'intro_tables.json': json.dumps({\n            'test': [\n            {\n                'Permissions': 'probably none'\n            }\n            ]\n        })\n      }\n    }\n  }\n}\n  '1500': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'events': {\n          'channel': 'trunk'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n        'systemInfo.stuff': {\n          'channel': 'dev'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'contextMenus': {\n          'channel': 'trunk'\n      }\n        'notifications': {\n          'channel': 'beta'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'dev'\n      }\n        'sync': {\n          'channel': 'trunk'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'cookies': {\n          'channel': 'dev'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'downloads': {\n          'channel': 'beta'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1453': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'events': {\n          'channel': 'dev'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n        'systemInfo.cpu': {\n          'channel': 'stable'\n      }\n        'systemInfo.stuff': {\n          'channel': 'dev'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'notifications': {\n          'channel': 'dev'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'dev'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'context_menus': {\n          'channel': 'trunk'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'downloads': {\n          'channel': 'dev'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1410': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'events': {\n          'channel': 'beta'\n      }\n        'notifications': {\n          'channel': 'dev'\n      }\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'context_menus': {\n          'channel': 'trunk'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1364': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1312': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1271': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'system_info_display': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'beta'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'alarms.idl': 'alarms contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1229': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'beta'\n      }\n    }),\n      'alarms.idl': 'alarms contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'system_info_display.idl': 'systemInfo.display contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1180': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'bookmarks.json': 'bookmarks contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1132': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'trunk'\n      }\n        'page_action': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'bookmarks.json': 'bookmarks contents',\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1084': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'contents': 'nothing of interest here,really'\n    }),\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'pageAction.json': 'pageAction contents',\n      'tabs.json': 'tabs contents',\n      'webRequest.json': 'webRequest contents'\n  }\n}\n  '1025': {\n    'api': {\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'pageAction.json': 'pageAction contents',\n      'tabs.json': 'tabs contents',\n      'webRequest.json': 'webRequest contents'\n  }\n}\n  '963': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      {\n          'namespace': 'webRequest'\n      }\n      ])\n  }\n}\n  '912': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      {\n          'namespace': 'experimental.webRequest'\n      }\n      ])\n  }\n}\n  '874': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '835': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '782': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '742': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '696': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '648': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '597': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '552': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '544': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      ])\n  }\n}\n  '495': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      ])\n  }\n}\n  '396': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'experimental.menus'\n      }\n      ])\n  }\n}\n}\n" }
{ "repo_name": "MotorolaMobilityLLC/external-chromium_org", "ref": "refs/heads/kitkat-mr1-release-falcon-gpe", "path": "chrome/common/extensions/docs/server2/test_data/canned_data.py", "content": "# Copyright 2013 The Chromium Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\nimport json\n\nCANNED_CHANNELS = {\n  'trunk': 'trunk',\n  'dev': 28,\n  'beta': 27,\n  'stable': 26\n}\n\nCANNED_BRANCHES = {\n  'trunk': 'trunk',\n  28: 1500,\n  27: 1453,\n  26: 1410,\n  25: 1364,\n  24: 1312,\n  23: 1271,\n  22: 1229,\n  21: 1180,\n  20: 1132,\n  19: 1084,\n  18: 1025,\n  17: 963,\n  16: 912,\n  15: 874,\n  14: 835,\n  13: 782,\n  12: 742,\n  11: 696,\n  10: 648,\n   9: 597,\n   8: 552,\n   7: 544,\n   6: 495,\n   5: 396\n}\n\nCANNED_TEST_FILE_SYSTEM_DATA = {\n  'api': {\n    '_api_features.json': json.dumps({\n      'ref_test': { 'dependencies': ['permission:ref_test'] }\n      'tester': { 'dependencies': ['permission:tester', 'manifest:tester'] }\n  }),\n    '_manifest_features.json': json.dumps({\n      'manifest': 'features'\n  }),\n    '_permission_features.json': json.dumps({\n      'permission': 'features'\n  })\n}\n  'docs': {\n    'templates': {\n      'intros': {\n        'test.html': '<h1>hi</h1>you<h2>first</h2><h3>inner</h3><h2>second</h2>'\n    }\n      'json': {\n        'api_availabilities.json': json.dumps({\n          'tester': {\n              'channel': 'stable',\n              'version': 42\n          }\n        }),\n        'intro_tables.json': json.dumps({\n          'tester': {\n            'Permissions': [\n            {\n                'class': 'override',\n                'text': '\"tester\"'\n            }\n            {\n                'text': 'is an API for testing things.'\n            }\n            ],\n            'Learn More': [\n            {\n                'link': 'https://tester.test.com/welcome.html',\n                'text': 'Welcome!'\n            }\n            ]\n        }\n      })\n    }\n      'private': {\n        'intro_tables': {\n          'trunk_message.html': 'available on trunk'\n      }\n    }\n  }\n}\n}\n\nCANNED_API_FILE_SYSTEM_DATA = {\n  'trunk': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'contextMenus': {\n          'channel': 'stable'\n      }\n        'events': {\n          'channel': 'stable'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'history': {\n          'channel': 'beta'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'beta'\n      }\n        'sync': {\n          'channel': 'trunk'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'cookies': {\n          'channel': 'dev'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'falseBetaAPI': {\n          'channel': 'beta'\n      }\n        'trunkAPI': {\n          'channel': 'trunk'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n    'docs': {\n      'templates': {\n        'json': {\n          'api_availabilities.json': json.dumps({\n            'jsonAPI1': {\n              'channel': 'stable',\n              'version': 10\n          }\n            'jsonAPI2': {\n              'channel': 'trunk'\n          }\n            'jsonAPI3': {\n              'channel': 'dev'\n          }\n        }),\n          'intro_tables.json': json.dumps({\n            'test': [\n            {\n                'Permissions': 'probably none'\n            }\n            ]\n        })\n      }\n    }\n  }\n}\n  '1500': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'events': {\n          'channel': 'trunk'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n        'systemInfo.stuff': {\n          'channel': 'dev'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'contextMenus': {\n          'channel': 'trunk'\n      }\n        'notifications': {\n          'channel': 'beta'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'dev'\n      }\n        'sync': {\n          'channel': 'trunk'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'cookies': {\n          'channel': 'dev'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'downloads': {\n          'channel': 'beta'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1453': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'events': {\n          'channel': 'dev'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n        'systemInfo.cpu': {\n          'channel': 'stable'\n      }\n        'systemInfo.stuff': {\n          'channel': 'dev'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'notifications': {\n          'channel': 'dev'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'dev'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'context_menus': {\n          'channel': 'trunk'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'downloads': {\n          'channel': 'dev'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1410': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'events': {\n          'channel': 'beta'\n      }\n        'notifications': {\n          'channel': 'dev'\n      }\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'context_menus': {\n          'channel': 'trunk'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1364': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1312': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1271': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'system_info_display': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'beta'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'alarms.idl': 'alarms contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1229': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'beta'\n      }\n    }),\n      'alarms.idl': 'alarms contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'system_info_display.idl': 'systemInfo.display contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1180': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'bookmarks.json': 'bookmarks contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1132': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'trunk'\n      }\n        'page_action': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'bookmarks.json': 'bookmarks contents',\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1084': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'contents': 'nothing of interest here,really'\n    }),\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'pageAction.json': 'pageAction contents',\n      'tabs.json': 'tabs contents',\n      'webRequest.json': 'webRequest contents'\n  }\n}\n  '1025': {\n    'api': {\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'pageAction.json': 'pageAction contents',\n      'tabs.json': 'tabs contents',\n      'webRequest.json': 'webRequest contents'\n  }\n}\n  '963': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      {\n          'namespace': 'webRequest'\n      }\n      ])\n  }\n}\n  '912': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      {\n          'namespace': 'experimental.webRequest'\n      }\n      ])\n  }\n}\n  '874': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '835': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '782': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '742': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '696': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '648': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '597': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '552': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '544': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      ])\n  }\n}\n  '495': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      ])\n  }\n}\n  '396': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'experimental.menus'\n      }\n      ])\n  }\n}\n}\n" }
{ "repo_name": "KitKatXperience/platform_external_chromium_org", "ref": "refs/heads/kk", "path": "chrome/common/extensions/docs/server2/test_data/canned_data.py", "content": "# Copyright 2013 The Chromium Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\nimport json\n\nCANNED_CHANNELS = {\n  'trunk': 'trunk',\n  'dev': 28,\n  'beta': 27,\n  'stable': 26\n}\n\nCANNED_BRANCHES = {\n  'trunk': 'trunk',\n  28: 1500,\n  27: 1453,\n  26: 1410,\n  25: 1364,\n  24: 1312,\n  23: 1271,\n  22: 1229,\n  21: 1180,\n  20: 1132,\n  19: 1084,\n  18: 1025,\n  17: 963,\n  16: 912,\n  15: 874,\n  14: 835,\n  13: 782,\n  12: 742,\n  11: 696,\n  10: 648,\n   9: 597,\n   8: 552,\n   7: 544,\n   6: 495,\n   5: 396\n}\n\nCANNED_TEST_FILE_SYSTEM_DATA = {\n  'api': {\n    '_api_features.json': json.dumps({\n      'ref_test': { 'dependencies': ['permission:ref_test'] }\n      'tester': { 'dependencies': ['permission:tester', 'manifest:tester'] }\n  }),\n    '_manifest_features.json': json.dumps({\n      'manifest': 'features'\n  }),\n    '_permission_features.json': json.dumps({\n      'permission': 'features'\n  })\n}\n  'docs': {\n    'templates': {\n      'intros': {\n        'test.html': '<h1>hi</h1>you<h2>first</h2><h3>inner</h3><h2>second</h2>'\n    }\n      'json': {\n        'api_availabilities.json': json.dumps({\n          'tester': {\n              'channel': 'stable',\n              'version': 42\n          }\n        }),\n        'intro_tables.json': json.dumps({\n          'tester': {\n            'Permissions': [\n            {\n                'class': 'override',\n                'text': '\"tester\"'\n            }\n            {\n                'text': 'is an API for testing things.'\n            }\n            ],\n            'Learn More': [\n            {\n                'link': 'https://tester.test.com/welcome.html',\n                'text': 'Welcome!'\n            }\n            ]\n        }\n      })\n    }\n      'private': {\n        'intro_tables': {\n          'trunk_message.html': 'available on trunk'\n      }\n    }\n  }\n}\n}\n\nCANNED_API_FILE_SYSTEM_DATA = {\n  'trunk': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'contextMenus': {\n          'channel': 'stable'\n      }\n        'events': {\n          'channel': 'stable'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'history': {\n          'channel': 'beta'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'beta'\n      }\n        'sync': {\n          'channel': 'trunk'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'cookies': {\n          'channel': 'dev'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'falseBetaAPI': {\n          'channel': 'beta'\n      }\n        'trunkAPI': {\n          'channel': 'trunk'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n    'docs': {\n      'templates': {\n        'json': {\n          'api_availabilities.json': json.dumps({\n            'jsonAPI1': {\n              'channel': 'stable',\n              'version': 10\n          }\n            'jsonAPI2': {\n              'channel': 'trunk'\n          }\n            'jsonAPI3': {\n              'channel': 'dev'\n          }\n        }),\n          'intro_tables.json': json.dumps({\n            'test': [\n            {\n                'Permissions': 'probably none'\n            }\n            ]\n        })\n      }\n    }\n  }\n}\n  '1500': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'events': {\n          'channel': 'trunk'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n        'systemInfo.stuff': {\n          'channel': 'dev'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'contextMenus': {\n          'channel': 'trunk'\n      }\n        'notifications': {\n          'channel': 'beta'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'dev'\n      }\n        'sync': {\n          'channel': 'trunk'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'cookies': {\n          'channel': 'dev'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'downloads': {\n          'channel': 'beta'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1453': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'events': {\n          'channel': 'dev'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n        'systemInfo.cpu': {\n          'channel': 'stable'\n      }\n        'systemInfo.stuff': {\n          'channel': 'dev'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'notifications': {\n          'channel': 'dev'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'dev'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'context_menus': {\n          'channel': 'trunk'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'downloads': {\n          'channel': 'dev'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1410': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'events': {\n          'channel': 'beta'\n      }\n        'notifications': {\n          'channel': 'dev'\n      }\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'context_menus': {\n          'channel': 'trunk'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1364': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1312': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1271': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'system_info_display': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'beta'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'alarms.idl': 'alarms contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1229': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'beta'\n      }\n    }),\n      'alarms.idl': 'alarms contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'system_info_display.idl': 'systemInfo.display contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1180': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'bookmarks.json': 'bookmarks contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1132': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'trunk'\n      }\n        'page_action': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'bookmarks.json': 'bookmarks contents',\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1084': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'contents': 'nothing of interest here,really'\n    }),\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'pageAction.json': 'pageAction contents',\n      'tabs.json': 'tabs contents',\n      'webRequest.json': 'webRequest contents'\n  }\n}\n  '1025': {\n    'api': {\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'pageAction.json': 'pageAction contents',\n      'tabs.json': 'tabs contents',\n      'webRequest.json': 'webRequest contents'\n  }\n}\n  '963': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      {\n          'namespace': 'webRequest'\n      }\n      ])\n  }\n}\n  '912': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      {\n          'namespace': 'experimental.webRequest'\n      }\n      ])\n  }\n}\n  '874': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '835': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '782': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '742': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '696': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '648': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '597': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '552': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '544': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      ])\n  }\n}\n  '495': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      ])\n  }\n}\n  '396': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'experimental.menus'\n      }\n      ])\n  }\n}\n}\n" }
{ "repo_name": "BigBrother1984/android_external_chromium_org", "ref": "refs/heads/kitkat", "path": "chrome/common/extensions/docs/server2/test_data/canned_data.py", "content": "# Copyright 2013 The Chromium Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\nimport json\n\nCANNED_CHANNELS = {\n  'trunk': 'trunk',\n  'dev': 28,\n  'beta': 27,\n  'stable': 26\n}\n\nCANNED_BRANCHES = {\n  'trunk': 'trunk',\n  28: 1500,\n  27: 1453,\n  26: 1410,\n  25: 1364,\n  24: 1312,\n  23: 1271,\n  22: 1229,\n  21: 1180,\n  20: 1132,\n  19: 1084,\n  18: 1025,\n  17: 963,\n  16: 912,\n  15: 874,\n  14: 835,\n  13: 782,\n  12: 742,\n  11: 696,\n  10: 648,\n   9: 597,\n   8: 552,\n   7: 544,\n   6: 495,\n   5: 396\n}\n\nCANNED_TEST_FILE_SYSTEM_DATA = {\n  'api': {\n    '_api_features.json': json.dumps({\n      'ref_test': { 'dependencies': ['permission:ref_test'] }\n      'tester': { 'dependencies': ['permission:tester', 'manifest:tester'] }\n  }),\n    '_manifest_features.json': json.dumps({\n      'manifest': 'features'\n  }),\n    '_permission_features.json': json.dumps({\n      'permission': 'features'\n  })\n}\n  'docs': {\n    'templates': {\n      'intros': {\n        'test.html': '<h1>hi</h1>you<h2>first</h2><h3>inner</h3><h2>second</h2>'\n    }\n      'json': {\n        'api_availabilities.json': json.dumps({\n          'tester': {\n              'channel': 'stable',\n              'version': 42\n          }\n        }),\n        'intro_tables.json': json.dumps({\n          'tester': {\n            'Permissions': [\n            {\n                'class': 'override',\n                'text': '\"tester\"'\n            }\n            {\n                'text': 'is an API for testing things.'\n            }\n            ],\n            'Learn More': [\n            {\n                'link': 'https://tester.test.com/welcome.html',\n                'text': 'Welcome!'\n            }\n            ]\n        }\n      })\n    }\n      'private': {\n        'intro_tables': {\n          'trunk_message.html': 'available on trunk'\n      }\n    }\n  }\n}\n}\n\nCANNED_API_FILE_SYSTEM_DATA = {\n  'trunk': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'contextMenus': {\n          'channel': 'stable'\n      }\n        'events': {\n          'channel': 'stable'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'history': {\n          'channel': 'beta'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'beta'\n      }\n        'sync': {\n          'channel': 'trunk'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'cookies': {\n          'channel': 'dev'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'falseBetaAPI': {\n          'channel': 'beta'\n      }\n        'trunkAPI': {\n          'channel': 'trunk'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n    'docs': {\n      'templates': {\n        'json': {\n          'api_availabilities.json': json.dumps({\n            'jsonAPI1': {\n              'channel': 'stable',\n              'version': 10\n          }\n            'jsonAPI2': {\n              'channel': 'trunk'\n          }\n            'jsonAPI3': {\n              'channel': 'dev'\n          }\n        }),\n          'intro_tables.json': json.dumps({\n            'test': [\n            {\n                'Permissions': 'probably none'\n            }\n            ]\n        })\n      }\n    }\n  }\n}\n  '1500': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'events': {\n          'channel': 'trunk'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n        'systemInfo.stuff': {\n          'channel': 'dev'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'contextMenus': {\n          'channel': 'trunk'\n      }\n        'notifications': {\n          'channel': 'beta'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'dev'\n      }\n        'sync': {\n          'channel': 'trunk'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'cookies': {\n          'channel': 'dev'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'downloads': {\n          'channel': 'beta'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1453': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'events': {\n          'channel': 'dev'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n        'systemInfo.cpu': {\n          'channel': 'stable'\n      }\n        'systemInfo.stuff': {\n          'channel': 'dev'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'notifications': {\n          'channel': 'dev'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'dev'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'context_menus': {\n          'channel': 'trunk'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'downloads': {\n          'channel': 'dev'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1410': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'events': {\n          'channel': 'beta'\n      }\n        'notifications': {\n          'channel': 'dev'\n      }\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'context_menus': {\n          'channel': 'trunk'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1364': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1312': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1271': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'system_info_display': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'beta'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'alarms.idl': 'alarms contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1229': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'beta'\n      }\n    }),\n      'alarms.idl': 'alarms contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'system_info_display.idl': 'systemInfo.display contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1180': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'bookmarks.json': 'bookmarks contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1132': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'trunk'\n      }\n        'page_action': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'bookmarks.json': 'bookmarks contents',\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1084': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'contents': 'nothing of interest here,really'\n    }),\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'pageAction.json': 'pageAction contents',\n      'tabs.json': 'tabs contents',\n      'webRequest.json': 'webRequest contents'\n  }\n}\n  '1025': {\n    'api': {\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'pageAction.json': 'pageAction contents',\n      'tabs.json': 'tabs contents',\n      'webRequest.json': 'webRequest contents'\n  }\n}\n  '963': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      {\n          'namespace': 'webRequest'\n      }\n      ])\n  }\n}\n  '912': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      {\n          'namespace': 'experimental.webRequest'\n      }\n      ])\n  }\n}\n  '874': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '835': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '782': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '742': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '696': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '648': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '597': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '552': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '544': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      ])\n  }\n}\n  '495': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      ])\n  }\n}\n  '396': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'experimental.menus'\n      }\n      ])\n  }\n}\n}\n" }
{ "repo_name": "AOKP/external_chromium_org", "ref": "refs/heads/kitkat", "path": "chrome/common/extensions/docs/server2/test_data/canned_data.py", "content": "# Copyright 2013 The Chromium Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\nimport json\n\nCANNED_CHANNELS = {\n  'trunk': 'trunk',\n  'dev': 28,\n  'beta': 27,\n  'stable': 26\n}\n\nCANNED_BRANCHES = {\n  'trunk': 'trunk',\n  28: 1500,\n  27: 1453,\n  26: 1410,\n  25: 1364,\n  24: 1312,\n  23: 1271,\n  22: 1229,\n  21: 1180,\n  20: 1132,\n  19: 1084,\n  18: 1025,\n  17: 963,\n  16: 912,\n  15: 874,\n  14: 835,\n  13: 782,\n  12: 742,\n  11: 696,\n  10: 648,\n   9: 597,\n   8: 552,\n   7: 544,\n   6: 495,\n   5: 396\n}\n\nCANNED_TEST_FILE_SYSTEM_DATA = {\n  'api': {\n    '_api_features.json': json.dumps({\n      'ref_test': { 'dependencies': ['permission:ref_test'] }\n      'tester': { 'dependencies': ['permission:tester', 'manifest:tester'] }\n  }),\n    '_manifest_features.json': json.dumps({\n      'manifest': 'features'\n  }),\n    '_permission_features.json': json.dumps({\n      'permission': 'features'\n  })\n}\n  'docs': {\n    'templates': {\n      'intros': {\n        'test.html': '<h1>hi</h1>you<h2>first</h2><h3>inner</h3><h2>second</h2>'\n    }\n      'json': {\n        'api_availabilities.json': json.dumps({\n          'tester': {\n              'channel': 'stable',\n              'version': 42\n          }\n        }),\n        'intro_tables.json': json.dumps({\n          'tester': {\n            'Permissions': [\n            {\n                'class': 'override',\n                'text': '\"tester\"'\n            }\n            {\n                'text': 'is an API for testing things.'\n            }\n            ],\n            'Learn More': [\n            {\n                'link': 'https://tester.test.com/welcome.html',\n                'text': 'Welcome!'\n            }\n            ]\n        }\n      })\n    }\n      'private': {\n        'intro_tables': {\n          'trunk_message.html': 'available on trunk'\n      }\n    }\n  }\n}\n}\n\nCANNED_API_FILE_SYSTEM_DATA = {\n  'trunk': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'contextMenus': {\n          'channel': 'stable'\n      }\n        'events': {\n          'channel': 'stable'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'history': {\n          'channel': 'beta'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'beta'\n      }\n        'sync': {\n          'channel': 'trunk'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'cookies': {\n          'channel': 'dev'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'falseBetaAPI': {\n          'channel': 'beta'\n      }\n        'trunkAPI': {\n          'channel': 'trunk'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n    'docs': {\n      'templates': {\n        'json': {\n          'api_availabilities.json': json.dumps({\n            'jsonAPI1': {\n              'channel': 'stable',\n              'version': 10\n          }\n            'jsonAPI2': {\n              'channel': 'trunk'\n          }\n            'jsonAPI3': {\n              'channel': 'dev'\n          }\n        }),\n          'intro_tables.json': json.dumps({\n            'test': [\n            {\n                'Permissions': 'probably none'\n            }\n            ]\n        })\n      }\n    }\n  }\n}\n  '1500': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'events': {\n          'channel': 'trunk'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n        'systemInfo.stuff': {\n          'channel': 'dev'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'contextMenus': {\n          'channel': 'trunk'\n      }\n        'notifications': {\n          'channel': 'beta'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'dev'\n      }\n        'sync': {\n          'channel': 'trunk'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'cookies': {\n          'channel': 'dev'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'downloads': {\n          'channel': 'beta'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1453': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'events': {\n          'channel': 'dev'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n        'systemInfo.cpu': {\n          'channel': 'stable'\n      }\n        'systemInfo.stuff': {\n          'channel': 'dev'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'notifications': {\n          'channel': 'dev'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'dev'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'context_menus': {\n          'channel': 'trunk'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'downloads': {\n          'channel': 'dev'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1410': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'events': {\n          'channel': 'beta'\n      }\n        'notifications': {\n          'channel': 'dev'\n      }\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'context_menus': {\n          'channel': 'trunk'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1364': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1312': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1271': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'system_info_display': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'beta'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'alarms.idl': 'alarms contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1229': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'beta'\n      }\n    }),\n      'alarms.idl': 'alarms contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'system_info_display.idl': 'systemInfo.display contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1180': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'bookmarks.json': 'bookmarks contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1132': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'trunk'\n      }\n        'page_action': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'bookmarks.json': 'bookmarks contents',\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1084': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'contents': 'nothing of interest here,really'\n    }),\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'pageAction.json': 'pageAction contents',\n      'tabs.json': 'tabs contents',\n      'webRequest.json': 'webRequest contents'\n  }\n}\n  '1025': {\n    'api': {\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'pageAction.json': 'pageAction contents',\n      'tabs.json': 'tabs contents',\n      'webRequest.json': 'webRequest contents'\n  }\n}\n  '963': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      {\n          'namespace': 'webRequest'\n      }\n      ])\n  }\n}\n  '912': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      {\n          'namespace': 'experimental.webRequest'\n      }\n      ])\n  }\n}\n  '874': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '835': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '782': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '742': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '696': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '648': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '597': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '552': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '544': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      ])\n  }\n}\n  '495': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      ])\n  }\n}\n  '396': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'experimental.menus'\n      }\n      ])\n  }\n}\n}\n" }
{ "repo_name": "Evervolv/android_external_chromium_org", "ref": "refs/heads/kitkat", "path": "chrome/common/extensions/docs/server2/test_data/canned_data.py", "content": "# Copyright 2013 The Chromium Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\nimport json\n\nCANNED_CHANNELS = {\n  'trunk': 'trunk',\n  'dev': 28,\n  'beta': 27,\n  'stable': 26\n}\n\nCANNED_BRANCHES = {\n  'trunk': 'trunk',\n  28: 1500,\n  27: 1453,\n  26: 1410,\n  25: 1364,\n  24: 1312,\n  23: 1271,\n  22: 1229,\n  21: 1180,\n  20: 1132,\n  19: 1084,\n  18: 1025,\n  17: 963,\n  16: 912,\n  15: 874,\n  14: 835,\n  13: 782,\n  12: 742,\n  11: 696,\n  10: 648,\n   9: 597,\n   8: 552,\n   7: 544,\n   6: 495,\n   5: 396\n}\n\nCANNED_TEST_FILE_SYSTEM_DATA = {\n  'api': {\n    '_api_features.json': json.dumps({\n      'ref_test': { 'dependencies': ['permission:ref_test'] }\n      'tester': { 'dependencies': ['permission:tester', 'manifest:tester'] }\n  }),\n    '_manifest_features.json': json.dumps({\n      'manifest': 'features'\n  }),\n    '_permission_features.json': json.dumps({\n      'permission': 'features'\n  })\n}\n  'docs': {\n    'templates': {\n      'intros': {\n        'test.html': '<h1>hi</h1>you<h2>first</h2><h3>inner</h3><h2>second</h2>'\n    }\n      'json': {\n        'api_availabilities.json': json.dumps({\n          'tester': {\n              'channel': 'stable',\n              'version': 42\n          }\n        }),\n        'intro_tables.json': json.dumps({\n          'tester': {\n            'Permissions': [\n            {\n                'class': 'override',\n                'text': '\"tester\"'\n            }\n            {\n                'text': 'is an API for testing things.'\n            }\n            ],\n            'Learn More': [\n            {\n                'link': 'https://tester.test.com/welcome.html',\n                'text': 'Welcome!'\n            }\n            ]\n        }\n      })\n    }\n      'private': {\n        'intro_tables': {\n          'trunk_message.html': 'available on trunk'\n      }\n    }\n  }\n}\n}\n\nCANNED_API_FILE_SYSTEM_DATA = {\n  'trunk': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'contextMenus': {\n          'channel': 'stable'\n      }\n        'events': {\n          'channel': 'stable'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'history': {\n          'channel': 'beta'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'beta'\n      }\n        'sync': {\n          'channel': 'trunk'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'cookies': {\n          'channel': 'dev'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'falseBetaAPI': {\n          'channel': 'beta'\n      }\n        'trunkAPI': {\n          'channel': 'trunk'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n    'docs': {\n      'templates': {\n        'json': {\n          'api_availabilities.json': json.dumps({\n            'jsonAPI1': {\n              'channel': 'stable',\n              'version': 10\n          }\n            'jsonAPI2': {\n              'channel': 'trunk'\n          }\n            'jsonAPI3': {\n              'channel': 'dev'\n          }\n        }),\n          'intro_tables.json': json.dumps({\n            'test': [\n            {\n                'Permissions': 'probably none'\n            }\n            ]\n        })\n      }\n    }\n  }\n}\n  '1500': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'events': {\n          'channel': 'trunk'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n        'systemInfo.stuff': {\n          'channel': 'dev'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'contextMenus': {\n          'channel': 'trunk'\n      }\n        'notifications': {\n          'channel': 'beta'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'dev'\n      }\n        'sync': {\n          'channel': 'trunk'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'cookies': {\n          'channel': 'dev'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'downloads': {\n          'channel': 'beta'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1453': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'events': {\n          'channel': 'dev'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n        'systemInfo.cpu': {\n          'channel': 'stable'\n      }\n        'systemInfo.stuff': {\n          'channel': 'dev'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'notifications': {\n          'channel': 'dev'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'dev'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'context_menus': {\n          'channel': 'trunk'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'downloads': {\n          'channel': 'dev'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1410': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'events': {\n          'channel': 'beta'\n      }\n        'notifications': {\n          'channel': 'dev'\n      }\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'context_menus': {\n          'channel': 'trunk'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1364': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1312': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1271': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'system_info_display': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'beta'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'alarms.idl': 'alarms contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1229': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'beta'\n      }\n    }),\n      'alarms.idl': 'alarms contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'system_info_display.idl': 'systemInfo.display contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1180': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'bookmarks.json': 'bookmarks contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1132': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'trunk'\n      }\n        'page_action': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'bookmarks.json': 'bookmarks contents',\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1084': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'contents': 'nothing of interest here,really'\n    }),\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'pageAction.json': 'pageAction contents',\n      'tabs.json': 'tabs contents',\n      'webRequest.json': 'webRequest contents'\n  }\n}\n  '1025': {\n    'api': {\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'pageAction.json': 'pageAction contents',\n      'tabs.json': 'tabs contents',\n      'webRequest.json': 'webRequest contents'\n  }\n}\n  '963': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      {\n          'namespace': 'webRequest'\n      }\n      ])\n  }\n}\n  '912': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      {\n          'namespace': 'experimental.webRequest'\n      }\n      ])\n  }\n}\n  '874': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '835': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '782': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '742': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '696': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '648': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '597': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '552': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '544': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      ])\n  }\n}\n  '495': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      ])\n  }\n}\n  '396': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'experimental.menus'\n      }\n      ])\n  }\n}\n}\n" }
{ "repo_name": "brototyp/CouchPotato", "ref": "refs/heads/german", "path": "library/sqlalchemy/connectors/mxodbc.py", "content": "\"\"\"\nProvide an SQLALchemy connector for the eGenix mxODBC commercial\nPython adapter for ODBC. This is not a free product, but eGenix\nprovides SQLAlchemy with a license for use in continuous integration\ntesting.\n\nThis has been tested for use with mxODBC 3.1.2 on SQL Server 2005\nand 2008, using the SQL Server Native driver. However, it is\npossible for this to be used on other database platforms.\n\nFor more info on mxODBC, see http://www.egenix.com/\n\n\"\"\"\n\nimport sys\nimport re\nimport warnings\nfrom decimal import Decimal\n\nfrom sqlalchemy.connectors import Connector\nfrom sqlalchemy import types as sqltypes\nimport sqlalchemy.processors as processors\n\nclass MxODBCConnector(Connector):\n    driver='mxodbc'\n    \n    supports_sane_multi_rowcount = False\n    supports_unicode_statements = False\n    supports_unicode_binds = False\n    \n    supports_native_decimal = True\n    \n    @classmethod\n    def dbapi(cls):\n        # this classmethod will normally be replaced by an instance\n        # attribute of the same name, so this is normally only called once.\n        cls._load_mx_exceptions()\n        platform = sys.platform\n        if platform == 'win32':\n            from mx.ODBC import Windows as module\n        # this can be the string \"linux2\", and possibly others\n        elif 'linux' in platform:\n            from mx.ODBC import unixODBC as module\n        elif platform == 'darwin':\n            from mx.ODBC import iODBC as module\n        else:\n            raise ImportError, \"Unrecognized platform for mxODBC import\"\n        return module\n\n    @classmethod\n    def _load_mx_exceptions(cls):\n        \"\"\" Import mxODBC exception classes into the module namespace,\n        as if they had been imported normally. This is done here\n        to avoid requiring all SQLAlchemy users to install mxODBC.\n        \"\"\"\n        global InterfaceError, ProgrammingError\n        from mx.ODBC import InterfaceError\n        from mx.ODBC import ProgrammingError\n\n    def on_connect(self):\n        def connect(conn):\n            conn.stringformat = self.dbapi.MIXED_STRINGFORMAT\n            conn.datetimeformat = self.dbapi.PYDATETIME_DATETIMEFORMAT\n            conn.decimalformat = self.dbapi.DECIMAL_DECIMALFORMAT\n            conn.errorhandler = self._error_handler()\n        return connect\n    \n    def _error_handler(self):\n        \"\"\" Return a handler that adjusts mxODBC's raised Warnings to\n        emit Python standard warnings.\n        \"\"\"\n        from mx.ODBC.Error import Warning as MxOdbcWarning\n        def error_handler(connection, cursor, errorclass, errorvalue):\n\n            if issubclass(errorclass, MxOdbcWarning):\n                errorclass.__bases__ = (Warning,)\n                warnings.warn(message=str(errorvalue),\n                          category=errorclass,\n                          stacklevel=2)\n            else:\n                raise errorclass, errorvalue\n        return error_handler\n\n    def create_connect_args(self, url):\n        \"\"\" Return a tuple of *args,**kwargs for creating a connection.\n\n        The mxODBC 3.x connection constructor looks like this:\n\n            connect(dsn, user='', password='',\n                    clear_auto_commit=1, errorhandler=None)\n\n        This method translates the values in the provided uri\n        into args and kwargs needed to instantiate an mxODBC Connection.\n\n        The arg 'errorhandler' is not used by SQLAlchemy and will\n        not be populated.\n        \n        \"\"\"\n        opts = url.translate_connect_args(username='user')\n        opts.update(url.query)\n        args = opts.pop('host')\n        opts.pop('port', None)\n        opts.pop('database', None)\n        return (args,), opts\n\n    def is_disconnect(self, e):\n        # eGenix recommends checking connection.closed here,\n        # but how can we get a handle on the current connection?\n        if isinstance(e, self.dbapi.ProgrammingError):\n            return \"connection already closed\" in str(e)\n        elif isinstance(e, self.dbapi.Error):\n            return '[08S01]' in str(e)\n        else:\n            return False\n\n    def _get_server_version_info(self, connection):\n        # eGenix suggests using conn.dbms_version instead \n        # of what we're doing here\n        dbapi_con = connection.connection\n        version = []\n        r = re.compile('[.\\-]')\n        # 18 == pyodbc.SQL_DBMS_VER\n        for n in r.split(dbapi_con.getinfo(18)[1]):\n            try:\n                version.append(int(n))\n            except ValueError:\n                version.append(n)\n        return tuple(version)\n\n    def do_execute(self, cursor, statement, parameters, context=None):\n        if context:\n            native_odbc_execute = context.execution_options.\\\n                                        get('native_odbc_execute', 'auto')\n            if native_odbc_execute is True:\n                # user specified native_odbc_execute=True\n                cursor.execute(statement, parameters)\n            elif native_odbc_execute is False:\n                # user specified native_odbc_execute=False\n                cursor.executedirect(statement, parameters)\n            elif context.is_crud:\n                # statement is UPDATE, DELETE, INSERT\n                cursor.execute(statement, parameters)\n            else:\n                # all other statements\n                cursor.executedirect(statement, parameters)\n        else:\n            cursor.executedirect(statement, parameters)\n" }
{ "repo_name": "aospx-kitkat/platform_external_chromium_org", "ref": "refs/heads/kitkat", "path": "chrome/common/extensions/docs/server2/test_data/canned_data.py", "content": "# Copyright 2013 The Chromium Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\nimport json\n\nCANNED_CHANNELS = {\n  'trunk': 'trunk',\n  'dev': 28,\n  'beta': 27,\n  'stable': 26\n}\n\nCANNED_BRANCHES = {\n  'trunk': 'trunk',\n  28: 1500,\n  27: 1453,\n  26: 1410,\n  25: 1364,\n  24: 1312,\n  23: 1271,\n  22: 1229,\n  21: 1180,\n  20: 1132,\n  19: 1084,\n  18: 1025,\n  17: 963,\n  16: 912,\n  15: 874,\n  14: 835,\n  13: 782,\n  12: 742,\n  11: 696,\n  10: 648,\n   9: 597,\n   8: 552,\n   7: 544,\n   6: 495,\n   5: 396\n}\n\nCANNED_TEST_FILE_SYSTEM_DATA = {\n  'api': {\n    '_api_features.json': json.dumps({\n      'ref_test': { 'dependencies': ['permission:ref_test'] }\n      'tester': { 'dependencies': ['permission:tester', 'manifest:tester'] }\n  }),\n    '_manifest_features.json': json.dumps({\n      'manifest': 'features'\n  }),\n    '_permission_features.json': json.dumps({\n      'permission': 'features'\n  })\n}\n  'docs': {\n    'templates': {\n      'intros': {\n        'test.html': '<h1>hi</h1>you<h2>first</h2><h3>inner</h3><h2>second</h2>'\n    }\n      'json': {\n        'api_availabilities.json': json.dumps({\n          'tester': {\n              'channel': 'stable',\n              'version': 42\n          }\n        }),\n        'intro_tables.json': json.dumps({\n          'tester': {\n            'Permissions': [\n            {\n                'class': 'override',\n                'text': '\"tester\"'\n            }\n            {\n                'text': 'is an API for testing things.'\n            }\n            ],\n            'Learn More': [\n            {\n                'link': 'https://tester.test.com/welcome.html',\n                'text': 'Welcome!'\n            }\n            ]\n        }\n      })\n    }\n      'private': {\n        'intro_tables': {\n          'trunk_message.html': 'available on trunk'\n      }\n    }\n  }\n}\n}\n\nCANNED_API_FILE_SYSTEM_DATA = {\n  'trunk': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'contextMenus': {\n          'channel': 'stable'\n      }\n        'events': {\n          'channel': 'stable'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'history': {\n          'channel': 'beta'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'beta'\n      }\n        'sync': {\n          'channel': 'trunk'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'cookies': {\n          'channel': 'dev'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'falseBetaAPI': {\n          'channel': 'beta'\n      }\n        'trunkAPI': {\n          'channel': 'trunk'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n    'docs': {\n      'templates': {\n        'json': {\n          'api_availabilities.json': json.dumps({\n            'jsonAPI1': {\n              'channel': 'stable',\n              'version': 10\n          }\n            'jsonAPI2': {\n              'channel': 'trunk'\n          }\n            'jsonAPI3': {\n              'channel': 'dev'\n          }\n        }),\n          'intro_tables.json': json.dumps({\n            'test': [\n            {\n                'Permissions': 'probably none'\n            }\n            ]\n        })\n      }\n    }\n  }\n}\n  '1500': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'events': {\n          'channel': 'trunk'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n        'systemInfo.stuff': {\n          'channel': 'dev'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'contextMenus': {\n          'channel': 'trunk'\n      }\n        'notifications': {\n          'channel': 'beta'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'dev'\n      }\n        'sync': {\n          'channel': 'trunk'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'cookies': {\n          'channel': 'dev'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'downloads': {\n          'channel': 'beta'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1453': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'events': {\n          'channel': 'dev'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n        'systemInfo.cpu': {\n          'channel': 'stable'\n      }\n        'systemInfo.stuff': {\n          'channel': 'dev'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'notifications': {\n          'channel': 'dev'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'dev'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'context_menus': {\n          'channel': 'trunk'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'downloads': {\n          'channel': 'dev'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1410': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'events': {\n          'channel': 'beta'\n      }\n        'notifications': {\n          'channel': 'dev'\n      }\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'context_menus': {\n          'channel': 'trunk'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1364': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1312': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1271': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'system_info_display': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'beta'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'alarms.idl': 'alarms contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1229': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'beta'\n      }\n    }),\n      'alarms.idl': 'alarms contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'system_info_display.idl': 'systemInfo.display contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1180': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'bookmarks.json': 'bookmarks contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1132': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'trunk'\n      }\n        'page_action': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'bookmarks.json': 'bookmarks contents',\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1084': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'contents': 'nothing of interest here,really'\n    }),\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'pageAction.json': 'pageAction contents',\n      'tabs.json': 'tabs contents',\n      'webRequest.json': 'webRequest contents'\n  }\n}\n  '1025': {\n    'api': {\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'pageAction.json': 'pageAction contents',\n      'tabs.json': 'tabs contents',\n      'webRequest.json': 'webRequest contents'\n  }\n}\n  '963': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      {\n          'namespace': 'webRequest'\n      }\n      ])\n  }\n}\n  '912': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      {\n          'namespace': 'experimental.webRequest'\n      }\n      ])\n  }\n}\n  '874': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '835': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '782': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '742': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '696': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '648': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '597': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '552': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '544': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      ])\n  }\n}\n  '495': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      ])\n  }\n}\n  '396': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'experimental.menus'\n      }\n      ])\n  }\n}\n}\n" }
{ "repo_name": "gfreed/android_external_chromium-org", "ref": "refs/heads/android-4.4", "path": "chrome/common/extensions/docs/server2/test_data/canned_data.py", "content": "# Copyright 2013 The Chromium Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\nimport json\n\nCANNED_CHANNELS = {\n  'trunk': 'trunk',\n  'dev': 28,\n  'beta': 27,\n  'stable': 26\n}\n\nCANNED_BRANCHES = {\n  'trunk': 'trunk',\n  28: 1500,\n  27: 1453,\n  26: 1410,\n  25: 1364,\n  24: 1312,\n  23: 1271,\n  22: 1229,\n  21: 1180,\n  20: 1132,\n  19: 1084,\n  18: 1025,\n  17: 963,\n  16: 912,\n  15: 874,\n  14: 835,\n  13: 782,\n  12: 742,\n  11: 696,\n  10: 648,\n   9: 597,\n   8: 552,\n   7: 544,\n   6: 495,\n   5: 396\n}\n\nCANNED_TEST_FILE_SYSTEM_DATA = {\n  'api': {\n    '_api_features.json': json.dumps({\n      'ref_test': { 'dependencies': ['permission:ref_test'] }\n      'tester': { 'dependencies': ['permission:tester', 'manifest:tester'] }\n  }),\n    '_manifest_features.json': json.dumps({\n      'manifest': 'features'\n  }),\n    '_permission_features.json': json.dumps({\n      'permission': 'features'\n  })\n}\n  'docs': {\n    'templates': {\n      'intros': {\n        'test.html': '<h1>hi</h1>you<h2>first</h2><h3>inner</h3><h2>second</h2>'\n    }\n      'json': {\n        'api_availabilities.json': json.dumps({\n          'tester': {\n              'channel': 'stable',\n              'version': 42\n          }\n        }),\n        'intro_tables.json': json.dumps({\n          'tester': {\n            'Permissions': [\n            {\n                'class': 'override',\n                'text': '\"tester\"'\n            }\n            {\n                'text': 'is an API for testing things.'\n            }\n            ],\n            'Learn More': [\n            {\n                'link': 'https://tester.test.com/welcome.html',\n                'text': 'Welcome!'\n            }\n            ]\n        }\n      })\n    }\n      'private': {\n        'intro_tables': {\n          'trunk_message.html': 'available on trunk'\n      }\n    }\n  }\n}\n}\n\nCANNED_API_FILE_SYSTEM_DATA = {\n  'trunk': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'contextMenus': {\n          'channel': 'stable'\n      }\n        'events': {\n          'channel': 'stable'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'history': {\n          'channel': 'beta'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'beta'\n      }\n        'sync': {\n          'channel': 'trunk'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'cookies': {\n          'channel': 'dev'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'falseBetaAPI': {\n          'channel': 'beta'\n      }\n        'trunkAPI': {\n          'channel': 'trunk'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n    'docs': {\n      'templates': {\n        'json': {\n          'api_availabilities.json': json.dumps({\n            'jsonAPI1': {\n              'channel': 'stable',\n              'version': 10\n          }\n            'jsonAPI2': {\n              'channel': 'trunk'\n          }\n            'jsonAPI3': {\n              'channel': 'dev'\n          }\n        }),\n          'intro_tables.json': json.dumps({\n            'test': [\n            {\n                'Permissions': 'probably none'\n            }\n            ]\n        })\n      }\n    }\n  }\n}\n  '1500': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'events': {\n          'channel': 'trunk'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n        'systemInfo.stuff': {\n          'channel': 'dev'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'contextMenus': {\n          'channel': 'trunk'\n      }\n        'notifications': {\n          'channel': 'beta'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'dev'\n      }\n        'sync': {\n          'channel': 'trunk'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'cookies': {\n          'channel': 'dev'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'downloads': {\n          'channel': 'beta'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1453': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'events': {\n          'channel': 'dev'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n        'systemInfo.cpu': {\n          'channel': 'stable'\n      }\n        'systemInfo.stuff': {\n          'channel': 'dev'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'notifications': {\n          'channel': 'dev'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'dev'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'context_menus': {\n          'channel': 'trunk'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'downloads': {\n          'channel': 'dev'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1410': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'events': {\n          'channel': 'beta'\n      }\n        'notifications': {\n          'channel': 'dev'\n      }\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'context_menus': {\n          'channel': 'trunk'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1364': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1312': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1271': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'system_info_display': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'beta'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'alarms.idl': 'alarms contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1229': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'beta'\n      }\n    }),\n      'alarms.idl': 'alarms contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'system_info_display.idl': 'systemInfo.display contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1180': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'bookmarks.json': 'bookmarks contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1132': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'trunk'\n      }\n        'page_action': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'bookmarks.json': 'bookmarks contents',\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1084': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'contents': 'nothing of interest here,really'\n    }),\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'pageAction.json': 'pageAction contents',\n      'tabs.json': 'tabs contents',\n      'webRequest.json': 'webRequest contents'\n  }\n}\n  '1025': {\n    'api': {\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'pageAction.json': 'pageAction contents',\n      'tabs.json': 'tabs contents',\n      'webRequest.json': 'webRequest contents'\n  }\n}\n  '963': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      {\n          'namespace': 'webRequest'\n      }\n      ])\n  }\n}\n  '912': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      {\n          'namespace': 'experimental.webRequest'\n      }\n      ])\n  }\n}\n  '874': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '835': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '782': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '742': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '696': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '648': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '597': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '552': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '544': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      ])\n  }\n}\n  '495': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      ])\n  }\n}\n  '396': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'experimental.menus'\n      }\n      ])\n  }\n}\n}\n" }
{ "repo_name": "ROMFactory/android_external_chromium_org", "ref": "refs/heads/kitkat", "path": "chrome/common/extensions/docs/server2/test_data/canned_data.py", "content": "# Copyright 2013 The Chromium Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\nimport json\n\nCANNED_CHANNELS = {\n  'trunk': 'trunk',\n  'dev': 28,\n  'beta': 27,\n  'stable': 26\n}\n\nCANNED_BRANCHES = {\n  'trunk': 'trunk',\n  28: 1500,\n  27: 1453,\n  26: 1410,\n  25: 1364,\n  24: 1312,\n  23: 1271,\n  22: 1229,\n  21: 1180,\n  20: 1132,\n  19: 1084,\n  18: 1025,\n  17: 963,\n  16: 912,\n  15: 874,\n  14: 835,\n  13: 782,\n  12: 742,\n  11: 696,\n  10: 648,\n   9: 597,\n   8: 552,\n   7: 544,\n   6: 495,\n   5: 396\n}\n\nCANNED_TEST_FILE_SYSTEM_DATA = {\n  'api': {\n    '_api_features.json': json.dumps({\n      'ref_test': { 'dependencies': ['permission:ref_test'] }\n      'tester': { 'dependencies': ['permission:tester', 'manifest:tester'] }\n  }),\n    '_manifest_features.json': json.dumps({\n      'manifest': 'features'\n  }),\n    '_permission_features.json': json.dumps({\n      'permission': 'features'\n  })\n}\n  'docs': {\n    'templates': {\n      'intros': {\n        'test.html': '<h1>hi</h1>you<h2>first</h2><h3>inner</h3><h2>second</h2>'\n    }\n      'json': {\n        'api_availabilities.json': json.dumps({\n          'tester': {\n              'channel': 'stable',\n              'version': 42\n          }\n        }),\n        'intro_tables.json': json.dumps({\n          'tester': {\n            'Permissions': [\n            {\n                'class': 'override',\n                'text': '\"tester\"'\n            }\n            {\n                'text': 'is an API for testing things.'\n            }\n            ],\n            'Learn More': [\n            {\n                'link': 'https://tester.test.com/welcome.html',\n                'text': 'Welcome!'\n            }\n            ]\n        }\n      })\n    }\n      'private': {\n        'intro_tables': {\n          'trunk_message.html': 'available on trunk'\n      }\n    }\n  }\n}\n}\n\nCANNED_API_FILE_SYSTEM_DATA = {\n  'trunk': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'contextMenus': {\n          'channel': 'stable'\n      }\n        'events': {\n          'channel': 'stable'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'history': {\n          'channel': 'beta'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'beta'\n      }\n        'sync': {\n          'channel': 'trunk'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'cookies': {\n          'channel': 'dev'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'falseBetaAPI': {\n          'channel': 'beta'\n      }\n        'trunkAPI': {\n          'channel': 'trunk'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n    'docs': {\n      'templates': {\n        'json': {\n          'api_availabilities.json': json.dumps({\n            'jsonAPI1': {\n              'channel': 'stable',\n              'version': 10\n          }\n            'jsonAPI2': {\n              'channel': 'trunk'\n          }\n            'jsonAPI3': {\n              'channel': 'dev'\n          }\n        }),\n          'intro_tables.json': json.dumps({\n            'test': [\n            {\n                'Permissions': 'probably none'\n            }\n            ]\n        })\n      }\n    }\n  }\n}\n  '1500': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'events': {\n          'channel': 'trunk'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n        'systemInfo.stuff': {\n          'channel': 'dev'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'contextMenus': {\n          'channel': 'trunk'\n      }\n        'notifications': {\n          'channel': 'beta'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'dev'\n      }\n        'sync': {\n          'channel': 'trunk'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'cookies': {\n          'channel': 'dev'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'downloads': {\n          'channel': 'beta'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1453': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'events': {\n          'channel': 'dev'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n        'systemInfo.cpu': {\n          'channel': 'stable'\n      }\n        'systemInfo.stuff': {\n          'channel': 'dev'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'notifications': {\n          'channel': 'dev'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'dev'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'context_menus': {\n          'channel': 'trunk'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'downloads': {\n          'channel': 'dev'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1410': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'events': {\n          'channel': 'beta'\n      }\n        'notifications': {\n          'channel': 'dev'\n      }\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'context_menus': {\n          'channel': 'trunk'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1364': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1312': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1271': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'system_info_display': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'beta'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'alarms.idl': 'alarms contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1229': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'beta'\n      }\n    }),\n      'alarms.idl': 'alarms contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'system_info_display.idl': 'systemInfo.display contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1180': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'bookmarks.json': 'bookmarks contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1132': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'trunk'\n      }\n        'page_action': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'bookmarks.json': 'bookmarks contents',\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1084': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'contents': 'nothing of interest here,really'\n    }),\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'pageAction.json': 'pageAction contents',\n      'tabs.json': 'tabs contents',\n      'webRequest.json': 'webRequest contents'\n  }\n}\n  '1025': {\n    'api': {\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'pageAction.json': 'pageAction contents',\n      'tabs.json': 'tabs contents',\n      'webRequest.json': 'webRequest contents'\n  }\n}\n  '963': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      {\n          'namespace': 'webRequest'\n      }\n      ])\n  }\n}\n  '912': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      {\n          'namespace': 'experimental.webRequest'\n      }\n      ])\n  }\n}\n  '874': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '835': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '782': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '742': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '696': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '648': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '597': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '552': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '544': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      ])\n  }\n}\n  '495': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      ])\n  }\n}\n  '396': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'experimental.menus'\n      }\n      ])\n  }\n}\n}\n" }
{ "repo_name": "MIPS/external-chromium_org", "ref": "refs/heads/dev-mips-jb-kitkat", "path": "chrome/common/extensions/docs/server2/test_data/canned_data.py", "content": "# Copyright 2013 The Chromium Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\nimport json\n\nCANNED_CHANNELS = {\n  'trunk': 'trunk',\n  'dev': 28,\n  'beta': 27,\n  'stable': 26\n}\n\nCANNED_BRANCHES = {\n  'trunk': 'trunk',\n  28: 1500,\n  27: 1453,\n  26: 1410,\n  25: 1364,\n  24: 1312,\n  23: 1271,\n  22: 1229,\n  21: 1180,\n  20: 1132,\n  19: 1084,\n  18: 1025,\n  17: 963,\n  16: 912,\n  15: 874,\n  14: 835,\n  13: 782,\n  12: 742,\n  11: 696,\n  10: 648,\n   9: 597,\n   8: 552,\n   7: 544,\n   6: 495,\n   5: 396\n}\n\nCANNED_TEST_FILE_SYSTEM_DATA = {\n  'api': {\n    '_api_features.json': json.dumps({\n      'ref_test': { 'dependencies': ['permission:ref_test'] }\n      'tester': { 'dependencies': ['permission:tester', 'manifest:tester'] }\n  }),\n    '_manifest_features.json': json.dumps({\n      'manifest': 'features'\n  }),\n    '_permission_features.json': json.dumps({\n      'permission': 'features'\n  })\n}\n  'docs': {\n    'templates': {\n      'intros': {\n        'test.html': '<h1>hi</h1>you<h2>first</h2><h3>inner</h3><h2>second</h2>'\n    }\n      'json': {\n        'api_availabilities.json': json.dumps({\n          'tester': {\n              'channel': 'stable',\n              'version': 42\n          }\n        }),\n        'intro_tables.json': json.dumps({\n          'tester': {\n            'Permissions': [\n            {\n                'class': 'override',\n                'text': '\"tester\"'\n            }\n            {\n                'text': 'is an API for testing things.'\n            }\n            ],\n            'Learn More': [\n            {\n                'link': 'https://tester.test.com/welcome.html',\n                'text': 'Welcome!'\n            }\n            ]\n        }\n      })\n    }\n      'private': {\n        'intro_tables': {\n          'trunk_message.html': 'available on trunk'\n      }\n    }\n  }\n}\n}\n\nCANNED_API_FILE_SYSTEM_DATA = {\n  'trunk': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'contextMenus': {\n          'channel': 'stable'\n      }\n        'events': {\n          'channel': 'stable'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'history': {\n          'channel': 'beta'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'beta'\n      }\n        'sync': {\n          'channel': 'trunk'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'cookies': {\n          'channel': 'dev'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'falseBetaAPI': {\n          'channel': 'beta'\n      }\n        'trunkAPI': {\n          'channel': 'trunk'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n    'docs': {\n      'templates': {\n        'json': {\n          'api_availabilities.json': json.dumps({\n            'jsonAPI1': {\n              'channel': 'stable',\n              'version': 10\n          }\n            'jsonAPI2': {\n              'channel': 'trunk'\n          }\n            'jsonAPI3': {\n              'channel': 'dev'\n          }\n        }),\n          'intro_tables.json': json.dumps({\n            'test': [\n            {\n                'Permissions': 'probably none'\n            }\n            ]\n        })\n      }\n    }\n  }\n}\n  '1500': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'events': {\n          'channel': 'trunk'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n        'systemInfo.stuff': {\n          'channel': 'dev'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'contextMenus': {\n          'channel': 'trunk'\n      }\n        'notifications': {\n          'channel': 'beta'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'dev'\n      }\n        'sync': {\n          'channel': 'trunk'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'cookies': {\n          'channel': 'dev'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'downloads': {\n          'channel': 'beta'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1453': {\n    'api': {\n      '_api_features.json': json.dumps({\n        'events': {\n          'channel': 'dev'\n      }\n        'extension': {\n          'channel': 'stable'\n      }\n        'systemInfo.cpu': {\n          'channel': 'stable'\n      }\n        'systemInfo.stuff': {\n          'channel': 'dev'\n      }\n    }),\n      '_manifest_features.json': json.dumps({\n        'notifications': {\n          'channel': 'dev'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'storage': {\n          'channel': 'dev'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'context_menus': {\n          'channel': 'trunk'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'downloads': {\n          'channel': 'dev'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1410': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'events': {\n          'channel': 'beta'\n      }\n        'notifications': {\n          'channel': 'dev'\n      }\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bluetooth': {\n          'channel': 'dev'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'context_menus': {\n          'channel': 'trunk'\n      }\n        'declarativeContent': {\n          'channel': 'trunk'\n      }\n        'declarativeWebRequest': [\n        { 'channel': 'beta' }\n          # whitelist\n        { 'channel': 'stable'}\n        ],\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1364': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1312': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'stable'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'stable'\n      }\n    }),\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1271': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'system_info_display': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'alarms': {\n          'channel': 'beta'\n      }\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'alarms.idl': 'alarms contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents',\n      'windows.json': 'windows contents'\n  }\n}\n  '1229': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n        'web_request': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'systemInfo.display': {\n          'channel': 'beta'\n      }\n    }),\n      'alarms.idl': 'alarms contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'system_info_display.idl': 'systemInfo.display contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1180': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'page_action': {\n          'channel': 'stable'\n      }\n        'runtime': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'stable'\n      }\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'bookmarks.json': 'bookmarks contents',\n      'idle.json': 'idle contents',\n      'input_ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1132': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'bookmarks': {\n          'channel': 'trunk'\n      }\n        'page_action': {\n          'channel': 'stable'\n      }\n    }),\n      '_permission_features.json': json.dumps({\n        'webRequest': {\n          'channel': 'stable'\n      }\n    }),\n      'bookmarks.json': 'bookmarks contents',\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'tabs.json': 'tabs contents'\n  }\n}\n  '1084': {\n    'api': {\n      '_manifest_features.json': json.dumps({\n        'contents': 'nothing of interest here,really'\n    }),\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'pageAction.json': 'pageAction contents',\n      'tabs.json': 'tabs contents',\n      'webRequest.json': 'webRequest contents'\n  }\n}\n  '1025': {\n    'api': {\n      'idle.json': 'idle contents',\n      'input.ime.json': 'input.ime contents',\n      'menus.json': 'menus contents',\n      'pageAction.json': 'pageAction contents',\n      'tabs.json': 'tabs contents',\n      'webRequest.json': 'webRequest contents'\n  }\n}\n  '963': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      {\n          'namespace': 'webRequest'\n      }\n      ])\n  }\n}\n  '912': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      {\n          'namespace': 'experimental.webRequest'\n      }\n      ])\n  }\n}\n  '874': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '835': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '782': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '742': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '696': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '648': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '597': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '552': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      {\n          'namespace': 'pageAction'\n      }\n      ])\n  }\n}\n  '544': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      ])\n  }\n}\n  '495': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'menus'\n      }\n      ])\n  }\n}\n  '396': {\n    'api': {\n      'extension_api.json': json.dumps([\n      {\n          'namespace': 'idle'\n      }\n      {\n          'namespace': 'experimental.menus'\n      }\n      ])\n  }\n}\n}\n" }